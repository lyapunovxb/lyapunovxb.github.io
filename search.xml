<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Git1_git命令</title>
    <url>/2025/11/04/Git/Git1_git%20%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[git commmit -v和git push origin develop之后，我怎么撤销本次commit提交的代码，将origin develop的仓库返回值提交之前的状态？
在Git中，如果你想要撤销最近的一次提交并将仓库状态回退到提交之前，你可以使用git reset命令。这里有几种方法可以撤销提交：

使用git reset --soft：
这个命令会将HEAD指针移动到指定的提交，但是不会改变工作目录和索引的状态。这意味着你的更改仍然在暂存区（staged），你可以重新提交。
命令：git reset --soft HEAD~1（将HEAD指针回退到上一个提交）


使用git reset --mixed（默认选项）：
这个命令会将HEAD指针移动到指定的提交，并且将索引（staged changes）重置到HEAD的状态，但是不会改变工作目录。
命令：git reset --mixed HEAD~1（将HEAD和索引回退到上一个提交，但工作目录不变）


使用git reset --hard：
这个命令会将HEAD指针、索引和工作目录都重置到指定的提交状态。这意味着所有未提交的更改都会丢失。
命令：git reset --hard HEAD~1（将HEAD、索引和工作目录都回退到上一个提交）



如果你已经将代码推送到了远程仓库（比如origin develop），并且想要撤销这次推送，你可以使用git push命令配合--force选项来强制推送本地的更改到远程仓库。但是请注意，这会覆盖远程仓库的历史，所以只有在你确定远程仓库没有其他人的提交或者你不介意丢失这些提交时才应该使用。
命令如下：
git push origin develop --force

或者，如果你使用的是Git 2.0或更高版本，可以使用更安全的--force-with-lease选项，它会在远程分支没有新的提交时才允许强制推送。
命令如下：
git push origin develop --force-with-lease

警告：使用--force选项会覆盖远程仓库的历史，这是一个破坏性的操作。在团队协作的环境中，这可能会导致其他协作者的工作丢失，所以请谨慎使用。
]]></content>
      <categories>
        <category>开发</category>
      </categories>
      <tags>
        <tag>开发</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>Git2_gerrit仓库代码提交流程</title>
    <url>/2025/11/04/Git/Git2_gerrit%E4%BB%93%E5%BA%93%E4%BB%A3%E7%A0%81%E6%8F%90%E4%BA%A4%E6%B5%81%E7%A8%8B/</url>
    <content><![CDATA[
生成个人密钥ssh-keygen -C wangxiangbo_JTAGI@cmss.chinamobile.com
修改config文件，增加gerrit仓库配置，增加刚生成的个人密钥id_ed25519host gerritport 29418hostname gerrit.cmss.comuser wangxiangbo_JTAGIIdentityFile ~/.ssh/id_ed25519
在gerrit中setting设置中，增加ssh的公钥，即id_ed25519.pub
设置邮箱，邮箱名wangxiangbo@cmss.chinamobile.com为不带JTAGI后缀的邮箱。
用ssh clone代码仓库git clone &quot;ssh://wangxiangbo_JTAGI@gerrit.cmss.com:29418/AGI/CM_OPTIMUS&quot; &amp;&amp; scp -p -P 29418 wangxiangbo_JTAGI@gerrit.cmss.com:hooks/commit-msg &quot;CM_OPTIMUS/.git/hooks/&quot;
查看分支git branch -a
查看远端分支git branch -r
通过远端origin&#x2F;develop仓库，创建一个本地develop开发分支git checkout -b develop origin/develop
修改代码后，add之后并commit提交git commit -v
推送远端origin&#x2F;develop仓库git push origin HEAD:refs/for/develop
在推送过程中会出现缺失 Change-Id 的错误gitdir=$(git rev-parse --git-dir); scp -p -P 29418 wangxiangbo_JTAGI@gerrit.cmss.com:hooks/commit-msg $&#123;gitdir&#125;/hooks/
执行完毕后如果出现subsystem request failed on channel 0，则将-p修改为-Ogitdir=$(git rev-parse --git-dir); scp -O -P 29418 wangxiangbo_JTAGI@gerrit.cmss.com:hooks/commit-msg $&#123;gitdir&#125;/hooks/
将本次commit提交的末尾加上Change-Id git commit --amend --no-edit
再次pushgit push origin HEAD:refs/for/develop
提交完成之后，打开gerrit，找到develop分支的gitweb
选择review
找到刚刚提交的代码
点击add reviewer，评审人要最少要两个以上
第一次之后提交代码步骤git pull origingit add xxxgit commit -v git push origin HEAD:refs/for/develop

]]></content>
      <categories>
        <category>开发</category>
      </categories>
      <tags>
        <tag>开发</tag>
        <tag>gerrit</tag>
      </tags>
  </entry>
  <entry>
    <title>Git3_gitlab仓库代码提交流程</title>
    <url>/2025/11/04/Git/Git3_gitlab%E4%BB%93%E5%BA%93%E4%BB%A3%E7%A0%81%E6%8F%90%E4%BA%A4%E6%B5%81%E7%A8%8B/</url>
    <content><![CDATA[
gitlab上fork主仓库，生成个人的远端仓库origin&#x2F;develop
修改git提交用户配置为九天账号git config --global --listgit config --global user.name wangxiangbo_JTAGIgit config --global user.email wangxiangbo_JTAGI@cmss.chinamobile.com
拉取个人的远端仓库git clone http://gitlab.cmss.com/wangxiangbo/CM_OPTIMUS.git 
查看分支git branch -a
查看远程仓库分支git branch -r
通过个人的远端origin&#x2F;develop仓库，创建一个本地develop开发分支git checkout -b develop origin/develop
列出所有的远程仓库以及对应的 URLgit remote -v
将远程仓库地址添加到本地Git仓库的远程仓库列表中，本地的upstream&#x2F;develop仓库会和gitlab远程仓库关联起来git remote add upstream http://gitlab.cmss.com/AGI/CM_OPTIMUS.git
upstream&#x2F;develop远端仓库拉取最新的代码git fetch upstream
将upstream&#x2F;develop远端仓库的最新代码合并到本地的develop分支中git merge upstream/develop
将本地develop最新的代码推到个人的远端仓库origin&#x2F;develop中git push origin develop
提交develop到origin&#x2F;develop代码之前，保证自己的本地个人的远端仓库origin&#x2F;develop和本地gitlab的远端仓库upstream&#x2F;develop保持一致再提交，防止后续origin&#x2F;develop合并打upstream&#x2F;develop上出现冲突。#本地代码修改后拉取最新代码#1.拉取源代码git fetch upstream #2.暂存本地修改的代码git stash#3.合并源代码到当前的develop仓库git merge upstream/develop#4.将本地修改的推送到远程的origin分支，使origin/develop和upstream/develop保持一致git push origin develop#5.将暂存的代码弹出来git stash pop
souretree上add需要提交的代码
提交add之后的代码git commit -v
#修改下方的提交信息，第一行为提交描述信息deepseek-7B预训练Code Source From: Self CodeDescription: deepseek-7B预训练Jira: #CMOPTIMUS-1089市场项目编号（名称）：CM_OPTIMUS
将提交完之后的代码合并到origin&#x2F;develop上git push origin develop
gitlab中找的到自己仓库下CM_OPTIMUS
找到Merge requests，然后点击开始一个合并
然后选择自己的分支为develop，还有旁边的分支develop，然后点击最下方的merge即可。该操作是将自己个人远端的orgin&#x2F;develop仓库提交修改后的代码合并到gitlab远端的主仓库中（upstream&#x2F;develop已和其关联，并通过git fetch保持最新）选中自己刚刚提交到origin&#x2F;develop上的代码，合并到AGI&#x2F;CM_OPTIMUS的develop分支上在Write里添加合并人信息

]]></content>
      <categories>
        <category>开发</category>
      </categories>
      <tags>
        <tag>开发</tag>
        <tag>gitlab</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux1_kimi问题</title>
    <url>/2025/11/04/Linux/Linux1_kimi%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[
权重转换代码换行符Kimi: 出现这些错误通常是因为脚本文件在不同的操作系统环境下被编辑或创建，导致文件的换行符不一致。Unix&#x2F;Linux系统使用LF（Line Feed，\n）作为换行符，而Windows系统使用CR+LF（Carriage Return + Line Feed，\r\n）作为换行符。错误信息中的 $&#39;\r&#39;: command not found 表示脚本尝试执行一个以 \r 开头的命令，这通常是因为脚本文件中的换行符是 \r\n 而不是 \n。此外，syntax error near unexpected token &#39;elif&#39; 错误表明脚本解析器在遇到 elif 时遇到了语法错误，这可能是因为 elif 之前的行（可能是第59行）以 \r\n 结尾，导致 elif 行实际上是从一个新的行开始，而不是在预期的位置。要解决这个问题，你可以使用 dos2unix 工具将脚本文件从Windows格式转换为Unix&#x2F;Linux格式。如果你没有 dos2unix 工具，可以使用 sed 命令来移除 \r 字符：sed -i &#x27;s/\r$//&#x27; hf2mcore_convertor.sh
这条命令会查找文件中的所有行，并移除每行末尾的 \r 字符。如果你有 dos2unix 工具，可以使用以下命令：dos2unix hf2mcore_convertor.sh
这将把文件从Windows格式转换为Unix&#x2F;Linux格式。在运行这些命令之后，再次执行脚本应该就不会出现这些错误了。
修改文件遇到Read-only file systemKimi: 当你遇到 “Read-only file system” 错误时，通常意味着你的文件系统出于某种原因被挂载为只读模式。这可能是由于文件系统损坏、磁盘硬件问题、或者挂载时指定了错误的参数。以下是一些解决步骤：
检查文件系统挂载状态：使用 mount 命令查看所有挂载的文件系统及其状态。你可以使用如下命令：mount | grep /path/to/mount/point
查看挂载点是否为只读（ro）。
重新挂载文件系统为读写模式：如果文件系统被挂载为只读，你可以尝试重新挂载它为读写模式。使用以下命令：sudo mount -o remount,rw /path/to/mount/point
请将 /path/to/mount/point 替换为实际的挂载点路径。
检查和修复文件系统：如果重新挂载不起作用，可能是文件系统损坏。你可以使用 fsck 命令来检查和修复文件系统。例如，对于 ext4 文件系统，可以使用：sudo fsck -f /dev/sda1
请确保替换 /dev/sda1 为你的实际分区。

]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>运维</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux2_Linux命令</title>
    <url>/2025/11/04/Linux/Linux2_linux%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[
当执行训练任务时，手动关闭训练，此时gup资源仍然占用，需要手动kill掉进程查询正在运行的进程并gerp finetune_lora_single_gpu.shps aux | grep finetune_lora_single_gpu.shps aux | grep finetune_lora_ds.shkill -9 372813 根据上一步查出来的进程号，用kill -9强制删除nvidia-smi 查看是否gpu显存已经清空
查看某个文件的前20行head -n 20 train_data_law.json
查看当前文件夹的大小du -sh .
查看当前文件夹挂载的是哪一个盘df -h .从大到小查看当前文件夹的下的文件大小du -sh * | sort -rh
查看当前文件下所有文件的大小ls -lh
把一个名为Yuan2的文件夹的所有内容（包括该文件夹名），cp到&#x2F;mnt&#x2F;users&#x2F;wangxiangbo&#x2F;nemo&#x2F;model目录下，使最后的目录为 &#x2F;mnt&#x2F;users&#x2F;wangxiangbo&#x2F;nemo&#x2F;model&#x2F;Yuan2cp -a Yuan2 /mnt/users/wangxiangbo/nemo/model/
通过pid查看某个进程的详细信息&lt;font style=&quot;color:rgb(56, 58, 66);background-color:rgb(250, 250, 250);&quot;&gt;ps -fp 167891&lt;/font&gt;
查看当前目录下所有文件的磁盘占用情况du -ah | sort -hr | head -n 20
使用以下命令将megatron-core文件夹压缩成一个名为megatron-core.zip的zip文件 zip -r megatron-core.zip megatron-core 
使用以下命令将megatron-core.zip解压缩unzip megatron-core.zip 
hg上面下载模型pip install -U huggingface_hubhuggingface-cli download bigscience/bloom-560m --local-dir bloom-560mhuggingface-cli download Qwen/Qwen2-7B-Instruct --local-dir Qwen2-7B-Instructhuggingface-cli download Qwen/Qwen2.5-7B-Instruct --local-dir Qwen2.5-7B-Instructhuggingface-cli download BAAI/IndustryCorpus_computer --repo-type dataset --local-dir IndustryCorpus_computerhuggingface-cli download BAAI/IndustryCorpus2_current_affairs_government_administration --repo-type dataset --local-dir government_administrationhuggingface-cli download ShengbinYue/DISC-Law-SFT --repo-type dataset --local-dir DISC-Law-SFThuggingface-cli download TigerResearch/sft_zh
归档压缩文件#-c：创建一个新的压缩文件。#-z：通过 gzip 压缩文件。#-v：显示详细的压缩过程。#-f：指定压缩后的文件名，这里是 colossalai.tar.gztar -czvf colossalai.tar.gz colossalai/  #-x：表示解压。#-z：表示解压 .gz 格式的文件。#-v：显示解压过程。#-f：指定解压的文件tar -xzvf file.tar.gz

]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>运维</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>前端1_调用api接口的写法</title>
    <url>/2025/11/06/%E5%89%8D%E7%AB%AF/%E5%89%8D%E7%AB%AF1_%E8%B0%83%E7%94%A8api%E6%8E%A5%E5%8F%A3%E7%9A%84%E5%86%99%E6%B3%95/</url>
    <content><![CDATA[Get请求写法1. 看Parameters中是否有需要带参数，其中Authorization为授权认证的token可以不用考虑。1.1 若是没有其余的参数限定，那么SyncRequestFuncType&lt;请求参数类型,响应返回参数类型&gt;，第一个参数就为void或者undefined。返回类型可以使用any，等获取到响应参数之后，在对其通过Interface&#x2F;type进行明确。
export const getApi: SyncRequestFuncType&lt;void,responseType&gt; = () =&gt; &#123;return javaAxios(&#123; method: &quot;get&quot;, url: &quot;xxx/xxxx&quot;,&#125;);&#125;;

1.2 若是有其余参数限定，这时需要箭头函数中需要带着params来进行请求，且reuturn中也需要将params带着。
1.2.1 `单个参数`，例如id，这时在请求参数类型中，需要明确出请求参数的类型&lt;&#123;id:string&#125;,responseType&gt;，这时请求参数的类型为对象&#123;&#125;的形式，可以直接在尖括号中写出来，也可以通过引入定义的Interface/type类型来写&lt;IdType,responseType&gt;。

export const getApi: SyncRequestFuncType&lt; &#123;id:string&#125;, void&gt; = (params) =&gt; &#123;return javaAxios(&#123; method: &quot;get&quot;, url: &quot;xxx/xxxx&quot;, params,&#125;);&#125;;

1.2.2 `多个参数`，例如email，type...，因为参数比较多，最好通过Interface/type的方式SendEmailCaptchaForUserInfoModifyType来明确请求参数类型。

export type SendEmailCaptchaForUserInfoModifyType = &#123;type: ModifyType;email?: string;&#125;;

export const getApi: SyncRequestFuncType&lt;SendEmailCaptchaForUserInfoModifyType,void&gt; = (params) =&gt; &#123;return javaAxios(&#123; method: &quot;get&quot;, url: &quot;xxx/xxx&quot;, params,&#125;);&#125;;

Post请求写法1. 看看Parameters中是否有需要带参数，其中Authorization为授权认证的token可以不用考虑。1.1 若是没有其余的参数限定，那么SyncRequestFuncType&lt;请求参数类型,响应返回参数类型&gt;，第一个参数就为void或者undefined。返回类型可以使用any，等获取到响应参数之后，在对其通过Interface&#x2F;type进行明确。
export const clearVideoRecycle: SyncRequestFuncType&lt;void, void&gt; = () =&gt; &#123;return javaAxios(&#123; method: &quot;post&quot;, url: &quot;xxx/xxx&quot;,&#125;);&#125;;

1.2 若是有其余参数限定，这时需要箭头函数中需要带着params来进行请求，且reuturn中也需要将params带着。
1.2.1 单个参数时

export const cancelSubscribeVideo: SyncRequestFuncType&lt;&#123; themeId: string &#125;,any&gt; = (params) =&gt; &#123;return javaAxios(&#123; method: &quot;post&quot;, url: &quot;xxx/xxx&quot;, params,&#125;);&#125;;

1.2.2 多个参数时

export type SendEmailCaptchaForUserInfoModifyType = &#123;type: ModifyType;email?: string;&#125;;

export const sendEmailCaptchaForUserInfoModify: SyncRequestFuncType&lt;SendEmailCaptchaForUserInfoModifyType,void&gt; = (params) =&gt; &#123;return javaAxios(&#123; method: &quot;get&quot;, url: &quot;xxx/xxx&quot;, params,&#125;);&#125;;

2. 当出现请求体Request body时，这时就需要在return的javaAxios中添加键值对data: params，来将参数添加到请求体中传递过去。2.1 Request body为：
[&quot;string&quot;]

export const batchDeleteVideo: SyncRequestFuncType&lt;string[], void&gt; = (params) =&gt; &#123;return javaAxios(&#123; method: &quot;post&quot;, url: &quot;videos/themes/batchDel&quot;, data: params,&#125;);&#125;;

2.2 Request body为：这时候需要在data中进一步在约束一下，使其对应api的请求体的格式。
&#123;&quot;themes&quot;: [ &quot;string&quot;]&#125;

export const sortVideos: SyncRequestFuncType&lt;string[], void&gt; = (params) =&gt; &#123;return javaAxios(&#123; method: &quot;post&quot;, url: &quot;videos/themes/changeVideoThemesSort&quot;, data: &#123; themes: params &#125;,&#125;);&#125;;

]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>前端</tag>
        <tag>Javascript</tag>
      </tags>
  </entry>
  <entry>
    <title>运维2_k8s命令</title>
    <url>/2025/11/04/%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%90%E7%BB%B4/%E8%BF%90%E7%BB%B42_k8s%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[
获取特定命名空间的详细信息kubectl get ns namespace-name -o wide
kubectl通过ns获取所有的pods的详细信息kubectl get pods -n &lt;ns_name&gt; -o wide
删除启动失败的pod，可以直接删除启动时的yaml，否则pod会自动重启kubectl delete -f qwentest.yaml
查看所有的node的lable标签信息kubectl get node --show-labelskubectl get node xxx --show-labelskubectl get node --show-labels | grep model
打标签kubectl label nodes ecs-jhjs-1234-003 key=vaule
删除某节点的lable标签kubectl label nodes cce100-64-29-79.cce-stack.com model-
创建一个命名空间namespacekubectl create namespace xxx
查看所有节点的标签kubectl get nodes --show-labelskubectl get nodes --show-labels | grep model=llama2-70b

]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>运维</tag>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title>测试 Hexo 标签分类2</title>
    <url>/2025/10/31/%E9%A1%B5%E9%9D%A2%E6%B5%8B%E8%AF%95/test%20copy/</url>
    <content><![CDATA[这是文章正文。
]]></content>
      <categories>
        <category>测试</category>
      </categories>
      <tags>
        <tag>测试2</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>运维1_docker命令</title>
    <url>/2025/11/04/%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%90%E7%BB%B4/%E8%BF%90%E7%BB%B41_docker%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[
启动一个容器
sudo docker run -it --name qwen --gpus all nvidia/cuda:12.2.2-cudnn8-devel-ubuntu22.04
启动一个容器后，又通过exit关闭。发现docker ps没有了，该如何重新启动这个qwen容器？
docker ps -adocker start qwendocker exec -it 容器id bash

拉取一个新镜像后，通过这个镜像创建一个容器。
docker run -it --name qwen --gpus all 镜像名:镜像tags bash

将此时qwen容器打成镜像
docker commit -a &quot;wangxiangbo&quot; -m &quot;qwen 7B&quot; 02649afd9710 qwen-7b:v1.0

]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>运维</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>2-Qwen模型镜像制作</title>
    <url>/2025/11/06/%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E8%B0%83%E4%BC%98/NVIDIA/Qwen/2-Qwen%E6%A8%A1%E5%9E%8B%E9%95%9C%E5%83%8F%E5%88%B6%E4%BD%9C/</url>
    <content><![CDATA[由于新机器挂载文件存储速度非常慢，通过dockerfile文件来直接生成镜像非常慢，所以本镜像在自己的V100云主机中进行打包。
1. 首先docker pull拉取一个ubuntu基础环境https://hub.docker.com/r/nvidia/cuda/tags?page=11&page_size&#x3D;&amp;name&#x3D;&amp;ordering&#x3D;docker pull nvidia/cuda:12.2.2-cudnn8-devel-ubuntu22.04
2. 安装nvidia-container-toolkit，使docker可以调用宿主机gpu资源2.1 下载nvidia-container-toolkit distribution=$(. /etc/os-release;echo $ID$VERSION_ID) &amp;&amp; \ curl -fsSL [https://nvidia.github.io/libnvidia-container/gpgkey](https://nvidia.github.io/libnvidia-container/gpgkey) | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg &amp;&amp; \ curl -s -L [https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list](https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list) | sed &#39;s#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g&#39; | sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
2.2 安装nvidia-container-toolkit  sudo apt-get update &amp;&amp; sudo apt-get install -y nvidia-container-toolkit
2.3 添加nvidia-docker源  curl -s -L [https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list](https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list) |   sudo tee /etc/apt/sources.list.d/nvidia-docker.list
2.4 更新并重新执行安装  sudo apt-get update &amp;&amp; sudo apt-get install -y nvidia-container-toolkit如果执行过程中报W: GPG error: https://nvidia.github.io/libnvidia-container/stable/ubuntu18.04/amd64  InRelease: The following signatures couldn’t be verified because the public key is not available: NO_PUBKEY DDCAE044F796ECB0，则需要确认你的系统是否信任NVIDIA的GPG密钥。如果没有，你需要导入它。可以通过以下命令导入GPG密钥：curl -s [https://nvidia.github.io/libnvidia-container/gpgkey](https://nvidia.github.io/libnvidia-container/gpgkey) | sudo apt-key add -
2.5 完成 nvidia-container-toolkit 的安装之后，我们继续执行 nvidia-ctk runtime configure 命令，为 Docker 添加 nvidia 这个运行时。完成后，我们的应用就能在容器中使用显卡资源了  sudo nvidia-ctk runtime configure --runtime=docker
  
2.6 重启docker  sudo systemctl restart docker
2.7 查看是否安装成功  dpkg -l | grep nvidia-container-toolkit
  
3. 拉取基础镜像成功后，创建一个docker容器docker imagessudo docker run -it --name qwen --gpus all nvidia/cuda:12.2.2-cudnn8-devel-ubuntu22.04exit
4. 退出容器后，将本地跑同的qwen模型代码&#x2F;权重&#x2F;数据集&#x2F;环境cp到创建的qwen镜像中docker cp /opt/tmp/Qwen/ 02649afd9710:/qwen
5. 重启docker，exec执行docker ps -adocker start qwendocker exec -it 02649afd9710 bash
6. 因为想在容器中执行自身的python环境，不借用宿主机的环境，所以需要单独再安装conda、pytorch等环境。7. 安装完基础环境后，需要安装qwen模型的依赖pip install -r requirements.txt
8. 没有vim编辑器还需安装vimapt-get updateapt-get install -y vim
9. deepspeed安装pip install &quot;peft&lt;0.8.0&quot; deepspeed
10. 此时在qwen容器中执行训练脚本，拉起训练。bash finetune/finetune_lora_single_gpu.sh
11. 将此时qwen容器打成镜像docker commit -a &quot;wangxiangbo&quot; -m &quot;qwen 7B&quot; 02649afd9710 qwen-7b:v1.0
12. 将打好的镜像转成tar包，供新机器解压使用docker save -o qwen-7b.tar qwen-7b:v1.0
13. 加载tar镜像, 使用load进行从tar文件导出镜像docker load -i qwen-7b.tar
14. 由于新机器挂载文件存储的原因，镜像解压速度太慢，于是打算将打好的qwen镜像push到阿里云个人仓库中，在新机器中直接pull该镜像。15. 将镜像推送到Registrydocker login --username=aliyun9599911612 registry.cn-shanghai.aliyuncs.comdocker tag 37c7b97b67f6 registry.cn-shanghai.aliyuncs.com/aliyun_repository_wxb/repository_wxb:v1.0docker push registry.cn-shanghai.aliyuncs.com/aliyun_repository_wxb/repository_wxb:v1.0
16. 在3号机器中，拉取该镜像docker pull registry.cn-shanghai.aliyuncs.com/aliyun_repository_wxb/repository_wxb:v1.0
17. 通过该镜像，run一个容器docker run -it --name qwen --gpus all registry.cn-shanghai.aliyuncs.com/aliyun_repository_wxb/repository_wxb:v1.0 bash
]]></content>
      <categories>
        <category>模型训练调优 -NVIDIA</category>
      </categories>
      <tags>
        <tag>模型训练调优</tag>
        <tag>Nvidia</tag>
        <tag>Qwen</tag>
      </tags>
  </entry>
  <entry>
    <title>1-Qwen模型本地部署与单机单卡/多卡训练</title>
    <url>/2025/11/06/%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E8%B0%83%E4%BC%98/NVIDIA/Qwen/1-Qwen%E6%A8%A1%E5%9E%8B%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%8D%95%E6%9C%BA%E5%8D%95%E5%8D%A1_%E5%A4%9A%E5%8D%A1%E8%AE%AD%E7%BB%83/</url>
    <content><![CDATA[一、V100环境部署

项目地址： https://github.com/QwenLM/Qwen

下载到本地git clone  https://github.com/QwenLM/Qwen.git 

基础环境搭建conda create -n qwen python=3.10conda activate qwen

安装pytorchconda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia

安装依赖环境pip install -r requirements.txt 

7B模型下载git clone [https://www.modelscope.cn/qwen/Qwen-7B-Chat.git](https://www.modelscope.cn/qwen/Qwen-7B-Chat.git)在使用sdk的python脚本下载权重时，需要pip安装modelscopepip install modelscope使用git clone发现权重未下载成功，使用modelscope官方sdk脚本下载。将以下代码写入download.py文件中，并执行python download.py
#模型下载from modelscope import snapshot_downloadmodel_dir = snapshot_download(&#x27;qwen/Qwen-7B-Chat&#x27;, cache_dir=&#x27;/opt/tmp/Qwen&#x27;, revision=&#x27;v1.1.9&#x27;)
数据集下载进入modelscope下载数据集https://modelscope.cn/datasets/Robin021/DISC-Law-SFT/files

数据格式处理数据集处理后会生成train_data_law.json文件head -n 20 train_data_law.json处理之后的数据格式如下：
import json# 读取以.jsonl结尾的文件json_data = []with open(&#x27;/opt/tmp/Qwen/dataset/DISC-Law-SFT-Triplet-released.jsonl&#x27;, &#x27;r&#x27;, encoding=&#x27;utf-8&#x27;) as file:    for line in file:        data = json.loads(line)        json_data.append(data)# 待填入的模板template = []# 遍历json数据集for idx, data in enumerate(json_data[:]):    conversation = [        &#123;            &quot;from&quot;:&quot;user&quot;,            &quot;value&quot;: data[&quot;input&quot;]        &#125;,        &#123;            &quot;from&quot;: &quot;assistant&quot;,            &quot;value&quot;: data[&quot;output&quot;]        &#125;    ]    template.append(&#123;        &quot;id&quot;: f&quot;identity_&#123;idx&#125;&quot;,        &quot;conversations&quot;: conversation    &#125;)print(len(template))# 输出填充数据后的模板print(json.dumps(template[2], ensure_ascii=False, indent=2))# 将template写入到本地文件output_file_path = &quot;/opt/tmp/Qwen/train_data_law.json&quot;with open(output_file_path, &#x27;w&#x27;, encoding=&#x27;utf-8&#x27;) as f:    json.dump(template, f, ensure_ascii=False, indent=2)print(f&quot;处理好的数据已写入到本地文件: &#123;output_file_path&#125;&quot;)
训练依赖安装deepspeed安装pip install &quot;peft&lt;0.8.0&quot; deepspeed

修改模型微调脚本参数修改MODEL和DATA的路径，及per_device_train_batch_size
#!/bin/bashexport CUDA_DEVICE_MAX_CONNECTIONS=1MODEL=&quot;/opt/tmp/Qwen/Qwen-7B-Chat&quot; # Set the path if you do not want to load from huggingface directly# ATTENTION: specify the path to your training data, which should be a json file consisting of a list of conversations.# See the section for finetuning in README for more information.DATA=&quot;/opt/tmp/Qwen/train_data_law.json&quot;function usage() &#123;    echo &#x27;Usage: bash finetune/finetune_lora_single_gpu.sh [-m MODEL_PATH] [-d DATA_PATH]&#x27;&#125;while [[ &quot;$1&quot; != &quot;&quot; ]]; do    case $1 in        -m | --model )            shift            MODEL=$1            ;;        -d | --data )            shift            DATA=$1            ;;        -h | --help )            usage            exit 0            ;;        * )            echo &quot;Unknown argument $&#123;1&#125;&quot;            exit 1            ;;    esac    shiftdoneexport CUDA_VISIBLE_DEVICES=0python finetune.py \  --model_name_or_path $MODEL \  --data_path $DATA \  --bf16 False \  --output_dir output_qwen \  --num_train_epochs 5 \  --per_device_train_batch_size 2 \  --per_device_eval_batch_size 1 \  --gradient_accumulation_steps 8 \  --evaluation_strategy &quot;no&quot; \  --save_strategy &quot;steps&quot; \  --save_steps 100 \  --save_total_limit 10 \  --learning_rate 3e-4 \  --weight_decay 0.1 \  --adam_beta2 0.95 \  --warmup_ratio 0.01 \  --lr_scheduler_type &quot;cosine&quot; \  --logging_steps 1 \  --report_to &quot;none&quot; \  --model_max_length 512 \  --lazy_preprocess True \  --gradient_checkpointing \  --use_lora# If you use fp16 instead of bf16, you should use deepspeed# --fp16 True --deepspeed finetune/ds_config_zero2.json

开启单机单卡训练bash finetune/finetune_lora_single_gpu.sh

单机多卡训练（在分配的3号机器上执行）gpu显存利用情况


]]></content>
      <categories>
        <category>模型训练调优 -NVIDIA</category>
      </categories>
      <tags>
        <tag>模型训练调优</tag>
        <tag>Nvidia</tag>
        <tag>Qwen</tag>
      </tags>
  </entry>
  <entry>
    <title>3-基于docker的Qwen单机单卡_多卡训练</title>
    <url>/2025/11/06/%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E8%B0%83%E4%BC%98/NVIDIA/Qwen/3-%E5%9F%BA%E4%BA%8Edocker%E7%9A%84Qwen%E5%8D%95%E6%9C%BA%E5%8D%95%E5%8D%A1_%E5%A4%9A%E5%8D%A1%E8%AE%AD%E7%BB%83/</url>
    <content><![CDATA[1. 查看容器docker ps
2. exec进入容器docker exec -it containerid bash
3. 进入qwen目录并修改finetune_lora_single_gpu.sh参数#!/bin/bashexport CUDA_DEVICE_MAX_CONNECTIONS=1MODEL=&quot;/qwen/Qwen-7B-Chat&quot; # Set the path if you do not want to load from huggingface directly# ATTENTION: specify the path to your training data, which should be a json file consisting of a list of conversations.# See the section for finetuning in README for more information.DATA=&quot;/qwen/train_data_law.json&quot;function usage() &#123;    echo &#x27;Usage: bash finetune/finetune_lora_single_gpu.sh [-m MODEL_PATH] [-d DATA_PATH]&#x27;&#125;while [[ &quot;$1&quot; != &quot;&quot; ]]; do    case $1 in        -m | --model )            shift            MODEL=$1            ;;        -d | --data )            shift            DATA=$1            ;;        -h | --help )            usage            exit 0            ;;        * )            echo &quot;Unknown argument $&#123;1&#125;&quot;            exit 1            ;;    esac    shiftdoneexport CUDA_VISIBLE_DEVICES=0python finetune.py \  --model_name_or_path $MODEL \  --data_path $DATA \  --bf16 True \  --output_dir output_qwen \  --num_train_epochs 5 \  --per_device_train_batch_size 1 \  --per_device_eval_batch_size 1 \  --gradient_accumulation_steps 8 \  --evaluation_strategy &quot;no&quot; \  --save_strategy &quot;steps&quot; \  --save_steps 100 \  --save_total_limit 10 \  --learning_rate 3e-4 \  --weight_decay 0.1 \  --adam_beta2 0.95 \  --warmup_ratio 0.01 \  --lr_scheduler_type &quot;cosine&quot; \  --logging_steps 1 \  --report_to &quot;none&quot; \  --model_max_length 512 \  --lazy_preprocess True \  --gradient_checkpointing \  --use_lora# If you use fp16 instead of bf16, you should use deepspeed# --fp16 True --deepspeed finetune/ds_config_zero2.json
4. 执行finetune_lora_single_gpu.sh单机单卡5. 修改finetune_lora_ds.sh参数#!/bin/bashexport CUDA_DEVICE_MAX_CONNECTIONS=1DIR=`pwd`# Guide:# This script supports distributed training on multi-gpu workers (as well as single-worker training).# Please set the options below according to the comments.# For multi-gpu workers training, these options should be manually set for each worker.# After setting the options, please run the script on each worker.# Number of GPUs per GPU workerGPUS_PER_NODE=$(python -c &#x27;import torch; print(torch.cuda.device_count())&#x27;)# Number of GPU workers, for single-worker training, please set to 1NNODES=$&#123;NNODES:-1&#125;# The rank of this worker, should be in &#123;0, ..., WORKER_CNT-1&#125;, for single-worker training, please set to 0NODE_RANK=$&#123;NODE_RANK:-0&#125;# The ip address of the rank-0 worker, for single-worker training, please set to localhostMASTER_ADDR=$&#123;MASTER_ADDR:-localhost&#125;# The port for communicationMASTER_PORT=$&#123;MASTER_PORT:-6001&#125;MODEL=&quot;/qwen/Qwen-7B-Chat&quot; # Set the path if you do not want to load from huggingface directly# ATTENTION: specify the path to your training data, which should be a json file consisting of a list of conversations.# See the section for finetuning in README for more information.DATA=&quot;/qwen/train_data_law.json&quot;DS_CONFIG_PATH=&quot;finetune/ds_config_zero2.json&quot;function usage() &#123;    echo &#x27;Usage: bash finetune/finetune_lora_ds.sh [-m MODEL_PATH] [-d DATA_PATH] [--deepspeed DS_CONFIG_PATH]&#x27;&#125;while [[ &quot;$1&quot; != &quot;&quot; ]]; do    case $1 in        -m | --model )            shift            MODEL=$1            ;;        -d | --data )            shift            DATA=$1            ;;        --deepspeed )            shift            DS_CONFIG_PATH=$1            ;;        -h | --help )            usage            exit 0            ;;        * )            echo &quot;Unknown argument $&#123;1&#125;&quot;            exit 1            ;;    esac    shiftdoneDISTRIBUTED_ARGS=&quot;    --nproc_per_node $GPUS_PER_NODE \    --nnodes $NNODES \    --node_rank $NODE_RANK \    --master_addr $MASTER_ADDR \    --master_port $MASTER_PORT&quot;#export CUDA_VISIBLE_DEVICES=2,3torchrun $DISTRIBUTED_ARGS finetune.py \    --model_name_or_path $MODEL \    --data_path $DATA \    --bf16 False \    --output_dir output_qwen \    --num_train_epochs 5 \    --per_device_train_batch_size 2 \    --per_device_eval_batch_size 1 \    --gradient_accumulation_steps 8 \    --evaluation_strategy &quot;no&quot; \    --save_strategy &quot;steps&quot; \    --save_steps 100 \    --save_total_limit 10 \    --learning_rate 3e-4 \    --weight_decay 0.1 \    --adam_beta2 0.95 \    --warmup_ratio 0.01 \    --lr_scheduler_type &quot;cosine&quot; \    --logging_steps 1 \    --report_to &quot;none&quot; \    --model_max_length 512 \    --lazy_preprocess True \    --use_lora \    --gradient_checkpointing \    --deepspeed $&#123;DS_CONFIG_PATH&#125;
6. 修改deepspeed中ds_config_zero2.json配置文件，增加TFlops显示其中具体增加的参数配置为flops_profiler
&quot;flops_profiler&quot;: &#123;        &quot;enabled&quot;: true,        &quot;profile_step&quot;: 1,        &quot;module_depth&quot;: -1,        &quot;top_modules&quot;: 1,        &quot;detailed&quot;: false,        &quot;output_file&quot;: null    &#125;,
&#123;    &quot;fp16&quot;: &#123;        &quot;enabled&quot;: &quot;auto&quot;,        &quot;loss_scale&quot;: 0,        &quot;loss_scale_window&quot;: 1000,        &quot;initial_scale_power&quot;: 16,        &quot;hysteresis&quot;: 2,        &quot;min_loss_scale&quot;: 1    &#125;,    &quot;bf16&quot;: &#123;        &quot;enabled&quot;: &quot;auto&quot;    &#125;,    &quot;optimizer&quot;: &#123;        &quot;type&quot;: &quot;AdamW&quot;,        &quot;params&quot;: &#123;            &quot;lr&quot;: &quot;auto&quot;,            &quot;betas&quot;: &quot;auto&quot;,            &quot;eps&quot;: &quot;auto&quot;,            &quot;weight_decay&quot;: &quot;auto&quot;        &#125;    &#125;,    &quot;scheduler&quot;: &#123;        &quot;type&quot;: &quot;WarmupLR&quot;,        &quot;params&quot;: &#123;            &quot;warmup_min_lr&quot;: &quot;auto&quot;,            &quot;warmup_max_lr&quot;: &quot;auto&quot;,            &quot;warmup_num_steps&quot;: &quot;auto&quot;        &#125;    &#125;,    &quot;zero_optimization&quot;: &#123;        &quot;stage&quot;: 2,        &quot;offload_optimizer&quot;: &#123;            &quot;device&quot;: &quot;none&quot;,            &quot;pin_memory&quot;: true        &#125;,        &quot;allgather_partitions&quot;: true,        &quot;allgather_bucket_size&quot;: 2e8,        &quot;overlap_comm&quot;: true,        &quot;reduce_scatter&quot;: true,        &quot;reduce_bucket_size&quot;: 2e8,        &quot;contiguous_gradients&quot;: true    &#125;,    &quot;flops_profiler&quot;: &#123;        &quot;enabled&quot;: true,        &quot;profile_step&quot;: 1,        &quot;module_depth&quot;: -1,        &quot;top_modules&quot;: 1,        &quot;detailed&quot;: false,        &quot;output_file&quot;: null    &#125;,    &quot;gradient_accumulation_steps&quot;: &quot;auto&quot;,    &quot;gradient_clipping&quot;: &quot;auto&quot;,    &quot;steps_per_print&quot;: 100,    &quot;train_batch_size&quot;: &quot;auto&quot;,    &quot;train_micro_batch_size_per_gpu&quot;: &quot;auto&quot;,    &quot;wall_clock_breakdown&quot;: false&#125;
7. 执行finetune_lora_ds.sh单机多卡训练其中报了Error while creating shared memory segment &#x2F;dev&#x2F;shm&#x2F;nccl-KXWrmA (size 9637888)导致在docker中单机多卡拉起失败问题原因：docker的shm共享内存不足，可以通过命令df -h | grep shm查看当前容器的shm大小，默认为64M，这是远远不够的，所以要增加该容器的shm共享内存大小。参考博文https://blog.csdn.net/gg864461719/article/details/112466585
解决方法1：创建完容器之后，手动修改shm共享内存大小a. 首先要关闭docker, 否则下面的操作步骤会无效.service docker stop
b. 进入宿主机中&#x2F;docker&#x2F;containers&#x2F;容器id 修改该容器的hostconfig.json文件，把其中的ShmSize的大小后面增加22（就变为了6.3G）其默认的是67108864_KB_ 就约等于64M。c. 重启docker服务systemctl start docker
d. 解决完之后，重新查看shm的共享内存大小，此时已经变为了6.3G解决方法2：在通过镜像run容器时，就直接指定–shm-size 6Gdocker run -it --name qwen --gpus all --shm-size 6G registry.cn-shanghai.aliyuncs.com/aliyun_repository_wxb/repository_wxb:v1.0 bash
重新拉起训练bash finetune/finetune_lora_ds.sh其中tflops在9.5~10.5之间
]]></content>
      <categories>
        <category>模型训练调优 -NVIDIA</category>
      </categories>
      <tags>
        <tag>模型训练调优</tag>
        <tag>Nvidia</tag>
        <tag>Qwen</tag>
      </tags>
  </entry>
  <entry>
    <title>4-基于k8s拉起Qwen模型的多机多卡微调</title>
    <url>/2025/11/06/%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E8%B0%83%E4%BC%98/NVIDIA/Qwen/4-%E5%9F%BA%E4%BA%8Ek8s%E6%8B%89%E8%B5%B7Qwen%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%A4%9A%E6%9C%BA%E5%A4%9A%E5%8D%A1%E5%BE%AE%E8%B0%83/</url>
    <content><![CDATA[一、镜像准备
1. 查看镜像docker images
2. 修改镜像标签docker tag ec99659d9677 registry.paas/library/qwen:v3.0
3. 将镜像推至仓库docker push registry.paas/library/qwen:v3.0
4. 如果出现签名认证失败，需要修改docker守护进程配置文件vim /etc/docker/daemon.json增加如下配置：
&#123;&quot;insecure-registries&quot;:[&quot;registry.paas&quot;]&#125;
重启dockersystemctl daemon-reload &amp;&amp; systemctl restart docker
5. 重新push至registry.paas&#x2F;library&#x2F;xxx:tags仓库二、修改配置文件
1. qwentest.yamlapiVersion: apps/v1kind: DaemonSetmetadata:  name: qwentestspec:  selector:    matchLabels:      app: qwentest  template:    metadata:      labels:        app: qwentest    spec:      hostNetwork: true      nodeSelector:        model: qwen-7b      containers:      - name: qwentest        image: registry.paas/library/qwen:v3.0        imagePullPolicy: IfNotPresent        resources:         limits:           nvidia.com/gpu: &quot;4&quot;         requests:           nvidia.com/gpu: &quot;4&quot;        command:                                  # training command, which can be modified              - &quot;/bin/bash&quot;              - &quot;-c&quot;                #- sleep 10000              - |                cd /mnt/ &amp;&amp;                cp setRank.sh /qwen/ &amp;&amp;                cd /qwen/ &amp;&amp;                chmod +x setRank.sh &amp;&amp;                bash setRank.sh &amp;&amp;                chmod +x finetune_lora_ds.sh &amp;&amp;                bash finetune_lora_ds.sh        securityContext:          privileged: true        volumeMounts:        - name: processeddata          mountPath: /mnt        - name: dshm          mountPath: /dev/shm        - name: tmp-volume          mountPath: /tmp      volumes:      - name: processeddata        hostPath:          path: /mnt/users/wangxiangbo/runk8s      - name: dshm        emptyDir:          medium: Memory          sizeLimit: 1G      - name: tmp-volume        hostPath:          path: /tmp
2. hostfile192.168.0.20192.168.0.58
3. setRank.sh#!/bin/bashshell_name=&quot;finetune_lora_ds.sh&quot;shell_dir=&quot;/mnt/&quot;local_dir=&quot;/qwen/&quot;## 复制脚本到/qwen/下cp $shell_dir$shell_name $local_dir## 读取hostfilereadarray -t ips &lt; &lt;(grep -vE &#x27;^[[:space:]]*$&#x27; &quot;$shell_dir&quot;hostfile)## 获取rank0 IPrank0_ip=$(echo &quot;$&#123;ips[0]&#125;&quot; | tr -d &#x27;[:space:]&#x27;)nodes=$&#123;#ips[@]&#125;## 获取hostfile中配置的IP前缀## 使用cut提取IP地址的前三个数字部分ip_prefix=$(echo &quot;$&#123;ips[0]&#125;&quot; | cut -d &#x27;.&#x27; -f 1-3)## 获取本机IPip=$(hostname -I | grep -oE &quot;$ip_prefix\.[0-9]+&quot;)ls# 初始化ranknode_rank=-1# 遍历数组for i in &quot;$&#123;!ips[@]&#125;&quot;; do    # 使用tr命令去除空白字符    clean_string=$(echo &quot;$&#123;ips[$i]&#125;&quot; | tr -d &#x27;[:space:]&#x27;)    if [[ &quot;$clean_string&quot; == &quot;$ip&quot; ]]; then        node_rank=$i        break    fidoneif [ $node_rank -ne -1 ]; then    ## 修改脚本中MASTER_ADDR    sed -i &quot;s/^MASTER_ADDR=.*/MASTER_ADDR=$rank0_ip/&quot; $local_dir$shell_name    ## 修改NNODES    sed -i &quot;s/^NNODES=.*/NNODES=$nodes/&quot; $local_dir$shell_name    ## 修改NODE_RANK    sed -i &quot;s/^NODE_RANK=.*/NODE_RANK=$node_rank/&quot; $local_dir$shell_namefi

4. sh#!/bin/bash/bin/bash -i &lt;&lt;&#x27;EOF&#x27;export NCCL_IB_DISABLE=1export NCCL_SOCKET_IFNAME=eth0export NCCL_P2P_DISABLE=1export NCCL_DEBUG=INFOsource ~/.bashrc. /opt/miniconda/etc/profile.d/conda.shconda activate qwenexport CUDA_DEVICE_MAX_CONNECTIONS=1export CUDA_VISIBLE_DEVICES=0,1,2,3DIR=`pwd`# Number of GPUs per GPU workerGPUS_PER_NODE=4# Number of GPU workers, for single-worker training, please set to 1NNODES=2# The rank of this worker, should be in &#123;0, ..., WORKER_CNT-1&#125;, for single-worker training, please set to 0NODE_RANK=0# The ip address of the rank-0 worker, for single-worker training, please set to localhostMASTER_ADDR=192.168.0.20# The port for communicationMASTER_PORT=6003MODEL=&quot;/qwen/Qwen-7B-Chat&quot; # Set the path if you do not want to load from huggingface directly# ATTENTION: specify the path to your training data, which should be a json file consisting of a list of conversations.# See the section for finetuning in README for more information.DATA=&quot;/qwen/train_data_law.json&quot;DS_CONFIG_PATH=&quot;/qwen/finetune/ds_config_zero2.json&quot;function usage() &#123;    echo &#x27;Usage: bash finetune_lora_ds.sh [-m MODEL_PATH] [-d DATA_PATH] [--deepspeed DS_CONFIG_PATH]&#x27;&#125;while [[ &quot;$1&quot; != &quot;&quot; ]]; do    case $1 in        -m | --model )            shift            MODEL=$1            ;;        -d | --data )            shift            DATA=$1            ;;        --deepspeed )            shift            DS_CONFIG_PATH=$1            ;;        -h | --help )            usage            exit 0            ;;        * )            echo &quot;Unknown argument $&#123;1&#125;&quot;            exit 1            ;;    esac    shiftdoneDISTRIBUTED_ARGS=&quot;    --nproc_per_node $GPUS_PER_NODE \    --nnodes $NNODES \    --node_rank $NODE_RANK \    --master_addr $MASTER_ADDR \    --master_port $MASTER_PORT&quot;torchrun $DISTRIBUTED_ARGS finetune.py \    --model_name_or_path $MODEL \    --data_path $DATA \    --bf16 False \    --output_dir output_qwen \    --num_train_epochs 5 \    --per_device_train_batch_size 8 \    --per_device_eval_batch_size 1 \    --gradient_accumulation_steps 8 \    --evaluation_strategy &quot;no&quot; \    --save_strategy &quot;steps&quot; \    --save_steps 100 \    --save_total_limit 10 \    --learning_rate 3e-4 \    --weight_decay 0.1 \    --adam_beta2 0.95 \    --warmup_ratio 0.01 \    --lr_scheduler_type &quot;cosine&quot; \    --logging_steps 1 \    --report_to &quot;none&quot; \    --model_max_length 512 \    --lazy_preprocess True \    --use_lora \    --gradient_checkpointing \    --ddp_find_unused_parameters False \EOF
三、拉起训练（3号和4号两机8卡）
1. 切换到1号机器master节点上，给带训练得3号和4号机器打上标签kubectl label nodes ecs-jhjs-1234-003 model=qwen-7bkubectl label nodes ecs-jhjs-1234-004 model=qwen-7b
2. 准备好启动脚本等文件后，在master节点1号机器上，利用修改好的qwentest.yaml文件拉起训练任务3. kubectl apply -f qwentest.yaml4. 通过kubectl查看pod节点启动信息
5. 查看两个节点pod的logs日志kubectl logs qwentest-czm8n -fkubectl logs qwentest-qthsf -f
]]></content>
      <categories>
        <category>模型训练调优 -NVIDIA</category>
      </categories>
      <tags>
        <tag>模型训练调优</tag>
        <tag>Nvidia</tag>
        <tag>Qwen</tag>
      </tags>
  </entry>
  <entry>
    <title>5-Qwen多机多卡调优</title>
    <url>/2025/11/06/%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E8%B0%83%E4%BC%98/NVIDIA/Qwen/5-Qwen%E5%A4%9A%E6%9C%BA%E5%A4%9A%E5%8D%A1%E8%B0%83%E4%BC%98/</url>
    <content><![CDATA[1. lora1.1 per_device_train_batch_size测试，最优为16


per_device_train_batch_size
per_device_eval_batch_size
model_max_length
gradient_accumulation_steps
bf16
tflops



2
1
512
8
true
8.37


4
1
512
8
true
9.07


8
1
512
8
true
9.88


16
1
512
8
true
10.32


32
1
512
8
true
OOM


单个GPU批次大小增加时，需要的内存也会增加，GPU内存不足以支持更大的批次，可能会导致溢出或效率降低。
1.2 per_device_eval_batch_size测试，最优为2


per_device_train_batch_size
per_device_eval_batch_size
model_max_length
gradient_accumulation_steps
bf16
tflops



16
1
512
8
true
10.32


16
2
512
8
true
10.33


16
4
512
8
true
10.26


1.3 model_max_length测试，最优为512


per_device_train_batch_size
per_device_eval_batch_size
model_max_length
gradient_accumulation_steps
bf16
flops



16
2
128
8
true
8.95


16
2
256
8
true
9.56


16
2
512
8
true
10.33


16
2
1024
8
true
OOM


1.4 gradient_accumulation_steps测试，最优为16


per_device_train_batch_size
per_device_eval_batch_size
model_max_length
gradient_accumulation_steps
bf16
tflops



16
2
512
1
true
9.07


16
2
512
2
true
9.24


16
2
512
4
true
9.89


16
2
512
8
true
10.33


16
2
512
16
true
11.63


1.5 开启Fp16测试


per_device_train_batch_size
per_device_eval_batch_size
model_max_length
gradient_accumulation_steps
fp16
tflops



16
2
512
16
true
67.13


1.6 关闭gradient_checkpointing


per_device_train_batch_size
per_device_eval_batch_size
model_max_length
gradient_accumulation_steps
fp16
gradient_checkpointing
tflops



16
2
512
16
true
true
67.13


16
2
512
16
true
false
OOM





参数配置
per_device_train_batch_size
per_device_eval_batch_size
model_max_length
gradient_accumulation_steps
bf16&#x2F;fp16
gradient_checkpointing
tflops



默认
2
1
512
8
bf16
true
8.32


调优后
16
2
512
16
fp16
true
67.13


基于2机8卡的V100，Qwen-7B模型的lora微调训练中（采用deepspeed的zero2的内存优化并行方式），Tflops的值最高为67.13**（8.32）
最佳参数配置（per_device_train_batch_size：16，per_device_eval_batch_size：2，model_max_length：512，gradient_accumulation_steps：16，Fp16精度，gradient_checkpointing：True）
2. qloraqlora使用4比特量化模型以及paged attention等技术实现更小的显存开销
2.1 per_device_train_batch_size测试，最优为32


per_device_train_batch_size
per_device_eval_batch_size
model_max_length
gradient_accumulation_steps
fp16
tflops



2
1
512
8
true
31.71


4
1
512
8
true
42.91


8
1
512
8
true
51.14


16
1
512
8
true
55.75


32
1
512
8
true
58.44


64
1
512
8
true
OOM


2.2 per_device_eval_batch_size测试，最优为4


per_device_train_batch_size
per_device_eval_batch_size
model_max_length
gradient_accumulation_steps
fp16
tflops



32
1
512
8
true
58.44


32
2
512
8
true
58.84


32
4
512
8
true
59.05


32
8
512
8
true
58.42


2.3 model_max_length测试，最优为512


per_device_train_batch_size
per_device_eval_batch_size
model_max_length
gradient_accumulation_steps
fp16
tflops



32
4
128
8
true
48.68


32
4
256
8
true
53.02


32
4
512
8
true
59.05


32
4
1024
8
true
OOM


2.4 gradient_accumulation_steps测试，最优为


per_device_train_batch_size
per_device_eval_batch_size
model_max_length
gradient_accumulation_steps
fp16
tflops



32
4
512
1
true
52.66


32
4
512
2
true
52.18


32
4
512
4
true
54.99


32
4
512
8
true
59.05


32
4
512
16
true
64.26


32
4
512
32
true
80.37


32
4
512
64
true
103.89


2.5 开启BF16测试


per_device_train_batch_size
per_device_eval_batch_size
model_max_length
gradient_accumulation_steps
bf16&#x2F;fp16
tflops



32
4
512
64
bf16
14.23


32
4
512
64
fp16
103.89


2.6 关闭gradient_checkpointing


gradient_checkpointing
per_device_train_batch_size
per_device_eval_batch_size
model_max_length
gradient_accumulation_steps
fp16
tflops



True
32
4
512
64
true
103.89


False
32
4
512
64
true
OOM


DeepSpeed ZeRO 3 对节点间通信速率的要求远大于 ZeRO 2，在多机微调的情况下会大幅降低训练速度。因此，我们不建议在多机微调的情况下使用 DeepSpeed ZeRO 3 配置。



参数配置
per_device_train_batch_size
per_device_eval_batch_size
model_max_length
gradient_accumulation_steps
fp16
tflops



默认
2
1
512
8
true
31.71


调优后
32
4
512
64
true
103.89


基于2机8卡的V100，Qwen-7B模型的qlora微调训练中（采用deepspeed的zero2的内存优化并行方式），Tflops的值最高为103.89 
默认参数配置
最佳参数配置（gradient_checkpointing：True，per_device_train_batch_size：32，per_device_eval_batch_size：4，model_max_length：512，gradient_accumulation_steps：64，Fp16精度）
qlora在拉起训练时，需要对模型权重进行INT-4量化，会损失掉权重小数部分精度，量化后的权重由于使用更少的位数来表示，存储上比原始权重高效，在拉起模型训练过程过中tflops有明显提升。
]]></content>
      <categories>
        <category>模型训练调优 -NVIDIA</category>
      </categories>
      <tags>
        <tag>模型训练调优</tag>
        <tag>Nvidia</tag>
        <tag>Qwen</tag>
      </tags>
  </entry>
</search>
