[{"title":"Tulu3-8B-后训练实践","url":"/2025/11/12/模型训练调优/NVIDIA/Tulu3/Tulu3-8B-后训练实践/","content":"# 训练环境\n## 镜像\n```bash\nregistry.cn-shanghai.aliyuncs.com/aliyun_repository_wxb/repository_wxb:tulu3\n```\n\n镜像中已包含tulu3后训练所需要的所有依赖环境。\n\n## 代码结构\n```bash\n/mnt/users/wangxiangbo/model/tulu3/open-instruct-main\n```\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image1.png)\n\n### data\n包含了`sft`、`dpo`、`rlvr`所需的数据集\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image2.png)\n\n`eval`相关\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image3.png)\n\n### scripts/configs\n训练脚本\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image4.png)\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image5.png)\n\n```bash\ntulu3_sft.sh #tulu3 sft单机脚本\n```\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image6.png)\n\n```bash\nhostfile\nhostfile-12\nsetRank.sh\ntulu3_dpo.sh #多机dpo脚本\ntulu3_dpo_single.sh #单机4卡dpo脚本\ntulu3_dpo.yaml #多机yaml\ntulu3_sft.sh #多机sft脚本\n```\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image7.png)\n\n```bash\ntulu3_rlvr_single.sh #tulu3 rlvr单机脚本\n```\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image8.png)\n\n```bash\nloss_plot.py #loss曲线绘图脚本\n```\n\n### open_instruct\nsft、dpo、rlvr相关训练代码\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image9.png)\n\n\n\n## sft实践\n### 单机4卡测试\n#### sft数据集\nsft数据集采用tulu3官网提供的数据集\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image10.png)\n\nsft数据集样例：\n\n```json\n{\"id\":\"oasst1_2644\",\"messages\":[{\"content\":\"有缓解社交恐惧症的实用方法吗？\",\"role\":\"user\"},{\"content\":\"以下是一些实用的方法，可能有助于缓解社交恐惧症：\\n\\n1.  寻求专业帮助：寻求心理医生或心理治疗师的帮助是缓解社交恐惧症的最佳方法之一。专业的治疗师可以帮助你识别和处理恐惧的源头，并提供有效的治疗方案。\\n\\n2. 练习深呼吸和放松技巧：当你感到焦虑和紧张时，尝试通过深呼吸和放松技巧来帮助你冷静下来。深呼吸可以帮助你减轻身体上的压力和紧张感，从而使你更放松和镇定。\\n\\n3. 学习积极思考：避免消极的自我对话，例如“我会失败”、“我不行”等等。改变自己的思考方式，尝试以积极、自信的态度面对社交场合。\\n\\n4.  採取柔性方法：為了對抗焦慮症狀，建議使用一些方法來提醒你的身體是安全的，例如：  \\n\\n＊ 呼吸訓練（用鼻子深深的吸一口氣再用嘴巴將氣慢慢地吐出，當你專注在吐氣時，你就會被帶出抵抗或逃避的情緒中。） \\n\\n ＊ 專注於現在（這麼做讓你能夠專注於自己所經歷的每分每秒。試著說出你現在能看見、聞到、碰觸到並聽得到的東西，或是坐在椅子上並感受自己的腳觸碰地面的感覺，或身體正被支撐著的感覺。）\\n\\n5. 給自己一點從容：在過渡時期練習自我同情，並提醒自己感到不確定與不安是很正常的。\\n\\n这些方法可以帮助你缓解社交恐惧症，但不同的人可能需要不同的方法和治疗方案。如果你感到严重的焦虑和恐惧，请及时寻求专业帮助。\",\"role\":\"assistant\"},{\"content\":\"好吧，可是我要去哪裡尋求專業幫助？\",\"role\":\"user\"},{\"content\":\"您可以先參考美國精神疾病診斷標準 **DSM-5** 中的6點標準，或者進行一些專業的心理測試。如果您符合這些標准或測試結果顯示您有社交恐懼症，您應儘早尋求專業的幫助。\\n\\n尋求專業幫助的途徑有以下幾種：\\n\\n- **諮詢醫生或心理健康專家**。他們可以為您提供診斷，藥物治療，心理治療等服務。\\n- **參加心理諮詢或治療機構**。這些機構通常有專業的心理諮詢師或治療師，可以為您提供個人或團體的心理諮詢或治療服務。\\n- **加入互助小組或社區**。這些小組或社區通常由有相同或類似問題的人組成，可以為您提供支持，鼓勵，交流和分享的平台。\\n\\n以上是我為您搜索到的一些信息，希望對您有所幫助。如果您還有其他問題，歡迎繼續提問。\",\"role\":\"assistant\"}],\"source\":\"ai2-adapt-dev\\/oasst1_converted\"}\n```\n\n由于是.parquet格式数据，转成json后一共有93w条数据。\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image11.png)\n\n由于机器数量有限，训练其完整数据集需要较长时间，故将.parquet转为json后将数据集缩减至5k条，并再次转回.parquet格式数据。\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image12.png)\n\n#### 单机脚本配置\n```bash\nexport CUDA_VISIBLE_DEVICES=0,1,2,3\nexport WANDB_MODE=disabled\ncurrent_time=$(date \"+%Y.%m.%d-%H.%M.%S\")\nLOG_SAVE=\"/mnt/open-instruct-main/output/sft/${current_time}-tulu3-sft.log\"\nMODEL_SIZE=8B\nNUM_GPUS=4\nBATCH_SIZE_PER_GPU=2\nTOTAL_BATCH_SIZE=8\nGRADIENT_ACC_STEPS=$(($TOTAL_BATCH_SIZE/($NUM_GPUS * $BATCH_SIZE_PER_GPU)))\necho \"Training llama model ${MODEL_SIZE} using $NUM_GPUS GPUs, $BATCH_SIZE_PER_GPU batch size per GPU, $GRADIENT_ACC_STEPS gradient accumulation steps\"\n\naccelerate launch \\\n    --mixed_precision fp16 \\\n    --num_machines 1 \\\n    --num_processes $NUM_GPUS \\\n    --use_deepspeed \\\n    --deepspeed_config_file /mnt/open-instruct-main/configs/ds_configs/stage3_offloading_accelerate.conf \\\n    /mnt/open-instruct-main/open_instruct/finetune.py \\\n    --model_name_or_path /mnt/LLM-Research/Meta-Llama-31-8B \\\n    --tokenizer_name /mnt/LLM-Research/Meta-Llama-31-8B \\\n    --use_slow_tokenizer \\\n    --train_file /mnt/open-instruct-main/data/sft_data_json/sft_dataset_5k.json \\\n    --max_seq_length 4096 \\\n    --preprocessing_num_workers 4 \\\n    --per_device_train_batch_size $BATCH_SIZE_PER_GPU \\\n    --gradient_accumulation_steps $GRADIENT_ACC_STEPS \\\n    --learning_rate 2e-5 \\\n    --lr_scheduler_type linear \\\n    --warmup_ratio 0.03 \\\n    --weight_decay 0. \\\n    --num_train_epochs 1 \\\n    --output_dir /mnt/open-instruct-main/output/sft \\\n    --gradient_checkpointing true \\\n    --report_to none \\\n    --use_flash_attn false 2>&1 | tee -a \"$LOG_SAVE\"\n```\n\n为了尽可能地还原tulu3原论文的实验结果，其中部分超参与论文中最优保持一致。\n\n`--max_seq_length 4096`\n\n`--learning_rate 2e-5`\n\n`--lr_scheduler_type linear`\n\n`--warmup_ratio 0.03`\n\n其中的模型权重利用llama3.1-8B-base模型。\n\n#### 训练测试\n##### 训练结束\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image13.png)\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image14.png)\n\n| 资源类型 | 利用率 | 内存/显存占用量 |\n| :---: | :---: | :---: |\n| CPU | 53.2% | 80.7% |\n| GPU | 85.5% | 66.4% |\n\n\n##### loss曲线\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image15.png)\n\n##### eval\nllama3.1-8B通过tulu3提供的sft数据集（删减至5k条）后，得到的tulu3_sft权重\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image16.png)\n\n| 类别 | Llama-31-8B | tulu3-sft-weight | Llama-31-Tulu-3-8B-SFT |\n| :---: | :---: | :---: | :---: |\n| 平均准确率 | 0.6014 | 0.5729 | **<font style=\"color:#DF2A3F;\">0.6356</font>** |\n| 子类别准确率 | - | - | **<font style=\"color:#000000;\">-</font>** |\n| 数学 | 0.4098 | 0.3778 | **0.4192** |\n| 健康 | 0.6561 | 0.6183 | **0.6720** |\n| 物理 | 0.5063 | 0.4891 | **0.5328** |\n| 商业 | 0.7643 | 0.7346 | **0.8101** |\n| 生物 | 0.7555 | 0.6982 | **0.7775** |\n| 化学 | 0.4851 | 0.4851 | **0.5186** |\n| 计算机科学 | 0.5752 | 0.5194 | **0.6092** |\n| 经济 | 0.5930 | 0.5809 | **0.6213** |\n| 工程 | 0.5517 | 0.5172 | **0.5517** |\n| 哲学 | 0.4881 | 0.4627 | **0.5775** |\n| 其他 | 0.6524 | 0.6532<font style=\"color:#000000;\">⬆</font> | **0.7090** |\n| 历史 | 0.7452 | 0.7172 | **0.7774** |\n| 地理 | 0.7323 | 0.7273 | **0.7677** |\n| 政治 | 0.7546 | 0.7099 | **0.7762** |\n| 心理学 | 0.7174 | 0.6845 | **0.7485** |\n| 文化 | **0.8102** | 0.7440 | 0.7922 |\n| 法律 | 0.4878 | 0.4589 | **0.5020** |\n| 类别准确率 | - | - | - |\n| STEM | 0.5192 | 0.4864 | **0.5394** |\n| 人文学科 | 0.5388 | 0.5116 | **0.5887** |\n| 社会科学 | 0.7062 | 0.6740 | **0.7296** |\n| 其他（商业、健康等） | 0.6693 | 0.6465 | **0.7039** |\n\n\n##### eval结果分析\n+ SFT后权重的平均准确率: 0.5729\n+ SFT前权重的平均准确率: 0.6014\n\n整体平均准确率下降了 ~2.85%。\n\n原因：本次实验（由于机器环境限制）将原始的tulu3 SFT数据集（93w）删减到5k条，导致模型未能充分学习各个领域的知识和任务特性，泛化能力下降。\n\n## dpo实践\n### 单机4卡测试\n#### 偏好数据集\n偏好数据集采用tulu3官网提供的数据集。\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image17.png)\n\n偏好数据集样例：\n\n```json\n{\"id\":\"allenai\\/tulu-3-sft-reused-off-policy_0\",\"prompt\":\"Peter has 5 cages with rabbits (the cages are arranged in a row). It is known that there is at least one rabbit in each cage. We will call two rabbits neighbors if they are either in the same cage or in adjacent cages. It turned out that each rabbit has either 3 or 7 neighbors. How many rabbits are in the central cage?\",\"chosen\":[{\"content\":\"Peter has 5 cages with rabbits (the cages are arranged in a row). It is known that there is at least one rabbit in each cage. We will call two rabbits neighbors if they are either in the same cage or in adjacent cages. It turned out that each rabbit has either 3 or 7 neighbors. How many rabbits are in the central cage?\",\"role\":\"user\"},{\"content\":\"Here's how to solve this problem:\\n\\n**Understanding the Information**\\n\\n* **Each rabbit has 3 or 7 neighbors:** This means there must be a pattern in how the rabbits are distributed within the cages.\\n* **At least one rabbit in each cage:**  We can't have cages without any rabbits.\\n\\n**Reasoning**\\n\\n* **Corner Cages:**  Rabbits in the corner cages (cages 1 and 5) can only have 3 neighbors (two adjacent cages and one within their own cage).\\n* **Middle Cages:** Rabbits in the middle cages (cages 2, 3, and 4) must have 7 neighbors to balance out the setup. \\n\\n**The Solution**\\n\\nSince rabbits in the middle cages need 7 neighbors, and there's at least one rabbit in each cage, the central cage (cage 3) must have **4 rabbits**. \\n\\n\\n\\nLet me know if you'd like to explore other logic puzzles! \\n\",\"role\":\"assistant\"}],\"rejected\":[{\"content\":\"Peter has 5 cages with rabbits (the cages are arranged in a row). It is known that there is at least one rabbit in each cage. We will call two rabbits neighbors if they are either in the same cage or in adjacent cages. It turned out that each rabbit has either 3 or 7 neighbors. How many rabbits are in the central cage?\",\"role\":\"user\"},{\"content\":\"The central cage has the same number of rabbits as any other cage, so it also has either 3 or 7 neighbors.\\nThere are (at most) 7 rabbits in the central cage and (at most) 3 rabbits in any cage on either side. Hence, there are (at most) 7 rabbits in each of those cages. The total number of rabbits in the 5 cages is (at most) 5 * 7 + 1 = 36 + 1 = 37.\\nOne cage must have exactly the right number of neighbors, but two cages cannot have the right number.\\nIf each cage has exactly 3 neighbors, the total number of rabbits in all 5 cages is 1 + 5 * 3 = 16\\nIf each cage has exactly 7 neighbors, the total number of rabbits in all 5 cages is 1 + 5 * 7 = 32\\nNow that we know there are at most 36 rabbits, we can safely conclude that there is 1 rabbit in the central cage, that there are 5 cages with 3 rabbits each and one cage with 7 rabbits and that the central cage has 3 neighbors.\\nThe central cage has exactly 3 rabbits and 3 neighbors.\\nIn the other 4 cages, there are (at most) 5 * 3 = 15 rabbits.\\nIn the other 5 cages, there are (at least) 32 – 16 = 16 rabbits.\",\"role\":\"assistant\"}],\"source\":\"allenai\\/tulu-3-sft-reused-off-policy\"}\n```\n\n由于是.parquet格式数据，转成json后一共有67w条数据。\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image18.png)\n\n由于机器数量有限，训练其完整数据集需要较长时间，故将.parquet转为json后将数据集缩减至5k条，并再次转回.parquet格式数据。\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image19.png)\n\n#### 单机脚本配置\n单机脚本，部分配置OOM，采用deepseed中zero3以及cpu_offloading，开启梯度累积。\n\n```bash\n# you need 8 GPUs for full finetuning\nexport CUDA_VISIBLE_DEVICES=0,1,2,3\nexport WANDB_MODE=disabled\n\nNUM_GPUS=4\nBATCH_SIZE_PER_GPU=1\nTOTAL_BATCH_SIZE=8\nGRADIENT_ACC_STEPS=$(($TOTAL_BATCH_SIZE/$NUM_GPUS/$BATCH_SIZE_PER_GPU))\ncurrent_time=$(date \"+%Y.%m.%d-%H.%M.%S\")\nLOG_SAVE=\"/mnt/open-instruct-main/output/dpo/${current_time}-tulu3-dpo.log\"\necho \"Training model using $NUM_GPUS GPUs, $BATCH_SIZE_PER_GPU batch size per GPU, $GRADIENT_ACC_STEPS gradient accumulation steps\"\n\n#stage3_no_offloading_accelerate.conf\naccelerate launch \\\n    --mixed_precision fp16 \\\n    --num_machines 1 \\\n    --num_processes $NUM_GPUS \\\n    --use_deepspeed \\\n    --deepspeed_config_file /mnt/open-instruct-main/configs/ds_configs/stage3_offloading_accelerate.conf \\\n    /mnt/open-instruct-main/open_instruct/dpo_tune.py \\\n    --model_name_or_path /mnt/LLM-Research/Llama-31-Tulu-3-8B-SFT \\\n    --use_flash_attn  false\\\n    --gradient_checkpointing \\\n    --tokenizer_name /mnt/LLM-Research/Llama-31-Tulu-3-8B-SFT \\\n    --use_slow_tokenizer \\\n    --dataset_name /mnt/open-instruct-main/data/dpo_data_5k \\\n    --max_seq_length 2048 \\\n    --preprocessing_num_workers 4 \\\n    --per_device_train_batch_size $BATCH_SIZE_PER_GPU \\\n    --gradient_accumulation_steps $GRADIENT_ACC_STEPS \\\n    --learning_rate 5e-7 \\\n    --lr_scheduler_type linear \\\n    --warmup_ratio 0.1 \\\n    --weight_decay 0. \\\n    --num_train_epochs 1 \\\n    --output_dir /mnt/open-instruct-main/output/dpo \\\n    --with_tracking False \\\n    --logging_steps 1 2>&1 | tee -a \"$LOG_SAVE\"\n```\n\n为了尽可能地还原tulu3原论文的实验结果，其中部分超参与论文中最优保持一致。\n\n`--max_seq_length 2048`\n\n`--learning_rate 5e-7`\n\n`--lr_scheduler_type linear`\n\n`--warmup_ratio 0.1`\n\n其中的模型权重利用tulu3开源的经过llama3.1-8B sft得到的权重。\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image20.png)\n\n#### 训练测试\n##### 关闭cpu_offloading\n注：关闭cpu_offloading之后，迭代10步左右会OOM\n\n\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image21.png)\n\n| 资源类型 | 利用率 | 内存/显存占用量 |\n| :---: | :---: | :---: |\n| CPU | 16.5% | 12.1% |\n| GPU | 100% | 93.6% |\n\n\n##### 开启cpu_offloading\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image22.png)\n\n| 资源类型 | 利用率 | 内存/显存占用量 |\n| :---: | :---: | :---: |\n| CPU | 55.0% | 58.2% |\n| GPU | 85.8% | 68.7% |\n\n\n##### 训练完成\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image23.png)\n\n得到的dpo权重\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image24.png)\n\n##### loss曲线\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image25.png)\n\n##### eval\n评测数据集采用MMLU，一个包含来自各个知识领域的多项选择题的巨大多任务测试。 测试涵盖了人文学科、社会科学、自然科学以及其他对某些人来说重要的学习领域。 数据集中的问题是由研究生和本科生从在线免费资源中手动收集的。这包括研究生入学考试和美国医学执照考试等考试的练习题。还包括为本科生课程设计的题目，以及为牛津大学出版社书籍读者设计的题目。 一些任务涵盖一个主题，如心理学，但难度级别特定，例如“初阶”、“高中”、“大学”或“专业”。 例如，“专业心理学”任务借鉴了心理学专业实践考试的免费练习题中的问题，而“高中心理学”任务则包含类似高级 Placement 心理学考试中的问题。\n\n:::tips\nMMLU数据集样例如下，摘自MMLU论文[https://arxiv.org/abs/2009.03300](https://arxiv.org/abs/2009.03300)\n\n:::\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image26.png)\n\neg：以下是MMLU上<font style=\"color:rgb(0,0,0);\">College Biology类问题及答案</font>：\n\n```plain\n\"Based on the characteristic population curves that result from plotting population growth of a species, the most effective means of controlling the mosquito population is to\",\nmaintain the population at a point corresponding to the midpoint of its logistic curve,\nopt for zero population control once the K value of the curve has been reached,\nreduce the carrying capacity cif the environment to lower the K value,\nincrease the mortality rate,\nC\n```\n\neg：以下是`dpo_weight`在MMLU上<font style=\"color:rgb(0,0,0);\">College Biology类问题的回答</font>：\n\n```plain\n0,1,2,3,4,5,correct,choiceA_probs,choiceB_probs,choiceC_probs,choiceD_probs\n\"Based on the characteristic population curves that result from plotting population growth of a species, the most effective means of controlling the mosquito population is to\",\nmaintain the population at a point corresponding to the midpoint of its logistic curve,\nopt for zero population control once the K value of the curve has been reached,\nreduce the carrying capacity cif the environment to lower the K value,\nincrease the mortality rate,\nC,\nTrue,\n0.07324660569429398,\n0.0071399579755961895,\n0.6528399586677551,\n0.1929791122674942\n```\n\n\n\n本次dpo后得到的权重`dpo_weight`对比tulu3开源的sft权重`Llama-31-Tulu-3-8B-SFT`。\n\n`Llama-31-Tulu-3-8B-SFT`在MMLU上的表现：\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image27.png)\n\n`dpo_weight`在MMLU上的表现：\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image28.png)\n\n| 类别 | Llama-31-8B | Llama-31-Tulu-3-8B-SFT | dpo_weight | Llama-31-Tulu-3-8B-DPO |\n| :---: | :---: | :---: | :---: | :---: |\n| 平均准确率 | 0.6014 | 0.6356 | **<font style=\"color:#DF2A3F;\">0.6377</font>**⬆ | 0.6352 |\n| 子类别准确率 | - | **<font style=\"color:#000000;\">-</font>** | **<font style=\"color:#000000;\">-</font>** | - |\n| 数学 | 0.4098 | 0.4192 | **0.4352**⬆ | 0.4258 |\n| 健康 | 0.6561 | 0.6720 | 0.6726⬆ | **0.6915** |\n| 物理 | 0.5063 | 0.5328 | **0.5500**⬆ | 0.5391 |\n| 商业 | 0.7643 | **0.8101** | 0.7941 | 0.7849 |\n| 生物 | 0.7555 | 0.7775 | **0.7775**⬆ | 0.7731 |\n| 化学 | 0.4851 | 0.5186 | 0.5182 | **0.5248** |\n| 计算机科学 | 0.5752 | 0.6092 | **0.6189**⬆ | 0.6117 |\n| 经济 | 0.5930 | 0.6213 | 0.6173 | **0.6429** |\n| 工程 | 0.5517 | 0.5517 | **0.5655**⬆ | 0.5586 |\n| 哲学 | 0.4881 | **0.5775** | 0.5626 | 0.5388 |\n| 其他 | 0.6524 | 0.7090 | **0.7107**⬆ | 0.7082 |\n| 历史 | 0.7452 | 0.7774 | **0.7828**⬆ | 0.7720 |\n| 地理 | 0.7323 | 0.7677 | 0.7778⬆ | **0.7778** |\n| 政治 | 0.7546 | 0.7762 | **0.7793**⬆ | 0.7762 |\n| 心理学 | 0.7174 | 0.7485 | **0.7519**⬆ | 0.7476 |\n| 文化 | **0.8102** | 0.7922 | 0.7892 | 0.8042 |\n| 法律 | 0.4878 | 0.5020 | **0.5133**⬆ | 0.5156 |\n| 父类别准确率 | - | - | **-** | - |\n| STEM | 0.5192 | 0.5394 | **0.5507**⬆ | 0.5437 |\n| 人文学科 | 0.5388 | **0.5887** | 0.5877 | 0.5762 |\n| 社会科学 | 0.7062 | 0.7296 | 0.7309⬆ | **0.7364** |\n| 其他（商业、健康、杂项） | 0.6693 | 0.7039 | 0.7027 | **0.7101** |\n\n\n### dpo代码实现分析\n#### Length-Normalized DPO 的实现\n##### `_get_batch_logps` 函数  \ntulu3论文中说明了，tulu3-8B的dpo使用了长度归一化的DPO（Length-Normalized DPO），以此来消除<font style=\"color:#000000;background-color:#F1A2AB;\">因回答的序列长度（对比来说很长的话）带来的概率偏好影响。</font> 当 `average_log_prob=True` 时，会将每个 token 的 log 概率进行平均处理，实现序列长度归一化。 如果`average_log_prob=False`，则是直接求和。\n\n代码具体实现如下：\n\n```python\ndef _get_batch_logps(\n    logits: torch.FloatTensor, labels: torch.LongTensor, average_log_prob: bool = False\n) -> torch.FloatTensor:\n    # 确保logits和labels的形状在除了最后一个维度外是相同的。\n    assert logits.shape[:-1] == labels.shape\n    # 两行代码分别对labels和logits进行切片操作，去掉了每个序列的第一个和最后一个元素。\n    labels = labels[:, 1:].clone()\n    logits = logits[:, :-1, :]\n    # 这行代码创建了一个掩码loss_mask，用于标识哪些标签不是-100（即不是要被忽略的标签）。\n    loss_mask = labels != -100\n\n    # 这行代码将labels中值为-100的元素替换为0，因为在PyTorch中，0可以作为无效索引。\n    labels[labels == -100] = 0\n\n    # 计算每个token的对数概率。首先对logits应用log_softmax函数，然后在最后一个维度上使用torch.gather根据labels索引来选择对应的对数概率。\n    per_token_logps = torch.gather(logits.log_softmax(-1), dim=2, index=labels.unsqueeze(2)).squeeze(2)\n\n    # 根据average_log_prob的值决定返回值。如果average_log_prob为True，则返回每个样本的平均对数概率；否则，返回每个样本的对数概率之和\n    if average_log_prob:\n        return (per_token_logps * loss_mask).sum(-1) / loss_mask.sum(-1)\n    else:\n        return (per_token_logps * loss_mask).sum(-1)\n```\n\n:::tips\n<font style=\"color:rgba(0, 0, 0, 0.85);\">函数_get_batch_logps用于计算给定标签（labels）在给定的模型输出（logits）下的对数概率（log probabilities）。</font>\n\n<font style=\"color:rgba(0, 0, 0, 0.85);\">参数说明：</font>\n\n+ <font style=\"color:rgba(0, 0, 0, 0.85);\">logits</font><font style=\"color:rgba(0, 0, 0, 0.85);\">：模型的输出（未归一化的）。形状为</font><font style=\"color:rgba(0, 0, 0, 0.85);\">(batch_size, sequence_length, vocab_size)</font><font style=\"color:rgba(0, 0, 0, 0.85);\">，其中</font><font style=\"color:rgba(0, 0, 0, 0.85);\">batch_size</font><font style=\"color:rgba(0, 0, 0, 0.85);\">是批次大小，</font><font style=\"color:rgba(0, 0, 0, 0.85);\">sequence_length</font><font style=\"color:rgba(0, 0, 0, 0.85);\">是序列长度，</font><font style=\"color:rgba(0, 0, 0, 0.85);\">vocab_size</font><font style=\"color:rgba(0, 0, 0, 0.85);\">是词汇表的大小。</font>\n+ <font style=\"color:rgba(0, 0, 0, 0.85);\">labels</font><font style=\"color:rgba(0, 0, 0, 0.85);\">：要计算对数概率的标签。值为-100的标签标记将被忽略。形状为</font><font style=\"color:rgba(0, 0, 0, 0.85);\">(batch_size, sequence_length)</font><font style=\"color:rgba(0, 0, 0, 0.85);\">。</font>\n+ <font style=\"color:rgba(0, 0, 0, 0.85);\">average_log_prob</font><font style=\"color:rgba(0, 0, 0, 0.85);\">：一个布尔值，默认为</font><font style=\"color:rgba(0, 0, 0, 0.85);\">False</font><font style=\"color:rgba(0, 0, 0, 0.85);\">。如果为</font><font style=\"color:rgba(0, 0, 0, 0.85);\">True</font><font style=\"color:rgba(0, 0, 0, 0.85);\">，则返回每个（未被掩码的）token的平均对数概率；如果为</font><font style=\"color:rgba(0, 0, 0, 0.85);\">False</font><font style=\"color:rgba(0, 0, 0, 0.85);\">，则返回（未被掩码的）token的对数概率之和。</font>\n\n<font style=\"color:rgba(0, 0, 0, 0.85);\">返回值：</font>\n\n+ <font style=\"color:rgba(0, 0, 0, 0.85);\">返回一个形状为</font><font style=\"color:rgba(0, 0, 0, 0.85);\">(batch_size,)</font><font style=\"color:rgba(0, 0, 0, 0.85);\">的张量，包含给定标签在给定logits下的对数概率的平均值或总和。</font>\n\n<font style=\"color:rgba(0, 0, 0, 0.85);\">该函数是用来计算模型预测的概率，并根据标签来确定哪些预测是有效的（即标签值不为-100）。如果average_log_prob参数为True，则函数返回的是平均对数概率；如果为False，则返回的是总和。</font>\n\n:::\n\n##### `concatenated_forward` 函数  \n 在训练中，`concatenated_forward` 负责对模型的 `logps` 进行计算：  \n\n```python\ndef concatenated_forward(\n    model: nn.Module,\n    batch: Dict[str, Union[List, torch.LongTensor]],\n    average_log_prob: bool = False,\n    output_router_logits: bool = False,\n) -> Tuple[torch.FloatTensor, torch.FloatTensor]:\n    concatenated_batch = concatenated_inputs(batch)\n    if output_router_logits:\n        outputs = model(\n            input_ids=concatenated_batch[\"concatenated_input_ids\"],\n            attention_mask=concatenated_batch[\"concatenated_attention_mask\"],\n            output_router_logits=True,\n        )\n        logits = outputs.logits.to(torch.float32)\n        aux_loss = outputs.aux_loss\n    else:\n        logits = model(\n            input_ids=concatenated_batch[\"concatenated_input_ids\"],\n            attention_mask=concatenated_batch[\"concatenated_attention_mask\"],\n        ).logits.to(torch.float32)\n        aux_loss = None\n    all_logps = _get_batch_logps(logits, concatenated_batch[\"concatenated_labels\"], average_log_prob=average_log_prob)\n    chosen_logps = all_logps[: batch[\"chosen_input_ids\"].shape[0]]\n    rejected_logps = all_logps[batch[\"chosen_input_ids\"].shape[0] :]\n    return chosen_logps, rejected_logps, aux_loss\n```\n\n 参数 `average_log_prob` 是从主脚本`dpo_tune.py`中传递的，当设置为 `True` 时，启用长度归一化。  \n\n##### `dpo_loss` 函数  \n`dpo_loss` 中计算 logits 的差值：  \n\n```python\npi_logratios = policy_chosen_logps - policy_rejected_logps\nref_logratios = reference_chosen_logps - reference_rejected_logps\nlogits = pi_logratios - ref_logratios\n```\n\n 如果 `average_log_prob=True`，则 `policy_chosen_logps` 和 `policy_rejected_logps` 都是归一化的值，从而影响最终的 logits 和损失计算。  \n\n##### 控制参数  \n 在主脚本dpo_tune.py中，通过以下代码控制是否启用长度归一化：  \n\n```python\naverage_log_prob_loss_types = [\"simpo\", \"dpo_norm\"]\naverage_log_prob = args.dpo_loss_type in average_log_prob_loss_types\n```\n\n 当 `dpo_loss_type` 设置为 `\"dpo_norm\"` 时，`average_log_prob`归一化被启用，进而在 `_get_batch_logps` 和 `concatenated_forward` 中触发长度归一化逻辑。  \n\n## rlvr实践\n### 单机4卡测试\n####  训练数据集\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image29.png)\n\n.parquet转为json后的数据集样例：\n\n```json\n{\"messages\":[{\"content\":\"Question: Find the domain of the expression $\\\\frac{\\\\sqrt{x-2}}{\\\\sqrt{5-x}}$.}\\nAnswer:The expressions inside each square root must be non-negative.\\nTherefore, $x-2 \\\\ge 0$, so $x\\\\ge2$, and $5 - x \\\\ge 0$, so $x \\\\le 5$.\\nAlso, the denominator cannot be equal to zero, so $5-x>0$, which gives $x<5$.\\nTherefore, the domain of the expression is $\\\\boxed{[2,5)}$.\\n\\nQuestion: If $\\\\det \\\\mathbf{A} = 2$ and $\\\\det \\\\mathbf{B} = 12,$ then find $\\\\det (\\\\mathbf{A} \\\\mathbf{B}).$\\nAnswer:We have that $\\\\det (\\\\mathbf{A} \\\\mathbf{B}) = (\\\\det \\\\mathbf{A})(\\\\det \\\\mathbf{B}) = (2)(12) = \\\\boxed{24}.$\\n\\nQuestion: Terrell usually lifts two 20-pound weights 12 times. If he uses two 15-pound weights instead, how many times must Terrell lift them in order to lift the same total weight?\\nAnswer:If Terrell lifts two 20-pound weights 12 times, he lifts a total of $2\\\\cdot 12\\\\cdot20=480$ pounds of weight.  If he lifts two 15-pound weights instead for $n$ times, he will lift a total of $2\\\\cdot15\\\\cdot n=30n$ pounds of weight.  Equating this to 480 pounds, we can solve for $n$: \\\\begin{align*}\\n30n&=480\\\\\\\\\\n\\\\Rightarrow\\\\qquad n&=480\\/30=\\\\boxed{16}\\n\\\\end{align*}\\n\\nQuestion: If the system of equations\\n\\n\\\\begin{align*}\\n6x-4y&=a,\\\\\\\\\\n6y-9x &=b.\\n\\\\end{align*}has a solution $(x, y)$ where $x$ and $y$ are both nonzero, find $\\\\frac{a}{b},$ assuming $b$ is nonzero.\\nAnswer:If we multiply the first equation by $-\\\\frac{3}{2}$, we obtain\\n\\n$$6y-9x=-\\\\frac{3}{2}a.$$Since we also know that $6y-9x=b$, we have\\n\\n$$-\\\\frac{3}{2}a=b\\\\Rightarrow\\\\frac{a}{b}=\\\\boxed{-\\\\frac{2}{3}}.$$\\n\\nQuestion: What is the modulo $13$ residue of $247+5 \\\\cdot 39 + 7 \\\\cdot 143 +4 \\\\cdot 15?$\",\"role\":\"user\"}],\"ground_truth\":\"8\",\"dataset\":\"MATH\",\"constraint_type\":null,\"constraint\":null}\n```\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image30.png)\n\n#### 验证数据集\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image31.png)\n\n```json\n{\"messages\":[{\"content\":\"Question: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\\nAnswer:There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. So the answer is 6.\\n\\nQuestion: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\\nAnswer:There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. So the answer is 5.\\n\\nQuestion: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\\nAnswer:Originally, Leah had 32 chocolates. Her sister had 42. So in total they had 32 + 42 = 74. After eating 35, they had 74 - 35 = 39. So the answer is 39.\\n\\nQuestion: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did Jason give to Denny?\\nAnswer:Jason started with 20 lollipops. Then he had 12 after giving some to Denny. So he gave Denny 20 - 12 = 8. So the answer is 8.\\n\\nQuestion: Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does he have now?\\nAnswer:Shawn started with 5 toys. If he got 2 toys each from his mom and dad, then that is 4 more toys. 5 + 4 = 9. So the answer is 9.\\n\\nQuestion: There were nine computers in the server room. Five more computers were installed each day, from monday to thursday. How many computers are now in the server room?\\nAnswer:There were originally 9 computers. For each of 4 days, 5 more computers were added. So 5 * 4 = 20 computers were added. 9 + 20 is 29. So the answer is 29.\\n\\nQuestion: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf balls did he have at the end of wednesday?\\nAnswer:Michael started with 58 golf balls. After losing 23 on tuesday, he had 58 - 23 = 35. After losing 2 more, he had 35 - 2 = 33 golf balls. So the answer is 33.\\n\\nQuestion: Olivia has $23. She bought five bagels for $3 each. How much money does she have left?\\nAnswer:Olivia had 23 dollars. 5 bagels for 3 dollars each will be 5 x 3 = 15 dollars. So she has 23 - 15 dollars left. 23 - 15 is 8. So the answer is 8.\\n\\nQuestion: A robe takes 2 bolts of blue fiber and half that much white fiber.  How many bolts in total does it take?\",\"role\":\"user\"}],\"ground_truth\":\"3\",\"dataset\":\"gsm8k\"}\n{\"messages\":[{\"content\":\"Question: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\\nAnswer:There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. So the answer is 6.\\n\\nQuestion: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\\nAnswer:There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. So the answer is 5.\\n\\nQuestion: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\\nAnswer:Originally, Leah had 32 chocolates. Her sister had 42. So in total they had 32 + 42 = 74. After eating 35, they had 74 - 35 = 39. So the answer is 39.\\n\\nQuestion: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did Jason give to Denny?\\nAnswer:Jason started with 20 lollipops. Then he had 12 after giving some to Denny. So he gave Denny 20 - 12 = 8. So the answer is 8.\\n\\nQuestion: Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does he have now?\\nAnswer:Shawn started with 5 toys. If he got 2 toys each from his mom and dad, then that is 4 more toys. 5 + 4 = 9. So the answer is 9.\\n\\nQuestion: There were nine computers in the server room. Five more computers were installed each day, from monday to thursday. How many computers are now in the server room?\\nAnswer:There were originally 9 computers. For each of 4 days, 5 more computers were added. So 5 * 4 = 20 computers were added. 9 + 20 is 29. So the answer is 29.\\n\\nQuestion: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf balls did he have at the end of wednesday?\\nAnswer:Michael started with 58 golf balls. After losing 23 on tuesday, he had 58 - 23 = 35. After losing 2 more, he had 35 - 2 = 33 golf balls. So the answer is 33.\\n\\nQuestion: Olivia has $23. She bought five bagels for $3 each. How much money does she have left?\\nAnswer:Olivia had 23 dollars. 5 bagels for 3 dollars each will be 5 x 3 = 15 dollars. So she has 23 - 15 dollars left. 23 - 15 is 8. So the answer is 8.\\n\\nQuestion: Josh decides to try flipping a house.  He buys a house for $80,000 and then puts in $50,000 in repairs.  This increased the value of the house by 150%.  How much profit did he make?\",\"role\":\"user\"}],\"ground_truth\":\"70000\",\"dataset\":\"gsm8k\"}\n```\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image32.png)\n\n#### 单机脚本配置\n```bash\nexport WANDB_MODE=disabled\nexport PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n\ncurrent_time=$(date \"+%Y.%m.%d-%H.%M.%S\")\nLOG_SAVE=\"/mnt/open-instruct-main/output/rlvr/${current_time}-tulu3-rlvr.log\"\n\npython /mnt/open-instruct-main/open_instruct/ppo_vllm_thread_ray_gtrl.py \\\n    --dataset_mixer '{\"/mnt/open-instruct-main/data/gsm8k_math_ground_truth_mixed\": 1.0}' \\\n    --dataset_train_splits train \\\n    --dataset_eval_mixer '{\"/mnt/open-instruct-main/data/gsm8k_math_ground_truth\": 1.0}' \\\n    --dataset_eval_splits test \\\n    --max_token_length 2048 \\\n    --max_prompt_token_length 2048 \\\n    --response_length 2048 \\\n    --model_name_or_path /mnt/LLM-Research/Llama-31-Tulu-3-8B-DPO \\\n    --reward_model_path /mnt/LLM-Research/LLama-31-Tulu3-8B-RM \\\n    --non_stop_penalty \\\n    --stop_token eos \\\n    --temperature 1.0 \\\n    --ground_truths_key ground_truth \\\n    --chat_template tulu \\\n    --sft_messages_key messages \\\n    --learning_rate 3e-7 \\\n    --total_episodes 10000000 \\\n    --penalty_reward_value -10.0 \\\n    --deepspeed_stage 3 \\\n    --per_device_train_batch_size 1 \\\n    --local_rollout_forward_batch_size 1 \\\n    --local_mini_batch_size 16 \\\n    --local_rollout_batch_size 16 \\\n    --actor_num_gpus_per_node 3 \\\n    --vllm_tensor_parallel_size 2 \\\n    --beta 0.05 \\\n    --apply_verifiable_reward true \\\n    --output_dir /mnt/open-instruct-main/output/rlvr \\\n    --seed 3 \\\n    --num_evals 3 \\\n    --save_freq 100 \\\n    --reward_model_multiplier 0.0 \\\n    --gradient_checkpointing \\\n    --with_tracking False 2>&1 | tee -a \"$LOG_SAVE\"\n```\n\n为了尽可能地还原tulu3原论文的实验结果，其中部分超参与论文中最优保持一致。\n\n`--max_token_length 2048`\n\n`--max_prompt_token_length 2048` \n\n`--response_length 2048`\n\n`--learning_rate 3e-7`\n\n`--penalty_reward_value -10.0`\n\n`--reward_model_multiplier 0.0`\n\n其中的模型权重利用tulu3开源的经过tulu3-sft dpo得到的Llama-31-Tulu-3-8B-DPO权重，奖励模型采用tulu3开源的LLama-31-Tulu3-8B-RM。\n\n#### 训练测试\n加载ckpt时一直卡住不动，尚未解决。\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image33.png)\n\n","tags":["模型训练调优","Nvidia","V100","Tulu3"],"categories":["模型训练调优","NVIDIA"]},{"title":"前端1_调用api接口的写法","url":"/2025/11/06/前端/前端1_调用api接口的写法/","content":"\n### Get请求写法\n#### 1. 看Parameters中是否有需要带参数，其中`Authorization`为授权认证的token可以不用考虑。\n1.1 若是没有其余的参数限定，那么SyncRequestFuncType<请求参数类型,响应返回参数类型>，第一个参数就为void或者undefined。返回类型可以使用any，等获取到响应参数之后，在对其通过Interface/type进行明确。\n\n```javascript\nexport const getApi: SyncRequestFuncType<\nvoid,\nresponseType\n> = () => {\nreturn javaAxios({\n method: \"get\",\n url: \"xxx/xxxx\",\n});\n};\n```\n\n1.2 若是有其余参数限定，这时需要箭头函数中需要带着params来进行请求，且reuturn中也需要将params带着。\n\n\t1.2.1 `单个参数`，例如id，这时在请求参数类型中，需要明确出请求参数的类型<{id:string},responseType>，这时请求参数的类型为对象{}的形式，可以直接在尖括号中写出来，也可以通过引入定义的Interface/type类型来写<IdType,responseType>。\n\n```javascript\nexport const getApi: SyncRequestFuncType<\n {id:string},\n void\n> = (params) => {\nreturn javaAxios({\n method: \"get\",\n url: \"xxx/xxxx\",\n params,\n});\n};\n```\n\n\t1.2.2 `多个参数`，例如email，type...，因为参数比较多，最好通过Interface/type的方式SendEmailCaptchaForUserInfoModifyType来明确请求参数类型。\n\n```javascript\nexport type SendEmailCaptchaForUserInfoModifyType = {\ntype: ModifyType;\nemail?: string;\n};\n```\n\n```javascript\nexport const getApi: SyncRequestFuncType<\nSendEmailCaptchaForUserInfoModifyType,\nvoid\n> = (params) => {\nreturn javaAxios({\n method: \"get\",\n url: \"xxx/xxx\",\n params,\n});\n};\n```\n\n### Post请求写法\n#### 1. 看看Parameters中是否有需要带参数，其中`Authorization`为授权认证的token可以不用考虑。\n1.1 若是没有其余的参数限定，那么SyncRequestFuncType<请求参数类型,响应返回参数类型>，第一个参数就为void或者undefined。返回类型可以使用any，等获取到响应参数之后，在对其通过Interface/type进行明确。\n\n```javascript\nexport const clearVideoRecycle: SyncRequestFuncType<void, void> = () => {\nreturn javaAxios({\n method: \"post\",\n url: \"xxx/xxx\",\n});\n};\n```\n\n1.2 若是有其余参数限定，这时需要箭头函数中需要带着params来进行请求，且reuturn中也需要将params带着。\n\n\t1.2.1 单个参数时\n\n```javascript\nexport const cancelSubscribeVideo: SyncRequestFuncType<\n{ themeId: string },\nany\n> = (params) => {\nreturn javaAxios({\n method: \"post\",\n url: \"xxx/xxx\",\n params,\n});\n};\n```\n\n\t1.2.2 多个参数时\n\n```javascript\nexport type SendEmailCaptchaForUserInfoModifyType = {\ntype: ModifyType;\nemail?: string;\n};\n```\n\n```javascript\nexport const sendEmailCaptchaForUserInfoModify: SyncRequestFuncType<\nSendEmailCaptchaForUserInfoModifyType,\nvoid\n> = (params) => {\nreturn javaAxios({\n method: \"get\",\n url: \"xxx/xxx\",\n params,\n});\n};\n```\n\n#### 2. 当出现请求体`Request body`时，这时就需要在return的javaAxios中添加键值对`data: params`，来将参数添加到请求体中传递过去。\n2.1 Request body为：\n\n```javascript\n[\n\"string\"\n]\n```\n\n```javascript\nexport const batchDeleteVideo: SyncRequestFuncType<string[], void> = (\nparams\n) => {\nreturn javaAxios({\n method: \"post\",\n url: \"videos/themes/batchDel\",\n data: params,\n});\n};\n```\n\n2.2 Request body为：这时候需要在data中进一步在约束一下，使其对应api的请求体的格式。\n\n```javascript\n{\n\"themes\": [\n \"string\"\n]\n}\n```\n\n```javascript\nexport const sortVideos: SyncRequestFuncType<string[], void> = (params) => {\nreturn javaAxios({\n method: \"post\",\n url: \"videos/themes/changeVideoThemesSort\",\n data: { themes: params },\n});\n};\n```\n\n","tags":["前端","Javascript"],"categories":["前端"]},{"title":"1.1-Qwen模型本地部署与单机单卡/多卡训练","url":"/2025/11/06/模型训练调优/NVIDIA/Qwen/1.1-Qwen模型本地部署与单机单卡_多卡训练/","content":"一、V100环境部署\n1. 项目地址： [https://github.com/QwenLM/Qwen](https://github.com/QwenLM/Qwen)\n2. 下载到本地\n`git clone  https://github.com/QwenLM/Qwen.git `\n3. 基础环境搭建\n`conda create -n qwen python=3.10`\n`conda activate qwen`\n4. 安装pytorch\n`conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia`\n5. 安装依赖环境\n`pip install -r requirements.txt `\n7. 7B模型下载\n`git clone [https://www.modelscope.cn/qwen/Qwen-7B-Chat.git](https://www.modelscope.cn/qwen/Qwen-7B-Chat.git)`\n在使用sdk的python脚本下载权重时，需要pip安装modelscope\n`pip install modelscope`\n使用git clone发现权重未下载成功，使用modelscope官方sdk脚本下载。\n将以下代码写入download.py文件中，并执行`python download.py`\n```python\n#模型下载\nfrom modelscope import snapshot_download\nmodel_dir = snapshot_download('qwen/Qwen-7B-Chat', cache_dir='/opt/tmp/Qwen', revision='v1.1.9')\n```\n8. 数据集下载\n进入modelscope下载数据集\n`https://modelscope.cn/datasets/Robin021/DISC-Law-SFT/files`\n9. 数据格式处理\n数据集处理后会生成train_data_law.json文件\n`head -n 20 train_data_law.json`\n处理之后的数据格式如下：\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/qwen/qwen1.png)\n```python\nimport json\n# 读取以.jsonl结尾的文件\njson_data = []\nwith open('/opt/tmp/Qwen/dataset/DISC-Law-SFT-Triplet-released.jsonl', 'r', encoding='utf-8') as file:\n    for line in file:\n        data = json.loads(line)\n        json_data.append(data)\n# 待填入的模板\ntemplate = []\n\n# 遍历json数据集\nfor idx, data in enumerate(json_data[:]):\n    conversation = [\n        {\n            \"from\":\"user\",\n            \"value\": data[\"input\"]\n        },\n        {\n            \"from\": \"assistant\",\n            \"value\": data[\"output\"]\n        }\n    ]\n    template.append({\n        \"id\": f\"identity_{idx}\",\n        \"conversations\": conversation\n    })\nprint(len(template))\n# 输出填充数据后的模板\nprint(json.dumps(template[2], ensure_ascii=False, indent=2))\n# 将template写入到本地文件\noutput_file_path = \"/opt/tmp/Qwen/train_data_law.json\"\nwith open(output_file_path, 'w', encoding='utf-8') as f:\n    json.dump(template, f, ensure_ascii=False, indent=2)\nprint(f\"处理好的数据已写入到本地文件: {output_file_path}\")\n```\n10. 训练依赖安装\ndeepspeed安装\n`pip install \"peft<0.8.0\" deepspeed`\n11. 修改模型微调脚本参数\n修改MODEL和DATA的路径，及per_device_train_batch_size\n```bash\n#!/bin/bash\nexport CUDA_DEVICE_MAX_CONNECTIONS=1\n\nMODEL=\"/opt/tmp/Qwen/Qwen-7B-Chat\" # Set the path if you do not want to load from huggingface directly\n# ATTENTION: specify the path to your training data, which should be a json file consisting of a list of conversations.\n# See the section for finetuning in README for more information.\nDATA=\"/opt/tmp/Qwen/train_data_law.json\"\n\nfunction usage() {\n    echo '\nUsage: bash finetune/finetune_lora_single_gpu.sh [-m MODEL_PATH] [-d DATA_PATH]\n'\n}\n\nwhile [[ \"$1\" != \"\" ]]; do\n    case $1 in\n        -m | --model )\n            shift\n            MODEL=$1\n            ;;\n        -d | --data )\n            shift\n            DATA=$1\n            ;;\n        -h | --help )\n            usage\n            exit 0\n            ;;\n        * )\n            echo \"Unknown argument ${1}\"\n            exit 1\n            ;;\n    esac\n    shift\ndone\n\nexport CUDA_VISIBLE_DEVICES=0\n\npython finetune.py \\\n  --model_name_or_path $MODEL \\\n  --data_path $DATA \\\n  --bf16 False \\\n  --output_dir output_qwen \\\n  --num_train_epochs 5 \\\n  --per_device_train_batch_size 2 \\\n  --per_device_eval_batch_size 1 \\\n  --gradient_accumulation_steps 8 \\\n  --evaluation_strategy \"no\" \\\n  --save_strategy \"steps\" \\\n  --save_steps 100 \\\n  --save_total_limit 10 \\\n  --learning_rate 3e-4 \\\n  --weight_decay 0.1 \\\n  --adam_beta2 0.95 \\\n  --warmup_ratio 0.01 \\\n  --lr_scheduler_type \"cosine\" \\\n  --logging_steps 1 \\\n  --report_to \"none\" \\\n  --model_max_length 512 \\\n  --lazy_preprocess True \\\n  --gradient_checkpointing \\\n  --use_lora\n\n# If you use fp16 instead of bf16, you should use deepspeed\n# --fp16 True --deepspeed finetune/ds_config_zero2.json\n```\n\n12. 开启单机单卡训练\n`bash finetune/finetune_lora_single_gpu.sh`\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/qwen/qwen2.png)\n13. 单机多卡训练（在分配的3号机器上执行）\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/qwen/qwen3.png)\ngpu显存利用情况\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/qwen/qwen4.png)\n\n\n\n","tags":["模型训练调优","Nvidia","Qwen","V100"],"categories":["模型训练调优","NVIDIA"]},{"title":"1.2-Qwen模型镜像制作","url":"/2025/11/06/模型训练调优/NVIDIA/Qwen/1.2-Qwen模型镜像制作/","content":"由于新机器挂载文件存储速度非常慢，通过dockerfile文件来直接生成镜像非常慢，所以本镜像在自己的V100云主机中进行打包。\n### 1. 首先docker pull拉取一个ubuntu基础环境\n[https://hub.docker.com/r/nvidia/cuda/tags?page=11&page_size=&name=&ordering=](https://hub.docker.com/r/nvidia/cuda/tags?page=11&page_size=&name=&ordering=)\n`docker pull nvidia/cuda:12.2.2-cudnn8-devel-ubuntu22.04`\n### 2. 安装nvidia-container-toolkit，使docker可以调用宿主机gpu资源\n  #### 2.1 下载nvidia-container-toolkit\n `distribution=$(. /etc/os-release;echo $ID$VERSION_ID) && \\ curl -fsSL [https://nvidia.github.io/libnvidia-container/gpgkey](https://nvidia.github.io/libnvidia-container/gpgkey) | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg && \\ curl -s -L [https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list](https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list) | sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list`\n  #### 2.2 安装nvidia-container-toolkit\n  `sudo apt-get update && sudo apt-get install -y nvidia-container-toolkit`\n  #### 2.3 添加nvidia-docker源\n  `curl -s -L [https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list](https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list) |   sudo tee /etc/apt/sources.list.d/nvidia-docker.list`\n  #### 2.4 更新并重新执行安装\n  `sudo apt-get update && sudo apt-get install -y nvidia-container-toolkit`\n如果执行过程中报W: GPG error: [https://nvidia.github.io/libnvidia-container/stable/ubuntu18.04/amd64](https://nvidia.github.io/libnvidia-container/stable/ubuntu18.04/amd64)  InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY DDCAE044F796ECB0，则需要确认你的系统是否信任NVIDIA的GPG密钥。如果没有，你需要导入它。可以通过以下命令导入GPG密钥：\n`curl -s [https://nvidia.github.io/libnvidia-container/gpgkey](https://nvidia.github.io/libnvidia-container/gpgkey) | sudo apt-key add -`\n  #### 2.5 完成 nvidia-container-toolkit 的安装之后，我们继续执行 nvidia-ctk runtime configure 命令，为 Docker 添加 nvidia 这个运行时。完成后，我们的应用就能在容器中使用显卡资源了\n  `sudo nvidia-ctk runtime configure --runtime=docker`\n\n  ![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/qwen/qwen5.png)\n  #### 2.6 重启docker\n  `sudo systemctl restart docker`\n  #### 2.7 查看是否安装成功  \n  `dpkg -l | grep nvidia-container-toolkit`\n\n  ![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/qwen/qwen6.png)\n\n### 3. 拉取基础镜像成功后，创建一个docker容器\n`docker images`\n`sudo docker run -it --name qwen --gpus all nvidia/cuda:12.2.2-cudnn8-devel-ubuntu22.04`\n`exit`\n#### 4. 退出容器后，将本地跑同的qwen模型代码/权重/数据集/环境cp到创建的qwen镜像中\n`docker cp /opt/tmp/Qwen/ 02649afd9710:/qwen`\n#### 5. 重启docker，exec执行\n`docker ps -a`\n`docker start qwen`\n`docker exec -it 02649afd9710 bash`\n#### 6. 因为想在容器中执行自身的python环境，不借用宿主机的环境，所以需要单独再安装conda、pytorch等环境。\n#### 7. 安装完基础环境后，需要安装qwen模型的依赖\n`pip install -r requirements.txt`\n#### 8. 没有vim编辑器还需安装vim\n`apt-get update`\n`apt-get install -y vim`\n#### 9. deepspeed安装\n`pip install \"peft<0.8.0\" deepspeed`\n#### 10. 此时在qwen容器中执行训练脚本，拉起训练。\n`bash finetune/finetune_lora_single_gpu.sh`\n#### 11. 将此时qwen容器打成镜像\n`docker commit -a \"wangxiangbo\" -m \"qwen 7B\" 02649afd9710 qwen-7b:v1.0`\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/qwen/qwen7.png)\n#### 12. 将打好的镜像转成tar包，供新机器解压使用\n`docker save -o qwen-7b.tar qwen-7b:v1.0`\n#### 13. 加载tar镜像, 使用load进行从tar文件导出镜像\n`docker load -i qwen-7b.tar`\n#### 14. 由于新机器挂载文件存储的原因，镜像解压速度太慢，于是打算将打好的qwen镜像push到阿里云个人仓库中，在新机器中直接pull该镜像。\n#### 15. 将镜像推送到Registry\n`docker login --username=aliyun9599911612 registry.cn-shanghai.aliyuncs.com`\n`docker tag 37c7b97b67f6 registry.cn-shanghai.aliyuncs.com/aliyun_repository_wxb/repository_wxb:v1.0`\n`docker push registry.cn-shanghai.aliyuncs.com/aliyun_repository_wxb/repository_wxb:v1.0`\n#### 16. 在3号机器中，拉取该镜像\n`docker pull registry.cn-shanghai.aliyuncs.com/aliyun_repository_wxb/repository_wxb:v1.0`\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/qwen/qwen8.png)\n#### 17. 通过该镜像，run一个容器\n`docker run -it --name qwen --gpus all registry.cn-shanghai.aliyuncs.com/aliyun_repository_wxb/repository_wxb:v1.0 bash`\n\n","tags":["模型训练调优","Nvidia","Qwen","V100"],"categories":["模型训练调优","NVIDIA"]},{"title":"1.3-基于docker的Qwen单机单卡_多卡训练","url":"/2025/11/06/模型训练调优/NVIDIA/Qwen/1.3-基于docker的Qwen单机单卡_多卡训练/","content":"### 1. 查看容器\n`docker ps`\n### 2. exec进入容器\n`docker exec -it containerid bash`\n### 3. 进入qwen目录并修改finetune_lora_single_gpu.sh参数\n```bash\n#!/bin/bash\nexport CUDA_DEVICE_MAX_CONNECTIONS=1\n\nMODEL=\"/qwen/Qwen-7B-Chat\" # Set the path if you do not want to load from huggingface directly\n# ATTENTION: specify the path to your training data, which should be a json file consisting of a list of conversations.\n# See the section for finetuning in README for more information.\nDATA=\"/qwen/train_data_law.json\"\n\nfunction usage() {\n    echo '\nUsage: bash finetune/finetune_lora_single_gpu.sh [-m MODEL_PATH] [-d DATA_PATH]\n'\n}\n\nwhile [[ \"$1\" != \"\" ]]; do\n    case $1 in\n        -m | --model )\n            shift\n            MODEL=$1\n            ;;\n        -d | --data )\n            shift\n            DATA=$1\n            ;;\n        -h | --help )\n            usage\n            exit 0\n            ;;\n        * )\n            echo \"Unknown argument ${1}\"\n            exit 1\n            ;;\n    esac\n    shift\ndone\n\nexport CUDA_VISIBLE_DEVICES=0\n\npython finetune.py \\\n  --model_name_or_path $MODEL \\\n  --data_path $DATA \\\n  --bf16 True \\\n  --output_dir output_qwen \\\n  --num_train_epochs 5 \\\n  --per_device_train_batch_size 1 \\\n  --per_device_eval_batch_size 1 \\\n  --gradient_accumulation_steps 8 \\\n  --evaluation_strategy \"no\" \\\n  --save_strategy \"steps\" \\\n  --save_steps 100 \\\n  --save_total_limit 10 \\\n  --learning_rate 3e-4 \\\n  --weight_decay 0.1 \\\n  --adam_beta2 0.95 \\\n  --warmup_ratio 0.01 \\\n  --lr_scheduler_type \"cosine\" \\\n  --logging_steps 1 \\\n  --report_to \"none\" \\\n  --model_max_length 512 \\\n  --lazy_preprocess True \\\n  --gradient_checkpointing \\\n  --use_lora\n\n# If you use fp16 instead of bf16, you should use deepspeed\n# --fp16 True --deepspeed finetune/ds_config_zero2.json\n```\n### 4. 执行finetune_lora_single_gpu.sh单机单卡\n### 5. 修改finetune_lora_ds.sh参数\n```bash\n#!/bin/bash\nexport CUDA_DEVICE_MAX_CONNECTIONS=1\nDIR=`pwd`\n\n# Guide:\n# This script supports distributed training on multi-gpu workers (as well as single-worker training).\n# Please set the options below according to the comments.\n# For multi-gpu workers training, these options should be manually set for each worker.\n# After setting the options, please run the script on each worker.\n\n# Number of GPUs per GPU worker\nGPUS_PER_NODE=$(python -c 'import torch; print(torch.cuda.device_count())')\n\n# Number of GPU workers, for single-worker training, please set to 1\nNNODES=${NNODES:-1}\n\n# The rank of this worker, should be in {0, ..., WORKER_CNT-1}, for single-worker training, please set to 0\nNODE_RANK=${NODE_RANK:-0}\n\n# The ip address of the rank-0 worker, for single-worker training, please set to localhost\nMASTER_ADDR=${MASTER_ADDR:-localhost}\n\n# The port for communication\nMASTER_PORT=${MASTER_PORT:-6001}\n\nMODEL=\"/qwen/Qwen-7B-Chat\" # Set the path if you do not want to load from huggingface directly\n# ATTENTION: specify the path to your training data, which should be a json file consisting of a list of conversations.\n# See the section for finetuning in README for more information.\nDATA=\"/qwen/train_data_law.json\"\nDS_CONFIG_PATH=\"finetune/ds_config_zero2.json\"\n\nfunction usage() {\n    echo '\nUsage: bash finetune/finetune_lora_ds.sh [-m MODEL_PATH] [-d DATA_PATH] [--deepspeed DS_CONFIG_PATH]\n'\n}\n\nwhile [[ \"$1\" != \"\" ]]; do\n    case $1 in\n        -m | --model )\n            shift\n            MODEL=$1\n            ;;\n        -d | --data )\n            shift\n            DATA=$1\n            ;;\n        --deepspeed )\n            shift\n            DS_CONFIG_PATH=$1\n            ;;\n        -h | --help )\n            usage\n            exit 0\n            ;;\n        * )\n            echo \"Unknown argument ${1}\"\n            exit 1\n            ;;\n    esac\n    shift\ndone\n\nDISTRIBUTED_ARGS=\"\n    --nproc_per_node $GPUS_PER_NODE \\\n    --nnodes $NNODES \\\n    --node_rank $NODE_RANK \\\n    --master_addr $MASTER_ADDR \\\n    --master_port $MASTER_PORT\n\"\n#export CUDA_VISIBLE_DEVICES=2,3\n\ntorchrun $DISTRIBUTED_ARGS finetune.py \\\n    --model_name_or_path $MODEL \\\n    --data_path $DATA \\\n    --bf16 False \\\n    --output_dir output_qwen \\\n    --num_train_epochs 5 \\\n    --per_device_train_batch_size 2 \\\n    --per_device_eval_batch_size 1 \\\n    --gradient_accumulation_steps 8 \\\n    --evaluation_strategy \"no\" \\\n    --save_strategy \"steps\" \\\n    --save_steps 100 \\\n    --save_total_limit 10 \\\n    --learning_rate 3e-4 \\\n    --weight_decay 0.1 \\\n    --adam_beta2 0.95 \\\n    --warmup_ratio 0.01 \\\n    --lr_scheduler_type \"cosine\" \\\n    --logging_steps 1 \\\n    --report_to \"none\" \\\n    --model_max_length 512 \\\n    --lazy_preprocess True \\\n    --use_lora \\\n    --gradient_checkpointing \\\n    --deepspeed ${DS_CONFIG_PATH}\n\n```\n### 6. 修改deepspeed中ds_config_zero2.json配置文件，增加TFlops显示\n其中具体增加的参数配置为flops_profiler\n```json\n\"flops_profiler\": {\n        \"enabled\": true,\n        \"profile_step\": 1,\n        \"module_depth\": -1,\n        \"top_modules\": 1,\n        \"detailed\": false,\n        \"output_file\": null\n    },\n```\n```json\n{\n    \"fp16\": {\n        \"enabled\": \"auto\",\n        \"loss_scale\": 0,\n        \"loss_scale_window\": 1000,\n        \"initial_scale_power\": 16,\n        \"hysteresis\": 2,\n        \"min_loss_scale\": 1\n    },\n    \"bf16\": {\n        \"enabled\": \"auto\"\n    },\n    \"optimizer\": {\n        \"type\": \"AdamW\",\n        \"params\": {\n            \"lr\": \"auto\",\n            \"betas\": \"auto\",\n            \"eps\": \"auto\",\n            \"weight_decay\": \"auto\"\n        }\n    },\n\n    \"scheduler\": {\n        \"type\": \"WarmupLR\",\n        \"params\": {\n            \"warmup_min_lr\": \"auto\",\n            \"warmup_max_lr\": \"auto\",\n            \"warmup_num_steps\": \"auto\"\n        }\n    },\n\n    \"zero_optimization\": {\n        \"stage\": 2,\n        \"offload_optimizer\": {\n            \"device\": \"none\",\n            \"pin_memory\": true\n        },\n        \"allgather_partitions\": true,\n        \"allgather_bucket_size\": 2e8,\n        \"overlap_comm\": true,\n        \"reduce_scatter\": true,\n        \"reduce_bucket_size\": 2e8,\n        \"contiguous_gradients\": true\n    },\n\n    \"flops_profiler\": {\n        \"enabled\": true,\n        \"profile_step\": 1,\n        \"module_depth\": -1,\n        \"top_modules\": 1,\n        \"detailed\": false,\n        \"output_file\": null\n    },\n\n    \"gradient_accumulation_steps\": \"auto\",\n    \"gradient_clipping\": \"auto\",\n    \"steps_per_print\": 100,\n    \"train_batch_size\": \"auto\",\n    \"train_micro_batch_size_per_gpu\": \"auto\",\n    \"wall_clock_breakdown\": false\n}\n\n```\n### 7. 执行finetune_lora_ds.sh单机多卡训练\n其中报了Error while creating shared memory segment /dev/shm/nccl-KXWrmA (size 9637888)导致在docker中单机多卡拉起失败\n问题原因：docker的shm共享内存不足，可以通过命令\n`df -h | grep shm`查看当前容器的shm大小，默认为64M，这是远远不够的，所以要增加该容器的shm共享内存大小。参考博文[https://blog.csdn.net/gg864461719/article/details/112466585](https://blog.csdn.net/gg864461719/article/details/112466585)\n#### 解决方法1：创建完容器之后，手动修改shm共享内存大小\n##### a. 首先要关闭docker, 否则下面的操作步骤会无效.\n`service docker stop`\n##### b. 进入宿主机中/docker/containers/容器id 修改该容器的hostconfig.json文件，把其中的ShmSize的大小后面增加22（就变为了6.3G）其默认的是67108864_KB_ 就约等于64M。\n##### c. 重启docker服务\n`systemctl start docker`\n##### d. 解决完之后，重新查看shm的共享内存大小，此时已经变为了6.3G\n#### 解决方法2：在通过镜像run容器时，就直接指定--shm-size 6G\n`docker run -it --name qwen --gpus all --shm-size 6G registry.cn-shanghai.aliyuncs.com/aliyun_repository_wxb/repository_wxb:v1.0 bash`\n### 重新拉起训练\n`bash finetune/finetune_lora_ds.sh`\n其中tflops在9.5~10.5之间\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/qwen/qwen9.png)\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/qwen/qwen10.png)\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/qwen/qwen11.png)\n\n","tags":["模型训练调优","Nvidia","Qwen","V100"],"categories":["模型训练调优","NVIDIA"]},{"title":"1.5-Qwen多机多卡调优","url":"/2025/11/06/模型训练调优/NVIDIA/Qwen/1.5-Qwen多机多卡调优/","content":"### 1. lora\n#### 1.1 per_device_train_batch_size测试，最优为16\n\n| per_device_train_batch_size | per_device_eval_batch_size | model_max_length | gradient_accumulation_steps | bf16 | tflops |\n| --- | --- | --- | --- | --- | --- |\n| 2 | 1 | 512 | 8 | true | 8.37 |\n| 4 | 1 | 512 | 8 | true | 9.07 |\n| 8 | 1 | 512 | 8 | true | 9.88 |\n| **16** | **1** | **512** | **8** | **true** | **10.32** |\n| 32 | 1 | 512 | 8 | true | OOM |\n\n\n单个GPU批次大小增加时，需要的内存也会增加，GPU内存不足以支持更大的批次，可能会导致溢出或效率降低。\n\n#### 1.2 per_device_eval_batch_size测试，最优为2\n\n| per_device_train_batch_size | per_device_eval_batch_size | model_max_length | gradient_accumulation_steps | bf16 | tflops |\n| --- | --- | --- | --- | --- | --- |\n| 16 | 1 | 512 | 8 | true | 10.32 |\n| **16** | **2** | **512** | **8** | **true** | **10.33** |\n| 16 | 4 | 512 | 8 | true | 10.26 |\n\n\n#### 1.3 model_max_length测试，最优为512\n\n| per_device_train_batch_size | per_device_eval_batch_size | model_max_length | gradient_accumulation_steps | bf16 | flops |\n| --- | --- | --- | --- | --- | --- |\n| 16 | 2 | 128 | 8 | true | 8.95 |\n| 16 | 2 | 256 | 8 | true | 9.56 |\n| **16** | **2** | **512** | **8** | **true** | **10.33** |\n| 16 | 2 | 1024 | 8 | true | OOM |\n\n\n#### 1.4 gradient_accumulation_steps测试，最优为16\n\n| per_device_train_batch_size | per_device_eval_batch_size | model_max_length | gradient_accumulation_steps | bf16 | tflops |\n| --- | --- | --- | --- | --- | --- |\n| 16 | 2 | 512 | 1 | true | 9.07 |\n| 16 | 2 | 512 | 2 | true | 9.24 |\n| 16 | 2 | 512 | 4 | true | 9.89 |\n| 16 | 2 | 512 | 8 | true | 10.33 |\n| **16** | **2** | **512** | **16** | **true** | **11.63** |\n\n\n#### 1.5 开启Fp16测试\n\n| per_device_train_batch_size | per_device_eval_batch_size | model_max_length | gradient_accumulation_steps | fp16 | tflops |\n| --- | --- | --- | --- | --- | --- |\n| **16** | **2** | **512** | **16** | **true** | **67.13** |\n\n\n#### 1.6 关闭gradient_checkpointing\n\n| per_device_train_batch_size | per_device_eval_batch_size | model_max_length | gradient_accumulation_steps | fp16 | gradient_checkpointing | tflops |\n| --- | --- | --- | --- | --- | --- | --- |\n| **16** | **2** | **512** | **16** | **true** | **true** | **67.13** |\n| 16 | 2 | 512 | 16 | true | false | OOM |\n\n\n| 参数配置 | per_device_train_batch_size | per_device_eval_batch_size | model_max_length | gradient_accumulation_steps | bf16/fp16 | gradient_checkpointing | tflops |\n| --- | --- | --- | --- | --- | --- | --- | --- |\n| 默认 | 2 | 1 | 512 | 8 | bf16 | **true** | 8.32 |\n| 调优后 | **<font style=\"color:#DF2A3F;\">16</font>** | **<font style=\"color:#DF2A3F;\">2</font>** | **<font style=\"color:#DF2A3F;\">512</font>** | **<font style=\"color:#DF2A3F;\">16</font>** | **<font style=\"color:#DF2A3F;\">fp16</font>** | **<font style=\"color:#DF2A3F;\">true</font>** | **<font style=\"color:#DF2A3F;\">67.13</font>** |\n\n\n基于2机8卡的V100，Qwen-7B模型的lora微调训练中（采用deepspeed的zero2的内存优化并行方式），Tflops的值最高为<font style=\"color:#DF2A3F;\">67.13</font>**（8.32）\n\n最佳参数配置（per_device_train_batch_size：16，per_device_eval_batch_size：2，model_max_length：512，gradient_accumulation_steps：16，Fp16精度，gradient_checkpointing：True）\n\n### 2. qlora\n\nqlora使用4比特量化模型以及paged attention等技术实现更小的显存开销\n\n#### 2.1 per_device_train_batch_size测试，最优为32\n\n| per_device_train_batch_size | per_device_eval_batch_size | model_max_length | gradient_accumulation_steps | fp16 | tflops |\n| --- | --- | --- | --- | --- | --- |\n| 2 | 1 | 512 | 8 | true | 31.71 |\n| 4 | 1 | 512 | 8 | true | 42.91 |\n| 8 | 1 | 512 | 8 | true | 51.14 |\n| 16 | 1 | 512 | 8 | true | 55.75 |\n| **32** | **1** | **512** | **8** | **true** | **58.44** |\n| 64 | 1 | 512 | 8 | true | OOM |\n\n\n#### 2.2 per_device_eval_batch_size测试，最优为4\n\n| per_device_train_batch_size | per_device_eval_batch_size | model_max_length | gradient_accumulation_steps | fp16 | tflops |\n| --- | --- | --- | --- | --- | --- |\n| 32 | 1 | 512 | 8 | true | 58.44 |\n| 32 | 2 | 512 | 8 | true | 58.84 |\n| **32** | **4** | **512** | **8** | **true** | **59.05** |\n| 32 | 8 | 512 | 8 | true | 58.42 |\n\n\n#### 2.3 model_max_length测试，最优为512\n\n| per_device_train_batch_size | per_device_eval_batch_size | model_max_length | gradient_accumulation_steps | fp16 | tflops |\n| --- | --- | --- | --- | --- | --- |\n| 32 | 4 | 128 | 8 | true | 48.68 |\n| 32 | 4 | 256 | 8 | true | 53.02 |\n| **32** | **4** | **512** | **8** | **true** | **59.05** |\n| 32 | 4 | 1024 | 8 | true | OOM |\n\n\n#### 2.4 gradient_accumulation_steps测试，最优为\n\n| per_device_train_batch_size | per_device_eval_batch_size | model_max_length | gradient_accumulation_steps | fp16 | tflops |\n| --- | --- | --- | --- | --- | --- |\n| 32 | 4 | 512 | 1 | true | 52.66 |\n| 32 | 4 | 512 | 2 | true | 52.18 |\n| 32 | 4 | 512 | 4 | true | 54.99 |\n| 32 | 4 | 512 | 8 | true | 59.05 |\n| 32 | 4 | 512 | 16 | true | 64.26 |\n| 32 | 4 | 512 | 32 | true | 80.37 |\n| **32** | **4** | **512** | **64** | **true** | **103.89** |\n\n\n#### 2.5 开启BF16测试\n\n| per_device_train_batch_size | per_device_eval_batch_size | model_max_length | gradient_accumulation_steps | bf16/fp16 | tflops |\n| --- | --- | --- | --- | --- | --- |\n| 32 | 4 | 512 | 64 | bf16 | 14.23 |\n| **32** | **4** | **512** | **64** | **fp16** | **103.89** |\n\n\n#### 2.6 关闭gradient_checkpointing\n\n| gradient_checkpointing | per_device_train_batch_size | per_device_eval_batch_size | model_max_length | gradient_accumulation_steps | fp16 | tflops |\n| --- | --- | --- | --- | --- | --- | --- |\n| **<font style=\"color:#000000;\">True</font>** | **<font style=\"color:#000000;\">32</font>** | **<font style=\"color:#000000;\">4</font>** | **<font style=\"color:#000000;\">512</font>** | **<font style=\"color:#000000;\">64</font>** | **<font style=\"color:#000000;\">true</font>** | **<font style=\"color:#000000;\">103.89</font>** |\n| False | 32 | 4 | 512 | 64 | true | OOM |\n\n\nDeepSpeed ZeRO 3 对节点间通信速率的要求远大于 ZeRO 2，在多机微调的情况下会大幅降低训练速度。因此，我们不建议在多机微调的情况下使用 DeepSpeed ZeRO 3 配置。\n\n| 参数配置 | per_device_train_batch_size | per_device_eval_batch_size | model_max_length | gradient_accumulation_steps | fp16 | tflops |\n| --- | --- | --- | --- | --- | --- | --- |\n| 默认 | 2 | 1 | 512 | 8 | true | 31.71 |\n| 调优后 | **<font style=\"color:#DF2A3F;\">32</font>** | **<font style=\"color:#DF2A3F;\">4</font>** | **<font style=\"color:#DF2A3F;\">512</font>** | **<font style=\"color:#DF2A3F;\">64</font>** | **<font style=\"color:#DF2A3F;\">true</font>** | **<font style=\"color:#DF2A3F;\">103.89</font>** |\n\n\n基于2机8卡的V100，Qwen-7B模型的qlora微调训练中（采用deepspeed的zero2的内存优化并行方式），Tflops的值最高为<font style=\"color:#DF2A3F;\">103.89 </font>\n\n默认参数配置\n\n最佳参数配置（gradient_checkpointing：True，per_device_train_batch_size：32，per_device_eval_batch_size：4，model_max_length：512，gradient_accumulation_steps：64，Fp16精度）\n\nqlora在拉起训练时，需要对模型权重进行INT-4量化，会损失掉权重小数部分精度，量化后的权重由于使用更少的位数来表示，存储上比原始权重高效，在拉起模型训练过程过中tflops有明显提升。\n\n","tags":["模型训练调优","Nvidia","Qwen","V100"],"categories":["模型训练调优","NVIDIA"]},{"title":"1.4-基于k8s拉起Qwen模型的多机多卡微调","url":"/2025/11/06/模型训练调优/NVIDIA/Qwen/1.4-基于k8s拉起Qwen模型的多机多卡微调/","content":"一、镜像准备\n### 1. 查看镜像\n`docker images`\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/qwen/qwen12.png)\n### 2. 修改镜像标签\n`docker tag ec99659d9677 registry.paas/library/qwen:v3.0`\n### 3. 将镜像推至仓库\n`docker push registry.paas/library/qwen:v3.0`\n### 4. 如果出现签名认证失败，需要修改docker守护进程配置文件\n`vim /etc/docker/daemon.json`\n增加如下配置：\n```json\n{\n\"insecure-registries\":[\"registry.paas\"]\n}\n```\n重启docker\n`systemctl daemon-reload && systemctl restart docker`\n### 5. 重新push至registry.paas/library/xxx:tags仓库\n二、修改配置文件\n### 1. qwentest.yaml\n```yaml\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: qwentest\nspec:\n  selector:\n    matchLabels:\n      app: qwentest\n  template:\n    metadata:\n      labels:\n        app: qwentest\n    spec:\n      hostNetwork: true\n      nodeSelector:\n        model: qwen-7b\n      containers:\n      - name: qwentest\n        image: registry.paas/library/qwen:v3.0\n        imagePullPolicy: IfNotPresent\n        resources:\n         limits:\n           nvidia.com/gpu: \"4\"\n         requests:\n           nvidia.com/gpu: \"4\"\n        command:                                  # training command, which can be modified\n              - \"/bin/bash\"\n              - \"-c\"\n                #- sleep 10000\n              - |\n                cd /mnt/ &&\n                cp setRank.sh /qwen/ &&\n                cd /qwen/ &&\n                chmod +x setRank.sh &&\n                bash setRank.sh &&\n                chmod +x finetune_lora_ds.sh &&\n                bash finetune_lora_ds.sh\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - name: processeddata\n          mountPath: /mnt\n        - name: dshm\n          mountPath: /dev/shm\n        - name: tmp-volume\n          mountPath: /tmp\n      volumes:\n      - name: processeddata\n        hostPath:\n          path: /mnt/users/wangxiangbo/runk8s\n      - name: dshm\n        emptyDir:\n          medium: Memory\n          sizeLimit: 1G\n      - name: tmp-volume\n        hostPath:\n          path: /tmp\n```\n### 2. hostfile\n```shell\n192.168.0.20\n192.168.0.58\n```\n### 3. setRank.sh\n```shell\n#!/bin/bash\n\nshell_name=\"finetune_lora_ds.sh\"\n\nshell_dir=\"/mnt/\"\n\nlocal_dir=\"/qwen/\"\n\n## 复制脚本到/qwen/下\ncp $shell_dir$shell_name $local_dir\n\n\n## 读取hostfile\nreadarray -t ips < <(grep -vE '^[[:space:]]*$' \"$shell_dir\"hostfile)\n\n## 获取rank0 IP\nrank0_ip=$(echo \"${ips[0]}\" | tr -d '[:space:]')\n\nnodes=${#ips[@]}\n\n## 获取hostfile中配置的IP前缀\n## 使用cut提取IP地址的前三个数字部分\nip_prefix=$(echo \"${ips[0]}\" | cut -d '.' -f 1-3)\n\n## 获取本机IP\nip=$(hostname -I | grep -oE \"$ip_prefix\\.[0-9]+\")\n\nls\n# 初始化rank\nnode_rank=-1\n\n# 遍历数组\nfor i in \"${!ips[@]}\"; do\n    # 使用tr命令去除空白字符\n    clean_string=$(echo \"${ips[$i]}\" | tr -d '[:space:]')\n    if [[ \"$clean_string\" == \"$ip\" ]]; then\n        node_rank=$i\n        break\n    fi\ndone\n\nif [ $node_rank -ne -1 ]; then\n    ## 修改脚本中MASTER_ADDR\n    sed -i \"s/^MASTER_ADDR=.*/MASTER_ADDR=$rank0_ip/\" $local_dir$shell_name\n\n    ## 修改NNODES\n    sed -i \"s/^NNODES=.*/NNODES=$nodes/\" $local_dir$shell_name\n\n    ## 修改NODE_RANK\n    sed -i \"s/^NODE_RANK=.*/NODE_RANK=$node_rank/\" $local_dir$shell_name\nfi\n\n```\n\n### 4. sh\n```shell\n#!/bin/bash\n/bin/bash -i <<'EOF'\nexport NCCL_IB_DISABLE=1\nexport NCCL_SOCKET_IFNAME=eth0\nexport NCCL_P2P_DISABLE=1\nexport NCCL_DEBUG=INFO\nsource ~/.bashrc\n\n. /opt/miniconda/etc/profile.d/conda.sh\nconda activate qwen\nexport CUDA_DEVICE_MAX_CONNECTIONS=1\nexport CUDA_VISIBLE_DEVICES=0,1,2,3\nDIR=`pwd`\n\n# Number of GPUs per GPU worker\nGPUS_PER_NODE=4\n# Number of GPU workers, for single-worker training, please set to 1\nNNODES=2\n# The rank of this worker, should be in {0, ..., WORKER_CNT-1}, for single-worker training, please set to 0\nNODE_RANK=0\n# The ip address of the rank-0 worker, for single-worker training, please set to localhost\nMASTER_ADDR=192.168.0.20\n# The port for communication\nMASTER_PORT=6003\n\nMODEL=\"/qwen/Qwen-7B-Chat\" # Set the path if you do not want to load from huggingface directly\n# ATTENTION: specify the path to your training data, which should be a json file consisting of a list of conversations.\n# See the section for finetuning in README for more information.\nDATA=\"/qwen/train_data_law.json\"\nDS_CONFIG_PATH=\"/qwen/finetune/ds_config_zero2.json\"\n\nfunction usage() {\n    echo '\nUsage: bash finetune_lora_ds.sh [-m MODEL_PATH] [-d DATA_PATH] [--deepspeed DS_CONFIG_PATH]\n'\n}\n\nwhile [[ \"$1\" != \"\" ]]; do\n    case $1 in\n        -m | --model )\n            shift\n            MODEL=$1\n            ;;\n        -d | --data )\n            shift\n            DATA=$1\n            ;;\n        --deepspeed )\n            shift\n            DS_CONFIG_PATH=$1\n            ;;\n        -h | --help )\n            usage\n            exit 0\n            ;;\n        * )\n            echo \"Unknown argument ${1}\"\n            exit 1\n            ;;\n    esac\n    shift\ndone\n\nDISTRIBUTED_ARGS=\"\n    --nproc_per_node $GPUS_PER_NODE \\\n    --nnodes $NNODES \\\n    --node_rank $NODE_RANK \\\n    --master_addr $MASTER_ADDR \\\n    --master_port $MASTER_PORT\n\"\n\ntorchrun $DISTRIBUTED_ARGS finetune.py \\\n    --model_name_or_path $MODEL \\\n    --data_path $DATA \\\n    --bf16 False \\\n    --output_dir output_qwen \\\n    --num_train_epochs 5 \\\n    --per_device_train_batch_size 8 \\\n    --per_device_eval_batch_size 1 \\\n    --gradient_accumulation_steps 8 \\\n    --evaluation_strategy \"no\" \\\n    --save_strategy \"steps\" \\\n    --save_steps 100 \\\n    --save_total_limit 10 \\\n    --learning_rate 3e-4 \\\n    --weight_decay 0.1 \\\n    --adam_beta2 0.95 \\\n    --warmup_ratio 0.01 \\\n    --lr_scheduler_type \"cosine\" \\\n    --logging_steps 1 \\\n    --report_to \"none\" \\\n    --model_max_length 512 \\\n    --lazy_preprocess True \\\n    --use_lora \\\n    --gradient_checkpointing \\\n    --ddp_find_unused_parameters False \\\nEOF\n\n```\n三、拉起训练（3号和4号两机8卡）\n### 1. 切换到1号机器master节点上，给带训练得3号和4号机器打上标签\n`kubectl label nodes ecs-jhjs-1234-003 model=qwen-7b`\n`kubectl label nodes ecs-jhjs-1234-004 model=qwen-7b`\n### 2. 准备好启动脚本等文件后，在master节点1号机器上，利用修改好的qwentest.yaml文件拉起训练任务\n### 3. `kubectl apply -f qwentest.yaml`\n### 4. 通过kubectl查看pod节点启动信息\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/qwen/qwen13.png)\n### 5. 查看两个节点pod的logs日志\n`kubectl logs qwentest-czm8n -f`\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/qwen/qwen14.png)\n`kubectl logs qwentest-qthsf -f`\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/qwen/qwen15.png)\n\n","tags":["模型训练调优","Nvidia","Qwen","V100"],"categories":["模型训练调优","NVIDIA"]},{"title":"基于Modellink的llama2-7b和Mistral-7b模型微调","url":"/2025/11/06/模型训练调优/昇腾/Modellink/llama2-7B+Mistral-7B/","content":"## 基于docker的mistral-7B微调\n### 容器挂载\n```bash\nsudo docker run -dit --ipc=host --net=host \\\n--name=modellink_wxb \\\n--device=/dev/davinci0 \\\n--device=/dev/davinci1 \\\n--device=/dev/davinci2 \\\n--device=/dev/davinci3 \\\n--device=/dev/davinci4 \\\n--device=/dev/davinci5 \\\n--device=/dev/davinci6 \\\n--device=/dev/davinci7 \\\n--device=/dev/davinci_manager \\\n--device=/dev/devmm_svm \\\n--device=/dev/hisi_hdc \\\n-v /etc/ascend_install.info:/etc/ascend_install.info \\\n-v /etc/hccn.conf:/etc/hccn.conf \\\n-v /etc/localtime:/etc/localtime \\\n-v /var/log/npu/:/usr/slog \\\n-v /usr/local/sbin/npu-smi:/usr/local/sbin/npu-smi \\\n-v /usr/local/Ascend/driver:/usr/local/Ascend/driver \\\n-v /reason-sharedata/training_inference/wangxiangbo/modellink/code/Modellink:/job/code \\\n-v /reason-sharedata/training_inference/wangxiangbo/modellink/data:/job/data \\\n-v /reason-sharedata/training_inference/wangxiangbo/modellink/output:/job/output \\\n-v /mnt/weight-1:/job/mnt \\\nregistry.paas/cmss/modellink-cann8.0-torch2.1-mindspeed-0.7:v1.0 \\\n/bin/bash\n```\n\n### 权重转换\n```bash\n# 修改 ascend-toolkit 路径\nsource /usr/local/Ascend/ascend-toolkit/set_env.sh\n```\n\n```bash\npython  tools/checkpoint/convert_ckpt.py \\\n    --model-type GPT \\\n    --loader llama2_hf \\\n    --saver megatron \\\n    --load-dir /job/mnt/huggingface/mistral-7b-hf/ \\\n    --save-dir /job/data/megatron/mistral-7b-tp4-pp2 \\\n    --tokenizer-model /job/mnt/huggingface/mistral-7b-hf/tokenizer.model \\\n    --target-tensor-parallel-size 4 \\\n    --target-pipeline-parallel-size 2\n```\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Modellink/image1.png)\n\n### 数据集\n#### 下载\n```bash\nsudo wget https://hf-mirror.com/datasets/silk-road/alpaca-data-gpt4-chinese/resolve/main/Alpaca_data_gpt4_zh.jsonl\n```\n\n#### 处理\n```bash\npython tools/preprocess_data.py \\\n    --input /job/data/dataset/mistral/Alpaca_data_gpt4_zh.jsonl \\\n    --output-prefix /job/data/dataset/mistral/Alpaca_finetune/ \\\n    --tokenizer-type PretrainedFromHF \\\n    --tokenizer-name-or-path /job/mnt/huggingface/mistral-7b-hf/ \\\n    --append-eod \\\n    --tokenizer-not-use-fast \\\n    --handler-name GeneralInstructionHandler \\\n    --workers 4\n```\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Modellink/image2.png)\n\n处理完成\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Modellink/image3.png)\n\n### 微调\n#### 微调脚本\n```bash\n#!/bin/bash\nexport CUDA_DEVICE_MAX_CONNECTIONS=1\nexport PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n\nGPUS_PER_NODE=8\nMASTER_ADDR=localhost\nMASTER_PORT=6006\nNNODES=1\nNODE_RANK=0\nWORLD_SIZE=$(($GPUS_PER_NODE * $NNODES))\n\nDISTRIBUTED_ARGS=\"\n    --nproc_per_node $GPUS_PER_NODE \\\n    --nnodes $NNODES \\\n    --node_rank $NODE_RANK \\\n    --master_addr $MASTER_ADDR \\\n    --master_port $MASTER_PORT\n\"\n\necho \"NODE_RANK ${NODE_RANK}\"\n\nDATA_PATH=\"/job/data/dataset/mistral/Alpaca_finetune/\"\nTOKENIZER_MODEL=\"/job/mnt/huggingface/mistral-7b-hf\"\nCKPT_SAVE_DIR=\"/job/output/mistral_ckpt/\"\nCKPT_LOAD_DIR=\"/job/data/megatron/mistral-7b-tp4-pp2/\"\n\n\nTP=4\nPP=2\nNUM_LAYERS=32\n\nGPT_ARGS=\"\n    --tensor-model-parallel-size ${TP} \\\n    --pipeline-model-parallel-size ${PP} \\\n    --sequence-parallel \\\n    --sliding-window 4096 \\\n    --num-layers ${NUM_LAYERS} \\\n    --hidden-size 4096 \\\n    --ffn-hidden-size 14336 \\\n    --num-attention-heads 32 \\\n    --group-query-attention \\\n    --num-query-groups 8 \\\n    --tokenizer-type PretrainedFromHF \\\n    --tokenizer-name-or-path ${TOKENIZER_MODEL} \\\n    --seq-length 32768 \\\n    --max-position-embeddings 32768 \\\n    --micro-batch-size 1 \\\n    --global-batch-size 32 \\\n    --make-vocab-size-divisible-by 1 \\\n    --lr 1.25e-6 \\\n    --train-iters 1000 \\\n    --lr-decay-style cosine \\\n    --untie-embeddings-and-output-weights \\\n    --disable-bias-linear \\\n    --attention-dropout 0.0 \\\n    --init-method-std 0.01 \\\n    --hidden-dropout 0.0 \\\n    --position-embedding-type rope \\\n    --normalization RMSNorm \\\n    --use-fused-rmsnorm \\\n    --use-fused-swiglu \\\n    --use-rotary-position-embeddings \\\n    --use-fused-rotary-pos-emb \\\n    --use-mc2 \\\n    --swiglu \\\n    --use-flash-attn \\\n    --no-masked-softmax-fusion \\\n    --attention-softmax-in-fp32 \\\n    --min-lr 1.25e-7 \\\n    --weight-decay 1e-1 \\\n    --lr-warmup-fraction 0.01 \\\n    --clip-grad 1.0 \\\n    --adam-beta1 0.9 \\\n    --initial-loss-scale 65536 \\\n    --adam-beta2 0.95 \\\n    --no-gradient-accumulation-fusion \\\n    --no-load-optim \\\n    --no-load-rng \\\n    --use-distributed-optimizer \\\n    --overlap-grad-reduce \\\n    --load ${CKPT_LOAD_DIR} \\\n    --save ${CKPT_SAVE_DIR} \\\n    --bf16 \\\n    --finetune \\\n    --is-instruction-dataset \\\n    --log-throughput \\\n    --recompute-granularity full \\\n    --recompute-method block \\\n    --recompute-num-layers 32\n\"\n\nDATA_ARGS=\"\n    --data-path $DATA_PATH  \\\n    --split 100,0,0 \\\n\"\n\nOUTPUT_ARGS=\"\n    --log-interval 1 \\\n    --save-interval 1000 \\\n    --eval-interval 1000 \\\n    --eval-iters 0 \\\n\"\n\ntorchrun $DISTRIBUTED_ARGS ../pretrain_gpt.py \\\n  $GPT_ARGS \\\n  $DATA_ARGS \\\n  $OUTPUT_ARGS \\\n  --distributed-backend nccl \\\n  | tee /job/output/logs/train_mistral_7B.log\n```\n\n#### 拉起训练\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Modellink/image4.png)\n\n\n\n## 基于docker的llama2-7B微调\n### 容器挂载\n```bash\nsudo docker run -dit --ipc=host --net=host \\\n--name=modellink_wxb \\\n--device=/dev/davinci0 \\\n--device=/dev/davinci1 \\\n--device=/dev/davinci2 \\\n--device=/dev/davinci3 \\\n--device=/dev/davinci4 \\\n--device=/dev/davinci5 \\\n--device=/dev/davinci6 \\\n--device=/dev/davinci7 \\\n--device=/dev/davinci_manager \\\n--device=/dev/devmm_svm \\\n--device=/dev/hisi_hdc \\\n-v /etc/ascend_install.info:/etc/ascend_install.info \\\n-v /etc/hccn.conf:/etc/hccn.conf \\\n-v /etc/localtime:/etc/localtime \\\n-v /var/log/npu/:/usr/slog \\\n-v /usr/local/sbin/npu-smi:/usr/local/sbin/npu-smi \\\n-v /usr/local/Ascend/driver:/usr/local/Ascend/driver \\\n-v /reason-sharedata/training_inference/wangxiangbo/modellink/code/Modellink:/job/code \\\n-v /reason-sharedata/training_inference/wangxiangbo/modellink/data:/job/data \\\n-v /reason-sharedata/training_inference/wangxiangbo/modellink/output:/job/output \\\n-v /mnt/weight-1:/job/mnt \\\nregistry.paas/cmss/modellink-cann8.0-torch2.1-mindspeed-0.7:v1.0 \\\n/bin/bash\n```\n\n### 权重转换\n```bash\n# 修改 ascend-toolkit 路径\nsource /usr/local/Ascend/ascend-toolkit/set_env.sh\n```\n\n```bash\npython  tools/checkpoint/convert_ckpt.py \\\n       --model-type GPT \\\n       --loader llama2_hf \\\n       --saver megatron \\\n       --target-tensor-parallel-size 8 \\\n       --target-pipeline-parallel-size 1 \\\n       --load-dir /job/mnt/huggingface/Llama-2-7b-hf// \\\n       --save-dir /job/data/megatron/llama-2-7b-hf-v0.1-tp8-pp1/ \\\n       --tokenizer-model /job/mnt/huggingface/Llama-2-7b-hf/tokenizer.json\n```\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Modellink/image5.png)\n\n### 数据集\n```bash\npython tools/preprocess_data.py \\\n    --input /job/data/dataset/mistral/Alpaca_data_gpt4_zh.jsonl \\\n    --output-prefix /job/data/dataset/llama2/Alpaca_finetune/ \\\n    --tokenizer-type PretrainedFromHF \\\n    --tokenizer-name-or-path /job/mnt/huggingface/Llama-2-7b-hf/ \\\n    --append-eod \\\n    --tokenizer-not-use-fast \\\n    --handler-name GeneralInstructionHandler \\\n    --workers 4\n```\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Modellink/image6.png)\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Modellink/image7.png)\n\n### 微调\n#### 微调脚本\n```bash\n\n#!/bin/bash\nexport CUDA_DEVICE_MAX_CONNECTIONS=1\nexport PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n\nGPUS_PER_NODE=8\nMASTER_ADDR=localhost\nMASTER_PORT=6006\nNNODES=1\nNODE_RANK=0\nWORLD_SIZE=$(($GPUS_PER_NODE * $NNODES))\n\nDISTRIBUTED_ARGS=\"\n    --nproc_per_node $GPUS_PER_NODE \\\n    --nnodes $NNODES \\\n    --node_rank $NODE_RANK \\\n    --master_addr $MASTER_ADDR \\\n    --master_port $MASTER_PORT\n\"\n\necho \"NODE_RANK ${NODE_RANK}\"\n\nDATA_PATH=\"/job/data/dataset/llama2/Alpaca_finetune\"\nTOKENIZER_MODEL=\"/job/mnt/huggingface/Llama-2-7b-hf/\"\nCKPT_SAVE_DIR=\"/job/output/llama2_ckpt/\"\nCKPT_LOAD_DIR=\"/job/data/megatron/llama-2-7b-hf-v0.1-tp8-pp1\"\n\n\nTP=8\nPP=1\nNUM_LAYERS=32\n\nGPT_ARGS=\"\n    --tensor-model-parallel-size ${TP} \\\n    --pipeline-model-parallel-size ${PP} \\\n    --sequence-parallel \\\n    --num-layers 32 \\\n    --hidden-size 4096 \\\n    --ffn-hidden-size 11008 \\\n    --num-attention-heads 32 \\\n    --tokenizer-type Llama2Tokenizer \\\n    --tokenizer-model ${TOKENIZER_MODEL} \\\n    --seq-length 4096 \\\n    --max-position-embeddings 4096 \\\n    --micro-batch-size 1 \\\n    --global-batch-size 256 \\\n    --make-vocab-size-divisible-by 1 \\\n    --lr 1.25e-6 \\\n    --train-iters 5000 \\\n    --lr-decay-style cosine \\\n    --untie-embeddings-and-output-weights \\\n    --disable-bias-linear \\\n    --attention-dropout 0.0 \\\n    --init-method-std 0.01 \\\n    --hidden-dropout 0.0 \\\n    --position-embedding-type rope \\\n    --normalization RMSNorm \\\n    --use-fused-rmsnorm \\\n    --swiglu \\\n    --use-flash-attn \\\n    --no-masked-softmax-fusion \\\n    --attention-softmax-in-fp32 \\\n    --min-lr 1.25e-7 \\\n    --weight-decay 1e-1 \\\n    --lr-warmup-fraction 0.01 \\\n    --clip-grad 1.0 \\\n    --adam-beta1 0.9 \\\n    --initial-loss-scale 65536 \\\n    --adam-beta2 0.95 \\\n    --no-gradient-accumulation-fusion \\\n    --no-load-optim \\\n    --no-load-rng \\\n    --use-distributed-optimizer \\\n    --use-fused-swiglu \\\n    --use-fused-rotary-pos-emb \\\n    --overlap-grad-reduce \\\n    --bf16\n\"\n\nDATA_ARGS=\"\n    --data-path $DATA_PATH  \\\n    --split 100,0,0 \\\n\"\n\nOUTPUT_ARGS=\"\n    --log-interval 1 \\\n    --save-interval 1000 \\\n    --eval-interval 1000 \\\n    --eval-iters 0 \\\n\"\n\ntorchrun $DISTRIBUTED_ARGS ../pretrain_gpt.py \\\n  $GPT_ARGS \\\n  $DATA_ARGS \\\n  $OUTPUT_ARGS \\\n  --distributed-backend nccl \\\n  | tee /job/output/logs/train_llama2_7B.log\n\n```\n\n#### 拉起训练\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Modellink/image8.png)\n\n\n","tags":["模型训练调优","昇腾","910B","Mindformers"],"categories":["模型训练调优","昇腾"]},{"title":"基于Mindformers的llama3.1模型微调","url":"/2025/11/06/模型训练调优/昇腾/Mindformers/llama3.1微调/","content":"## 启动容器\n```bash\ndocker run -dit --ipc=host --net=host \\\n--name=wxb_mindformers \\\n--device=/dev/davinci0 \\\n--device=/dev/davinci1 \\\n--device=/dev/davinci2 \\\n--device=/dev/davinci3 \\\n--device=/dev/davinci4 \\\n--device=/dev/davinci5 \\\n--device=/dev/davinci6 \\\n--device=/dev/davinci7 \\\n--device=/dev/davinci_manager \\\n--device=/dev/devmm_svm \\\n--device=/dev/hisi_hdc \\\n-v /etc/ascend_install.info:/etc/ascend_install.info \\\n-v /etc/hccn.conf:/etc/hccn.conf \\\n-v /etc/localtime:/etc/localtime \\\n-v /var/log/npu/:/usr/slog \\\n-v /usr/local/sbin/npu-smi:/usr/local/sbin/npu-smi \\\n-v /usr/local/Ascend/driver:/usr/local/Ascend/driver \\\n-v /reason-sharedata/training_inference/wangxiangbo/mindformers/code:/job/code \\\n-v /reason-sharedata/training_inference/wangxiangbo/mindformers/data:/job/data \\\n-v /reason-sharedata/training_inference/wangxiangbo/mindformers/output:/job/output \\\n-v /mnt/weight-1:/job/mnt \\\nswr.cn-central-221.ovaijisuan.com/mindformers/mindformers1.3_mindspore2.4:20241114 \\\n/bin/bash\n```\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Mindformers/image1.png)\n\n## 代码准备\n```bash\ngit clone https://gitee.com/mindspore/mindformers.git\n```\n\n## 数据集\n```bash\npython research/llama3/llama_preprocess.py \\\n--dataset_type qa \\\n--input_glob /job/data/alpaca/alpaca-data-conversation.json \\\n--model_file /job/mnt/huggingface/llama-3-8b-hf \\\n--seq_length 8192 \\\n--output_file /job/data/alpaca\n```\n\n## 权重转换\n```bash\npython convert_weight.py --model llama --input_path /job/mnt/huggingface/llama-3-8b-hf --output_path /job/data/mindformers/llama3_8b_ckpt\n```\n\n## 训练脚本\n```bash\nseed: 0\noutput_dir: '/job/output' # path to save checkpoint/strategy\nload_checkpoint: '/job/data/mindformers/llama3_8b_ckpt/'\nsrc_strategy_path_or_dir: ''\nauto_trans_ckpt: False  # If true, auto transform load_checkpoint to load in distributed model\nonly_save_strategy: False\nresume_training: False\nrun_mode: 'finetune'\n \n# trainer config\ntrainer:\n  type: CausalLanguageModelingTrainer\n  model_name: 'llama3_8b'\n \n# runner config\nrunner_config:\n  epochs: 2\n  batch_size: 1\n  sink_mode: True\n  sink_size: 2\n \n# optimizer\noptimizer:\n  type: FP32StateAdamWeightDecay\n  beta1: 0.9\n  beta2: 0.95\n  eps: 1.e-8\n \n# lr sechdule\nlr_schedule:\n  type: CosineWithWarmUpLR\n  learning_rate: 1.e-5\n  lr_end: 0.0\n  warmup_ratio: 0.03\n  total_steps: -1 # -1 means it will load the total steps of the dataset\n \n# dataset\ntrain_dataset: &train_dataset\n  data_loader:\n    type: MindDataset\n    dataset_dir: \"/job/data/alpaca/alpaca_llama3_8192/alpaca-fastchat8192.mindrecord\"\n    shuffle: True\n  input_columns: [\"input_ids\",\"labels\"]  # \"input_ids\", \"labels\" , labels are used in instruction finetune.\n  num_parallel_workers: 8\n  python_multiprocessing: False\n  drop_remainder: True\n  batch_size: 6\n  repeat: 1\n  numa_enable: False\n  prefetch_size: 1\ntrain_dataset_task:\n  type: CausalLanguageModelDataset\n  dataset_config: *train_dataset\n# if True, do evaluate during the training process. if false, do nothing.\n# note that the task trainer should support _evaluate_in_training function.\ndo_eval: False\n \n# eval dataset\neval_dataset: &eval_dataset\n  data_loader:\n    type: MindDataset\n    dataset_dir: \"\"\n    shuffle: False\n  input_columns: [\"input_ids\"]\n  num_parallel_workers: 8\n  python_multiprocessing: False\n  drop_remainder: False\n  repeat: 1\n  numa_enable: False\n  prefetch_size: 1\neval_dataset_task:\n  type: CausalLanguageModelDataset\n  dataset_config: *eval_dataset\n \nuse_parallel: True\n# parallel context config\nparallel:\n  parallel_mode: 1 # 0-data parallel, 1-semi-auto parallel, 2-auto parallel, 3-hybrid parallel\n  gradients_mean: False\n  enable_alltoall: False\n  full_batch: True\n  search_mode: \"sharding_propagation\"\n  enable_parallel_optimizer: True\n  strategy_ckpt_save_file: \"./ckpt_strategy.ckpt\"\n  parallel_optimizer_config:\n    gradient_accumulation_shard: False\n    parallel_optimizer_threshold: 64\n# default parallel of device num = 8 for Atlas 800T A2\nparallel_config:\n  data_parallel: 1\n  model_parallel: 4\n  pipeline_stage: 2\n  use_seq_parallel: False\n  micro_batch_num: 8\n  vocab_emb_dp: True\n  gradient_aggregation_group: 4\n# when model parallel is greater than 1, we can set micro_batch_interleave_num=2, that may accelerate the train process.\nmicro_batch_interleave_num: 1\n \n# recompute config\nrecompute_config:\n  recompute: True\n  select_recompute: False\n  parallel_optimizer_comm_recompute: True\n  mp_comm_recompute: True\n  recompute_slice_activation: True\n \n# callbacks\ncallbacks:\n  - type: MFLossMonitor\n  - type: CheckpointMointor\n    prefix: \"llama3_8b\"\n    save_checkpoint_steps: 10000\n    integrated_save: False\n    async_save: False\n  - type: ObsMonitor\n \n# mindspore context init config\ncontext:\n  mode: 0 #0--Graph Mode; 1--Pynative Mode\n  device_target: \"Ascend\"\n  enable_graph_kernel: False\n  graph_kernel_flags: \"--disable_expand_ops=Softmax,Dropout --enable_parallel_fusion=true --reduce_fuse_depth=8 --enable_auto_tensor_inplace=true\"\n  max_call_depth: 10000\n  max_device_memory: \"26GB\"\n  save_graphs: False\n  save_graphs_path: \"./graph\"\n  device_id: 0\n  runtime_num_threads: 1\n \n# model config\nmodel:\n  model_config:\n    type: LlamaConfig\n    batch_size: 1 # add for increase predict\n    seq_length: 8192\n    hidden_size: 4096\n    num_layers: 32\n    num_heads: 32\n    n_kv_heads: 8\n    vocab_size: 128256\n    intermediate_size: 14336\n    rms_norm_eps: 1.0e-5\n    bos_token_id: 128000\n    eos_token_id: 128001\n    pad_token_id: 128002\n    ignore_token_id: -100\n    compute_dtype: \"bfloat16\"\n    layernorm_compute_type: \"float32\"\n    softmax_compute_type: \"float32\"\n    rotary_dtype: \"float32\"\n    param_init_type: \"bfloat16\"\n    use_past: False\n    scaling_factor: 1.0\n    theta: 500000\n    extend_method: \"None\" # support \"None\", \"PI\", \"NTK\"\n    use_flash_attention: True # FA can accelerate training or finetune\n    offset: 0\n    fine_grain_interleave: 1\n    checkpoint_name_or_path: \"\"\n    repetition_penalty: 1\n    max_decode_length: 512\n    top_k: 3\n    top_p: 1\n    do_sample: False\n  arch:\n    type: LlamaForCausalLM\n \n# metric\nmetric:\n  type: PerplexityMetric\n \n# wrapper cell config\nrunner_wrapper:\n  type: MFTrainOneStepCell\n  scale_sense: 1.0\n  use_clip_grad: True\n \neval_callbacks:\n  - type: ObsMonitor\n \nauto_tune: False\nfilepath_prefix: './autotune'\nautotune_per_step: 10\n \nprofile: False\nprofile_start_step: 5\nprofile_stop_step: 7\ninit_start_profile: True\nprofile_communication: True\nprofile_memory: True\nlayer_scale: False\nlayer_decay: 0.65\nlr_scale_factor: 256\n \n# aicc\nremote_save_url: \"Please input obs url on AICC platform.\"\n```\n\n## 训练拉起\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Mindformers/image2.png)\n\n<font style=\"color:transparent;\">git</font>\n\n<font style=\"color:transparent;\"> clone https://gitee.com/mindspore/mindformers.gitgit</font>\n\n<font style=\"color:transparent;\"> clone https://gitee.com/mindspore/mindformers.git</font>\n\n","tags":["模型训练调优","昇腾","910B","Mindformers"],"categories":["模型训练调优","昇腾"]},{"title":"Git1_git命令","url":"/2025/11/04/Git/Git1_git 命令/","content":"**<font style=\"background-color:#FBDE28;\">git commmit -v和git push origin develop之后，我怎么撤销本次commit提交的代码，将origin develop的仓库返回值提交之前的状态？</font>**\n\n在Git中，如果你想要撤销最近的一次提交并将仓库状态回退到提交之前，你可以使用`git reset`命令。这里有几种方法可以撤销提交：\n\n1. **使用**`git reset --soft`：\n    - 这个命令会将HEAD指针移动到指定的提交，但是不会改变工作目录和索引的状态。这意味着你的更改仍然在暂存区（staged），你可以重新提交。\n    - 命令：`git reset --soft HEAD~1`（将HEAD指针回退到上一个提交）\n2. **使用**`git reset --mixed`（默认选项）：\n    - 这个命令会将HEAD指针移动到指定的提交，并且将索引（staged changes）重置到HEAD的状态，但是不会改变工作目录。\n    - 命令：`git reset --mixed HEAD~1`（将HEAD和索引回退到上一个提交，但工作目录不变）\n3. **使用**`git reset --hard`：\n    - 这个命令会将HEAD指针、索引和工作目录都重置到指定的提交状态。这意味着所有未提交的更改都会丢失。\n    - 命令：`git reset --hard HEAD~1`（将HEAD、索引和工作目录都回退到上一个提交）\n\n如果你已经将代码推送到了远程仓库（比如`origin develop`），并且想要撤销这次推送，你可以使用`git push`命令配合`--force`选项来强制推送本地的更改到远程仓库。但是请注意，这会覆盖远程仓库的历史，所以只有在你确定远程仓库没有其他人的提交或者你不介意丢失这些提交时才应该使用。\n\n命令如下：\n\n```bash\ngit push origin develop --force\n```\n\n或者，如果你使用的是Git 2.0或更高版本，可以使用更安全的`--force-with-lease`选项，它会在远程分支没有新的提交时才允许强制推送。\n\n命令如下：\n\n```bash\ngit push origin develop --force-with-lease\n```\n\n**警告**：使用`--force`选项会覆盖远程仓库的历史，这是一个破坏性的操作。在团队协作的环境中，这可能会导致其他协作者的工作丢失，所以请谨慎使用。\n\n","tags":["开发","git"],"categories":["开发","git"]},{"title":"Git2_gerrit仓库代码提交流程","url":"/2025/11/04/Git/Git2_gerrit仓库代码提交流程/","content":"1. 生成个人密钥\n```bash\nssh-keygen -C wangxiangbo_JTAGI@cmss.chinamobile.com\n```\n2. 修改config文件，增加gerrit仓库配置，增加刚生成的个人密钥`id_ed25519`\n```bash\nhost gerrit\nport 29418\nhostname gerrit.cmss.com\nuser wangxiangbo_JTAGI\nIdentityFile ~/.ssh/id_ed25519\n```\n3. 在gerrit中setting设置中，增加ssh的公钥，即`id_ed25519.pub`\n4. 设置邮箱，邮箱名`wangxiangbo@cmss.chinamobile.com`为不带JTAGI后缀的邮箱。\n5. 用ssh clone代码仓库\n```bash\ngit clone \"ssh://wangxiangbo_JTAGI@gerrit.cmss.com:29418/AGI/CM_OPTIMUS\" && scp -p -P 29418 wangxiangbo_JTAGI@gerrit.cmss.com:hooks/commit-msg \"CM_OPTIMUS/.git/hooks/\"\n```\n6. 查看分支\n```bash\ngit branch -a\n```\n7. 查看远端分支\n```bash\ngit branch -r\n```\n8. 通过远端origin/develop仓库，创建一个本地develop开发分支\n```bash\ngit checkout -b develop origin/develop\n```\n9. 修改代码后，add之后并commit提交\n```bash\ngit commit -v\n```\n10. 推送远端origin/develop仓库\n```bash\ngit push origin HEAD:refs/for/develop\n```\n11. 在推送过程中会出现缺失 `Change-Id `的错误\n```bash\ngitdir=$(git rev-parse --git-dir); scp -p -P 29418 wangxiangbo_JTAGI@gerrit.cmss.com:hooks/commit-msg ${gitdir}/hooks/\n```\n执行完毕后如果出现subsystem request failed on channel 0，则将-p修改为-O\n```bash\ngitdir=$(git rev-parse --git-dir); scp -O -P 29418 wangxiangbo_JTAGI@gerrit.cmss.com:hooks/commit-msg ${gitdir}/hooks/\n```\n将本次commit提交的末尾加上Change-Id \n```bash\ngit commit --amend --no-edit\n```\n再次push\n```bash\ngit push origin HEAD:refs/for/develop\n```\n12. 提交完成之后，打开gerrit，找到develop分支的gitweb\n13. 选择review\n14. 找到刚刚提交的代码\n15. 点击add reviewer，评审人要最少要两个以上\n16. 第一次之后提交代码步骤\n```bash\ngit pull origin\ngit add xxx\ngit commit -v \ngit push origin HEAD:refs/for/develop\n```\n\n","tags":["开发","gerrit"],"categories":["开发","git"]},{"title":"Git3_gitlab仓库代码提交流程","url":"/2025/11/04/Git/Git3_gitlab仓库代码提交流程/","content":"1. gitlab上fork主仓库，生成个人的远端仓库origin/develop\n2. 修改git提交用户配置为九天账号\n```bash\ngit config --global --list\ngit config --global user.name wangxiangbo_JTAGI\ngit config --global user.email wangxiangbo_JTAGI@cmss.chinamobile.com\n```\n3. 拉取个人的远端仓库\n```bash\ngit clone http://gitlab.cmss.com/wangxiangbo/CM_OPTIMUS.git \n```\n4. 查看分支\n```bash\ngit branch -a\n```\n5. 查看远程仓库分支\n```bash\ngit branch -r\n```\n6. 通过个人的远端origin/develop仓库，创建一个本地develop开发分支\n```bash\ngit checkout -b develop origin/develop\n```\n7. <font style=\"color:rgba(0, 0, 0, 0.85);\">列出所有的远程仓库以及对应的 URL</font>\n```bash\ngit remote -v\n```\n8. <font style=\"color:rgba(0, 0, 0, 0.85);\">将远程仓库地址添加到本地Git仓库的远程仓库列表中，本地的upstream/develop仓库会和gitlab远程仓库关联起来</font>\n```bash\ngit remote add upstream http://gitlab.cmss.com/AGI/CM_OPTIMUS.git\n```\n8. upstream/develop远端仓库拉取最新的代码\n```bash\ngit fetch upstream\n```\n9. 将upstream/develop远端仓库的最新代码合并到本地的develop分支中\n```bash\ngit merge upstream/develop\n```\n10. 将本地develop最新的代码推到个人的远端仓库origin/develop中\n```bash\ngit push origin develop\n```\n11. <font style=\"background-color:#FBDE28;\">提交develop到origin/develop代码之前，保证自己的本地个人的远端仓库origin/develop和本地gitlab的远端仓库upstream/develop保持一致再提交</font>，防止后续origin/develop合并打upstream/develop上出现冲突。\n```bash\n#本地代码修改后拉取最新代码\n#1.拉取源代码\ngit fetch upstream \n#2.暂存本地修改的代码\ngit stash\n#3.合并源代码到当前的develop仓库\ngit merge upstream/develop\n#4.将本地修改的推送到远程的origin分支，使origin/develop和upstream/develop保持一致\ngit push origin develop\n#5.将暂存的代码弹出来\ngit stash pop\n```\n12. souretree上add需要提交的代码\n13. 提交add之后的代码\n```bash\ngit commit -v\n```\n```bash\n#修改下方的提交信息，第一行为提交描述信息\ndeepseek-7B预训练\n\nCode Source From: Self Code\nDescription: deepseek-7B预训练\nJira: #CMOPTIMUS-1089\n市场项目编号（名称）：CM_OPTIMUS\n```\n14. <font style=\"color:rgb(55, 53, 47);\">将提交完之后的代码合并到origin/develop上</font>\n```bash\ngit push origin develop\n```\n15. <font style=\"color:rgb(55, 53, 47);\">gitlab中找的到自己仓库下CM_OPTIMUS</font>\n16. <font style=\"color:rgb(55, 53, 47);\">找到Merge requests，然后点击开始一个合并</font>\n17. <font style=\"color:rgb(55, 53, 47);\">然后选择自己的分支为develop，还有旁边的分支develop，然后点击最下方的merge即可。该操作是将自己个人远端的orgin/develop仓库提交修改后的代码合并到gitlab远端的主仓库中（upstream/develop已和其关联，并通过git fetch保持最新）</font>\n选中自己刚刚提交到origin/develop上的代码，合并到AGI/CM_OPTIMUS的develop分支上\n在Write里添加合并人信息\n\n\n\n","tags":["开发","gitlab"],"categories":["开发","git"]},{"title":"Linux1_kimi问题","url":"/2025/11/04/Linux/Linux1_kimi问题/","content":"1. 权重转换代码换行符\nKimi: 出现这些错误通常是因为脚本文件在不同的操作系统环境下被编辑或创建，导致文件的换行符不一致。Unix/Linux系统使用LF（Line Feed，`\\n`）作为换行符，而Windows系统使用CR+LF（Carriage Return + Line Feed，`\\r\\n`）作为换行符。\n错误信息中的 `$'\\r': command not found` 表示脚本尝试执行一个以 `\\r` 开头的命令，这通常是因为脚本文件中的换行符是 `\\r\\n` 而不是 `\\n`。\n此外，`syntax error near unexpected token 'elif'` 错误表明脚本解析器在遇到 `elif` 时遇到了语法错误，这可能是因为 `elif` 之前的行（可能是第59行）以 `\\r\\n` 结尾，导致 `elif` 行实际上是从一个新的行开始，而不是在预期的位置。\n要解决这个问题，你可以使用 `dos2unix` 工具将脚本文件从Windows格式转换为Unix/Linux格式。如果你没有 `dos2unix` 工具，可以使用 `sed` 命令来移除 `\\r` 字符：\n```bash\nsed -i 's/\\r$//' hf2mcore_convertor.sh\n```\n这条命令会查找文件中的所有行，并移除每行末尾的 `\\r` 字符。\n如果你有 `dos2unix` 工具，可以使用以下命令：\n```bash\ndos2unix hf2mcore_convertor.sh\n```\n这将把文件从Windows格式转换为Unix/Linux格式。\n在运行这些命令之后，再次执行脚本应该就不会出现这些错误了。\n2. 修改文件遇到Read-only file system\nKimi: 当你遇到 \"Read-only file system\" 错误时，通常意味着你的文件系统出于某种原因被挂载为只读模式。这可能是由于文件系统损坏、磁盘硬件问题、或者挂载时指定了错误的参数。以下是一些解决步骤：\n1. **检查文件系统挂载状态**：  \n使用 `mount` 命令查看所有挂载的文件系统及其状态。你可以使用如下命令：\n```bash\nmount | grep /path/to/mount/point\n```\n查看挂载点是否为只读（ro）。\n2. **重新挂载文件系统为读写模式**：  \n如果文件系统被挂载为只读，你可以尝试重新挂载它为读写模式。使用以下命令：\n```bash\nsudo mount -o remount,rw /path/to/mount/point\n```\n请将 `/path/to/mount/point` 替换为实际的挂载点路径。\n3. **检查和修复文件系统**：  \n如果重新挂载不起作用，可能是文件系统损坏。你可以使用 `fsck` 命令来检查和修复文件系统。例如，对于 ext4 文件系统，可以使用：\n```bash\nsudo fsck -f /dev/sda1\n```\n请确保替换 `/dev/sda1` 为你的实际分区。\n\n","tags":["运维","Linux"],"categories":["Linux"]},{"title":"运维1_docker命令","url":"/2025/11/04/服务器运维/运维1_docker命令/","content":"1. 启动一个容器\n```bash\nsudo docker run -it --name qwen --gpus all nvidia/cuda:12.2.2-cudnn8-devel-ubuntu22.04\n```\n启动一个容器后，又通过exit关闭。发现docker ps没有了，该如何重新启动这个qwen容器？\n```bash\ndocker ps -a\n\ndocker start qwen\n\ndocker exec -it 容器id bash\n```\n\n2. 拉取一个新镜像后，通过这个镜像创建一个容器。\n```bash\ndocker run -it --name qwen --gpus all 镜像名:镜像tags bash\n```\n\n3. 将此时qwen容器打成镜像\n```bash\ndocker commit -a \"wangxiangbo\" -m \"qwen 7B\" 02649afd9710 qwen-7b:v1.0\n```\n\n\n\n\n","tags":["运维","docker"],"categories":["运维","docker"]},{"title":"Linux2_Linux命令","url":"/2025/11/04/Linux/Linux2_linux命令/","content":"1. 当执行训练任务时，手动关闭训练，此时gup资源仍然占用，需要手动kill掉进程\n查询正在运行的进程并gerp finetune_lora_single_gpu.sh\n`ps aux | grep finetune_lora_single_gpu.sh`\n`ps aux | grep finetune_lora_ds.sh`\n`kill -9 372813` 根据上一步查出来的进程号，用kill -9强制删除\n`nvidia-smi `查看是否gpu显存已经清空\n2. 查看某个文件的前20行\n`head -n 20 train_data_law.json`\n3. 查看当前文件夹的大小\n`du -sh .`\n4. 查看当前文件夹挂载的是哪一个盘\n`df -h .`\n从大到小查看当前文件夹的下的文件大小\n`du -sh * | sort -rh`\n4. 查看当前文件下所有文件的大小\n`ls -lh`\n5. <font style=\"color:#000000;\">把一个名为Yuan2的文件夹的所有内容（包括该文件夹名），cp到/mnt/users/wangxiangbo/nemo/model目录下，使最后的目录为 /mnt/users/wangxiangbo/nemo/model/Yuan2</font>\n`cp -a Yuan2 /mnt/users/wangxiangbo/nemo/model/`\n6. 通过pid查看某个进程的详细信息\n`<font style=\"color:rgb(56, 58, 66);background-color:rgb(250, 250, 250);\">ps -fp 167891</font>`\n7. 查看当前目录下所有文件的磁盘占用情况\n`du -ah | sort -hr | head -n 20`\n8.  使用以下命令将`megatron-core`文件夹压缩成一个名为`megatron-core.zip`的zip文件\n \t` zip -r megatron-core.zip megatron-core  `\n9.  使用以下命令将`megatron-core.zip`解压缩  \n` unzip megatron-core.zip  `\n11. hg上面下载模型\n```bash\npip install -U huggingface_hub\nhuggingface-cli download bigscience/bloom-560m --local-dir bloom-560m\nhuggingface-cli download Qwen/Qwen2-7B-Instruct --local-dir Qwen2-7B-Instruct\nhuggingface-cli download Qwen/Qwen2.5-7B-Instruct --local-dir Qwen2.5-7B-Instruct\nhuggingface-cli download BAAI/IndustryCorpus_computer --repo-type dataset --local-dir IndustryCorpus_computer\nhuggingface-cli download BAAI/IndustryCorpus2_current_affairs_government_administration --repo-type dataset --local-dir government_administration\nhuggingface-cli download ShengbinYue/DISC-Law-SFT --repo-type dataset --local-dir DISC-Law-SFT\nhuggingface-cli download TigerResearch/sft_zh\n```\n12. 归档压缩文件\n```bash\n#-c：创建一个新的压缩文件。\n#-z：通过 gzip 压缩文件。\n#-v：显示详细的压缩过程。\n#-f：指定压缩后的文件名，这里是 colossalai.tar.gz\ntar -czvf colossalai.tar.gz colossalai/  \n\n#-x：表示解压。\n#-z：表示解压 .gz 格式的文件。\n#-v：显示解压过程。\n#-f：指定解压的文件\ntar -xzvf file.tar.gz\n```\n\n\n\n","tags":["运维","Linux"],"categories":["Linux"]},{"title":"运维2_k8s命令","url":"/2025/11/04/服务器运维/运维2_k8s命令/","content":"1. 获取特定命名空间的详细信息\n```bash\nkubectl get ns namespace-name -o wide\n```\n2. kubectl通过ns获取所有的pods的详细信息\n```bash\nkubectl get pods -n <ns_name> -o wide\n```\n3. 删除启动失败的pod，可以直接删除启动时的yaml，否则pod会自动重启\n```bash\nkubectl delete -f qwentest.yaml\n```\n4. 查看所有的node的lable标签信息\n```bash\nkubectl get node --show-labels\n\nkubectl get node xxx --show-labels\n\nkubectl get node --show-labels | grep model\n```\n5. 打标签\n```bash\nkubectl label nodes ecs-jhjs-1234-003 key=vaule\n```\n6. 删除某节点的lable标签\n```bash\nkubectl label nodes cce100-64-29-79.cce-stack.com model-\n```\n6. 创建一个命名空间namespace\n```bash\nkubectl create namespace xxx\n```\n7. 查看所有节点的标签\n```bash\nkubectl get nodes --show-labels\nkubectl get nodes --show-labels | grep model=llama2-70b\n```\n","tags":["运维","k8s"],"categories":["运维","k8s"]},{"title":"测试 Hexo 标签分类2","url":"/2025/10/31/页面测试/test copy/","content":"这是文章正文。","tags":["测试2","hexo"],"categories":["测试"]}]