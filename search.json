[{"title":"å¾®è°ƒæ•°æ®é›†å¤„ç†å…¨æµç¨‹è§£æ","url":"/2026/01/08/LLM/æ•°æ®å¤„ç†/å¾®è°ƒæ•°æ®é›†å¤„ç†å…¨æµç¨‹è§£æ/","content":"\n## è¡Œä¸šæ¨¡å‹å¾®è°ƒæµç¨‹å›¾\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/data/datajuicer/paint.png)\n\n## å¤§æ¨¡å‹å¾®è°ƒå…¨æµç¨‹è§£å†³æ–¹æ¡ˆ\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/data/datajuicer/image1%23.png)\n\n\n\n\n\n## pdfæ•°æ®æå–å¤„ç†\n\n### æ”¿ä¼ç±»æ•°æ®é›†.pdf\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/data/datajuicer/image2.png)\n\n### pdfæ•°æ®æå–\n\n#### é‡‡ç”¨mineruæ–¹å¼\n\n##### mineruç¯å¢ƒå®‰è£…\n\n[https://github.com/opendatalab/MinerU](https://github.com/opendatalab/MinerU)\n\n```bash\nconda create -n mineru python=3.10\nconda activate mineru\npip install -U \"magic-pdf[full]\" --extra-index-url https://wheels.myhloli.com -i https://mirrors.aliyun.com/pypi/simple\n```\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/data/datajuicer/image3.png)\n\n##### magic-pdf.jsoné…ç½®æ–‡ä»¶ä¿®æ”¹\n\n```json\n{\n    \"bucket_info\": {\n        \"bucket-name-1\": [\n            \"ak\",\n            \"sk\",\n            \"endpoint\"\n        ],\n        \"bucket-name-2\": [\n            \"ak\",\n            \"sk\",\n            \"endpoint\"\n        ]\n    },\n    \"models-dir\": \"/mnthp/users/wangxiangbo/model/opendatalab/PDF-Extract-Kit-1___0/models\",\n    \"layoutreader-model-dir\": \"/mnthp/users/wangxiangbo/model/ppaanngggg/layoutreader\",\n    \"device-mode\": \"cpu\",\n    \"layout-config\": {\n        \"model\": \"doclayout_yolo\"\n    },\n    \"formula-config\": {\n        \"mfd_model\": \"yolo_v8_mfd\",\n        \"mfr_model\": \"unimernet_small\",\n        \"enable\": true\n    },\n    \"table-config\": {\n        \"model\": \"rapid_table\",\n        \"sub_model\": \"slanet_plus\",\n        \"enable\": false,\n        \"max_time\": 400\n    },\n    \"llm-aided-config\": {\n        \"formula_aided\": {\n            \"api_key\": \"your_api_key\",\n            \"base_url\": \"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n            \"model\": \"qwen2.5-7b-instruct\",\n            \"enable\": false\n        },\n        \"text_aided\": {\n            \"api_key\": \"your_api_key\",\n            \"base_url\": \"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n            \"model\": \"qwen2.5-7b-instruct\",\n            \"enable\": false\n        },\n        \"title_aided\": {\n            \"api_key\": \"your_api_key\",\n            \"base_url\": \"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n            \"model\": \"qwen2.5-32b-instruct\",\n            \"enable\": false\n        }\n    },\n    \"config_version\": \"1.1.1\"\n}\n```\n\n##### pyè„šæœ¬æ–¹å¼å¤„ç†pdfæ–‡ä»¶\n\n```python\nimport os\n\nfrom magic_pdf.data.data_reader_writer import FileBasedDataWriter, FileBasedDataReader\nfrom magic_pdf.data.dataset import PymuDocDataset\nfrom magic_pdf.model.doc_analyze_by_custom_model import doc_analyze\nfrom magic_pdf.config.enums import SupportedPdfParseMethod\n\n# args\npdf_file_name = \"/mnthp/users/wangxiangbo/data/pdf2.pdf\"  # replace with the real pdf path\n# name_without_suff = pdf_file_name.split(\".\")[0]\nname_without_suff = os.path.basename(pdf_file_name).split(\".\")[0]\n\n# prepare env\nlocal_image_dir, local_md_dir = \"/mnthp/users/wangxiangbo/mineru/images\", \"/mnthp/users/wangxiangbo/mineru/data\"\nimage_dir = str(os.path.basename(local_image_dir))\n\nos.makedirs(local_image_dir, exist_ok=True)\n\nimage_writer, md_writer = FileBasedDataWriter(local_image_dir), FileBasedDataWriter(\n    local_md_dir\n)\n\n# read bytes\nreader1 = FileBasedDataReader(\"\")\npdf_bytes = reader1.read(pdf_file_name)  # read the pdf content\n\n# proc\n## Create Dataset Instance\nds = PymuDocDataset(pdf_bytes)\n\n## inference\nif ds.classify() == SupportedPdfParseMethod.OCR:\n    infer_result = ds.apply(doc_analyze, ocr=True)\n\n    ## pipeline\n    pipe_result = infer_result.pipe_ocr_mode(image_writer)\n\nelse:\n    infer_result = ds.apply(doc_analyze, ocr=False)\n\n    ## pipeline\n    pipe_result = infer_result.pipe_txt_mode(image_writer)\n\n### draw model result on each page\ninfer_result.draw_model(os.path.join(local_md_dir, f\"{name_without_suff}_model.pdf\"))\n\n### get model inference result\nmodel_inference_result = infer_result.get_infer_res()\n\n### draw layout result on each page\npipe_result.draw_layout(os.path.join(local_md_dir, f\"{name_without_suff}_layout.pdf\"))\n\n### draw spans result on each page\npipe_result.draw_span(os.path.join(local_md_dir, f\"{name_without_suff}_spans.pdf\"))\n\n### get markdown content\nmd_content = pipe_result.get_markdown(image_dir)\n\n### dump markdown\npipe_result.dump_md(md_writer, f\"{name_without_suff}.md\", image_dir)\n\n### get content list content\ncontent_list_content = pipe_result.get_content_list(image_dir)\n\n### dump content list\npipe_result.dump_content_list(md_writer, f\"{name_without_suff}_content_list.json\", image_dir)\n\n### get middle json\nmiddle_json_content = pipe_result.get_middle_json()\n\n### dump middle json\npipe_result.dump_middle_json(md_writer, f'{name_without_suff}_middle.json')\n```\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/data/datajuicer/image4.png)\n\n##### å¤„ç†ç»“æœ\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/data/datajuicer/image5.png)\n\n### åˆ©ç”¨Langchainåˆ‡åˆ†mdæ•°æ®ï¼Œå¹¶è½¬ä¸ºjsonlæ ¼å¼\n\n#### Langchainç¯å¢ƒå®‰è£…\n\n```bash\npip install langchain\n```\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/data/datajuicer/image6.png)\n\n#### pyè„šæœ¬åˆ‡åˆ†è½¬å¥½çš„mdæ•°æ®\n\n\nLangChain çš„ `**RecursiveCharacterTextSplitter**` ä¼š **æŒ‰ä¼˜å…ˆçº§** ä¾æ¬¡å°è¯• **åˆ†å‰²æ–‡æœ¬**ï¼š\n\n1. `**\\n**`ï¼ˆæ¢è¡Œç¬¦ï¼‰ï¼šå¦‚æœèƒ½æŒ‰æ®µè½åˆ†å‰²ï¼Œå°±ä¸ç»§ç»­å¾€ä¸‹ã€‚\n2. `**\". \"**`** / **`**\"ã€‚\"**`ï¼ˆå¥å·ï¼‰ï¼šå¦‚æœæ²¡æœ‰æ¢è¡Œç¬¦ï¼Œå°±æŒ‰å¥å·åˆ†å‰²ã€‚\n3. `**\"!\"**`** / **`**\"?\"**`** / **`**\"ï¼›\"**`** / **`**\";\"**`ï¼ˆå…¶ä»–æ ‡ç‚¹ï¼‰ï¼šå¦‚æœå¥å·ä¹Ÿæ²¡æœ‰ï¼Œå°±æŒ‰è¿™äº›ç¬¦å·åˆ‡åˆ†ã€‚\n\n**ğŸš€**** è¿™æ ·èƒ½ä¿è¯**ï¼š\n\n+ **å…ˆæŒ‰æ®µè½åˆ†å‰²**ï¼Œå¦‚æœæ®µè½å¤ªé•¿ï¼Œå†æŒ‰ **å¥å·** ç»†åˆ†ï¼›\n+ **å¦‚æœå¥å·ä¹Ÿä¸å¤Ÿç”¨ï¼Œå°±ç»§ç»­ç”¨å…¶ä»–æ ‡ç‚¹åˆ†å‰²**ï¼Œç¡®ä¿åˆ‡ç‰‡åˆç†ã€‚\n\n\n\n```python\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nimport json \n# è¯»å– Markdown æ–‡ä»¶\nwith open(\"/mnthp/users/wangxiangbo/mineru/data/pdf2.md\", \"r\", encoding=\"utf-8\") as f:\n    markdown_text = f.read()\n\n# ä½¿ç”¨ RecursiveCharacterTextSplitterï¼ŒæŒ‰å¥å·åˆ†å‰²\nsplitter = RecursiveCharacterTextSplitter(\n    chunk_size=300,   # æ¯ä¸ªå—æœ€å¤§é•¿åº¦\n    chunk_overlap=0, # å…è®¸çš„é‡å å­—ç¬¦\n    separators=[\"\\n\", \". \", \"ã€‚\", \"!\", \"?\", \"ï¼›\", \";\"],  # å…ˆæŒ‰æ¢è¡Œç¬¦åˆ†å‰²ï¼Œå†æŒ‰å¥å·ã€æ„Ÿå¹å·ç­‰\n)\n\nchunks = splitter.split_text(markdown_text)\n\n# ä¿å­˜ä¸º JSONL æ–‡ä»¶\noutput_path = \"/mnthp/users/wangxiangbo/mineru/data/output6.jsonl\"\nwith open(output_path, \"w\", encoding=\"utf-8\") as f:\n    for chunk in chunks:\n        f.write(json.dumps({\"text\": chunk}, ensure_ascii=False) + \"\\n\")\n\nprint(f\"æ–‡æœ¬å·²æŒ‰å¥å·åˆ†å‰²å¹¶ä¿å­˜åˆ° {output_path}\")\n\n```\n\n#### åˆ‡åˆ†ç»“æœ\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/data/datajuicer/image7.png)\n\n### Data-juicerè¿›è¡Œæ•°æ®æ¸…æ´—ä¸è´¨é‡åˆ†æ\n\n#### data-juicerç¯å¢ƒå®‰è£…\n\n\n[https://github.com/modelscope/data-juicer](https://github.com/modelscope/data-juicer)\n\n\n\nä¾èµ–ç¯å¢ƒæ­¥éª¤ç•¥å»ï¼Œå·²æ¨è‡³é•œåƒ\n\n```bash\nregistry.cn-shanghai.aliyuncs.com/aliyun_repository_wxb/repository_wxb:data-juicer\n```\n\n#### æ•°æ®æ¸…æ´—\n\n##### æ¸…æ´—é…ç½®\n\n```yaml\n# Process config example for dataset\n\n# global parameters\nproject_name: 'test-process'\ndataset_path: '/mnt/mineru/data/output6.jsonl'  # path to your dataset directory or file\nnp: 4  # number of subprocess to process your dataset\n\nexport_path: './outputs/demo-process/test-processed4.jsonl'\n\n# process schedule\n# a list of several process operators with their arguments\nprocess:\n  - language_id_score_filter:\n      lang: 'zh'\n      min_score: 0.8\n  - clean_email_mapper:                                     # remove emails from text.\n  - clean_html_mapper:                                      # remove html formats form text.\n  - clean_ip_mapper:                                        # remove ip addresses from text.\n  - clean_links_mapper:                                     # remove web links from text.\n  - average_line_length_filter:                             # filter text with the average length of lines out of specific range.\n      min_len: 50                                             # the min length of filter range\n      max_len: 10000                                          # the max length of filter range\n#   - perplexity_filter:\n#       lang: 'zh'\n#       max_ppl: 5000                                             #è¿‡æ»¤å›°æƒ‘åº¦å¤§äº5000çš„æ–‡æœ¬  \n#   - alphanumeric_filter:                                    # filter text with alphabet/numeric ratio out of specific range.\n#       tokenization: false                                     # whether to count the ratio of alphanumeric to the total number of tokens.\n#       min_ratio: 0.0                                          # ç¡®ä¿æ–‡æœ¬åŒ…å«è¶³å¤Ÿå¤šçš„å­—æ¯æ•°å­—å†…å®¹ï¼Œå­—æ¯æ•°å­—/æ€»å­—ç¬¦æ•° >0.7\n#       max_ratio: 0.9                                         # å…è®¸é«˜è¾¾90%çš„å­—æ¯æ•°å­—ï¼Œè¿‡æ»¤æ‰æ¥è¿‘çº¯å­—æ¯æ•°å­—çš„å¼‚å¸¸æ–‡æœ¬ã€‚\n```\n\n```bash\npython tools/process_data.py --config configs/demo/process.yaml\n```\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/data/datajuicer/image8.png)\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/data/datajuicer/image9.png)\n\n\n\n#### æ•°æ®åˆ†æï¼ˆè´¨é‡ï¼‰\n\n##### åˆ†æé…ç½®\n\n```yaml\n# Process config example for dataset\n\n# global parameters\nproject_name: 'demo-analyzer'\ndataset_path: './outputs/demo-process/test-processed4.jsonl'  # path to your dataset directory or file\nnp: 4  # number of subprocess to process your dataset\n\nexport_path: './outputs/demo-analyzer/demo-analyzer-result4.jsonl'\n\n# process schedule\n# a list of several process operators with their arguments\nprocess:\n  - language_id_score_filter:\n      lang: 'zh'\n  - perplexity_filter:\n      lang: 'zh'\n    #   max_ppl: 5000                                             #è¿‡æ»¤å›°æƒ‘åº¦å¤§äº5000çš„æ–‡æœ¬                                        \n#   - llm_difficulty_score_filter:                            # filter to keep sample with high difficulty score estimated by LLM.\n#       api_or_hf_model: 'gpt-4o'                               # API or huggingface model name.\n#       min_score: 0.5                                          # The lowest difficulty score threshold to keep the sample.\n#       api_endpoint: null                                      # URL endpoint for the API.\n#       response_path: null                                     # Path to extract content from the API response. Defaults to 'choices.0.message.content'.\n#       input_keys: ['text']                                    # Sub set of keys in the sample. Support data with multi fields such as 'query', 'analysis' and 'answer' in RFT data.\n#       field_names: ['text']                                   # Corresponding field names for input keys.\n#       system_prompt: null                                     # System prompt for the task.\n#       input_template: null                                    # The input template.\n#       field_template: null                                    # Template for each field in the prompt.\n#       try_num: 3                                              # The number of retry attempts when there is an API call error or output parsing error.\n#       enable_vllm: false                                      # If true, use VLLM for loading hugging face or local llm. Otherwise, use API for reference.\n#       model_params: {}                                        # Parameters for initializing the API model.\n#       sampling_params: {}                                     # Extra parameters passed to the API call. e.g {'temperature': 0.9, 'top_p': 0.95}\n#   - llm_quality_score_filter:                               # filter to keep sample with high quality score estimated by LLM.\n#       api_or_hf_model: 'gpt-4o'                               # API or huggingface model name.\n#       min_score: 0.5                                          # The lowest quality score threshold to keep the sample.\n#       api_endpoint: https://dashscope.aliyuncs.com/compatible-mode/v1                                      # URL endpoint for the API.\n#       response_path: null                                     # Path to extract content from the API response. Defaults to 'choices.0.message.content'.\n#       input_keys: ['text']                                    # Sub set of keys in the sample. Support data with multi fields such as 'query', 'analysis' and 'answer' in RFT data.\n#       field_names: ['text']                                   # Corresponding field names for input keys.\n#       system_prompt: null                                     # System prompt for the task.\n#       input_template: null                                    # The input template.\n#       field_template: null                                    # Template for each field in the prompt.\n#       try_num: 3                                              # The number of retry attempts when there is an API call error or output parsing error.\n#       enable_vllm: false                                      # If true, use VLLM for loading hugging face or local llm. Otherwise, use API for reference.\n#       model_params: {\n#         'api_key': \"sk-312f14f4e65144f1b9f9240a31b584f9\",  # ä½ çš„ OpenAI API Key\n#         'base_url': \"https://dashscope.aliyuncs.com/compatible-mode/v1\"  # OpenAI API Base URL\n#       }                                        # Parameters for initializing the API model.\n#       sampling_params: {\n#         'temperature': 0.9,\n#         'top_p': 0.95\n#       }                                     # Extra parameters passed to the API call. e.g {'temperature': 0.9, 'top_p': 0.95}\n\n```\n\n```bash\npython tools/analyze_data.py --config configs/demo/analyzer.yaml\n```\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/data/datajuicer/image10.png)\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/data/datajuicer/image11.png)\n\n\n**1. è¯­è¨€æ£€æµ‹ï¼ˆlangï¼‰**\n\n+ count: 19.0ï¼ˆ19 ä¸ªæ ·æœ¬éƒ½æœ‰è¯­è¨€æ ‡è®°ï¼‰ã€‚\n+ unique: 1.0ï¼ˆåªæœ‰ä¸€ç§è¯­è¨€ï¼‰ã€‚\n+ top: zhï¼ˆæœ€å¸¸è§çš„è¯­è¨€æ˜¯ä¸­æ–‡ï¼‰ã€‚\n+ freq: 19.0ï¼ˆæ‰€æœ‰ 19 ä¸ªæ ·æœ¬éƒ½æ˜¯ä¸­æ–‡ï¼‰ã€‚\n+ ç»“è®ºï¼šè¿™ä¸ªæ•°æ®é›†æ˜¯çº¯ä¸­æ–‡æ•°æ®é›†ï¼Œæ²¡æœ‰å…¶ä»–è¯­è¨€æ··å…¥ã€‚\n\n**2. è¯­è¨€å¾—åˆ†ï¼ˆlang_scoreï¼‰**\n\nå®šä¹‰ï¼šè¯­è¨€å¾—åˆ†é€šå¸¸è¡¨ç¤ºæ–‡æœ¬è¢«è¯†åˆ«ä¸ºæŸç§è¯­è¨€çš„å¯ä¿¡åº¦ï¼Œåˆ†æ•°èŒƒå›´ä¸€èˆ¬æ˜¯ 0 åˆ° 1ï¼Œè¶Šé«˜è¡¨ç¤ºè¶Šå¯èƒ½æ˜¯è¯¥è¯­è¨€ã€‚\n\nç»Ÿè®¡ç»“æœï¼š \n\n+ mean: 0.949412ï¼ˆå¹³å‡å¾—åˆ†çº¦ä¸º 0.95ï¼Œè¡¨æ˜æ–‡æœ¬è¢«è¯†åˆ«ä¸ºä¸­æ–‡çš„ç½®ä¿¡åº¦å¾ˆé«˜ï¼‰ã€‚\n+ std: 0.02133ï¼ˆæ ‡å‡†å·®è¾ƒå°ï¼Œè¯´æ˜å¾—åˆ†åˆ†å¸ƒè¾ƒä¸ºé›†ä¸­ï¼Œæ ·æœ¬é—´å·®å¼‚ä¸å¤§ï¼‰ã€‚\n+ min: 0.909303ï¼ˆæœ€ä½å¾—åˆ†ä»é«˜äº 0.9ï¼Œè¯´æ˜å³ä½¿æ˜¯æœ€å·®çš„æ ·æœ¬ï¼Œä¸­æ–‡è¯†åˆ«ç½®ä¿¡åº¦ä¹Ÿå¾ˆé«˜ï¼‰ã€‚\n+ 25%: 0.937739ï¼ˆ25% åˆ†ä½æ•°ï¼Œè¯´æ˜å¤§éƒ¨åˆ†æ ·æœ¬å¾—åˆ†é«˜äº 0.94ï¼‰ã€‚\n+ 50%: 0.95398ï¼ˆä¸­ä½æ•°ï¼Œæ¥è¿‘å‡å€¼ï¼Œåˆ†å¸ƒè¾ƒä¸ºå¯¹ç§°ï¼‰ã€‚\n+ 75%: 0.958543ï¼ˆ75% åˆ†ä½æ•°ï¼Œå¤§éƒ¨åˆ†æ ·æœ¬å¾—åˆ†é›†ä¸­åœ¨ 0.96 ä»¥ä¸‹ï¼‰ã€‚\n+ max: 0.98278ï¼ˆæœ€é«˜å¾—åˆ†æ¥è¿‘ 1ï¼Œè¡¨æ˜æœ‰äº›æ ·æœ¬å‡ ä¹è¢«å®Œç¾è¯†åˆ«ä¸ºä¸­æ–‡ï¼‰ã€‚\n\nç»“è®ºï¼šè¯­è¨€å¾—åˆ†æ•´ä½“è¾ƒé«˜ä¸”åˆ†å¸ƒç¨³å®šï¼Œè¯´æ˜æ•°æ®é›†çš„æ–‡æœ¬è¯­è¨€ä¸€è‡´æ€§éå¸¸å¥½ï¼Œå‡ ä¹å¯ä»¥ç¡®å®šä¸ºé«˜è´¨é‡çš„ä¸­æ–‡æ–‡æœ¬ã€‚\n\n**3. å›°æƒ‘åº¦ï¼ˆperplexityï¼‰**\n\nå®šä¹‰ï¼šå›°æƒ‘åº¦æ˜¯è¡¡é‡è¯­è¨€æ¨¡å‹å¯¹æ–‡æœ¬é¢„æµ‹éš¾åº¦çš„æŒ‡æ ‡ï¼Œé€šå¸¸ä¸æ–‡æœ¬çš„å¤æ‚æ€§ã€å¯é¢„æµ‹æ€§ç›¸å…³ã€‚å€¼è¶Šä½ï¼Œæ–‡æœ¬è¶Šå®¹æ˜“è¢«æ¨¡å‹ç†è§£ï¼›å€¼è¶Šé«˜ï¼Œæ–‡æœ¬å¯èƒ½æ›´å¤æ‚æˆ–å™ªå£°æ›´å¤§ã€‚\n\nç»Ÿè®¡ç»“æœï¼š \n\n+ mean: 4351.347368ï¼ˆå¹³å‡å›°æƒ‘åº¦çº¦ä¸º 4351ï¼Œåé«˜ï¼‰ã€‚\n+ std: 1360.413693ï¼ˆæ ‡å‡†å·®è¾ƒå¤§ï¼Œè¯´æ˜æ ·æœ¬é—´å›°æƒ‘åº¦å·®å¼‚æ˜æ˜¾ï¼‰ã€‚\n+ min: 1270.3ï¼ˆæœ€ä½å›°æƒ‘åº¦ï¼Œè¡¨æ˜æœ‰äº›æ ·æœ¬è¾ƒä¸ºç®€å•æˆ–è§„å¾‹æ€§å¼ºï¼‰ã€‚\n+ 25%: 3974.1ï¼ˆ25% åˆ†ä½æ•°ï¼Œå¤§å¤šæ•°æ ·æœ¬å›°æƒ‘åº¦é«˜äº 3974ï¼‰ã€‚\n+ 50%: 4415.3ï¼ˆä¸­ä½æ•°ï¼Œä¸å‡å€¼æ¥è¿‘ï¼Œåˆ†å¸ƒç›¸å¯¹å‡åŒ€ï¼‰ã€‚\n+ 75%: 5062.0ï¼ˆ75% åˆ†ä½æ•°ï¼Œè¡¨æ˜ 25% çš„æ ·æœ¬å›°æƒ‘åº¦é«˜äº 5062ï¼‰ã€‚\n+ max: 7357.8ï¼ˆæœ€é«˜å›°æƒ‘åº¦ï¼Œè¯´æ˜æŸäº›æ ·æœ¬å¯èƒ½éå¸¸å¤æ‚æˆ–åŒ…å«å™ªå£°ï¼‰ã€‚\n\nç»“è®ºï¼šå›°æƒ‘åº¦å‡å€¼å’ŒèŒƒå›´éƒ½è¾ƒé«˜ï¼ˆ1270.3 åˆ° 7357.8ï¼‰ï¼Œä¸”æ ‡å‡†å·®è¾ƒå¤§ï¼Œè¡¨æ˜æ•°æ®é›†æ–‡æœ¬å¤æ‚åº¦å·®å¼‚æ˜¾è‘—ã€‚éƒ¨åˆ†æ ·æœ¬å¯èƒ½åŒ…å«ä¸è§„åˆ™å†…å®¹ã€å™ªå£°æˆ–è¿‡äºå¤æ‚çš„è¡¨è¾¾ï¼Œè¿™å¯èƒ½ä¼šå½±å“æ¨¡å‹è®­ç»ƒæ•ˆæœã€‚\n\n\n\n## jsonlæ ¼å¼æ•°æ®->Q&Aé—®ç­”å¯¹æ ¼å¼\n\n### jsonlæ ¼å¼æ•°æ®é›†\n\n\né‡‡ç”¨huggingfaceå¼€æºçš„BAAI/IndustryCorpuså’ŒBAAI/IndustryCorpus2\n\nè®¡ç®—æœºæ•°æ®é›†ï¼š[https://huggingface.co/datasets/BAAI/IndustryCorpus_computer](https://huggingface.co/datasets/BAAI/IndustryCorpus_computer)\n\nå›½å®¶æ”¿æ²»ç±»æ•°æ®é›†ï¼š[https://huggingface.co/datasets/BAAI/IndustryCorpus2_current_affairs_government_administration](https://huggingface.co/datasets/BAAI/IndustryCorpus2_current_affairs_government_administration)\n\næ¸…æ´—å¤„ç†åçš„æ”¿ä¼ç±»æ•°æ®é›†ï¼š/mnthp/users/wangxiangbo/data-juicer-main/outputs/demo-process/test-processed4.jsonl\n\n\n\n#### è®¡ç®—æœºç±»æ•°æ®é›†jsonlæŠ½å–\n\nä¸ºäº†æµ‹è¯•ä»£ç å’ŒèŠ‚çº¦apiï¼Œä»…æµ‹è¯•å…¶ä¸­10æ¡æ•°æ®\n\n```json\n{\"text\":\"æ¨ç‰¹æ€æ ·æŸ¥çœ‹è¯„è®º(æ¨ç‰¹æ€ä¹ˆçœ‹è¯„è®ºåŒº)\\nå»å¹´22æœˆå¼€å§‹,æ¨ç‰¹å¼€å§‹æµ‹è¯•ç±»ä¼¼äºRedditçš„å¯¹è¯æ ‘ç”¨æˆ·ç•Œé¢,ä»¥å¸®åŠ©ç”¨æˆ·æ›´è½»æ¾åœ°è¿½è¸ªè½¬å‘å’Œåç»­æ¨æ–‡.åœ¨ç»è¿‡5ä¸ªå¤šæœˆçš„æµ‹è¯•ä¹‹å,è¯¥åŠŸèƒ½ç»ˆäºé¢å‘æ‰€æœ‰ç”¨æˆ·å¼€æ”¾.\\nç±»ä¼¼äºRedditçš„å¯¹è¯æ ‘ç°åœ¨å¯ä»¥åœ¨Windows10çš„Twitter PWAå’Œç½‘é¡µç«¯ä¸­ä½¿ç”¨.å¦‚æœä½ ä½¿ç”¨çš„æ˜¯Androidæ‰‹æœº,å¹¶ä¸”æ‰‹æœºä¸Šå®‰è£…äº†Twitter Lite,ä½ ä¹Ÿä¼šçœ‹åˆ°è¿™ä¸ªå˜åŒ–.å€¼å¾—æ³¨æ„çš„æ˜¯,ç”±äºè¿™æ˜¯ä¸€ä¸ªæœåŠ¡å™¨ç«¯çš„æ›´æ–°,æ‰€ä»¥ä¸éœ€è¦ä½ è®¿é—®Google Play Storeæˆ–Microsoft Store,ä¹Ÿä¸éœ€è¦ä½ å»æ›´æ–°Twitter webåº”ç”¨.\",\"alnum_ratio\":0.9172661871,\"avg_line_length\":92.6666666667,\"char_rep_ratio\":0.029739777,\"flagged_words_ratio\":0.0,\"industry_type\":\"è®¡ç®—æœº\",\"lang\":\"zh\",\"lang_score\":0.8875751495,\"max_line_length\":180,\"num_words\":73,\"perplexity\":1061.4,\"special_char_ratio\":0.1079136691,\"word_rep_ratio\":0.0,\"id\":3822520893459}\n```\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/data/datajuicer/image12.png)\n\n#### å›½å®¶æ”¿æ²»ç±»æ•°æ®é›†parquetæ ¼å¼è½¬ä¸ºjsonlæ ¼å¼\n\n```python\nimport pandas as pd\n\n# è¯»å– parquet æ–‡ä»¶\ndf = pd.read_parquet('/mnt/data/government_administration/chinese/middle/rank_00410.parquet')\n\n# è½¬æ¢ä¸º JSON Lines æ ¼å¼å¹¶ä¿å­˜\ndf.to_json(\"data.json\", orient=\"records\", lines=True, force_ascii=False)\n```\n\n```json\n{\"text\":\"ä¸­å›½å¤–äº¤éƒ¨å‘è¨€äººè€¿çˆ½27æ—¥åœ¨åŒ—äº¬è¡¨ç¤º,ä¸­æ–¹å‚ä¸æ‰“å‡»ç´¢é©¬é‡Œæµ·ç›—å›½é™…åˆä½œçš„è¡ŒåŠ¨,å¾—åˆ°äº†æœ‰å…³å›½å®¶çš„ç§¯æè¯„ä»·,ä¸ºç»´æŠ¤å›½é™…å’Œåœ°åŒºçš„å’Œå¹³ä¸å®‰å…¨ä½œå‡ºé‡è¦è´¡çŒ®,ä¹Ÿå±•ç°äº†ä¸­å›½è´Ÿè´£ä»»,æœ‰æ‹…å½“çš„å¤§å›½å½¢è±¡.\\nä¸­æ–°ç¤¾è®°è€… ä¾¯å®‡ æ‘„\\n  åœ¨å½“å¤©ä¸¾è¡Œçš„å¤–äº¤éƒ¨ä¾‹è¡Œè®°è€…ä¼šä¸Š,æœ‰è®°è€…æé—®:æ—¥å‰,è”åˆå›½ç§˜ä¹¦é•¿å‘å®‰ç†ä¼šæäº¤ç´¢é©¬é‡Œæµ·ç›—é—®é¢˜æŠ¥å‘Š.æŠ¥å‘Šå¤šæ¬¡æåŠä¸­å›½åœ¨äºšä¸æ¹¾å’Œç´¢é©¬é‡Œæµ·åŸŸæ‰§è¡ŒæŠ¤èˆªä»»åŠ¡,ä¸ºåº”å¯¹æµ·ç›—å¨èƒå‘æŒ¥äº†é‡è¦ä½œç”¨.ä¸­æ–¹å¯¹æ­¤æœ‰ä½•è¯„è®º?\\n  è€¿çˆ½å›åº”è¯´,2008å¹´12æœˆ,ç»è”åˆå›½å®‰ç†ä¼šæˆæƒ,ä¸­å›½æµ·å†›æ´¾å‡ºé¦–æ‰¹èˆ°è‰‡ç¼–é˜Ÿ,èµ´äºšä¸æ¹¾,ç´¢é©¬é‡Œæµ·åŸŸæ‰§è¡ŒæŠ¤èˆªä»»åŠ¡.æˆªè‡³2017å¹´7æœˆ,ä¸­å›½æµ·å†›å…ˆåæ´¾å‡ºäº†26æ‰¹æŠ¤èˆªç¼–é˜Ÿ,ä¸ºä¸­å¤–6400ä½™è‰˜èˆ¹åªæä¾›æŠ¤èˆª,é©±ç¦»ç–‘ä¼¼æµ·ç›—èˆ¹åª3000ä½™è‰˜æ¬¡,æœ‰åŠ›ä¿éšœäº†å›½é™…é‡è¦è´¸æ˜“èˆªé“å®‰å…¨.ä¸­æ–¹å‚ä¸æ‰“å‡»ç´¢é©¬é‡Œæµ·ç›—å›½é™…åˆä½œçš„è¡ŒåŠ¨,å¾—åˆ°äº†æœ‰å…³å›½å®¶çš„ç§¯æè¯„ä»·,ä¸ºç»´æŠ¤å›½é™…å’Œåœ°åŒºçš„å’Œå¹³ä¸å®‰å…¨ä½œå‡ºé‡è¦è´¡çŒ®,ä¹Ÿå±•ç°äº†ä¸­å›½è´Ÿè´£ä»»,æœ‰æ‹…å½“çš„å¤§å›½å½¢è±¡.\\n  \\\"è”åˆå›½ç§˜ä¹¦é•¿çš„æœ‰å…³æŠ¥å‘Šå¯¹ä¸­æ–¹æ‰€ä½œå·¥ä½œå’Œè´¡çŒ®ç»™äºˆäº†ç§¯æè¯„ä»·,æˆ‘ä»¬å¯¹æ­¤è¡¨ç¤ºèµèµ.\\\"è€¿çˆ½è¯´,æ­£å¦‚ä¹ è¿‘å¹³æ€»ä¹¦è®°åœ¨åä¹å¤§æŠ¥å‘Šä¸­æ‰€æŒ‡å‡ºçš„,ä¸­å›½å°†æªå®ˆç»´æŠ¤ä¸–ç•Œå’Œå¹³,ä¿ƒè¿›å…±åŒå‘å±•çš„å¤–äº¤æ”¿ç­–å®—æ—¨,å§‹ç»ˆåšä¸–ç•Œå’Œå¹³çš„å»ºè®¾è€…,å…¨çƒå‘å±•çš„è´¡çŒ®è€…,å›½é™…ç§©åºçš„ç»´æŠ¤è€….ä¸­æ–¹å°†ç»§ç»­ç§¯æå‚ä¸äºšä¸æ¹¾å’Œç´¢é©¬é‡Œæµ·åŸŸæŠ¤èˆªè¡ŒåŠ¨,æ‹“å±•å›½é™…æŠ¤èˆªåˆä½œ,å±¥è¡Œå›½é™…è´£ä»»å’Œä¹‰åŠ¡,ä¸ºç»´æŠ¤å›½é™…å’Œåœ°åŒºå’Œå¹³ä¸ç¨³å®š,ä¿éšœå›½é™…é‡è¦é€šé“å®‰å…¨å‘æŒ¥æ›´å¤§ä½œç”¨.(å®Œ)\",\"alnum_ratio\":0.9024793388,\"avg_line_length\":121.0,\"char_rep_ratio\":0.0771812081,\"flagged_words_ratio\":0.0,\"max_line_length\":204,\"num_words\":213,\"perplexity\":701.0,\"quality_score\":3.79296875,\"special_char_ratio\":0.1371900826,\"word_rep_ratio\":0.1848184818,\"_id\":1005000038194,\"industry_type\":\"æ—¶æ”¿_æ”¿åŠ¡_è¡Œæ”¿\"}\n```\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/data/datajuicer/image13.png)\n\n### é€šè¿‡é˜¿é‡Œapi_keyåˆ†æåŸå§‹jsonlå¹¶ç”ŸæˆQAå¾®è°ƒç±»æ•°æ®é›†\n\n#### pyè„šæœ¬\n\n```bash\nimport os\nimport json\nfrom openai import OpenAI\n\n# åˆå§‹åŒ–å®¢æˆ·ç«¯\ntry:\n    client = OpenAI(\n        api_key=\"sk-312f14f4e65144f1b9f9240a31b584f9\",  # è¯·æ›¿æ¢ä¸ºä½ çš„å®é™…API Key\n        base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n    )\n\n    # è¾“å…¥æ–‡ä»¶è·¯å¾„\n    input_file = \"/mnt/data/IndustryCorpus_computer/10.jsonl\"\n    \n    # è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆåªä¿å­˜Q&Aé—®ç­”å¯¹ï¼‰\n    output_file = \"/mnt/data/IndustryCorpus_computer/10_qa_pairs.jsonl\"\n\n    # è®¡æ•°å™¨\n    processed_count = 0\n\n    # æ‰“å¼€è¾“å…¥æ–‡ä»¶å¹¶é€è¡Œå¤„ç†\n    with open(input_file, 'r', encoding='utf-8') as f:\n        for line in f:\n            try:\n                # è§£ææ¯ä¸€è¡Œçš„JSONæ•°æ®\n                data = json.loads(line.strip())\n                \n                # æ„é€ è¯·æ±‚æ¶ˆæ¯ï¼Œè¦æ±‚è¿”å›ç‰¹å®šJSONæ ¼å¼\n                completion = client.chat.completions.create(\n                    model=\"qwen-plus\",\n                    messages=[\n                        {\n                            'role': 'system', \n                            'content': '''ä½ æ˜¯ä¸€ä¸ªæ“…é•¿ä¿¡æ¯æå–å’Œé—®ç­”å¯¹è½¬æ¢çš„åŠ©æ‰‹ã€‚è¯·æ ¹æ®æä¾›çš„æ–‡æœ¬ï¼Œåˆ†æå…¶å†…å®¹å¹¶è½¬æ¢ä¸ºé€‚åˆè®­ç»ƒçš„é—®ç­”å¯¹æ ¼å¼ï¼Œä¸€å¯¹é—®ç­”å¯¹å³å¯ã€‚è¾“å‡ºå¿…é¡»æ˜¯ä»¥ä¸‹JSONæ ¼å¼ï¼š\n                            {\n                                \"instruction\": \"é—®é¢˜\",\n                                \"output\": \"ç­”æ¡ˆ\"\n                            }\n                            ç¡®ä¿é—®é¢˜å’Œç­”æ¡ˆå†…å®¹å‡†ç¡®åæ˜ è¾“å…¥æ–‡æœ¬ä¿¡æ¯ã€‚'''\n                        },\n                        {\n                            'role': 'user', \n                            'content': json.dumps(data, ensure_ascii=False)\n                        }\n                    ]\n                )\n                \n                # è·å–å¤§æ¨¡å‹çš„è¾“å‡ºï¼ˆJSONæ ¼å¼çš„é—®ç­”å¯¹ï¼‰\n                qa_pair = completion.choices[0].message.content\n                \n                # æ‰“å°ç»“æœ\n                print(f\"å¤„ç†ç¬¬ {processed_count + 1} è¡Œ:\")\n                print(qa_pair)\n                print(\"-\" * 50)\n                \n                # ä¿å­˜JSONæ ¼å¼çš„é—®ç­”å¯¹åˆ°æ–‡ä»¶\n                with open(output_file, 'a', encoding='utf-8') as out_f:\n                    out_f.write(qa_pair + \"\\n\")\n                \n                processed_count += 1\n                \n            except Exception as line_error:\n                print(f\"å¤„ç†ç¬¬ {processed_count + 1} è¡Œæ—¶å‡ºé”™ï¼š{line_error}\")\n                continue\n    \n    print(f\"å¤„ç†å®Œæˆï¼Œæ€»å…±å¤„ç† {processed_count} è¡Œæ•°æ®\")\n\nexcept Exception as e:\n    print(f\"åˆå§‹åŒ–æˆ–ä¸»ç¨‹åºé”™è¯¯ï¼š{e}\")\n    print(\"è¯·å‚è€ƒæ–‡æ¡£ï¼šhttps://help.aliyun.com/zh/model-studio/developer-reference/error-code\")\n\n```\n\n#### å¤„ç†ç»“æœ\n\n##### è®¡ç®—æœºç±»æ•°æ®é›†\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/data/datajuicer/image14.png)\n\n\n\n### é€šè¿‡ç§»åŠ¨äº‘api_keyåˆ†æåŸå§‹jsonlå¹¶ç”ŸæˆQAå¾®è°ƒç±»æ•°æ®é›†\n\n#### pyè„šæœ¬\n\n```bash\nfrom openai import OpenAI\nimport json\nimport os\nimport re\nimport logging\n\n# è®¾ç½®æ—¥å¿—\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.FileHandler(\"/mnt/api/log/government.log\", encoding='utf-8'),\n        logging.StreamHandler()\n    ]\n)\nlogger = logging.getLogger(__name__)\n\n# åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯\nclient = OpenAI(\n    api_key=\"jn8P1B1vl7AbKZanw-rDQ9ahJmUH3eML_hAaKGP9wkA\",\n    base_url=\"https://zhenze-huhehaote.cmecloud.cn/inference-api/exp-api/inf-1336781912337387520/v1\"\n)\n\n# æ–‡ä»¶è·¯å¾„\ninput_file_path = \"/mnt/data-juicer-main/outputs/demo-process/test-processed2.jsonl\"\noutput_file_path = \"/mnt/api/res/government_qa.jsonl\"\n\n# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨\noutput_dir = os.path.dirname(output_file_path)\nif not os.path.exists(output_dir):\n    os.makedirs(output_dir)\n\n# ç³»ç»Ÿæç¤º\nsystem_prompt = {\n    \"role\": \"system\",\n    \"content\": \"\"\"ä½ æ˜¯ä¸€ä¸ªæ“…é•¿ä¿¡æ¯æå–å’Œé—®ç­”å¯¹è½¬æ¢çš„åŠ©æ‰‹ã€‚è¯·æ ¹æ®æä¾›çš„æ–‡æœ¬ï¼Œåˆ†æå…¶å†…å®¹å¹¶è½¬æ¢ä¸ºä¸€ä¸ªé—®ç­”å¯¹ï¼Œæ ¼å¼å¿…é¡»ä¸ºï¼š\n    {\"instruction\": \"é—®é¢˜\", \"input\": \"\", \"output\": \"ç­”æ¡ˆ\"}\n    åªç”Ÿæˆä¸€å¯¹é—®ç­”å¯¹ï¼Œè¿”å›JSONå­—ç¬¦ä¸²ã€‚\n    \"\"\"\n}\n\n# è®¡æ•°å™¨\nprocessed_count = 0\nerror_count = 0\n\n# ä»å“åº”ä¸­æå–JSONçš„å‡½æ•°\ndef extract_json_from_response(response):\n    # å°è¯•ç›´æ¥è§£ææ•´ä¸ªå“åº”ä¸ºJSON\n    try:\n        qa_json = json.loads(response)\n        if all(key in qa_json for key in [\"instruction\", \"input\", \"output\"]):\n            if qa_json[\"input\"] != \"\":\n                qa_json[\"input\"] = \"\"  # å¼ºåˆ¶è®¾ä¸ºç©ºå­—ç¬¦ä¸²\n            return qa_json\n    except json.JSONDecodeError:\n        pass\n    \n    # ä½¿ç”¨æ›´ç²¾ç¡®çš„æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…JSON\n    json_match = re.search(r'```json\\s*({.*?})\\s*```', response, re.DOTALL)\n    if json_match:\n        json_str = json_match.group(1)\n        try:\n            qa_json = json.loads(json_str)\n            if all(key in qa_json for key in [\"instruction\", \"input\", \"output\"]):\n                if qa_json[\"input\"] != \"\":\n                    qa_json[\"input\"] = \"\"  # å¼ºåˆ¶è®¾ä¸ºç©ºå­—ç¬¦ä¸²\n                return qa_json\n        except json.JSONDecodeError:\n            pass\n    \n    # å¦‚æœä»ç„¶å¤±è´¥ï¼Œè¿”å›None\n    return None\n\n# è¯»å–è¾“å…¥æ–‡ä»¶å¹¶å¤„ç†\nwith open(input_file_path, 'r', encoding='utf-8') as input_file, \\\n     open(output_file_path, 'w', encoding='utf-8') as output_file:\n    \n    for line_num, line in enumerate(input_file, 1):\n        try:\n            # è§£ææ¯ä¸€è¡Œçš„JSONæ•°æ®\n            data = json.loads(line.strip())\n            user_input = json.dumps(data, ensure_ascii=False)\n            \n            # æ„é€ æ¶ˆæ¯\n            messages = [\n                system_prompt,\n                {\"role\": \"user\", \"content\": user_input}\n            ]\n            \n            # è°ƒç”¨API\n            response = client.chat.completions.create(\n                model=\"default\",\n                messages=messages,\n                max_tokens=1024,\n                temperature=0.6,\n                stream=False\n            )\n            \n            # è·å–ç»“æœ\n            qa_result = response.choices[0].message.content.strip()\n            logger.info(f\"Line {line_num} - Raw response: {qa_result}\")\n            \n            # ä»å“åº”ä¸­æå–JSON\n            qa_json = extract_json_from_response(qa_result)\n            \n            # å¦‚æœæå–å¤±è´¥ï¼Œè®°å½•åŸå§‹å“åº”\n            if qa_json is None:\n                qa_json = {\n                    \"instruction\": \"é—®é¢˜æå–å¤±è´¥\",\n                    \"input\": \"\",\n                    \"output\": f\"åŸå§‹å“åº”: {qa_result}\"\n                }\n                logger.warning(f\"Line {line_num} - Failed to extract JSON, using fallback\")\n            else:\n                logger.info(f\"Line {line_num} - Successfully extracted JSON: {json.dumps(qa_json, ensure_ascii=False)}\")\n            \n            # å†™å…¥æ–‡ä»¶\n            output_file.write(json.dumps(qa_json, ensure_ascii=False) + '\\n')\n            processed_count += 1\n            \n            # æ§åˆ¶å°æ˜¾ç¤ºè¿›åº¦\n            print(f\"å·²å¤„ç†: {processed_count} è¡Œ\")\n            \n        except json.JSONDecodeError as e:\n            error_count += 1\n            logger.error(f\"Line {line_num} - JSONè§£æé”™è¯¯: {e}, Input: {line.strip()}\")\n            print(f\"Line {line_num} - JSONè§£æé”™è¯¯: {e}\")\n            print(\"-\" * 50)\n        except Exception as e:\n            error_count += 1\n            logger.error(f\"Line {line_num} - å¤„ç†å‡ºé”™: {e}, Input: {line.strip()}\")\n            print(f\"Line {line_num} - å¤„ç†å‡ºé”™: {e}\")\n            print(\"-\" * 50)\n\n# æ‰“å°æ€»ç»“\nprint(\"=\" * 50)\nprint(f\"å¤„ç†å®Œæˆï¼\")\nprint(f\"æ€»è®¡å¤„ç†è¡Œæ•°: {processed_count + error_count}\")\nprint(f\"æˆåŠŸç”Ÿæˆé—®ç­”å¯¹: {processed_count}\")\nprint(f\"é”™è¯¯è¡Œæ•°: {error_count}\")\nprint(f\"ç»“æœå·²ä¿å­˜è‡³: {output_file_path}\")\nprint(f\"æ—¥å¿—å·²ä¿å­˜è‡³: /mnt/api/log/government.log\")\n```\n\n#### å¤„ç†ç»“æœ\n\n##### å›½å®¶æ”¿æ²»ç±»æ•°æ®é›†\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/data/datajuicer/image15.png)\n\n```json\n{\"instruction\": \"ä¸­å›½æµ·å†›é¦–æ‰¹èµ´äºšä¸æ¹¾ã€ç´¢é©¬é‡Œæµ·åŸŸæ‰§è¡ŒæŠ¤èˆªä»»åŠ¡çš„èˆ°è‰‡ç¼–é˜Ÿæ˜¯åœ¨ä½•æ—¶æ´¾å‡ºçš„ï¼Ÿ\", \"input\": \"\", \"output\": \"2008å¹´12æœˆï¼Œç»è”åˆå›½å®‰ç†ä¼šæˆæƒï¼Œä¸­å›½æµ·å†›æ´¾å‡ºé¦–æ‰¹èˆ°è‰‡ç¼–é˜Ÿèµ´äºšä¸æ¹¾ã€ç´¢é©¬é‡Œæµ·åŸŸæ‰§è¡ŒæŠ¤èˆªä»»åŠ¡ã€‚\"}\n{\"instruction\": \"é—µè¡ŒåŒºä¸ƒå®é•‡å…šå§”åœ¨æå‡å…šç¾¤æœåŠ¡é˜µåœ°èƒ½çº§æ–¹é¢é‡‡å–äº†å“ªäº›æªæ–½ï¼Ÿ\", \"input\": \"\", \"output\": \"ä¸ƒå®é•‡å…šå§”é€šè¿‡ç»‡å¥½'ç†æƒ³ä¿¡å¿µç½‘'å¼ºåŒ–æ”¿æ²»å»ºè®¾ï¼Œé‡‡ç”¨'çº¿ä¸Š+çº¿ä¸‹'ç›¸ç»“åˆçš„ç«‹ä½“åŒ–å­¦ä¹ æ•™è‚²æ–¹å¼ï¼Œæ¨å‡ºåŒ…å«ä¸ƒå·æ¡¥ç¢‰å ¡ã€å¼ å……ä»çºªå¿µé¦†ç­‰18ä¸ªçº¢è‰²ç‚¹ä½ç»„æˆçš„è¡ŒçŸ¥è·¯çº¿ï¼Œå¹¶åˆ›æ–°å¼€å±•æƒ…æ™¯å…šè¯¾ï¼Œå…¨é¢æå‡å…šç¾¤æœåŠ¡é˜µåœ°èƒ½çº§ã€‚\"}\n{\"instruction\": \"æ±ªè¾œä¼šè°ˆåœ¨ä¸¤å²¸å…³ç³»å‘å±•ä¸­å…·æœ‰æ€æ ·çš„å†å²æ„ä¹‰ï¼Ÿ\", \"input\": \"\", \"output\": \"æ±ªè¾œä¼šè°ˆæ˜¯æµ·å³¡ä¸¤å²¸æˆæƒçš„æ°‘é—´æœºæ„æœ€é«˜è´Ÿè´£äººä¹‹é—´çš„é¦–æ¬¡ä¼šæ™¤ï¼Œä¹Ÿæ˜¯ä¸¤å²¸é«˜å±‚äººå£«åœ¨é•¿æœŸéš”æ–­åçš„é¦–æ¬¡æ­£å¼æ¥è§¦ï¼Œæ ‡å¿—ç€ä¸¤å²¸èµ°å‘å’Œè§£çš„å†å²æ€§çªç ´ï¼Œæˆä¸ºä¸¤å²¸å…³ç³»å‘å±•è¿›ç¨‹ä¸­çš„\\\"é‡è¦é‡Œç¨‹ç¢‘\\\"ã€‚å°½ç®¡ä¼šè°ˆèŒƒå›´é™äºæ°‘é—´æ€§ã€ç»æµæ€§å’Œäº‹åŠ¡æ€§é¢†åŸŸï¼Œä½†æˆåŠŸå¯åŠ¨äº†ä¸¤å²¸å¯¹è¯è°ˆåˆ¤æœºåˆ¶ï¼Œæ¨åŠ¨ä¸¤å²¸å…³ç³»å‘æ›´æ·±å±‚æ¬¡å‘å±•ï¼Œä¸ºåç»­ä¸¤å²¸å…³ç³»å’Œå¹³å‘å±•è¿›å…¥å·©å›ºæ·±åŒ–æœŸå¥ å®šäº†åŸºç¡€ã€‚\"}\n{\"instruction\": \"æ³°å·å¸‚äº”å±Šäººå¤§äºŒæ¬¡ä¼šè®®é€‰ä¸¾äº§ç”Ÿçš„å¸‚äººå¤§å¸¸å§”ä¼šä¸»ä»»å’Œå¸‚ç›‘å¯Ÿå§”å‘˜ä¼šä¸»ä»»åˆ†åˆ«æ˜¯è°ï¼Ÿ\", \"input\": \"\", \"output\": \"æ›²ç¦ç”°å½“é€‰ä¸ºå¸‚äººå¤§å¸¸å§”ä¼šä¸»ä»»ï¼Œæ±¤æˆå¿«å½“é€‰ä¸ºå¸‚ç›‘å¯Ÿå§”å‘˜ä¼šä¸»ä»»ã€‚\"}\n```\n\n##### æ¸…æ´—å¤„ç†åçš„æ”¿ä¼ç±»æ•°æ®é›†\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/data/datajuicer/image16.png)\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/data/datajuicer/image17.png)\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/data/datajuicer/image18.png)\n\n```json\n{\"instruction\": \"ä¼˜åŒ–æ”¿åŠ¡æœåŠ¡ã€æå‡è¡Œæ”¿æ•ˆèƒ½çš„é‡è¦æŠ“æ‰‹æ˜¯ä»€ä¹ˆï¼Ÿ\", \"input\": \"\", \"output\": \"æŠŠ\\\"é«˜æ•ˆåŠæˆä¸€ä»¶äº‹\\\"ä½œä¸ºä¼˜åŒ–æ”¿åŠ¡æœåŠ¡ã€æå‡è¡Œæ”¿æ•ˆèƒ½çš„é‡è¦æŠ“æ‰‹ï¼Œé€šè¿‡åŠ å¼ºæ•´ä½“è®¾è®¡ã€æ¨åŠ¨æ¨¡å¼åˆ›æ–°ã€æ³¨é‡æ”¹é©å¼•é¢†å’Œæ•°å­—èµ‹èƒ½åŒè½®é©±åŠ¨ï¼Œå®ç°åŠäº‹æ–¹å¼å¤šå…ƒåŒ–ã€æµç¨‹æœ€ä¼˜åŒ–ã€ææ–™æœ€ç®€åŒ–å’Œæˆæœ¬æœ€å°åŒ–ã€‚\"}\n{\"instruction\": \"åˆ°2027å¹´æˆ‘å›½é«˜æ•ˆæ”¿åŠ¡æœåŠ¡ä½“ç³»å»ºè®¾è¦å®ç°ä»€ä¹ˆç›®æ ‡ï¼Ÿ\", \"input\": \"\", \"output\": \"åŸºæœ¬å½¢æˆæ³›åœ¨å¯åŠã€æ™ºæ…§ä¾¿æ·ã€å…¬å¹³æ™®æƒ çš„é«˜æ•ˆæ”¿åŠ¡æœåŠ¡ä½“ç³»ï¼Œå®ç°ä¼ä¸šå’Œä¸ªäººä¸¤ä¸ªå…¨ç”Ÿå‘½å‘¨æœŸé‡è¦é˜¶æ®µ'é«˜æ•ˆåŠæˆä¸€ä»¶äº‹'é‡ç‚¹äº‹é¡¹è½åœ°è§æ•ˆï¼Œå¤§å¹…æå‡ä¼ä¸šå’Œç¾¤ä¼—åŠäº‹æ»¡æ„åº¦ã€è·å¾—æ„Ÿã€‚\"}\n{\"instruction\": \"å¦‚ä½•æ¨è¿›çº¿ä¸‹åŠäº‹â€œåªè¿›ä¸€é—¨â€ï¼Ÿ\", \"input\": \"\", \"output\": \"é€šè¿‡å®Œå–„é›†çº¦é«˜æ•ˆçš„çº¿ä¸‹æ”¿åŠ¡æœåŠ¡ä½“ç³»ï¼Œå¿çº§ä»¥ä¸Šæ”¿åŠ¡æœåŠ¡ä¸­å¿ƒåº”ç»Ÿä¸€è®¾ç½®ç»¼åˆ/ä¸“ä¸šæœåŠ¡çª—å£é›†ä¸­åŠç†æ”¿åŠ¡æœåŠ¡äº‹é¡¹ï¼›æ•´åˆéƒ¨é—¨å•è®¾çª—å£è‡³æœ¬çº§ä¸­å¿ƒæˆ–å®è¡Œä¸€ä½“åŒ–ç®¡ç†ï¼›ç»Ÿç­¹å»ºè®¾ä¹¡é•‡(è¡—é“)ä¾¿æ°‘æœåŠ¡ä¸­å¿ƒå’Œæ‘(ç¤¾åŒº)ä¾¿æ°‘æœåŠ¡ç«™ï¼›é¼“åŠ±åœ¨é“¶è¡Œç½‘ç‚¹ã€é‚®æ”¿ç½‘ç‚¹ã€å›­åŒºè®¾ç½®ä¾¿æ°‘æœåŠ¡ç‚¹ï¼Œå¹¶åˆ©ç”¨é›†æˆå¼è‡ªåŠ©ç»ˆç«¯æä¾›24å°æ—¶æœåŠ¡ã€‚\"}\n{\"instruction\": \"å¦‚ä½•æ¨è¿›çº¿ä¸ŠåŠäº‹â€œä¸€ç½‘é€šåŠâ€ï¼Ÿ\", \"input\": \"\", \"output\": \"åŠ å¼ºå›½å®¶æ”¿åŠ¡æœåŠ¡å¹³å°ä¸ºæ€»æ¢çº½çš„å…¨å›½æ”¿åŠ¡æœåŠ¡â€œä¸€å¼ ç½‘â€å»ºè®¾ï¼Œæ¨åŠ¨é«˜é¢‘äº‹é¡¹ç½‘ä¸ŠåŠã€æŒä¸ŠåŠã€ä¸€æ¬¡åŠï¼›å»ºè®¾çœçº§æ”¿åŠ¡æœåŠ¡å¹³å°ç»Ÿä¸€å—ç†ç«¯å®ç°åŠä»¶ä¿¡æ¯å®æ—¶å…±äº«ï¼›æ•´åˆå„çº§å¹³å°èµ„æºæ¨åŠ¨æ”¿åŠ¡æœåŠ¡äº‹é¡¹å’Œåº”ç”¨â€œåº”æ¥å°½æ¥ã€åº”ä¸Šå°½ä¸Šâ€ï¼Œé™¤æ³•å®šæˆ–æ¶‰å¯†æƒ…å†µå¤–æ‰€æœ‰äº‹é¡¹å‡çº³å…¥åŒçº§æ”¿åŠ¡æœåŠ¡å¹³å°åŠç†ã€‚\"}\n{\"instruction\": \"å¦‚ä½•æ¨è¿›ä¼ä¸šå’Œç¾¤ä¼—è¯‰æ±‚çš„â€œä¸€çº¿åº”ç­”â€ï¼Ÿ\", \"input\": \"\", \"output\": \"é€šè¿‡ä¾æ‰˜12345æ”¿åŠ¡æœåŠ¡ä¾¿æ°‘çƒ­çº¿åŠ å¼ºçƒ­çº¿å½’å¹¶ï¼Œè®¾ç½®é‡ç‚¹é¢†åŸŸä¸“å¸­æå‡æ¥åŠæ•ˆç‡ï¼Œå»ºç«‹â€œæ¥è¯‰å³åŠâ€æœºåˆ¶åŠæ—¶å“åº”è¯‰æ±‚ï¼Œæ¨åŠ¨12345ä¸110é«˜æ•ˆå¯¹æ¥è”åŠ¨ï¼Œå¹¶åŠ å¼ºçƒ­çº¿ä¸æ”¿åŠ¡æœåŠ¡å¹³å°æŠ•è¯‰å»ºè®®ä½“ç³»ã€â€œå¥½å·®è¯„â€ä½“ç³»çš„ä¸šåŠ¡ååŒï¼Œæ‰“é€ æ™ºæ…§æ”¿åŠ¡æœåŠ¡â€œæ€»å®¢æœâ€ã€‚\"}\n{\"instruction\": \"æ¨è¿›å…³è”äº‹é¡¹é›†æˆåŠéœ€è¦é‡‡å–å“ªäº›å…·ä½“æªæ–½ï¼Ÿ\", \"input\": \"\", \"output\": \"1. å»ºç«‹'ä¸€ä»¶äº‹'ç‰µå¤´éƒ¨é—¨ä¸é…åˆéƒ¨é—¨çš„èŒè´£åˆ†å·¥ä½“ç³»ï¼›2. é‡æ„è·¨éƒ¨é—¨ä¸šåŠ¡æµç¨‹ï¼Œå®ç°å¤šè¡¨åˆä¸€ã€ä¸€ç½‘é€šåŠå’Œææ–™ä¸€æ¬¡æäº¤ï¼›3. å¼€å±•çº¿ä¸Šçº¿ä¸‹å¹¶è”å®¡æ‰¹ã€è”åˆè¯„å®¡å’Œè”åˆéªŒæ”¶ï¼›4. é€šè¿‡ç³»ç»ŸååŒå’Œæ•°æ®å…±äº«å‹ç¼©åŠç†æ—¶é—´ï¼Œé™ä½åŠäº‹æˆæœ¬ã€‚\"}\n{\"instruction\": \"æ¨è¿›å®¹ç¼ºäº‹é¡¹æ‰¿è¯ºåŠä¸­æåˆ°çš„â€œå‘ŠçŸ¥æ‰¿è¯º+å®¹ç¼ºåŠç†â€å®¡æ‰¹æœåŠ¡æ¨¡å¼çš„ä¸»è¦ç›®æ ‡æ˜¯ä»€ä¹ˆï¼Ÿ\", \"input\": \"\", \"output\": \"åœ¨é£é™©å¯æ§ã€çº é”™æˆæœ¬ä½ä¸”èƒ½å¤Ÿé€šè¿‡äº‹ä¸­äº‹åç›‘ç®¡æœ‰æ•ˆé˜²èŒƒé£é™©çš„å‰æä¸‹ï¼Œæ¨è¿›æ”¿åŠ¡æœåŠ¡ä¾¿åˆ©åŒ–ï¼Œé€šè¿‡ç”³è¯·ææ–™åè¡¥/å…äº¤ã€å®è´¨å®¡æŸ¥åç½®/è±å…ç­‰æ–¹å¼å®ç°æ”¿åŠ¡æœåŠ¡äº‹é¡¹æ‰¿è¯ºåŠç†ï¼Œå¹¶å»ºç«‹å·®å¼‚åŒ–çš„å‘ŠçŸ¥æ‰¿è¯ºäº‹åæ ¸æŸ¥å’Œé£é™©é˜²èŒƒæœºåˆ¶ã€‚\"}\n{\"instruction\": \"å¦‚ä½•æ¨è¿›æ”¿åŠ¡æœåŠ¡å¼‚åœ°äº‹é¡¹è·¨åŸŸåŠç†ï¼Ÿ\", \"input\": \"\", \"output\": \"é€šè¿‡æ¨åŠ¨æ”¿åŠ¡æœåŠ¡äº‹é¡¹çœå†…é€šåŠã€è·¨çœé€šåŠï¼Œä¾æ‰˜å…¨å›½ä¸€ä½“åŒ–æ”¿åŠ¡æœåŠ¡å¹³å°å®ç°æ•°æ®å…±äº«å’Œç½‘ä¸ŠåŠç†ï¼›ä¼˜åŒ–çº¿ä¸‹ä»£æ”¶ä»£åŠæœåŠ¡æ¨¡å¼ï¼Œå»ºç«‹è·¨åŸŸçª—å£ååŒæœºåˆ¶ï¼›è¿ç”¨è¿œç¨‹è™šæ‹Ÿçª—å£æŠ€æœ¯æä¾›å¸®åŠæœåŠ¡ï¼Œå¹¶æ”¯æŒäº¬æ´¥å†€ç­‰é‡ç‚¹åŒºåŸŸæ¢ç´¢æ›´å¤šè·¨åŒºåŸŸåŠç†äº‹é¡¹ã€‚\"}\n{\"instruction\": \"å¦‚ä½•æ¨è¿›æ”¿ç­–æœåŠ¡å…ç”³åŠï¼Ÿ\", \"input\": \"\", \"output\": \"é€šè¿‡å…¨é¢æ¢³ç†æ”¿ç­–æ¡ä»¶ä¸è§„åˆ™ï¼Œä¾æ‰˜æ•°æ®å½’é›†å…±äº«ã€æ¨¡å‹ç®—æ³•å’Œå¤§æ•°æ®åˆ†æï¼Œç²¾å‡†åŒ¹é…ç¬¦åˆæ¡ä»¶çš„ä¼ä¸šä¸ç¾¤ä¼—ï¼Œæ¨åŠ¨æ”¿ç­–â€œå…ç”³å³äº«â€ï¼›å¯¹éœ€ç”³è¯·çš„æ”¿ç­–è‡ªåŠ¨ç”Ÿæˆç”³è¯·è¡¨å¹¶ç²¾å‡†æ¨é€ç”³è¯·ææ–™ï¼ŒåŒæ—¶ä¼˜åŒ–æ”¿åŠ¡æœåŠ¡å¹³å°ä¸“å±æœåŠ¡ç©ºé—´ï¼Œå®ç°æ”¿ç­–ç²¾å‡†ç›´è¾¾ã€‚\"}\n{\"instruction\": \"æ ¹æ®æ–‡æœ¬å†…å®¹ï¼Œæ¨åŠ¨æ”¿åŠ¡æœåŠ¡å¹³å°çš„æ•´åˆä¸­ï¼Œå…³äºåœ°å¸‚çº§ä»¥ä¸‹æ”¿åŠ¡æœåŠ¡å¹³å°çš„å»ºè®¾æœ‰ä»€ä¹ˆè§„å®šï¼Ÿ\", \"input\": \"\", \"output\": \"åŸåˆ™ä¸Šä¸å†å•ç‹¬å»ºè®¾åœ°å¸‚çº§ä»¥ä¸‹æ”¿åŠ¡æœåŠ¡å¹³å°ã€‚\"}\n{\"instruction\": \"å¦‚ä½•æå‡æ”¿åŠ¡æ•°æ®å…±äº«å®æ•ˆï¼Ÿ\", \"input\": \"\", \"output\": \"é€šè¿‡å®Œå–„æ”¿åŠ¡æ•°æ®å…±äº«è´£ä»»æ¸…å•æœºåˆ¶ï¼Œä¾æ‰˜å…¨å›½ä¸€ä½“åŒ–æ”¿åŠ¡æœåŠ¡å¹³å°æ•°æ®å…±äº«æ¢çº½æ¨åŠ¨éƒ¨é—¨æ•°æ®å›æµå’Œç›´è¾¾åŸºå±‚ï¼Œç¼–åˆ¶'ä¸€ä¼ä¸€æ¡£ã€ä¸€äººä¸€æ¡£'æ•°æ®è§„èŒƒå®ç°'ä¸€æ•°ä¸€æºä¸€æ ‡å‡†'ï¼Œæ·±åŒ–ç”µå­è¯ç…§è·¨åœ°åŒºè·¨éƒ¨é—¨äº’é€šäº’è®¤ï¼Œæ¨åŠ¨æ”¿åºœéƒ¨é—¨æ ¸å‘ææ–™å…æäº¤ã€å…±äº«æ ¸éªŒäº‹é¡¹å…è¯æ˜ã€ç”µå­è¯ç…§å…å®ä½“è¯ç…§ã€‚\"}\n{\"instruction\": \"å¦‚ä½•æ¨åŠ¨æ”¿åŠ¡æœåŠ¡ç”±äººåŠ›æœåŠ¡å‹å‘äººæœºäº¤äº’å‹å’Œæ•°æ®åˆ†æå‹è½¬å˜ï¼Ÿ\", \"input\": \"\", \"output\": \"é€šè¿‡åˆ›æ–°åº”ç”¨å¤§æ•°æ®ã€åŒºå—é“¾ã€äººå·¥æ™ºèƒ½ç­‰æ–°æŠ€æœ¯ï¼Œä¼˜åŒ–é‡æ„æœåŠ¡æµç¨‹å¹¶å®Œå–„æ™ºèƒ½é¢„å¡«ã€é¢„å®¡åŠŸèƒ½ï¼ŒåŒæ—¶åœ¨å…·ä½“åŠäº‹åœºæ™¯ä¸­åº”ç”¨è‡ªç„¶è¯­è¨€å¤§æ¨¡å‹æŠ€æœ¯æå‡æ™ºèƒ½å®¢æœèƒ½åŠ›ï¼Œæ¨åŠ¨æ”¿åŠ¡æœåŠ¡å‘äººæœºäº¤äº’å‹å’Œæ•°æ®åˆ†æå‹è½¬å˜ã€‚\"}\n{\"instruction\": \"å¦‚ä½•å¢å¼ºåœ¨é«˜æ–°åŒºã€äº§ä¸šå›­åŒºçš„é¡¹ç›®å¸®åŠä»£åŠèƒ½åŠ›ï¼Ÿ\", \"input\": \"\", \"output\": \"é€šè¿‡åŠ å¼ºé¡¹ç›®å…¨æµç¨‹å¸®åŠä»£åŠï¼Œç»“åˆå®é™…å»ºç«‹ä¸“ç­æœåŠ¡ã€ä¸“å‘˜è·Ÿè¿›ç­‰æœºåˆ¶ï¼ŒåŠæ—¶è§£å†³é¡¹ç›®æ¨è¿›ä¸­çš„éš¾ç‚¹é—®é¢˜ã€‚\"}\n{\"instruction\": \"åœ¨ä¸°å¯Œå…¬å…±æœåŠ¡ä¾›ç»™æ–¹é¢ï¼Œæ–°å¢äº†å“ªäº›ä¸ä¼ä¸šå’Œç¾¤ä¼—ç”Ÿäº§ç”Ÿæ´»å¯†åˆ‡ç›¸å…³çš„æœåŠ¡é¢†åŸŸï¼Ÿ\", \"input\": \"\", \"output\": \"æ–°å¢äº†æ°´ç”µæ°”çƒ­ã€ç½‘ç»œé€šä¿¡ç­‰å…¬ç”¨äº‹ä¸šé¢†åŸŸçš„é«˜é¢‘åŠç†æœåŠ¡äº‹é¡¹ã€‚\"}\n{\"instruction\": \"å¦‚ä½•æ‹“å±•æ¶‰ä¼å¢å€¼æœåŠ¡å†…å®¹ï¼Ÿ\", \"input\": \"\", \"output\": \"é€šè¿‡ç»Ÿç­¹è¡Œä¸šåä¼šã€å¸‚åœºåŒ–ä¸“ä¸šæœåŠ¡æœºæ„ç­‰èµ„æºï¼Œä¸€ç«™å¼æä¾›æ”¿ç­–æœåŠ¡ã€æ³•å¾‹æœåŠ¡ã€é‡‘èæœåŠ¡ã€äººæ‰æœåŠ¡ã€ç§‘åˆ›æœåŠ¡å’Œå›½é™…è´¸æ˜“æœåŠ¡ï¼Œå…·ä½“åŒ…æ‹¬æ”¿ç­–æ¨è/ç”³æŠ¥ã€å…¬è¯/åˆè§„æŒ‡å¯¼ã€èèµ„æ‹…ä¿/äº§ä¸šåŸºé‡‘å¯¹æ¥ã€äººæ‰è®¤å®š/ä½æˆ¿å®‰å±…ã€ç§‘æŠ€ä¼ä¸šåŸ¹è‚²ã€æŠ¥å…³é€€ç¨å’¨è¯¢ç­‰æœåŠ¡ã€‚\"}\n{\"instruction\": \"å¦‚ä½•å¥å…¨æ”¿åŠ¡æœåŠ¡æ ‡å‡†ä½“ç³»ï¼Ÿ\", \"input\": \"\", \"output\": \"å¥å…¨æ”¿åŠ¡æœåŠ¡æ ‡å‡†ä½“ç³»éœ€åŠ å¼ºæ€»ä½“è®¾è®¡ï¼Œåˆ¶å®šå…¨å›½ä¸€ä½“åŒ–æ”¿åŠ¡æœåŠ¡å¹³å°ã€æ”¿åŠ¡æœåŠ¡ä¸­å¿ƒå»ºè®¾åŠ12345çƒ­çº¿è¿è¡Œæ ‡å‡†ï¼Œç»Ÿä¸€æ”¿åŠ¡æœåŠ¡äº‹é¡¹åŸºç¡€æ ‡å‡†ï¼Œç¼–åˆ¶é›†æˆåŠç†\\\"ä¸€ä»¶äº‹\\\"æŒ‡å—ï¼Œå¹¶å®Œå–„è·¨åŒºåŸŸåŠäº‹ä¸šåŠ¡æ ‡å‡†ä¸æ“ä½œè§„ç¨‹ã€‚\"}\n{\"instruction\": \"å¦‚ä½•å¼ºåŒ–æ”¿åŠ¡æœåŠ¡åˆ¶åº¦ä¾›ç»™ï¼Ÿ\", \"input\": \"\", \"output\": \"å¼ºåŒ–æ”¿åŠ¡æœåŠ¡åˆ¶åº¦ä¾›ç»™éœ€é€šè¿‡ä¸‰æ–¹é¢æªæ–½ï¼š1.åŠ å¼ºå›½å®¶å±‚é¢ç«‹æ³•ç ”ç©¶å¹¶æ¸…ç†ä¿®è®¢ä¸é€‚åº”æ€§æ³•è§„ï¼›2.ç ´é™¤é›†æˆåŠ/æ‰¿è¯ºåŠ/è·¨åŸŸåŠ/å…ç”³åŠçš„åˆ¶åº¦éšœç¢ï¼›3.å®Œå–„æ•°å­—åŒ–åº”ç”¨é…å¥—æ”¿ç­–ä¿éšœç”µå­è¯ç…§å…±äº«å’Œç”µå­æ¡£æ¡ˆæ•ˆåŠ›ã€‚\"}\n{\"instruction\": \"å¦‚ä½•å¥å…¨æ”¿åŠ¡æœåŠ¡å·¥ä½œä½“ç³»ï¼Ÿ\", \"input\": \"\", \"output\": \"æ¨è¿›å›½å®¶ã€çœã€å¸‚ã€å¿ã€ä¹¡äº”çº§æ”¿åŠ¡æœåŠ¡ä½“ç³»å»ºè®¾ï¼Œå¥å…¨ä¸€ä½“è”åŠ¨ã€é«˜æ•ˆä¾¿æ·ã€æƒè´£æ¸…æ™°çš„å·¥ä½œæœºåˆ¶ï¼›åŠ å¼ºå„çº§æ”¿åŠ¡æœåŠ¡çª—å£ä»ä¸šäººå‘˜é…å¤‡ã€ç®¡ç†ã€åŸ¹è®­å’Œè€ƒæ ¸ï¼Œæ¨è¿›ç»¼åˆæœåŠ¡çª—å£äººå‘˜ç»Ÿä¸€é…å¤‡å’ŒèŒä¸šåŒ–å‘å±•ï¼›åˆ›æ–°æ”¿åŠ¡æœåŠ¡äººæ‰å¼•è¿›ã€åŸ¹å…»ã€é€‰æ‹”å’Œè¯„ä»·æœºåˆ¶ï¼Œæå‡å¹²éƒ¨é˜Ÿä¼æ³•æ²»æ€ç»´ã€æœåŠ¡æ„è¯†å’Œæ•°å­—ç´ å…»ï¼Œå¼ºåŒ–ä¸“ä¸šåŒ–é˜Ÿä¼å»ºè®¾ã€‚\"}\n{\"instruction\": \"å¦‚ä½•ç¡®ä¿â€œé«˜æ•ˆåŠæˆä¸€ä»¶äº‹â€å–å¾—å®æ•ˆï¼Ÿ\", \"input\": \"\", \"output\": \"1.å„åœ°åŒºè¦å¼ºåŒ–çœçº§ç»Ÿç­¹ï¼Œé€é¡¹åˆ¶å®šå·¥ä½œæ–¹æ¡ˆå¹¶æ˜ç¡®ç›®æ ‡ä»»åŠ¡ã€æ”¹é©æªæ–½å’ŒèŒè´£åˆ†å·¥ï¼›\\n2.å›½åŠ¡é™¢å„éƒ¨é—¨éœ€åŠ å¼ºæ¡å—è”åŠ¨ï¼Œæä¾›ä¸šåŠ¡æŒ‡å¯¼å’Œæ•°æ®å…±äº«æ”¯æ’‘ï¼›\\n3.å›½åŠ¡é™¢åŠå…¬å…è¦ç»Ÿç­¹åè°ƒï¼Œå¼€å±•è¯•ç‚¹ç¤ºèŒƒå¹¶é€å¹´æ¨å‡ºé‡ç‚¹äº‹é¡¹æ¸…å•ï¼Œæ¨åŠ¨æ”¿åŠ¡æœåŠ¡æè´¨å¢æ•ˆã€‚\"}\n\n```\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/data/datajuicer/image19.png)\n\n## å¾®è°ƒæµ‹è¯•\n\n### æ•°æ®é›†\n\næŒ‰ä¸Šè¿°æ–¹æ³•ï¼Œé‡æ–°å¢åŠ äº†æ”¿ä¼ç±»æ•°æ®é›†ã€‚\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/data/datajuicer/image20.png)\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/data/datajuicer/image21.png)<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/data/datajuicer/image22.png)\n\n#### æå–å¹¶åˆ‡åˆ†åçš„æ•°æ®\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/data/datajuicer/image23.png)\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/data/datajuicer/image24.png)\n\n#### æ¸…æ´—ç»“æœå¦‚ä¸‹\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/data/datajuicer/image25.png)\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/data/datajuicer/image26.png)\n\n#### æ¸…æ´—ç»“æœå¯¹æ¯” \n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/data/datajuicer/image27.png)\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/data/datajuicer/image28.png)\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/data/datajuicer/image29.png)\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/data/datajuicer/image30.png)\n\n#### é—®ç­”å¯¹ç”Ÿæˆ\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/data/datajuicer/image31.png)\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/data/datajuicer/image32.png)\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/data/datajuicer/image33.png)\n\n### ms-swift æ¡†æ¶å¾®è°ƒ\n\n#### ç¯å¢ƒæ­å»º\n\nms-swift è®­ç»ƒç¯å¢ƒå·²ä¼ è‡³é•œåƒ\n\n```bash\nregistry.cn-shanghai.aliyuncs.com/aliyun_repository_wxb/repository_wxb:swift\n```\n\n#### è®­ç»ƒè„šæœ¬\n\n##### åŸºäºæ”¿ä¼ç±»æ•°æ®é›†çš„ qwen2.5-7B-Ins-lora å¾®è°ƒ\n\n```bash\n# 22GB\nCUDA_VISIBLE_DEVICES=0,1,2,3 \\\nswift sft \\\n    --model /mnt/model/Qwen/Qwen2.5-7B-Instruct \\\n    --train_type lora \\\n    --dataset /mnt/ms-swift/data/train.jsonl \\\n    --torch_dtype float16 \\\n    --num_train_epochs 6 \\\n    --per_device_train_batch_size 1 \\\n    --per_device_eval_batch_size 1 \\\n    --learning_rate 1e-4 \\\n    --lora_rank 8 \\\n    --lora_alpha 32 \\\n    --target_modules all-linear \\\n    --gradient_accumulation_steps 1 \\\n    --eval_steps 50 \\\n    --save_steps 50 \\\n    --save_total_limit 5 \\\n    --logging_steps 1 \\\n    --max_length 2048 \\\n    --output_dir /mnt/ms-swift/output \\\n    --system 'ä½ æ˜¯ä¸€ä¸ªè‹å·æ”¿ä¼é—®ç­”å°åŠ©æ‰‹' \\\n    --warmup_ratio 0.05 \\\n    --dataloader_num_workers 4 \\\n    --model_author swift \\\n    --model_name swift-qwen2.5-7b\n```\n\n##### åŸºäºæ”¿ä¼ç±»æ•°æ®é›†çš„ qwen2.5-0.5B-Ins-å…¨å‚å¾®è°ƒ\n\n```bash\n# 76GiB\nCUDA_VISIBLE_DEVICES=0,1,2,3 \\\nswift sft \\\n    --model /mnt/model/Qwen2.5-0.5B-Instruct \\\n    --train_type full \\\n    --dataset /mnt/ms-swift/data/train.jsonl \\\n    --torch_dtype float32 \\\n    --num_train_epochs 6 \\\n    --per_device_train_batch_size 1 \\\n    --per_device_eval_batch_size 1 \\\n    --learning_rate 1e-5 \\\n    --gradient_accumulation_steps 16 \\\n    --eval_steps 100 \\\n    --save_steps 100 \\\n    --save_total_limit 5 \\\n    --logging_steps 1 \\\n    --max_length 2048 \\\n    --output_dir /mnt/ms-swift/output \\\n    --system 'You are a helpful assistant.' \\\n    --warmup_ratio 0.05 \\\n    --dataloader_num_workers 4 \\\n    --model_author swift \\\n    --model_name swift-qwen2.5-0.5b\n\n```\n\n#### è®­ç»ƒ\n\n##### æ—¥å¿—\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/data/datajuicer/image34.png)\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/data/datajuicer/image35.png)\n\n##### æ˜¾å­˜å ç”¨æƒ…å†µ\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/data/datajuicer/image36.png)\n\n##### loss æ›²çº¿\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/data/datajuicer/image37.png)\n\n#### æ¨ç†æµ‹è¯•\n\n##### å¼€å¯ swift web ç•Œé¢æœåŠ¡\n\n```bash\nswift web-ui --lang zh --server_port 16686\n```\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/data/datajuicer/image38.png)\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/data/datajuicer/image39.png)\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/data/datajuicer/image40.png)<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/data/datajuicer/image41.png)\n\n\n\n\n\n","tags":["æ¨¡å‹å¾®è°ƒ","NVIDIA","V100","æ•°æ®é›†å¤„ç†"],"categories":["æ¨¡å‹å¾®è°ƒ","æ•°æ®é›†å¤„ç†"]},{"title":"ColossalAIè®­ç»ƒæ¡†æ¶è§£è¯»","url":"/2026/01/08/LLM/è®­ç»ƒæ¡†æ¶/ColossalAI/","content":"## æ¡†æ¶ç‰¹ç‚¹\n\nColossal-AI æ¡†æ¶ä¸­çš„ **Gemini** æ˜¯ä¸€ç§å†…å­˜ä¼˜åŒ–ç­–ç•¥ï¼Œæ—¨åœ¨é€šè¿‡æ™ºèƒ½çš„å†…å­˜ç®¡ç†å’Œè®¡ç®—ä¼˜åŒ–æ¥å‡å°‘æ˜¾å­˜å ç”¨ï¼Œä»è€Œæ”¯æŒæ›´å¤§è§„æ¨¡çš„æ¨¡å‹è®­ç»ƒã€‚Gemini çš„æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡ **åŠ¨æ€å†…å­˜ç®¡ç†** å’Œ **è®¡ç®—ä¼˜åŒ–** æ¥æœ€å¤§åŒ–æ˜¾å­˜åˆ©ç”¨ç‡ï¼ŒåŒæ—¶å‡å°‘å†…å­˜ç¢ç‰‡å’Œå†—ä½™è®¡ç®—ã€‚\n\n## ä»¥llama2ä¸ºä¾‹çš„éªŒè¯\n\n### å¢åŠ æ¯éƒ¨è¿­ä»£æ‰“å°ä»¥åŠtflopsæ‰“å°\n\nColossalAIåˆå§‹æ‰“å°æ•ˆæœ\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/train_framework/colossalai/image1.png)\n\n## <!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/train_framework/colossalai/image2.png)<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/train_framework/colossalai/image3.png)<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/train_framework/colossalai/image4.png)\n\n### è„šæœ¬\n\n```bash\n#!/bin/bash\n# NCCL IB environment variables\nexport NCCL_IB_HCA=mlx5_1:1,mlx5_2:1,mlx5_3:1,mlx5_4:1\nexport NCCL_IB_DISABLE=0\nexport NCCL_SOCKET_IFNAME=eth0\nexport NCCL_IB_GID_INDEX=3\nexport NCCL_IB_TIMEOUT=23\nexport NCCL_IB_RETRY_CNT=7\nexport OMP_NUM_THREADS=4\ncurrent_time=$(date \"+%Y.%m.%d-%H.%M.%S\")\nLOG_SAVE=\"/mnt/colossalai/output/log/${current_time}-llama2-pretrain.log\"\nPROJECT_NAME=\"llama2-7B-pretrain\"\nPARENT_SAVE_DIR=\"/mnt/colossalai/output/save/\"\nPARENT_TENSORBOARD_DIR=\"/mnt/colossalai/output/tensorboard/\"\nPARENT_CONFIG_FILE=\"/mnt/colossalai/output/config/\"\nPRETRAINED_MODEL_PATH=\"/mnt/colossalai/weight/Llama-2-7b-hf\"\ndeclare -a dataset=(\n \"/mnt/colossalai/dataset/llama2_pretraindata/arrow/part-00000\"\n)\n\nTIMESTAMP=$(date +%Y-%m-%d-%H-%M-%S)\nFULL_PROJECT_NAME=\"${PROJECT_NAME}-${TIMESTAMP}\"\nSAVE_DIR=\"${PARENT_SAVE_DIR}${FULL_PROJECT_NAME}\"\nTENSORBOARD_DIR=\"${PARENT_TENSORBOARD_DIR}${FULL_PROJECT_NAME}\"\nCONFIG_FILE=\"${PARENT_CONFIG_FILE}${FULL_PROJECT_NAME}.json\"\ncolossalai run --nproc_per_node 4 --master_port 30012 train.py \\\n    --pretrained $PRETRAINED_MODEL_PATH \\\n    --dataset ${dataset[@]} \\\n    --plugin \"gemini\" \\\n    --microbatch_size 1 \\\n    --batch_size 4 \\\n    --save_interval 400 \\\n    --save_dir $SAVE_DIR \\\n    --tensorboard_dir $TENSORBOARD_DIR \\\n    --config_file $CONFIG_FILE \\\n    --num_epochs 1 \\\n    --accumulation_steps 1 \\\n    --lr 1e-4 \\\n    --mixed_precision \"fp16\" \\\n    --grad_clip 1.0 \\\n    --weight_decay 0.01 \\\n    --warmup_steps 100 \\\n    --use_grad_checkpoint \\\n    --pad_token \"unk\" \\\n    --max_length 1024 2>&1 | tee -a \"$LOG_SAVE\"\n```\n\n### è¶…å‚è®¾ç½®/GPUåˆ©ç”¨ç‡/TFlops\n\n#### mixed_precisionï¼šfp16/pluginï¼šgemini /mbsï¼š1/gbsï¼š4\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/train_framework/colossalai/image5.png)\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/train_framework/colossalai/image6.png)\n\n#### mixed_precisionï¼šfp16/pluginï¼šgemini_auto /mbsï¼š1/gbsï¼š4\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/train_framework/colossalai/image7.png)\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/train_framework/colossalai/image8.png)\n\n#### mixed_precisionï¼šbf16/pluginï¼šgemini_auto /mbsï¼š1/gbsï¼š4\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/train_framework/colossalai/image9.png)\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/train_framework/colossalai/image10.png)\n\n\n\n#### mixed_precisionï¼šfp16/pluginï¼šzero2  /mbsï¼š1/gbsï¼š4\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/train_framework/colossalai/image11.png)\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/train_framework/colossalai/image12.png)\n\n## Geminiå¹¶è¡Œç­–ç•¥åˆ†æ\n\n###  ä¼ ç»Ÿå¹¶è¡Œç­–ç•¥ vs Gemini  \n\n| å¹¶è¡Œç­–ç•¥                          | ä¸»è¦ç‰¹ç‚¹                                                     | ä¸»è¦é—®é¢˜                 |\n| --------------------------------- | ------------------------------------------------------------ | ------------------------ |\n| æ•°æ®å¹¶è¡Œï¼ˆDPï¼‰                    | æ¯ä¸ª GPU è®¡ç®—æ•´ä¸ªæ¨¡å‹çš„ä¸€éƒ¨åˆ†æ•°æ®ï¼Œæœ€ç»ˆèšåˆæ¢¯åº¦              | è®¡ç®—å†—ä½™ï¼Œæ˜¾å­˜æ¶ˆè€—å¤§     |\n| å¼ é‡å¹¶è¡Œï¼ˆTPï¼‰                    | ä¸åŒ GPU å¤„ç†çŸ©é˜µä¹˜æ³•çš„ä¸åŒéƒ¨åˆ†ï¼Œå‡å°‘å•å¡è´Ÿæ‹…                | é€šä¿¡å¼€é”€å¤§ï¼Œè´Ÿè½½ä¸å‡è¡¡   |\n| æµæ°´çº¿å¹¶è¡Œï¼ˆPPï¼‰                  | å°†æ¨¡å‹å±‚åˆ’åˆ†åˆ°å¤šä¸ª GPUï¼Œæµæ°´çº¿æ–¹å¼è¿›è¡Œè®¡ç®—                   | ä¾èµ–ä¸¥æ ¼çš„åŒæ­¥ï¼Œè°ƒåº¦å¤æ‚ |\n| ZeROï¼ˆZero Redundancy Optimizerï¼‰ | ZeRO-1: ä»…åˆ‡åˆ†ä¼˜åŒ–å™¨çŠ¶æ€   ZeRO-2: åˆ‡åˆ†ä¼˜åŒ–å™¨+æ¢¯åº¦   ZeRO-3: è¿›ä¸€æ­¥åˆ‡åˆ†æ¨¡å‹å‚æ•° | è®¡ç®—å’Œé€šä¿¡å¼€é”€è¾ƒé«˜       |\n| **Gemini**                        | **æ··åˆ ZeRO-2/3 + è®¡ç®—å’Œæ•°æ®è‡ªåŠ¨è°ƒåº¦**                       | é€‚ç”¨äºæ›´å¤§è§„æ¨¡æ¨¡å‹       |\n\n\n### Geminiçš„å…³é”®ä¼˜åŒ–ç‚¹\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/train_framework/colossalai/image13.png)\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/train_framework/colossalai/image14.png)\n\n####  ä¼˜åŒ–äº†å‚æ•°åˆ‡åˆ†ç­–ç•¥\n\nåœ¨ `GeminiPlugin` é‡Œï¼Œ`shard_param_frac` å’Œ `offload_optim_frac` æ§åˆ¶äº†å‚æ•°åˆ‡åˆ†å’Œä¼˜åŒ–å™¨çŠ¶æ€çš„å­˜å‚¨ï¼š\n\n```python\nshard_param_frac: float = 1.0  # 1.0 ç›¸å½“äº ZeRO-3, 0.0 ç›¸å½“äº ZeRO-2\noffload_optim_frac: float = 0.0  # æ§åˆ¶ä¼˜åŒ–å™¨çŠ¶æ€æ˜¯å¦ä¸‹æ”¾åˆ° CPU\n```\n\n+ **å¦‚æœ **`**shard_param_frac=1.0**`ï¼Œé‚£ä¹ˆæ‰€æœ‰å‚æ•°éƒ½ä¼šè¢« shardï¼ˆç±»ä¼¼ ZeRO-3ï¼‰ã€‚\n+ **å¦‚æœ **`**shard_param_frac=0.0**`ï¼Œåˆ™ä¸ä¼šå¯¹å‚æ•°è¿›è¡Œ shardï¼ˆç±»ä¼¼ ZeRO-2ï¼‰ã€‚\n+ **å¦‚æœ **`**offload_optim_frac=1.0**`ï¼Œä¼˜åŒ–å™¨çŠ¶æ€å¯ä»¥ä¸‹æ”¾åˆ° CPUï¼Œå‡å°‘ GPU å ç”¨ã€‚\n\n#### è®¡ç®—å›¾çš„æ™ºèƒ½åˆ†é…\n\n**Gemini ç»“åˆ TPï¼ˆå¼ é‡å¹¶è¡Œï¼‰+ DPï¼ˆæ•°æ®å¹¶è¡Œï¼‰+ ZeRO è¿›è¡Œè®¡ç®—ä¼˜åŒ–**ï¼š\n\n```python\nself.pg_mesh = ProcessGroupMesh(self.zero_size, self.extra_dp_size, self.tp_size)\n```\n\nå…¶ä¸­ï¼š\n\n+ `self.zero_group` è´Ÿè´£ **ZeRO å‚æ•°ç®¡ç†**ï¼ˆç±»ä¼¼ ZeRO-2/3ï¼‰ã€‚\n+ `self.extra_dp_group` æ§åˆ¶ **é¢å¤–çš„æ•°æ®å¹¶è¡Œç»„**ã€‚\n+ `self.tp_group` è´Ÿè´£ **å¼ é‡å¹¶è¡Œ**ï¼ˆTPï¼‰ã€‚\n\nè¿™æ ·ï¼ŒGemini å…è®¸ **åŠ¨æ€åˆ‡æ¢å¹¶è¡Œæ–¹å¼**ï¼Œé¿å…é™æ€åˆ†é…å¯¼è‡´çš„èµ„æºæµªè´¹ã€‚\n\n####  è‡ªé€‚åº”å†…å­˜ç®¡ç†  \n\n##### GPU-CPU æ··åˆå­˜å‚¨\n\nGemini æä¾›äº† `placement_policy` å‚æ•°ï¼š\n\n```python\nplacement_policy: str = \"static\"  # ä¹Ÿå¯è®¾ä¸º \"auto\"\n```\n\n+ `\"static\"` æ¨¡å¼ï¼šæ‰‹åŠ¨è®¾å®š `shard_param_frac` å’Œ `offload_optim_frac` æ¥æ§åˆ¶ ZeRO çº§åˆ«ã€‚\n+ `\"auto\"` æ¨¡å¼ï¼šGemini **è‡ªåŠ¨æ£€æµ‹æ˜¾å­˜ä½¿ç”¨æƒ…å†µ**ï¼Œæ™ºèƒ½åˆ†é…å‚æ•°åˆ° CPU/GPUï¼Œé˜²æ­¢ OOMã€‚\n\n##### GPU æ˜¾å­˜åˆ©ç”¨ç‡ä¼˜åŒ–\n\n```python\nwarmup_non_model_data_ratio: float = 0.8  # è®­ç»ƒå‰é¢„ç•™æ˜¾å­˜\nsteady_cuda_cap_ratio: float = 0.9  # è®­ç»ƒç¨³å®šåï¼Œæ¨¡å‹æœ€å¤§ä½¿ç”¨æ˜¾å­˜æ¯”ä¾‹\n```\n\n+ è®­ç»ƒåˆæœŸï¼Œé¢„ç•™ 80% æ˜¾å­˜ç»™éæ¨¡å‹æ•°æ®ï¼ˆå¦‚æ¿€æ´»å€¼ç¼“å­˜ï¼‰ã€‚\n+ è®­ç»ƒç¨³å®šåï¼ŒGemini å…è®¸æ¨¡å‹å ç”¨ 90% æ˜¾å­˜ï¼Œæé«˜åˆ©ç”¨ç‡ã€‚\n\n####  æ··åˆç²¾åº¦è®­ç»ƒ  \n\nGemini é€šè¿‡ `precision` å‚æ•°æ”¯æŒ `fp16/bf16` è®­ç»ƒï¼š\n\n```python\nprecision: str = \"fp16\"\n```\n\n+ `**fp16**`ï¼šå‡å°‘æ˜¾å­˜å ç”¨ï¼Œæå‡è®¡ç®—é€Ÿåº¦ã€‚\n+ `**bf16**`ï¼šè®­ç»ƒç¨³å®šæ€§æ›´å¥½ï¼Œé€‚ç”¨äº NVIDIA A100/H100ã€‚\n\næ­¤å¤–ï¼Œå®ƒè¿˜æ”¯æŒ `master_weights`ï¼ˆä¼˜åŒ–å™¨ä¿ç•™ FP32 æƒé‡ï¼‰ï¼š\n\n```python\nmaster_weights: bool = True\n```\n\n+ è¿™æ ·å¯ä»¥åœ¨ `fp16` è®¡ç®—æ—¶é¿å…ç²¾åº¦ä¸‹é™ã€‚\n\n####  æ¢¯åº¦åŒæ­¥ä¼˜åŒ–  \n\nGemini å…è®¸ **å¼‚æ­¥æ¢¯åº¦åŒæ­¥**ï¼Œå‡å°‘é€šä¿¡ç“¶é¢ˆï¼š\n\n```python\nenable_async_reduce: bool = True\n```\n\nå½“ `enable_async_reduce=True` æ—¶ï¼š\n\n1. åå‘ä¼ æ’­æ—¶ï¼Œæ¢¯åº¦ä¸ä¼šç«‹å³åŒæ­¥ï¼Œè€Œæ˜¯ **ç´¯ç§¯å¤šä¸ª step ä¹‹åå†åŒæ­¥**ã€‚\n2. è¿™æ ·å¯ä»¥ **å‡å°‘é€šä¿¡æ¬¡æ•°ï¼Œæé«˜ GPU è®¡ç®—æ•ˆç‡**ã€‚\n\n### ZeRO-3 vs Gemini\n\n| ç‰¹æ€§               | ZeRO-3                | Gemini                       |\n| ------------------ | --------------------- | ---------------------------- |\n| **å‚æ•°åˆ‡åˆ†**       | ä»…å‚æ•°                | å‚æ•° + è®¡ç®—çŠ¶æ€ï¼ˆæ›´å…¨é¢ï¼‰    |\n| **ä¼˜åŒ–å™¨çŠ¶æ€å­˜å‚¨** | GPU / CPUï¼ˆæ‰‹åŠ¨é…ç½®ï¼‰ | åŠ¨æ€è°ƒåº¦ï¼ˆè‡ªåŠ¨è°ƒæ•´ GPU/CPUï¼‰ |\n| **æ¢¯åº¦åŒæ­¥**       | æ¯æ­¥æ¢¯åº¦åŒæ­¥          | æ”¯æŒå¼‚æ­¥æ¢¯åº¦åŒæ­¥             |\n| **æ˜¾å­˜åˆ©ç”¨ç‡ä¼˜åŒ–** | éœ€è¦æ‰‹åŠ¨è°ƒæ•´ `stage`  | è‡ªåŠ¨åˆ†é…æ˜¾å­˜                 |\n| **è®¡ç®—å›¾ä¼˜åŒ–**     | ä»…é™ DP/TP/PP         | è‡ªåŠ¨é€‚é… DP/TP/PP            |\n| **é€‚ç”¨åœºæ™¯**       | é™æ€ä»»åŠ¡              | é€‚ç”¨äºåŠ¨æ€ä»»åŠ¡               |\n\n\n#### ä»£ç ç¤ºä¾‹\n\n**ï¼ˆ1ï¼‰ä¼ ç»Ÿ ZeRO-3**\n\n```python\nplugin = LowLevelZeroPlugin(stage=3, precision=\"fp16\")\n```\n\n**(2) Gemini è‡ªåŠ¨ä¼˜åŒ–**\n\n```python\nplugin = GeminiPlugin(precision=\"fp16\", placement_policy=\"auto\", enable_async_reduce=True)\n```\n\n+ `placement_policy=\"auto\"`**è‡ªåŠ¨è°ƒæ•´å‚æ•°åœ¨ CPU/GPU ä¹‹é—´çš„å­˜æ”¾**ã€‚\n+ `enable_async_reduce=True`**å¼€å¯å¼‚æ­¥æ¢¯åº¦åŒæ­¥ï¼Œå‡å°‘é€šä¿¡å¼€é”€**ã€‚\n\n### Gemini vs Gemini_auto\n\n#### ä¸»è¦åŒºåˆ«\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/train_framework/colossalai/image15.png)\n\n`**gemini**`\n\n+ `placement_policy=\"static\"`ï¼šåœ¨è¿™ä¸ªæ¨¡å¼ä¸‹ï¼ŒGemini ä½¿ç”¨å›ºå®šçš„å‚æ•°åˆ‡åˆ†ç­–ç•¥ï¼Œç”¨æˆ·éœ€è¦æ‰‹åŠ¨è®¾ç½® `shard_param_frac`ã€`offload_optim_frac` ç­‰å‚æ•°æ¥æ§åˆ¶æ¨¡å‹å‚æ•°å’Œä¼˜åŒ–å™¨çŠ¶æ€çš„å­˜æ”¾ä½ç½®ï¼ˆæ¯”å¦‚æ˜¯å¦å­˜æ”¾åœ¨ CPU æˆ– GPU ä¸Šï¼‰ã€‚\n+ åœ¨è¿™ç§æ¨¡å¼ä¸‹ï¼Œ**æ‰€æœ‰çš„å‚æ•°åˆ‡åˆ†ã€å­˜å‚¨å’Œè®¡ç®—èµ„æºçš„è°ƒåº¦**éƒ½ç”±ç”¨æˆ·æŒ‡å®šã€‚è™½ç„¶èƒ½è·å¾—è¾ƒé«˜çš„ç²¾ç»†æ§åˆ¶ï¼Œä½†ä¹Ÿéœ€è¦ç”¨æˆ·è¿›è¡Œæ›´å¤šçš„è°ƒä¼˜å·¥ä½œã€‚\n\n`**gemini_auto**`:\n\n+ `placement_policy=\"auto\"`ï¼šåœ¨è¿™ç§æ¨¡å¼ä¸‹ï¼ŒGemini ä¼šè‡ªåŠ¨æ ¹æ®ç¡¬ä»¶èµ„æºï¼ˆå¦‚ GPU æ˜¾å­˜ã€CPU æ˜¾å­˜ç­‰ï¼‰çš„æƒ…å†µåŠ¨æ€è°ƒæ•´**å‚æ•°åˆ‡åˆ†å’Œå­˜æ”¾**ï¼Œè€Œä¸éœ€è¦ç”¨æˆ·æ‰‹åŠ¨æŒ‡å®šã€‚ä¾‹å¦‚ï¼Œå½“ GPU å†…å­˜ä¸è¶³æ—¶ï¼Œå®ƒä¼šè‡ªåŠ¨å°†éƒ¨åˆ†å‚æ•°è½¬ç§»åˆ° CPUã€‚\n+ è‡ªåŠ¨çš„å†…å­˜ç®¡ç†ç­–ç•¥å¯ä»¥å‡å°‘ç”¨æˆ·çš„é…ç½®å·¥ä½œï¼ŒåŒæ—¶æé«˜è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ˜¾å­˜åˆ©ç”¨ç‡ï¼Œé¿å… OOMï¼ˆå†…å­˜æº¢å‡ºï¼‰é”™è¯¯ã€‚\n\n####  å†…å­˜å’Œæ˜¾å­˜åˆ†é…ç­–ç•¥  \n\n##### åœ¨ `gemini` æ¨¡å¼ä¸‹ï¼Œç”¨æˆ·éœ€è¦æ‰‹åŠ¨è®¾ç½®å†…å­˜å’Œè®¡ç®—èµ„æºçš„åˆ†é…ã€‚ä¾‹å¦‚ï¼š\n\n```python\nshard_param_frac: float = 1.0  # æ§åˆ¶å‚æ•°æ˜¯å¦è¿›è¡Œåˆ‡åˆ†\noffload_optim_frac: float = 0.0  # æ§åˆ¶ä¼˜åŒ–å™¨çŠ¶æ€æ˜¯å¦è½¬ç§»åˆ° CPU\n```\n\n+ `shard_param_frac=1.0` ä¼šå°†æ‰€æœ‰å‚æ•°åˆ‡åˆ†åˆ°ä¸åŒçš„ GPU ä¸Šï¼Œç±»ä¼¼äº ZeRO-3ã€‚\n+ `offload_optim_frac=0.0` åˆ™æ„å‘³ç€ä¼˜åŒ–å™¨çš„çŠ¶æ€ä»ç„¶ä¿ç•™åœ¨ GPU ä¸Šã€‚\n\néœ€è¦æ‰‹åŠ¨è°ƒèŠ‚æ˜¾å­˜åˆ©ç”¨ç‡ï¼ˆä¾‹å¦‚ï¼Œé€šè¿‡è®¾ç½® `shard_param_frac` å’Œ `offload_optim_frac` æ¥æ§åˆ¶å‚æ•°å’Œä¼˜åŒ–å™¨çš„å­˜æ”¾ä½ç½®ï¼‰ã€‚é€‚åˆé‚£äº› **å¯¹å†…å­˜ä½¿ç”¨æœ‰è¾ƒé«˜æ§åˆ¶éœ€æ±‚** çš„åœºæ™¯ï¼Œä½†éœ€è¦æ›´å¤šçš„äººå·¥è°ƒè¯•å’Œä¼˜åŒ–ã€‚\n\n##### åœ¨ `gemini_auto` æ¨¡å¼ä¸‹ï¼ŒGemini ä¼šè‡ªåŠ¨ä¼˜åŒ–å†…å­˜çš„ä½¿ç”¨ã€‚ä¾‹å¦‚ï¼š\n\n```python\nplacement_policy=\"auto\"\n```\n\n+ è‡ªåŠ¨æ ¹æ®ç¡¬ä»¶çŠ¶æ€è°ƒæ•´å†…å­˜å’Œå‚æ•°çš„å­˜æ”¾ä½ç½®ã€‚\n+ é€‚åˆåœ¨ **æ²¡æœ‰è¶³å¤Ÿç¡¬ä»¶ä¿¡æ¯æˆ–ä¸å¸Œæœ›è¿›è¡Œæ‰‹åŠ¨è°ƒä¼˜** çš„æƒ…å†µä¸‹ä½¿ç”¨ã€‚ç‰¹åˆ«æ˜¯åœ¨å¤š GPU æˆ–å¤šä¸ªæœºå™¨çš„è®­ç»ƒåœºæ™¯ä¸­ï¼Œè‡ªåŠ¨çš„å†…å­˜ç®¡ç†å¯ä»¥æœ‰æ•ˆé¿å… **OOM** å’Œæå‡æ˜¾å­˜åˆ©ç”¨ç‡ã€‚\n\nè¿™ç§æ¨¡å¼ä¼šæ ¹æ®å½“å‰ GPU çš„è´Ÿè½½ã€æ˜¾å­˜çš„å‰©ä½™æƒ…å†µç­‰å› ç´ ï¼ŒåŠ¨æ€å†³å®šæ˜¯å¦å°†éƒ¨åˆ†æ¨¡å‹å‚æ•°æˆ–ä¼˜åŒ–å™¨çŠ¶æ€ä» GPU è½¬ç§»åˆ° CPU ä¸Šï¼Œå‡å°‘ GPU å†…å­˜çš„å ç”¨ï¼Œé¿å…æ˜¾å­˜æº¢å‡ºã€‚è¿™ç§æ¨¡å¼é€šå¸¸ä¼šåœ¨è®­ç»ƒå¼€å§‹æ—¶è¿›è¡Œé¢„çƒ­ï¼Œå³æ ¹æ®æ¨¡å‹å’Œæ•°æ®çš„ç‰¹ç‚¹è‡ªåŠ¨è°ƒæ•´å‚æ•°çš„åˆ†é…æ–¹å¼ï¼Œä»¥ä¿è¯è®­ç»ƒè¿‡ç¨‹ä¸­å†…å­˜çš„é«˜æ•ˆåˆ©ç”¨ã€‚\n\n##### é€‚ç”¨åœºæ™¯\n\n+ `**gemini**`ï¼šé€‚åˆ **ç²¾ç¡®æ§åˆ¶ **å†…å­˜ä½¿ç”¨å’Œè®­ç»ƒè¿‡ç¨‹çš„åœºæ™¯ï¼Œå°¤å…¶æ˜¯å½“ç”¨æˆ·å¯¹ç¡¬ä»¶èµ„æºæœ‰æ·±å…¥äº†è§£å¹¶èƒ½è¿›è¡Œæ‰‹åŠ¨è°ƒä¼˜æ—¶ã€‚é€‚ç”¨äºè¶…å¤§è§„æ¨¡è®­ç»ƒï¼Œç‰¹åˆ«æ˜¯éœ€è¦æ˜¾å¼æ§åˆ¶æ¨¡å‹åˆ‡åˆ†å’Œå­˜å‚¨ä½ç½®çš„æƒ…å†µã€‚\n+ `**gemini_auto**`ï¼šé€‚åˆé‚£äº› **å¸Œæœ›å‡å°‘äººå·¥è°ƒä¼˜ **çš„ç”¨æˆ·ï¼Œç‰¹åˆ«æ˜¯åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åŠ¨æ€è°ƒæ•´èµ„æºå’Œå†…å­˜æ—¶ã€‚å®ƒä½¿å¾—è®­ç»ƒè¿‡ç¨‹æ›´åŠ çµæ´»ï¼Œç‰¹åˆ«æ˜¯åœ¨é¢å¯¹ **GPU å†…å­˜ç“¶é¢ˆ** å’Œ **å¤šå¡è®­ç»ƒ** æ—¶ï¼Œè‡ªåŠ¨è°ƒæ•´å†…å­˜å’Œè®¡ç®—èµ„æºåˆ†é…èƒ½å¤Ÿæé«˜è®­ç»ƒæ•ˆç‡ã€‚\n\n### æ€»ç»“\n\n**Gemini çš„å…³é”®æ”¹è¿›ç‚¹**ï¼š\n\n1. **å‚æ•°åˆ‡åˆ†æ›´åŠ çµæ´»**ï¼šæ”¯æŒ ZeRO-2/3 ä¹‹é—´çš„åŠ¨æ€è°ƒæ•´ã€‚\n2. **è®¡ç®—å›¾æ™ºèƒ½ä¼˜åŒ–**ï¼šç»“åˆ TP + DP + ZeRO è¿›è¡Œè´Ÿè½½å‡è¡¡ã€‚\n3. **æ˜¾å­˜ç®¡ç†æ›´é«˜æ•ˆ**ï¼šè‡ªåŠ¨è°ƒæ•´å‚æ•°åœ¨ CPU/GPU ä¹‹é—´çš„å­˜æ”¾ï¼Œé˜²æ­¢ OOMã€‚\n4. **æ··åˆç²¾åº¦æ”¯æŒ**ï¼šFP16/BF16 è®¡ç®—ï¼Œæé«˜è®¡ç®—æ•ˆç‡ã€‚\n5. **å¼‚æ­¥æ¢¯åº¦åŒæ­¥**ï¼šå‡å°‘é€šä¿¡å¼€é”€ï¼Œæé«˜ GPU åˆ©ç”¨ç‡ã€‚\n\n\n\n","tags":["NVIDIA","V100","æ¨¡å‹è®­ç»ƒè°ƒä¼˜","ColossalAI"],"categories":["æ¨¡å‹è®­ç»ƒæ¡†æ¶","ColossalAI"]},{"title":"xinferenceæ¨ç†å®è·µ","url":"/2026/01/08/LLM/æ¨ç†/xinferenceæ¨ç†å®è·µ/","content":"\n## NVç”Ÿæ€\n\n### å®¹å™¨åˆ›å»º\n\n```bash\ndocker run -d --restart=always --name=xinference_wxb \\\n -v /mnt/users/wangxiangbo/xinference:/opt/xinference -e XINFERENCE_HOME=/opt/xinference -e XINFERENCE_MODEL_SRC=modelscope \\\n -p 9998:9997 --gpus all registry.cn-hangzhou.aliyuncs.com/xprobe_xinference/xinference:latest xinference-local -H 0.0.0.0\n```\n\n```bash\ndocker run -d --restart=always --name=xinference_wxb \\\n -v /mnt/users/wangxiangbo/xinference:/opt/xinference -e XINFERENCE_HOME=/opt/xinference -e XINFERENCE_MODEL_SRC=hf-mirror.com \\\n -p 9998:9997 --gpus all registry.cn-hangzhou.aliyuncs.com/xprobe_xinference/xinference:latest xinference-local -H 0.0.0.0\n```\n\n```bash\ndocker run -d --restart=always --name=xinference_wxb \\\n -v /mnt/users/wangxiangbo/xinference:/opt/xinference -e XINFERENCE_HOME=/opt/xinference -p 9998:9997 --gpus all registry.cn-hangzhou.aliyuncs.com/xprobe_xinference/xinference:latest xinference-local -H 0.0.0.0\n```\n\n\n\nè¿›å…¥å®¹å™¨\n\n```bash\ndocker exec -it xinference_wxb bash\n```\n\n### æœåŠ¡åˆ›å»º\n\nå¼€å¯xinference-localæœåŠ¡\n\n```bash\nroot@979723eca011:/opt/inference/examples# xinference-local\n```\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/reasoning/xinference/image1.png)\n\n### webç«¯è°ƒç”¨\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/reasoning/xinference/image2.png)\n\né€‰æ‹©å¾…æ¨ç†çš„LLMæ¨¡å‹\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/reasoning/xinference/image3.png)\n\næ§åˆ¶å°å¼€å§‹ä¸‹è½½å¯¹åº”çš„Qwen1.5-Chat-1.8Bæ¨¡å‹\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/reasoning/xinference/image4.png)\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/reasoning/xinference/image5.png)\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/reasoning/xinference/image6.png)\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/reasoning/xinference/image7.png)\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/reasoning/xinference/image8.png)\n\n### ç»ˆç«¯APIè°ƒç”¨\n\n```python\nfrom gradio_client import Client\n\nclient = Client(\"http://127.0.0.1:54696/qwen1.5-chat/\")\nresult = client.predict(\n\t\tmessage=\"Hello!!\",\n\t\trequest=512,\n\t\tparam_3=1,\n\t\tparam_4=\"Hello!!\",\n\t\tapi_name=\"/chat\"\n)\nprint(result)\n```\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/reasoning/xinference/image9.png)\n\n## HWç”Ÿæ€\n\n### å®¹å™¨åˆ›å»º\n\n```bash\ndocker run -d --restart=always --name=xinference_wxb \\\n -v /reason-sharedata/training_inference/wangxiangbo/xinference:/opt/xinference -e XINFERENCE_HOME=/opt/xinference -e XINFERENCE_MODEL_SRC=modelscope \\\n -p 9998:9997 registry.cn-hangzhou.aliyuncs.com/xprobe_xinference/xinference:nightly-main-cpu xinference-local -H 0.0.0.0\n```\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/reasoning/xinference/image10.png)\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/reasoning/xinference/image11.png)\n\nç”±äºXinferenceæ¡†æ¶çš„æœ€æ–°é•œåƒéœ€è¦é…åˆGPUæ¥ä½¿ç”¨ï¼Œæ•…æœ¬æ¬¡åˆ©ç”¨cpuç‰ˆæœ¬è¿›è¡Œæ¨ç†éªŒè¯ã€‚\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/reasoning/xinference/image12.png)\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/reasoning/xinference/image13.png)\n\n### æœåŠ¡åˆ›å»º\n\n","tags":["NVIDIA","V100","æ¨¡å‹æ¨ç†","xinference"],"categories":["æ¨¡å‹æ¨ç†","xinference"]},{"title":"llama-factoryç¯å¢ƒæ­å»º-æ˜‡è…¾","url":"/2026/01/08/LLM/å®¢æˆ·æ”¯æ’‘/æŸå¾‹æ‰€å¤§æ¨¡å‹å¾®è°ƒ/llama-factoryç¯å¢ƒæ­å»º-æ˜‡è…¾/","content":"\n### è®­ç»ƒ\n\n```bash\nconda create --name llamafactory python=3.10\n\nconda activate llamafactory\n\npip install -e \".[torch-npu,metrics]\"\n\npip install --upgrade torch==2.6.0 -i https://pypi.tuna.tsinghua.edu.cn/simple\n\npip install --upgrade torch-npu==2.6.0rc1 -i https://pypi.tuna.tsinghua.edu.cn/simple\n\npip uninstall scikit-learn\n\nsource /usr/local/Ascend/ascend-toolkit/set_env.sh\n\nllamafactory-cli train examples/train_lora/qwen3_lora_sft.yaml\n```\n\n### æ¨ç†\n\n```bash\nllamafactory-cli chat examples/inference/qwen3_lora_sft.yaml\n\nvllmæ¨ç†\nsudo apt update\n\nsudo apt install libnuma-dev\n\npip install vllm==0.8.5 -i https://pypi.tuna.tsinghua.edu.cn/simple\n\npip install vllm-ascend==\n\nASCEND_RT_VISIBLE_DEVICES=2,4 llamafactory-cli chat examples/inference/qwen3_lora_sft.yaml\n\n\nbash Ascend-cann-nnal_8.0.0_linux-aarch64.run --install\n\nsource /usr/local/Ascend/nnal/atb/set_env.sh\n```\n\n\n\n\n\n","tags":["è®­ç»ƒç¯å¢ƒæ­å»º","æ˜‡è…¾","910B","llama-factory"],"categories":["è®­ç»ƒç¯å¢ƒæ­å»º","llama-factory"]},{"title":"tulu3è®ºæ–‡è§£è¯»","url":"/2026/01/08/LLM/è®ºæ–‡è§£è¯»/tulu3è®ºæ–‡è§£è¯»/","content":"\nè¯­è¨€æ¨¡å‹çš„åè®­ç»ƒå¯ä»¥æ”¹è¿›å…¶æ€§èƒ½å¹¶è§£é”æ–°æŠ€èƒ½ï¼Œä¸ºäº†ç¼©å°å¼€æºæ–¹æ³•åœ¨è¿™æ–¹é¢é€šå¸¸è½åäºä¸“æœ‰é—­æºæŠ€æœ¯è¿™ä¸€å·®è·ï¼Œç ”ç©¶è€…æ¨å‡ºäº†TÃœLU3ï¼Œä¸€ä¸ªå®Œå…¨å¼€æºçš„é«˜çº§åè®­ç»ƒæ¨¡å‹ç³»åˆ—ï¼ŒåŒ…æ‹¬å…¶æ•°æ®ã€ä»£ç å’Œè®­ç»ƒæ–¹æ³•ã€‚åŸºäºLlama 3.1åŸºç¡€æ¨¡å‹ï¼ŒTÃœLU3çš„è¡¨ç°ä¼˜äºå¤šä¸ªçŸ¥åæ¨¡å‹ï¼Œå¦‚Llama 3.1ã€Qwen 2.5ã€Mistralç­‰ï¼Œå¹¶ä¸”åœ¨æŸäº›æ–¹é¢ç”šè‡³è¶…è¿‡äº†GPT-4o-miniå’ŒClaude 3.5-Haikuè¿™æ ·çš„é—­æºæ¨¡å‹ã€‚TÃœLU3é‡‡ç”¨**ç›‘ç£å¾®è°ƒ(SFT)ã€ç›´æ¥åå¥½ä¼˜åŒ–(DPO)**ä»¥åŠä¸€ç§**æ–°çš„å¯éªŒè¯å¥–åŠ±å¼ºåŒ–å­¦ä¹ (RLVR)**æ–¹æ³•è¿›è¡Œè®­ç»ƒã€‚æ­¤å¤–ï¼Œè¿˜å»ºç«‹äº†ä¸€ä¸ªå…¨é¢çš„å¤šä»»åŠ¡è¯„ä¼°æ¡†æ¶ï¼Œæ¶µç›–äº†å¼€å‘ä¸æœªè§æµ‹è¯•ã€æ ‡å‡†åŸºå‡†åŠå¯¹ç°æœ‰å¼€æºæ•°æ®é›†çš„å¤§è§„æ¨¡æ¸…ç†ã€‚æœ€åï¼Œé¡¹ç›®æä¾›äº†æ¨¡å‹æƒé‡ã€ç¤ºä¾‹ã€æ•°æ®é›†ã€å·¥å…·åŒ…ã€è®­ç»ƒä»£ç å’Œè¯¦ç»†æŠ¥å‘Šï¼Œä»¥ä¾¿ä»–äººå¤åˆ¶ç»“æœå¹¶å°†è¿™äº›æŠ€æœ¯åº”ç”¨äºæ›´å¹¿æ³›çš„é¢†åŸŸã€‚\n\n\n[TÃœLU3 70B](https://huggingface.co/allenai/Llama-3.1-Tulu-3-70B)\n\n[TÃœLU3 8B](https://huggingface.co/allenai/Llama-3.1-Tulu-3-8B)\n\n[TÃœLU3 Data](https://huggingface.co/collections/allenai/tulu-3-datasets-673b8df14442393f7213f372)\n\n[TÃœLU3 Code](https://github.com/allenai/open-instruct)\n\n[TÃœLU3 Eval](https://github.com/allenai/olmes)\n\n\n#  Introduction\n\n_â€œæ­£å¦‚éª†é©¼ä¸å•†é˜Ÿä¸­çš„å…¶ä»–éª†é©¼åˆ†æ‹…è´Ÿæ‹…ä¸€æ ·ï¼Œæ™ºè€…ä¹Ÿä¼šåˆ†äº«ä»–ä»¬çš„è§è§£ï¼Œä»¥å‡è½»æ— çŸ¥çš„è´Ÿæ‹…ã€‚â€ â€“_ TÃœLU3äº§ç”Ÿçš„è°šè¯­ã€‚\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![å›¾ 1 TÃœLU3 recipeæ¦‚è¿°ã€‚è¿™åŒ…æ‹¬ï¼šé’ˆå¯¹ä¸€èˆ¬å’Œç›®æ ‡èƒ½åŠ›çš„æ•°æ®ç®¡ç†ã€è®­ç»ƒç­–ç•¥ä»¥åŠç”¨äºå¼€å‘å’Œæœ€ç»ˆè¯„ä¼°é˜¶æ®µçš„æ ‡å‡†åŒ–è¯„ä¼°å¥—ä»¶ã€‚](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/paper/tulu3/image1.png)\n\nä¸ºäº†ç¼©å°å¼€æºå¼å’Œé—­æºå¼åè®­ç»ƒä¹‹é—´çš„å·®è·ï¼Œä½œè€…ä»¬æ¨å‡ºäº†è¿™æ˜¯ä¸€ç³»åˆ—å¼€æºçš„å…ˆè¿›åè®­ç»ƒæ¨¡å‹ï¼Œä»¥åŠæ‰€æœ‰æ•°æ®ã€è®­ç»ƒæ–¹æ³•ã€ä»£ç ã€åŸºç¡€è®¾æ–½å’Œè¯„ä¼°æ¡†æ¶ã€‚\n\nä¸ºäº†æ„å»º TÃœLU3ï¼Œä½œè€…ä»¬ç¡®å®šäº†ä¸€ç»„åè®­ç»ƒéœ€è¦æ”¹è¿›çš„æ ¸å¿ƒæŠ€èƒ½ï¼ˆä¾‹å¦‚æ¨ç†ã€æ•°å­¦ã€ç¼–ç ã€å®‰å…¨ã€ç²¾ç¡®éµå¾ªæŒ‡ä»¤ã€çŸ¥è¯†å›å¿†ç­‰ï¼‰ï¼Œå¹¶å»ºç«‹äº†ä¸€ä¸ªè¯„ä¼°æ¡†æ¶ï¼Œä»¥å»ºç«‹æ˜ç¡®çš„ç»©æ•ˆç›®æ ‡å¹¶æŒ‡å¯¼æ¨¡å‹åœ¨ä¸€ç³»åˆ—å¼€å‘å’Œæœªè§è¿‡çš„ä»»åŠ¡ä¸Šçš„æ”¹è¿›ã€‚TÃœLU3å—ç›ŠåŒªæµ…ï¼Œå®ƒå……åˆ†åˆ©ç”¨äº†å…¬å¼€å¯ç”¨çš„å¼€æºæ•°æ®ï¼Œåœ¨å„ä¸ªè®­ç»ƒé˜¶æ®µç”Ÿæˆå¤šæ ·åŒ–ã€ç‰¹å®šæŠ€èƒ½çš„åˆæˆæ•°æ®ï¼Œå¹¶æ ¹æ®ä½œè€…ä»¬çš„è¯„ä¼°å¥—ä»¶ç§¯æåœ°å‡€åŒ–è¿™äº›æ•°æ®ã€‚\n\nTÃœLU3è®­ç»ƒRecipeæ¶‰åŠå¤šä¸ªé˜¶æ®µï¼Œæ¯ä¸ªé˜¶æ®µéƒ½ä»¥ä¹‹å‰çš„æ¨¡å‹ä¸ºåŸºç¡€ï¼Œå¹¶ä¾§é‡äºä¸åŒç±»å‹çš„æ•°æ®â€”â€”å³ç›‘ç£å¾®è°ƒçš„å¿«é€Ÿå®Œæˆå®ä¾‹ã€åå¥½è°ƒæ•´ä»¥åŠå¼ºåŒ–å­¦ä¹ çš„å¯éªŒè¯å¥–åŠ±ã€‚ä½œè€…ä»¬çš„æ–¹æ³•æœ‰åŠ©äºè¯†åˆ«æŠ€èƒ½ç¼ºé™·å¹¶æ”¹è¿›æ•°æ®ç»„åˆã€æ–¹æ³•å’Œå‚æ•°ï¼Œç¡®ä¿åœ¨æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ä¸­æ ¸å¿ƒæŠ€èƒ½çš„å¹³è¡¡è¡¨ç°ã€‚é€šè¿‡ä¸¥æ ¼ã€æœ‰åŸåˆ™çš„å®éªŒï¼Œä½œè€…ä»¬ç¡®å®šäº†ç›‘ç£å¾®è°ƒçš„æœ€ä½³æ•°æ®ç»„åˆï¼Œä»è€Œå¾—å‡º TÃœLU3SFT æ£€æŸ¥ç‚¹ã€‚åˆ©ç”¨åå¥½è°ƒæ•´æ–¹é¢çš„æœ€æ–°è¿›å±•ï¼Œä½œè€…ä»¬éšåé€šè¿‡æ¯”è¾ƒ TÃœLU3SFT å®Œæˆæƒ…å†µä¸å…¶ä»–è¯­è¨€æ¨¡å‹çš„è¾“å‡ºï¼Œä½¿ç”¨ç²¾å¿ƒç­–åˆ’çš„ç­–ç•¥åå¥½æ•°æ®æ¥è®­ç»ƒæ¨¡å‹ã€‚æ­¤å¤–ï¼Œä½œè€…ä»¬å¼•å…¥äº†ä¸€ä¸ªæ–°çš„æœ€ç»ˆå¾®è°ƒé˜¶æ®µâ€”â€”å¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹  (RLVR)â€”â€”å®ƒé‡‡ç”¨äº†ä¸€ç§æ–°é¢–çš„ RL ç›®æ ‡ï¼Œæ—¨åœ¨å¢å¼ºç‰¹å®šæŠ€èƒ½ï¼Œå…·æœ‰å¯éªŒè¯çš„ç­”æ¡ˆï¼Œä¾‹å¦‚æ•°å­¦å’Œç²¾ç¡®çš„æŒ‡ä»¤ã€‚\n\nä½œè€…ä»¬è¡¨ç°æœ€ä½³çš„æ–¹æ¡ˆäº§ç”Ÿçš„ TÃœLU3æ¨¡å‹çš„è¡¨ç°ä¼˜äºåŒç­‰è§„æ¨¡çš„æœ€å…ˆè¿›çš„åè®­ç»ƒå¼€æºæƒé‡æ¨¡å‹ï¼Œä¾‹å¦‚ Llama 3.1 Instructã€Qwen2.5 Instruct æˆ– Mistral-Instructï¼Œå¹¶ä¸”åœ¨ 70B è§„æ¨¡ä¸‹ï¼ŒTÃœLUå¯ä¸ Claude 3.5 Haiku å’Œ GPT-4o mini ç­‰é—­æºæä¾›å•†çš„äº§å“ç›¸åª²ç¾ã€‚\n\né—­æºæ¨¡å‹ç‰ˆæœ¬ï¼šGPT-3.5-Turbo-0125ã€GPT-4o-mini-2024-07-18ã€Claude 3.5 Haiku 20241022\n\næ€»è€Œè¨€ä¹‹ï¼ŒTÃœLU3ä»£è¡¨äº†ä¸€ç³»åˆ—æœ€å…ˆè¿›çš„å¼€æºè¯­è¨€æ¨¡å‹ï¼Œå…·æœ‰ç°ä»£çš„åè®­ç»ƒæ¡†æ¶ã€å®Œå…¨å¼€æºçš„æ•°æ® TÃœLU3D ATA ã€è¯„ä¼° TÃœLU3E VAL ã€è®­ç»ƒä»£ç  TÃœLU3C ODE å’Œå¼€å‘Recipe TÃœLU3R ECIPE ã€‚ä»¥ä¸‹æ˜¯ TÃœLUå¼€å‘çš„ä¸€äº›å…³é”®è´¡çŒ®ï¼š\n\n\n\n+ ä¸ºè¯„ä¼°ã€å‡€åŒ–å’ŒRecipeè®¾è®¡æä¾›å¹¿æ³›çš„æŒ‡å¯¼å’Œå·¥å…·ï¼Œ\n+ æ‰©å±•çš„ã€æ–°çš„åˆæˆæ•™å­¦æ•°æ®é›†ï¼Œ\n+ ä½¿ç”¨åŸºäºç­–ç•¥çš„ç”Ÿæˆæ¥æ‰©å±•åå¥½æ•°æ®ï¼Œ\n+ å…·æœ‰å¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ ï¼Œè¿™æ˜¯ä¸€ç§åŸºäº RL çš„æ–¹æ³•ï¼Œåªæœ‰åœ¨æ¨¡å‹çš„å®Œæˆè¢«éªŒè¯ä¸ºæ­£ç¡®æ—¶æ‰ä¼šè·å¾—å¥–åŠ±ï¼Œ\n+ å…ˆè¿›çš„åŸºç¡€è®¾æ–½ã€ç»†èŠ‚å’Œä»£ç ï¼Œä»¥ä¿ƒè¿›å¤§å‹æ¨¡å‹çš„æˆåŠŸå®æ–½\n\n\n\nä½œè€…ä»¬çš„å·¥ä½œæˆæœæ˜¯å®Œå…¨å¼€æºçš„è¯­è¨€æ¨¡å‹å¾®è°ƒpipelineã€‚ä½œè€…ä»¬å‘å¸ƒäº†åœ¨ Llama 3.1 åŸºç¡€ç‰ˆæœ¬åŸºç¡€ä¸Šè®­ç»ƒçš„æœ€ç»ˆæ¨¡å‹ï¼Œå…¶ä¸­åŒ…å«ä¸­é—´æ£€æŸ¥ç‚¹ã€è®­ç»ƒæ•°æ®ã€è®­ç»ƒä»£ç å’Œè¯„ä¼°ä»£ç ï¼ˆå‘å¸ƒçš„å®Œæ•´å·¥ä»¶åˆ—è¡¨è§è¡¨ 1ï¼‰ã€‚å€ŸåŠ©æ‰€æœ‰å‘å¸ƒçš„èµ„æºï¼Œå…¶ä»–äººå¯ä»¥é‡‡ç”¨å¼€æºçš„åŸºç¡€æ¨¡å‹å¹¶å¯¹å…¶è¿›è¡Œå¾®è°ƒï¼Œä»¥åœ¨ä»»ä½•æ„Ÿå…´è¶£çš„ä»»åŠ¡ä¸Šå®ç°é«˜æ€§èƒ½ï¼Œä¸ºå¤æ‚ã€å¤šç›®æ ‡å’Œå¤šé˜¶æ®µè®­ç»ƒæ–¹æ¡ˆä¸­çš„åè®­ç»ƒç ”ç©¶å¥ å®šåŸºç¡€ã€‚\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![è¡¨ 1 ä¸­é—´æ£€æŸ¥ç‚¹ã€è®­ç»ƒæ•°æ®ã€è®­ç»ƒä»£ç å’Œè¯„ä¼°ä»£ç ](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/paper/tulu3/image2.png)\n\n# TÃœLU3  Overview \n\nè¡¨ 2ï¼šTÃœLU3 EVALç”±å¼€å‘å’Œéšè—çš„åˆ†å‰²ç»„æˆï¼Œç”¨äºè¯„ä¼°æ ¸å¿ƒæŠ€èƒ½ã€‚å€ŸåŠ© TÃœLU3 EVAL ï¼Œä½œè€…ä»¬å‘å¸ƒäº†ç»Ÿä¸€çš„æ ‡å‡†åŒ–è¯„ä¼°å¥—ä»¶å’Œå·¥å…·åŒ…ï¼Œç”¨äºæ ¹æ®åŸºå‡†å¯¹è®­ç»ƒæ•°æ®è¿›è¡Œå‡€åŒ–ã€‚ä¸‹æ ‡æ˜¾ç¤ºäº†ä½œè€…ä»¬ç”¨äºè¯„ä¼°çš„æŒ‡æ ‡ã€‚TÃœLU3 Safety æ˜¯å®‰å…¨è¯„ä¼°çš„é›†åˆï¼Œè¯¦æƒ…è¯·å‚é˜…ç¬¬ 7.2.1 èŠ‚ã€‚\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![è¡¨ 2 TÃœLU3 EVAL å‘å¸ƒäº†ç»Ÿä¸€çš„æ ‡å‡†åŒ–è¯„ä¼°å¥—ä»¶å’Œå·¥å…·åŒ…](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/paper/tulu3/image3.png)\n\nTÃœLU3çªç ´äº†åè®­ç»ƒç ”ç©¶çš„ç•Œé™ï¼Œç¼©å°äº†å¼€æºå¼å’Œé—­æºå¼å¾®è°ƒæ–¹æ³•ä¹‹é—´çš„å·®è·ã€‚å€ŸåŠ© TÃœLU3ï¼Œä½œè€…ä»¬å¸Œæœ›å‘ç°å¼€æºç¤¾åŒºçš„å“ªäº›è·¯å¾„å°†å–å¾—æˆåŠŸï¼Œå“ªäº›è·¯å¾„ä¸ä¼šï¼ˆé€šè¿‡æŠ¥å‘Šè´Ÿé¢ç»“æœï¼‰ã€‚è¿™æ˜¯ä¸€ä¸ªå¤æ‚çš„è®­ç»ƒè¿‡ç¨‹ï¼Œå°†ä¸“æœ‰æ–¹æ³•çš„éƒ¨åˆ†ç»†èŠ‚ä¸æ–°æŠ€æœ¯å’Œæˆç†Ÿçš„å­¦æœ¯ç ”ç©¶ç›¸ç»“åˆã€‚mdelname 3 æˆåŠŸçš„å…³é”®å› ç´ åœ¨äºä»”ç»†çš„æ•°æ®ç®¡ç†ã€ä¸¥æ ¼çš„å®éªŒå’Œè¯„ä¼°ã€åˆ›æ–°çš„æ–¹æ³•å’Œæ”¹è¿›çš„è®­ç»ƒåŸºç¡€è®¾æ–½ã€‚ä½œè€…ä»¬éµå¾ªç³»ç»Ÿçš„æŒ‡å¯¼æ–¹é’ˆï¼Œé€šè¿‡åˆ›å»ºå¼€å‘å’Œæµ‹è¯•é›†è¿›è¡Œè¯„ä¼°ï¼Œå¯¹è¿™ä¸€è¿‡ç¨‹è¿›è¡Œç§‘å­¦è¯„ä¼°ï¼Œå¹¶å¯¹å…¬å¼€å¯ç”¨çš„æ•°æ®é›†è¿›è¡Œä»”ç»†çš„å‡€åŒ–ã€‚å¼€æºåè®­ç»ƒçš„TÃœLU3 ä¸ä»…ä»…æ˜¯ä¸€ä¸ªå·¥ä»¶ï¼Œè€Œæ˜¯ä¸€å¥—å…¨é¢çš„æ•°æ®å’Œå·¥å…·ï¼Œæ—¨åœ¨æ¨åŠ¨å‰æ²¿æŠ€æœ¯çš„å‘å±•ã€‚é€šè¿‡å…¬å¼€åˆ†äº«ä½œè€…ä»¬çš„æ•°æ®ã€Recipeå’Œå‘ç°ï¼Œä½œè€…ä»¬æ—¨åœ¨ä½¿ç¤¾åŒºèƒ½å¤Ÿæ¢ç´¢æ–°çš„å’Œåˆ›æ–°çš„åè®­ç»ƒæ–¹æ³•ã€‚\n\n## TÃœLU3 Data\n\næ ¸å¿ƒæŠ€èƒ½TÃœLU3 çš„å·¥ä½œé¦–å…ˆç¡®å®šäº†å¼€æºçš„åè®­ç»ƒæ–¹æ³•ç»å¸¸è½åçš„å…³é”®é¢†åŸŸï¼Œè¿™äº›é¢†åŸŸæ˜¯é€šç”¨è¯­è¨€æ¨¡å‹æ‰€éœ€çš„èƒ½åŠ›ã€‚è¡¨ 3 æ¦‚è¿°äº†ä½œè€…ä»¬æ—¨åœ¨å¢å¼ºçš„æ ¸å¿ƒèƒ½åŠ›ä»¥åŠä¸ºæ¶µç›–è¿™äº›æŠ€èƒ½è€Œé€‰æ‹©çš„è¯„ä¼°åŸºå‡†ã€‚åœ¨ TÃœLU3 ä¸­ï¼Œä½œè€…ä»¬ä¸“æ³¨äºçŸ¥è¯†å›å¿†ã€æ¨ç†ã€æ•°å­¦ã€ç¼–ç ã€æŒ‡ä»¤éµå¾ªã€ä¸€èˆ¬èŠå¤©å’Œå®‰å…¨ç­‰æ ¸å¿ƒæŠ€èƒ½ã€‚\n\nä½œè€…ä»¬é€šè¿‡ä»å…¬å…±æ•°æ®ä¸­è·å–æ•°æ®å¹¶ç»¼åˆæ•´ç†æ•°æ®æ¥æ•´ç†å’Œæ”¶é›† TÃœLU3D ATAä»¥é’ˆå¯¹è¿™äº›æ ¸å¿ƒæŠ€èƒ½ã€‚ä½œè€…ä»¬åœ¨è®­ç»ƒçš„ä¸åŒé˜¶æ®µä½¿ç”¨å„ç§æ•°æ®æ ¼å¼ã€‚è¡¨ 6 æ¦‚è¿°äº†ç”¨äºè®­ç»ƒä½œè€…ä»¬æ¨¡å‹çš„æ•°æ®é›†é›†åˆï¼Œæ›´å¤šè¯¦ç»†ä¿¡æ¯è¯·å‚è§ç¬¬ 3 èŠ‚ã€‚\n\n## TÃœLU3  Evaluation\n\nä½œè€…ä»¬çš„åè®­ç»ƒæ–¹æ³•å–å¾—æˆåŠŸçš„ä¸€ä¸ªå…³é”®å› ç´ æ˜¯å»ºç«‹æ˜ç¡®çš„ç»©æ•ˆç›®æ ‡å’Œè¯„ä¼°å·¥å…·ï¼Œä»¥æŒ‡å¯¼è¿™äº›é˜¶æ®µçš„æ”¹è¿›ã€‚å€ŸåŠ© TÃœLU3E VAL ï¼Œä½œè€…ä»¬å‘å¸ƒäº†ç»Ÿä¸€çš„æ ‡å‡†åŒ–è¯„ä¼°å¥—ä»¶å’Œå·¥å…·åŒ…ï¼Œä»¥æŒ‡å¯¼å¼€å‘å’Œè¯„ä¼°æœ€ç»ˆæ¨¡å‹å¹¶æ ¹æ®è¯„ä¼°åŸºå‡†å‡€åŒ–è®­ç»ƒæ•°æ®ã€‚\n\nä½œè€…ä»¬çš„æ¡†æ¶åŒ…æ‹¬ä¸€ä¸ªç”¨äºå¯é‡å¤è¯„ä¼°çš„å¼€æºè¯„ä¼°å·¥å…·åŒ…ï¼ˆç¬¬ 7.1 èŠ‚ï¼‰ã€ä¸€å¥—ç”¨äºè¯„ä¼°æŒ‡ä»¤è°ƒæ•´æ¨¡å‹ä¸­æ ¸å¿ƒæŠ€èƒ½çš„å¥—ä»¶ï¼ˆå…·æœ‰å•ç‹¬å¼€å‘ï¼ˆç¬¬ 7.2 èŠ‚ï¼‰å’Œä¿ç•™è¯„ä¼°ï¼ˆç¬¬ 7.3 èŠ‚ï¼‰ï¼Œä»¥åŠä¸€ç»„åŸºäºä½œè€…ä»¬å¯¹å„ç§æ¨¡å‹çš„å®éªŒåœ¨ä½œè€…ä»¬çš„è¯„ä¼°å¥—ä»¶ä¸Šè¿›è¡Œè¯„ä¼°çš„æ¨èè®¾ç½®ã€‚è¿™ä¸¤ç§åˆ’åˆ†éƒ½æ¶µç›–äº†æ‰€æœ‰å·²è¯†åˆ«çš„æŠ€èƒ½ã€‚è‡³å…³é‡è¦çš„æ˜¯ï¼Œä½œè€…ä»¬æ²¡æœ‰æ£€æŸ¥ä½œè€…ä»¬æœªè§é›†ä¸Šçš„åˆ†æ•°\n\n## TÃœLU3  Recipe \n\nåœ¨æœ¬èŠ‚ä¸­ï¼Œä½œè€…ä»¬æ¦‚è¿°äº† TÃœLU3 Recipe  ï¼Œä»¥è·å¾—æœ€å…ˆè¿›çš„åè®­ç»ƒæ¨¡å‹ã€‚ä½œè€…ä»¬åœ¨é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„åŸºç¡€ä¸Šé€šè¿‡å››é˜¶æ®µåè®­ç»ƒRecipeç”Ÿæˆ TÃœLU3æ¨¡å‹ï¼ˆè§å›¾ 1ï¼‰ã€‚TÃœLU3RECIPEæ˜¯ä¸€ä¸ªå…ˆè¿›çš„å¤šé˜¶æ®µè®­ç»ƒpipelineï¼Œç»“åˆäº†å¼ºåŒ–å­¦ä¹ ä¸­çš„æ–°ç®—æ³•è¿›æ­¥ã€å°–ç«¯åŸºç¡€è®¾æ–½å’Œä¸¥æ ¼çš„å®éªŒï¼Œä»¥æ•´ç†æ•°æ®å¹¶ä¼˜åŒ–å„ä¸ªè®­ç»ƒé˜¶æ®µçš„æ•°æ®ç»„åˆã€æ–¹æ³•å’Œå‚æ•°ã€‚åœ¨æ‰€æœ‰é˜¶æ®µï¼Œä½œè€…ä»¬ä½¿ç”¨ç²¾å¿ƒé€‰æ‹©çš„è¯„ä¼°å¥—ä»¶æ¥è¡¡é‡æ¨¡å‹æ€§èƒ½ã€‚é˜¶æ®µå¦‚ä¸‹ï¼š\n\n\n\n+ **ç¬¬ 1 é˜¶æ®µï¼šæ•°æ®ç®¡ç† (Â§3)ï¼Œ**ä½œè€…ä»¬ç®¡ç†å„ç§Promptsï¼Œä»¥åˆ†é…åˆ°å¤šä¸ªä¼˜åŒ–é˜¶æ®µã€‚ä½œè€…ä»¬åˆ›å»ºæ–°çš„åˆæˆPromptsï¼Œæˆ–è€…åœ¨å¯ç”¨æ—¶ä»ç°æœ‰æ•°æ®é›†ä¸­è·å–æºPromptsï¼Œä»¥é’ˆå¯¹ç‰¹å®šåŠŸèƒ½ã€‚ä½œè€…ä»¬ç¡®ä¿Promptsä¸ä¼šå—åˆ°ä½œè€…ä»¬çš„è¯„ä¼°å¥—ä»¶ TÃœLU3 EVAL çš„æ±¡æŸ“ã€‚\n+ **ç¬¬ 2 é˜¶æ®µï¼šç›‘ç£å¾®è°ƒ (Â§4)ï¼Œ**ä½œè€…ä»¬å¯¹ç²¾å¿ƒæŒ‘é€‰çš„Promptså’Œå®Œæˆå†…å®¹è¿›è¡Œç›‘ç£å¾®è°ƒ (SFT)ã€‚é€šè¿‡å½»åº•çš„å®éªŒï¼Œåœ¨ä½œè€…ä»¬çš„è¯„ä¼°æ¡†æ¶çš„æŒ‡å¯¼ä¸‹ï¼Œç¡®å®šæœ€ç»ˆçš„ SFT æ•°æ®å’Œè®­ç»ƒè¶…å‚æ•°ï¼Œä»¥å¢å¼ºç›®æ ‡æ ¸å¿ƒæŠ€èƒ½ï¼Œè€Œä¸ä¼šæ˜¾è‘—å½±å“å…¶ä»–æŠ€èƒ½çš„è¡¨ç°ã€‚\n+ **ç¬¬ 3 é˜¶æ®µï¼šåå¥½è°ƒæ•´ (Â§5)ï¼Œ**ä½œè€…ä»¬å°†åå¥½è°ƒæ•´ï¼ˆç‰¹åˆ«æ˜¯ DPOï¼‰åº”ç”¨äºæ–°æ•´ç†çš„åŸºäºç­–ç•¥çš„åˆæˆåå¥½æ•°æ®ï¼ˆä»é€‰å®šçš„Promptsä»¥åŠéç­–ç•¥æ•°æ®ä¸­ç”Ÿæˆï¼‰ã€‚ä¸ SFT é˜¶æ®µä¸€æ ·ï¼Œä½œè€…ä»¬é€šè¿‡å½»åº•çš„å®éªŒç¡®å®šæœ€ä½³åå¥½æ•°æ®ç»„åˆï¼Œå‘ç°å“ªäº›æ ¼å¼çš„æ•°æ®ã€æ–¹æ³•æˆ–è¶…å‚æ•°å¯ä»¥å¸¦æ¥æ”¹è¿›ã€‚\n+ **ç¬¬ 4 é˜¶æ®µï¼šå…·æœ‰å¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ ï¼ˆÂ§6ï¼‰**ï¼Œä½œè€…ä»¬å¼•å…¥äº†ä¸€ä¸ªæ–°çš„åŸºäº RL çš„åè®­ç»ƒé˜¶æ®µï¼Œè¯¥é˜¶æ®µä½¿ç”¨å¯éªŒè¯å¥–åŠ±è€Œä¸æ˜¯å¥–åŠ±æ¨¡å‹æ¥è®­ç»ƒæ¨¡å‹ï¼Œè¿™åœ¨ä¼ ç»Ÿ RLHF PPO è®­ç»ƒä¸­å¾ˆå¸¸è§ã€‚ä½œè€…ä»¬é€‰æ‹©å…·æœ‰å¯éªŒè¯ç»“æœçš„ä»»åŠ¡ï¼Œä¾‹å¦‚æ•°å­¦é—®é¢˜è§£å†³ï¼Œå¹¶ä¸”ä»…åœ¨æ¨¡å‹çš„ç”Ÿæˆè¢«éªŒè¯ä¸ºæ­£ç¡®æ—¶æ‰æä¾›å¥–åŠ±ã€‚ç„¶åä½œè€…ä»¬ä½¿ç”¨ RL æ¥è®­ç»ƒè¿™äº›å¥–åŠ±ã€‚\n\n\n\nä½œè€…ä»¬çš„ TÃœLU3æµç¨‹çš„ä¸»è¦è´¡çŒ®åœ¨äºæ”¹è¿›äº†æ•°æ®ã€æ–¹æ³•ã€åŸºç¡€è®¾æ–½å’Œä¸¥æ ¼çš„è¯„ä¼°ã€‚ä½œè€…ä»¬æµç¨‹çš„å…³é”®è¦ç´ åŒ…æ‹¬ï¼š\n\n\n\n+ **æ•°æ®è´¨é‡ã€æ¥æºå’Œè§„æ¨¡ï¼ˆÂ§3ï¼‰**ä½œè€…ä»¬é€šè¿‡ä»”ç»†è°ƒæŸ¥å¯ç”¨çš„å¼€æºæ•°æ®é›†ã€åˆ†æå…¶æ¥æºå¹¶å¯¹å…¶è¿›è¡Œå‡€åŒ–ï¼Œä»¥åŠç­–åˆ’é’ˆå¯¹æ ¸å¿ƒæŠ€èƒ½çš„åˆæˆPromptsæ¥è·å¾—Promptsã€‚ä¸ºäº†ç¡®ä¿æœ‰æ•ˆæ€§ï¼Œä½œè€…ä»¬è¿›è¡Œäº†å½»åº•çš„å®éªŒæ¥ç ”ç©¶å®ƒä»¬å¯¹ä½œè€…ä»¬çš„å¼€å‘è¯„ä¼°å¥—ä»¶çš„å½±å“ã€‚\n+ **åˆ›å»ºå¤šæŠ€èƒ½ SFT æ•°æ®é›†(Â§4.1) **é€šè¿‡å¯¹å„ç§æ•°æ®mixturesè¿›è¡Œå¤šè½®ç›‘ç£å¾®è°ƒï¼Œæ”¹è¿›äº†â€œä¸€èˆ¬â€å’Œâ€œç‰¹å®šæŠ€èƒ½â€ç±»åˆ«ä¸­Promptsçš„åˆ†å¸ƒã€‚ä¾‹å¦‚ï¼Œä¸ºäº†æé«˜æ•°å­¦æ¨ç†èƒ½åŠ›ï¼Œä½œè€…ä»¬é¦–å…ˆé€šè¿‡åˆ›å»ºæ•°å­¦ä¸“ä¸šæ¨¡å‹åœ¨è¯„ä¼°å¥—ä»¶ä¸­å»ºç«‹ä¸Šé™ï¼Œç„¶åæ··åˆæ•°æ®ä»¥ä½¿ä¸€èˆ¬æ¨¡å‹æ›´æ¥è¿‘è¿™ä¸ªä¸Šé™ã€‚\n+ **æ•´ç†åŸºäºç­–ç•¥çš„åå¥½æ•°æ®é›†(Â§5.2)** ä½œè€…ä»¬å¼€å‘äº†åŸºäºç­–ç•¥çš„æ•°æ®æ•´ç†æµç¨‹æ¥æ‰©å±•ä½œè€…ä»¬çš„åå¥½æ•°æ®é›†ç”Ÿæˆã€‚å…·ä½“æ¥è¯´ï¼Œä½œè€…ä»¬ä» TÃœLU3-SFT å’Œå…¶ä»–æ¨¡å‹ä¸­ä¸ºç»™å®šçš„Promptsç”Ÿæˆå›ç­”ï¼Œå¹¶é€šè¿‡å®ƒä»¬çš„æˆå¯¹æ¯”è¾ƒè·å¾—åå¥½æ ‡ç­¾ã€‚ä½œè€…ä»¬çš„æ–¹æ³•æ‰©å±•å¹¶æ”¹è¿›äº† Cui ç­‰äººæå‡ºçš„åŸºäºç­–ç•¥çš„åå¥½æ•°æ®ç”Ÿæˆæ–¹æ³• [2023]ã€‚é€šè¿‡ç²¾å¿ƒé€‰æ‹©åå¥½æ•°æ®ï¼Œä½œè€…ä»¬è·å¾—äº† 354,192 ä¸ªç”¨äºåå¥½è°ƒæ•´çš„å®ä¾‹ï¼Œåœ¨ä¸€ç³»åˆ—ä»»åŠ¡ä¸­è¡¨ç°å‡ºæ˜¾è‘—çš„æ”¹è¿›ã€‚\n+ **åå¥½è°ƒæ•´ç®—æ³•è®¾è®¡(Â§5.4) **ä½œè€…ä»¬è¯•éªŒäº†å‡ ç§åå¥½è°ƒæ•´ç®—æ³•ï¼Œå¹¶è§‚å¯Ÿåˆ°ä½¿ç”¨é•¿åº¦å½’ä¸€åŒ–çš„ç›´æ¥åå¥½ä¼˜åŒ–å¯ä»¥æé«˜æ€§èƒ½ã€‚ä½œè€…ä»¬åœ¨å®éªŒä¸­ä¼˜å…ˆè€ƒè™‘ç®€å•æ€§å’Œæ•ˆç‡ï¼Œå¹¶åœ¨æ•´ä¸ªå¼€å‘è¿‡ç¨‹å’Œè®­ç»ƒæœ€ç»ˆæ¨¡å‹æ—¶ä½¿ç”¨é•¿åº¦å½’ä¸€åŒ–çš„ DPOï¼Œè€Œä¸æ˜¯å¯¹åŸºäº PPO çš„æ–¹æ³•è¿›è¡Œæˆæœ¬æ›´é«˜çš„ç ”ç©¶ã€‚\n+ **å…·æœ‰å¯éªŒè¯å¥–åŠ±çš„æŠ€èƒ½ç‰¹å®šå¼ºåŒ–å­¦ä¹ (Â§6) **ä½œè€…ä»¬é‡‡ç”¨ä¸€ç§æ–°æ–¹æ³•ï¼Œåˆ©ç”¨æ ‡å‡†å¼ºåŒ–å­¦ä¹ èŒƒå¼æ¥é’ˆå¯¹å¯ä»¥æ ¹æ®çœŸå®ç»“æœï¼ˆä¾‹å¦‚æ•°å­¦ï¼‰è¿›è¡Œè¯„ä¼°çš„æŠ€èƒ½ã€‚ä½œè€…ä»¬å°†æ­¤ç®—æ³•ç§°ä¸ºå…·æœ‰å¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹  (RLVR)ï¼›å¦‚æœå®ŒæˆæˆåŠŸï¼Œå®ƒå°†è·å¾—æ’å®šçš„å¥–åŠ±å€¼ã€‚ä½œè€…ä»¬çš„ç»“æœè¡¨æ˜ï¼ŒRLVR å¯ä»¥æé«˜ GSM8Kã€MATH å’Œ IFEval æ€§èƒ½ã€‚\n+ **å¼ºåŒ–å­¦ä¹ çš„è®­ç»ƒåŸºç¡€è®¾æ–½ï¼ˆÂ§6.3ï¼‰**ä½œè€…ä»¬å®æ–½äº†å¼‚æ­¥ RL è®¾ç½®ï¼šä½œè€…ä»¬é€šè¿‡ vLLM é«˜æ•ˆè¿è¡Œ LLM æ¨ç†ï¼ŒåŒæ—¶å­¦ä¹ è€…åŒæ—¶æ‰§è¡Œæ¢¯åº¦æ›´æ–°ã€‚ä½œè€…ä»¬çš„ RL ä»£ç åº“ä¹Ÿå…·æœ‰é«˜åº¦å¯æ‰©å±•æ€§ï¼Œå¯ä»¥è®­ç»ƒ 70B RLVR ç­–ç•¥æ¨¡å‹ã€‚\n+ **è¯„ä¼°æ¡†æ¶ï¼šTÃœLU3EVALï¼ˆÂ§7ï¼‰**é™¤äº†è¯„ä¼°æœ€ç»ˆæ¨¡å‹ä¹‹å¤–ï¼Œä½œè€…ä»¬çš„è¯„ä¼°æ¡†æ¶æ˜¯ä¸€ä¸ªå¼€æºçš„è¯„ä¼°å·¥å…·åŒ…ï¼Œæ—¨åœ¨é€šè¿‡ç²¾å¿ƒæŒ‘é€‰çš„è¯„ä¼°å¥—ä»¶å’Œå‡€åŒ–å·¥å…·æ¥æŒ‡å¯¼å¼€å‘è¿›åº¦ã€‚\n\n\n\n##  Evaluation and Results \n\nåœ¨æ•´ä¸ªå·¥ä½œè¿‡ç¨‹ä¸­æŠ¥å‘Šåˆ†æ•°æ—¶ï¼Œä½œè€…ä»¬ä½¿ç”¨è¡¨ 3 ä¸­ç¡®å®šçš„æŒ‡æ ‡ï¼›åˆ†æ•°è¶Šé«˜è¶Šå¥½ã€‚åœ¨è®¡ç®—æ•´ä½“æ€§èƒ½æ—¶ï¼Œä½œè€…ä»¬åªæ˜¯å¯¹æ‰€æœ‰è¯„ä¼°å–å¹³å‡åˆ†æ•°ï¼Œå¯¹æ¯ä¸ªè¯„ä¼°ä¸€è§†åŒä»ã€‚åœ¨ä½œè€…ä»¬çš„å¼€å‘è¯„ä¼°å¥—ä»¶ä¸­ï¼Œåœ¨ Llama 3 åŸºç¡€æ¨¡å‹ä¸Šè®­ç»ƒçš„ TÃœLU3çš„è¡¨ç°ä¼˜äºå…¶å¤§å°ç±»åˆ«ä¸­çš„æ‰€æœ‰å…¶ä»–å¼€æºæƒé‡æ¨¡å‹ã€‚ä¸é—­æºæ¨¡å‹ç›¸æ¯”ï¼ŒTÃœLU370B ç”šè‡³è¶…è¶Šäº† GPT-3.5-Turbo-0125 æˆ– GPT-4o-mini-2024-07-18 ç­‰é—­æºæ¨¡å‹ï¼ŒåŒæ—¶æ¥è¿‘ Claude 3.5 Haiku 20241022 çš„æ€§èƒ½ã€‚è¡¨ 3æ˜¾ç¤ºäº†åœ¨ 80 äº¿å’Œ 700 äº¿ä¸ªå‚æ•°çš„ Llama 3 ä¸Šè®­ç»ƒçš„ TÃœLU3ä¸å®ƒä»¬å¤§å°ç±»åˆ«ä¸­çš„é¢†å…ˆæ¨¡å‹çš„æ€»ç»“ã€‚è¡¨ 4 æ˜¾ç¤ºäº† 8B ç‰ˆæœ¬æŒ‰è®­ç»ƒé˜¶æ®µçš„æ€§èƒ½ç»†åˆ†ï¼Œè¡¨ 5 æ˜¾ç¤ºäº† 70B ç‰ˆæœ¬æŒ‰è®­ç»ƒé˜¶æ®µçš„æ€§èƒ½ç»†åˆ†ã€‚\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![è¡¨ 3 TÃœLU3 EVAL suiteä¸Š 8B å’Œ 70B æ¨¡å‹çš„ç»“æœæ¦‚è§ˆã€‚æ¯ä¸ªåŸºå‡†ä¸Šæ¯ç§æ¨¡å‹å¤§å°è¡¨ç°æœ€ä½³çš„æ¨¡å‹ä»¥ç²—ä½“æ˜¾ç¤ºã€‚TÃœLU3 çš„è¡¨ç°ä¼˜äºç›¸åŒå¤§å°çš„æœ€å…ˆè¿›çš„åè®­ç»ƒå¼€æ”¾æƒé‡æ¨¡å‹ï¼Œå¹¶è¶…è¶Šäº† Claude Haikuã€GPT-3.5 Turbo å’Œ GPT-4o Miniã€‚ å°é—­æ¨¡å‹ç‰ˆæœ¬ï¼šGPT-3.5-Turbo-0125ã€GPT-4o-mini-2024-07-18ã€Claude 3.5 Haiku 20241022](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/paper/tulu3/image4.png)\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![è¡¨ 4 TÃœLU3 ç»“æœä¸åŒç±» 8B æ¨¡å‹çš„æ¯”è¾ƒæ€»ç»“ã€‚æ¯ä¸ªåŸºå‡†ä¸Šè¡¨ç°æœ€ä½³çš„æ¨¡å‹ ï¼ˆå³æ¯è¡Œï¼‰ä»¥ç²—ä½“æ˜¾ç¤ºã€‚TÃœLU3-8B çš„è¡¨ç°æ˜æ˜¾ä¼˜äºä¹‹å‰æœ€å…ˆè¿›çš„ 8B æ¨¡å‹ã€‚å„ä¸ªæ£€æŸ¥ç‚¹çš„è¿›å±•å‡¸æ˜¾äº†è®­ç»ƒçš„æ¯ä¸ªé˜¶æ®µåœ¨æé«˜æ ¸å¿ƒæŠ€èƒ½æ–¹é¢çš„è´¡çŒ®ã€‚è®¸å¤šæœ€ä½å€¼ï¼ˆä¾‹å¦‚ BigBenchHardï¼‰æ˜¯ç”±äºæœªéµå¾ªè¯„ä¼°æ‰€éœ€çš„å°‘æ ·æœ¬æ ¼å¼æˆ–å…¶ä»–é‡å¤æ€§é”™è¯¯é€ æˆçš„ - æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…Â§7ã€‚](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/paper/tulu3/image5.png)\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![è¡¨ 5 TÃœLU3 ç»“æœä¸åŒç±» 70B æ¨¡å‹çš„æ¯”è¾ƒæ€»ç»“ã€‚æ¯ä¸ªåŸºå‡†ä¸Šè¡¨ç°æœ€ä½³çš„æ¨¡å‹ ï¼ˆå³åœ¨æ¯ä¸€è¡Œï¼‰ä»¥ç²—ä½“æ˜¾ç¤ºã€‚TÃœLU3-70B çš„è¡¨ç°æ˜æ˜¾ä¼˜äºä¹‹å‰æœ€å…ˆè¿›çš„ 70B æ¨¡å‹ã€‚å„ä¸ªæ£€æŸ¥ç‚¹çš„è¿›å±•å‡¸æ˜¾äº†è®­ç»ƒçš„æ¯ä¸ªé˜¶æ®µå¯¹æé«˜æ ¸å¿ƒæŠ€èƒ½çš„è´¡çŒ®ã€‚Nemotron Llama 3.1 70B æ˜¯è¡¨ä¸­å”¯ä¸€ä¸€ä¸ªä»å¦ä¸€ä¸ªåè®­ç»ƒæ¨¡å‹ï¼ˆåœ¨æœ¬ä¾‹ä¸­ä¸º Llama 3.1 70B Instructï¼‰å¾®è°ƒçš„æ¨¡å‹ï¼Œè€Œå…¶ä»–æ¨¡å‹åˆ™æ¥è‡ªå„è‡ªçš„åŸºç¡€æ¨¡å‹ã€‚](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/paper/tulu3/image6.png)\n\n# TÃœLU3 Data\n\n Promptsä»£è¡¨ç”¨æˆ·ä¸æ¨¡å‹äº¤äº’çš„å„ç§æ–¹å¼ï¼Œæ˜¯æ‰€æœ‰åè®­ç»ƒé˜¶æ®µçš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚ä½œè€…ä»¬ç²¾å¿ƒæŒ‘é€‰äº†æ•°ç™¾ä¸‡ä¸ªPromptsä½œä¸º TÃœLU3åè®­ç»ƒRecipeçš„èµ·ç‚¹ã€‚ä»è¿™äº›Promptsä¸­é€‰æ‹©äº†ç”¨äºä¸‹ä¸€é˜¶æ®µè®­ç»ƒçš„æ•°æ®ã€‚è¡¨ 6 æ€»ç»“äº†è¿™äº›Promptsçš„å…³é”®ä¿¡æ¯ã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œä½œè€…ä»¬æè¿°äº†ä½œè€…ä»¬çš„Promptsç­–åˆ’è¿‡ç¨‹å’Œå‡€åŒ–å·¥ä½œï¼Œä»¥ç¡®ä¿ä½œè€…ä»¬çš„è¯„ä¼°ä¸ä¼šæ³„éœ²åœ¨è¿™äº›Promptsä¸­ã€‚åœ¨ä»¥ä¸‹éƒ¨åˆ†ä¸­ï¼Œä½œè€…ä»¬å°†æè¿°å¦‚ä½•ä½¿ç”¨Promptsè¿›è¡Œç›‘ç£å¾®è°ƒ Â§4 å’Œåå¥½è°ƒæ•´ Â§5ã€‚\n\n## Prompt æ‹“å±•\n\nä¸ºäº†ç„å‡†æ‰€éœ€çš„æ ¸å¿ƒæŠ€èƒ½ï¼Œä½œè€…ä»¬ä»å…·æœ‰æ˜ç¡®æ¥æºçš„å…¬å¼€æ•°æ®é›†ä¸­æŒ‘é€‰å‡ºä¸€ç»„å¤šæ ·åŒ–ã€é«˜è´¨é‡çš„Promptsï¼Œå¹¶ç»¼åˆç”ŸæˆPromptsä»¥å¡«è¡¥ä»»ä½•ç©ºç™½ã€‚\n\n### ä»å…¬å…±æ•°æ®é›†è·å–æ•°æ®\n\nè‡ªä½œè€…ä»¬å‘å¸ƒ TÃœLU2 ä»¥æ¥ï¼Œç¤¾åŒºè§è¯äº†å¤§é‡å·¥ä½œä¸ºåæœŸè®­ç»ƒåˆ›å»ºæ•°æ®é›†ï¼ŒåŒ…æ‹¬ç›‘ç£å¾®è°ƒå’Œåå¥½è°ƒæ•´ã€‚TÃœLU3æ—¨åœ¨æ•´åˆå’Œæ‰©å±•è¿™äº›èµ„æºä»¥æ„å»ºæ›´å¼ºå¤§çš„æ¨¡å‹ã€‚ä½œè€…ä»¬ä»å¯¹å…¬å…±æ•°æ®é›†çš„å¹¿æ³›è°ƒæŸ¥å¼€å§‹è¿™ä¸€è¿‡ç¨‹ï¼ŒåŒ…æ‹¬ç”±ä¸“èŒäººå‘˜æ³¨é‡Šçš„æ•°æ®é›†ã€æ¥è‡ªçœŸå®ç”¨æˆ·çš„æ•°æ®é›†ä»¥åŠä¸æ¨¡å‹åˆæˆçš„æ•°æ®é›†ã€‚ç„¶åï¼Œä½œè€…ä»¬æ‰‹åŠ¨å®¡æŸ¥æ¯ä¸ªæ•°æ®é›†ï¼Œå¹¶æ ¹æ®ä»¥ä¸‹è€ƒè™‘å› ç´ è¿›è¡Œé€‰æ‹©ã€‚\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![è¡¨ 6 tulu3 Promptæ•°æ®æ ·æœ¬æ‘˜è¦ï¼ŒÎ±æ ‡è®°ä¸ºæ±¡æŸ“ï¼Œâ†“ä¸ºåœ¨åŸå§‹æ•°æ®é›†ä¸Šè¿›è¡Œç¼©å‡é‡‡æ ·ï¼Œâ†‘ä¸ºä¸Šé‡‡æ ·ã€‚](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/paper/tulu3/image7.png)\n\n\t\n\n### é’ˆå¯¹ç›®æ ‡æŠ€èƒ½è¿›è¡Œåˆæˆ\n\nä¸ºäº†æ»¡è¶³å¯¹å¤šæ ·åŒ–å’Œç‰¹å®šæŠ€èƒ½æ•°æ®é›†æ—¥ç›Šå¢é•¿çš„éœ€æ±‚ï¼Œä½œè€…ä»¬é‡‡ç”¨äº†åˆæˆæ•°æ®ç”Ÿæˆä½œä¸ºè¡¥å……æ–¹æ³•ã€‚åˆæˆæ•°æ®ç”Ÿæˆå·²æˆä¸ºäººå·¥ç¼–å†™æ•°æ®çš„ä¸€ç§æœ‰å‰é€”çš„æ›¿ä»£æ–¹æ¡ˆï¼Œå› ä¸ºå®ƒæ›´å®¹æ˜“è·å–ã€å¯é’ˆå¯¹ä¸åŒç›®çš„è¿›è¡Œå®šåˆ¶ï¼Œå¹¶ä¸”åæ˜ äº†åº•å±‚æ¨¡å‹çš„ä¸°å¯ŒçŸ¥è¯† [Dubey et al., 2024]ã€‚ç„¶è€Œï¼Œå¤§è§„æ¨¡ç”Ÿæˆå¤šæ ·åŒ–å’Œé«˜è´¨é‡çš„æ•°æ®å¹¶éæ˜“äº‹ï¼Œå› ä¸º LM å¾ˆå®¹æ˜“é™·å…¥é‡å¤çš„æ¨¡å¼æˆ–æ¨¡å¼ï¼Œç§°ä¸ºâ€œæ¨¡å¼å´©æºƒâ€ã€‚ä¸ºäº†ç¡®ä¿ç”Ÿæˆçš„å¤šæ ·æ€§ï¼Œä½œè€…ä»¬éµå¾ª Chan ç­‰äºº [2024] ä¸­æœ€è¿‘é‡‡ç”¨çš„è§’è‰²é©±åŠ¨æ–¹æ³•æ¥ç”Ÿæˆåˆæˆæ•°æ®ã€‚å…³é”®æ€æƒ³æ˜¯ä½¿ç”¨ä¸åŒçš„è§’è‰²ï¼ˆä¾‹å¦‚ï¼Œâ€œä¸“æ³¨äºç¥ç»ç½‘ç»œçš„æœºå™¨å­¦ä¹ ç ”ç©¶äººå‘˜â€ï¼‰å’Œæ•°æ®åˆæˆPromptsï¼ˆä¾‹å¦‚ï¼Œâ€œåˆ›å»ºç¼–ç é—®é¢˜â€ï¼‰æ¥å¼•å¯¼ LLM åˆæˆå…·æœ‰ç›¸åº”è§†è§’çš„æ•°æ®ã€‚å…·ä½“æ¥è¯´ï¼Œä½œè€…ä»¬ä»¥ Persona Hub [Chan et al., 2024] ä¸­çš„ âˆ¼250K ä¸ªè§’è‰²ä¸ºæ¡ä»¶ï¼Œç”Ÿæˆé’ˆå¯¹ç‰¹å®šæŠ€èƒ½ï¼ˆä¾‹å¦‚ç²¾ç¡®éµå¾ªæŒ‡ä»¤ã€æ•°å­¦å’Œç¼–ç ï¼‰çš„Promptsã€‚\n\n\n\n+ **ç²¾ç¡®çš„æŒ‡ä»¤éµå¾ªï¼Œ**ç²¾ç¡®çš„æŒ‡ä»¤éµå¾ªæ˜¯æŒ‡éµå¾ªè‡ªç„¶è¯­è¨€ä¸­å¯éªŒè¯çš„æŒ‡ä»¤ï¼ˆä¾‹å¦‚â€œå†™ 3 æ®µè¯â€ï¼‰çš„èƒ½åŠ›ï¼Œè¿™äº›æŒ‡ä»¤å¯ä»¥é€šè¿‡å¯å‘å¼æ–¹æ³•è‡ªåŠ¨éªŒè¯ã€‚ä½œè€…ä»¬ä½¿ç”¨è§’è‰²é©±åŠ¨çš„æ–¹æ³•ç»¼åˆç”Ÿæˆå¯éªŒè¯æŒ‡ä»¤ï¼Œæ¶µç›– IFEval åŸºå‡†ä¸­å®šä¹‰çš„ 25 ç§ä¸åŒçº¦æŸç±»å‹ã€‚æ›´å…·ä½“åœ°è¯´ï¼Œä½œè€…ä»¬é¦–å…ˆä¸ºæ¯ä¸ªçº¦æŸæ‰‹åŠ¨ç¼–å†™ 1-2 ä¸ªç¤ºä¾‹æŒ‡ä»¤ï¼ˆç”¨ä½œseedPromptsã€‚ç„¶åï¼Œä½œè€…ä»¬ä½¿ç”¨ä¾‹å¦‚å•è¯æ•°æ¥ç”Ÿæˆæ–°æŒ‡ä»¤ï¼‰ï¼Œä»è€Œå¾—åˆ°æ€»å…±33 æ¡å¯éªŒè¯æŒ‡ä»¤ï¼Œä½œè€…ä»¬ç»™å‡ºäº†æ•°æ®åˆæˆPromptsã€è§’è‰²å’Œå•ä¸ªå¯éªŒè¯æŒ‡ä»¤ä½œä¸ºç¤ºä¾‹ã€‚\n+ **æ•°å­¦å’Œç¼–ç ï¼Œ**ä½œè€…ä»¬é‡‡ç”¨ç±»ä¼¼çš„è§’è‰²é©±åŠ¨æ–¹æ³•æ¥ç»¼åˆç”Ÿæˆå„ç§æ•°å­¦å•è¯å’Œç¼–ç é—®é¢˜ã€‚æ•°å­¦é—®é¢˜åŒ…æ‹¬éœ€è¦é«˜ç­‰æ•°å­¦æŠ€èƒ½çš„é—®é¢˜ä»¥åŠå°å­¦é—®é¢˜ã€‚å¯¹äºç¼–ç ï¼Œä½œè€…ä»¬ç”Ÿæˆå…¥é—¨åˆ°ä¸­çº§ç¨‹åºå‘˜éƒ½å¯ä»¥è§£å†³çš„ Python ç¼–ç¨‹é—®é¢˜ã€‚ä¸ç²¾ç¡®çš„æŒ‡ä»¤éµå¾ªä¸åŒï¼Œä½œè€…ä»¬é›¶æ ·æœ¬Prompts GPT-4o ç”Ÿæˆç‰¹å®šäºç»™å®šè§’è‰²è¾“å…¥çš„ç‹¬ç‰¹é—®é¢˜ã€‚ç”Ÿæˆé—®é¢˜åï¼Œä½œè€…ä»¬ç”Ÿæˆå¤šæ­¥éª¤ä½¿ç”¨ GPT-4o ç¼–å†™æ•°å­¦è§£å†³æ–¹æ¡ˆï¼Œä½¿ç”¨ claude-3-5-sonnet ç¼–å†™ Python ç¨‹åºã€‚\n+ **ä¸åˆè§„å’Œå®‰å…¨**ï¼Œéšç€ä½œè€…ä»¬å¢å¼ºæ¨¡å‹æœ‰æ•ˆååŠ©ç”¨æˆ·çš„èƒ½åŠ›ï¼Œç¡®ä¿å®ƒä»¬èƒ½å¤Ÿå¯é åœ°æ‹’ç»ä¸å®‰å…¨æŸ¥è¯¢å¹¶é€‚å½“å¤„ç†ç»†å¾®å’Œè¶…å‡ºèŒƒå›´çš„æŸ¥è¯¢è‡³å…³é‡è¦ã€‚\n\n\n\n## Prompt  æ¸…æ´—\n\nåœ¨æ‹“å±•ä½œè€…ä»¬çš„è®­ç»ƒç»„åˆæ—¶ï¼Œä¸€ä¸ªé‡è¦çš„è€ƒè™‘å› ç´ æ˜¯è®­ç»ƒé›†å’Œè¯„ä¼°é›†ä¹‹é—´å¯èƒ½å­˜åœ¨é‡å ã€‚ä½œè€…ä»¬æŒ‰å¦‚ä¸‹æ–¹å¼é‡åŒ–è¿™ç§é‡å ï¼Œå¹¶æ ¹æ®éœ€è¦ä»ä½œè€…ä»¬çš„è®­ç»ƒç»„åˆä¸­åˆ é™¤å®ä¾‹ï¼Œä»¥é˜²æ­¢æµ‹è¯•é›†æ±¡æŸ“ã€‚\n\n\n\n+ **åŒ¹é…æ–¹æ³•ã€‚**ä½œè€…ä»¬å°è¯•äº†å…¨å­—ç¬¦ä¸²ã€n-gram å’ŒåŸºäºåµŒå…¥çš„åŒ¹é…ï¼Œå‘ç° n-gram åŒ¹é…äº§ç”Ÿäº†æœ€æœ‰ç”¨çš„ç»“æœâ€”â€”è™½ç„¶åŸºäºåµŒå…¥çš„æ–¹æ³•åŸåˆ™ä¸Šå¯ä»¥è¯†åˆ«ç”±äºé‡Šä¹‰è€Œäº§ç”Ÿçš„éå¹³å‡¡æ±¡æŸ“ [Yang et al., 2023]ï¼Œä½†ä½œè€…ä»¬å‘ç°å¾ˆéš¾åŒºåˆ†å•çº¯çš„åˆ†å¸ƒç›¸ä¼¼æ€§å’Œå®é™…çš„é‡Šä¹‰ã€‚æ­¤å¤–ï¼Œä½¿ç”¨ n-gram åŒ¹é…çš„éƒ¨åˆ†è¡¨é¢é‡å æˆåŠŸåœ°è¯†åˆ«äº†æ±¡æŸ“çš„æƒ…å†µï¼Œå…¶ä¸­å®ä¾‹ç•¥æœ‰ä¸åŒï¼Œä¾‹å¦‚æ•°å­¦é—®é¢˜ä»…æ•°å­—ä¸åŒã€‚\n+ **è¯†åˆ«åŒ¹é…å®ä¾‹ã€‚**ç”±äºè®­ç»ƒæ•°æ®é›†ä¸­çš„è¡¥å…¨é€šå¸¸ä½¿ç”¨è¯­è¨€æ¨¡å‹é‡æ–°ç”Ÿæˆï¼Œå› æ­¤ä½œè€…ä»¬é€‰æ‹©ä»…è®¡ç®—Promptsä¸­çš„é‡å ï¼ˆæˆ–æ›´ä¸€èˆ¬åœ°è®¡ç®—å¤šè½®å¯¹è¯ä¸­çš„ç”¨æˆ·è½®æ¬¡ï¼‰ã€‚\n+ **å»æ±¡ã€‚** å¦‚æœè®­ç»ƒé›†ä¸­çš„ä»»ä½•å®ä¾‹æ•°é‡ä¸ä½œè€…ä»¬å¼€å‘å’Œæœªè§å¥—ä»¶ä¸­çš„ä»»ä½•è¯„ä¼°ä¸­è¶…è¿‡ 2% çš„å®ä¾‹é‡å ï¼Œåˆ™ä½œè€…ä»¬è®¤ä¸ºè¯¥è®­ç»ƒé›†å—åˆ°æ±¡æŸ“ã€‚ä½œè€…ä»¬ä¼šåˆ é™¤æ‰€æœ‰å—åˆ°æœªè§è¯„ä¼°æ±¡æŸ“çš„è®­ç»ƒé›†ã€‚å¯¹äºå—åˆ°å¼€å‘è¯„ä¼°æ±¡æŸ“çš„è®­ç»ƒé›†ï¼Œå¦‚æœè¿™æ ·åšä¸ä¼šæ˜¾è‘—å½±å“æœ€ç»ˆæ¨¡å‹çš„æ€§èƒ½ï¼Œä½œè€…ä»¬ä¼šåˆ é™¤æ•´ä¸ªæ•°æ®é›†ï¼›å¦åˆ™ï¼Œä½œè€…ä»¬ä¼šåˆ é™¤ä¸ä»»ä½•æµ‹è¯•å®ä¾‹åŒ¹é…çš„ç‰¹å®šå®ä¾‹ã€‚\n\n\n\n# SFT\n\nå°†é¢„è®­ç»ƒçš„åŸºç¡€æ¨¡å‹è°ƒæ•´ä¸ºå„ç§ä»»åŠ¡å’Œç”¨æˆ·è¯·æ±‚é€šå¸¸ä¾èµ–äºç›‘ç£å¾®è°ƒ (SFT)ï¼Œä¹Ÿç§°ä¸ºæŒ‡ä»¤å¾®è°ƒã€‚æ­¤è¿‡ç¨‹ä¸­çš„ä¸€ä¸ªå…³é”®æŒ‘æˆ˜æ˜¯å¹³è¡¡ä»£è¡¨ä¸åŒæŠ€èƒ½çš„æ··åˆè®­ç»ƒæ•°æ®é›†çš„æ¯”ä¾‹ã€‚å¯¹äº TÃœLU3ï¼Œä½œè€…ä»¬è¿›è¡Œäº†æ•°æ®æ··åˆæ¶ˆèå¹¶æ¢ç´¢äº†æ¨¡å‹åˆå¹¶æ•°æ®æœ€åˆç”¨äºæ„å»º Vicuna æ¨¡å‹ï¼Œä½†ç¡®åˆ‡çš„æ•°æ®é›†å°šæœªå‘å¸ƒã€‚\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![å›¾ 2ï¼šTÃœLU3æœ€ç»ˆ SFT æ··åˆäº†Promptsçš„æ¥æºå’Œé•¿åº¦ä»¥åŠæ ‡è®°çš„å®Œæˆæƒ…å†µï¼ˆä½¿ç”¨ Llama 3 æ ‡è®°å™¨ï¼‰ã€‚å°†æ­¤åˆ†å¸ƒä¸å›¾ 24 ä¸­ä¹‹å‰å¼€æºçš„ SFT è®­ç»ƒæ•°æ®é›†è¿›è¡Œæ¯”è¾ƒã€‚å®ä¾‹æœ€å¤šçš„æ•°æ®é›†ä½äºç›´æ–¹å›¾çš„åº•éƒ¨ã€‚](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/paper/tulu3/image8.png)\n\n## SFT æ•°æ®\n\n### ä»Promptsåˆ° SFT æ•°æ®\n\nä¸ºäº†åˆ›å»ºä½œè€…ä»¬çš„ SFT ç»„åˆï¼Œä½œè€…ä»¬é€šè¿‡ä¸¤ç§æ–¹å¼æ”¶é›†æˆ–åˆ›å»ºç¬¬ 3 èŠ‚ä¸­æè¿°çš„Promptsçš„å›ç­”ï¼šè¿‡æ»¤ç°æœ‰å›ç­”å’Œåˆ›å»ºæ–°å›ç­”ã€‚\n\nå¯¹äºæœ‰ç°æœ‰å›ç­”çš„Promptsï¼Œå¦‚æœåŸå§‹å›ç­”æ˜¯ç”±äººç±»æˆ–å‰æ²¿æ¨¡å‹ï¼ˆå¦‚ GPT-4oï¼‰ç¼–å†™çš„ï¼Œä½œè€…ä»¬é€šå¸¸ä¼šä¿ç•™åŸå§‹å›ç­”ã€‚å¯¹äºåŒ…å«æ¥è‡ªå‰æ²¿æ¨¡å‹å­é›†çš„å¤§å‹æ•°æ®é›†ï¼ˆä¾‹å¦‚ WildChatï¼‰ï¼Œä½œè€…ä»¬ä½¿ç”¨æ¥è‡ªæœ€ä½³æ¨¡å‹çš„å­é›†ã€‚ä½œè€…ä»¬è¿˜ä¼šè¿‡æ»¤ç©ºå›ç­”å’ŒåŒ…å«æœ‰å…³æ¨¡å‹æˆ–å…¶å¼€å‘äººå‘˜çš„ä¿¡æ¯çš„å›ç­”ã€‚å¦‚æœä¸€ç»„Promptsæ²¡æœ‰å›ç­”ï¼ˆä¾‹å¦‚ä½œè€…ä»¬çš„ Persona Promptsï¼‰ï¼Œæˆ–è€…åŸå§‹å›ç­”æ¥è‡ªè¾ƒå¼±çš„æ¨¡å‹ï¼ˆä¾‹å¦‚ WildGuardMixï¼‰ï¼Œä½œè€…ä»¬ä¼šä½¿ç”¨ GPT-4o ç”Ÿæˆæ–°å›ç­”ã€‚ä½œè€…ä»¬è¿˜æ‰‹å†™äº†å¯¹ç¡¬ç¼–ç Promptsçš„å›ç­”ã€‚\n\n### TÃœLU3 SFT Mix\n\nä¸ºäº†å¼€å‘ä½œè€…ä»¬çš„ SFT ç»„åˆï¼Œä½œè€…ä»¬é¦–å…ˆä½¿ç”¨åœ¨ TÃœLU2 ä¸Šè®­ç»ƒçš„ Llama3.1 ä½œä¸ºåŸºçº¿ï¼Œç¡®å®šäº†è½åäºæœ€å…ˆè¿›æ¨¡å‹çš„æŠ€èƒ½ã€‚é’ˆå¯¹æ¯ä¸€é¡¹æŠ€èƒ½ï¼Œä½œè€…ä»¬æ”¶é›†äº†é«˜è´¨é‡çš„å…¬å¼€æ•°æ®é›†å¹¶åˆ›å»ºäº†åˆæˆæ•°æ®é›†ï¼ˆå¦‚ç¬¬ 3.1.2 èŠ‚æ‰€è¿°ï¼‰ï¼ŒåŒæ—¶åˆ é™¤äº†ä¸€äº›ä½œè€…ä»¬çš„å‘ç°ä¸å…¶ä»–è¾ƒæ–°çš„æ•°æ®é›†ç›¸æ¯”ï¼Œå…¶è´¨é‡ç›¸å¯¹è¾ƒä½çš„æ•°æ®é›†ã€‚\n\nä¸ºäº†è®¾è®¡æœ€ç»ˆçš„ SFT ç»„åˆï¼Œä½œè€…ä»¬é¦–å…ˆæ„å»ºäº†ç‰¹å®šæŠ€èƒ½çš„æ•°æ®ç»„åˆå’Œæ¨¡å‹ï¼Œä¿ç•™äº†åœ¨å•ä¸ªæŠ€èƒ½ä¸Šè¡¨ç°æœ€ä½³çš„æ··åˆæ•°æ®ï¼Œå¿½ç•¥äº†å…¶ä»–è¯„ä¼°ã€‚è¿™æ ·åšæ˜¯ä¸ºäº†æ ¹æ®ä½œè€…ä»¬çš„è®¾ç½®ä¼°ç®—å‡ºæ¯ä¸ªè¯„ä¼°çš„ä¸Šé™ã€‚\n\nç„¶åï¼Œä½œè€…ä»¬å°†è¿™äº›mixturesç»„åˆèµ·æ¥ï¼Œåˆ›å»ºäº†ä½œè€…ä»¬çš„åˆå§‹ TÃœLU3é¢„è§ˆç»„åˆã€‚ç„¶åï¼Œä½œè€…ä»¬ç»§ç»­é€šè¿‡æ·»åŠ æˆ–åˆ é™¤æ•°æ®é›†æ¥è¿­ä»£mixturesï¼Œä»¥æé«˜æ»åæŠ€èƒ½ï¼Œå¹¶æ ¹æ®ä½œè€…ä»¬çš„è¯„ä¼°è¿›è¡Œå‡€åŒ–æ··åˆï¼Œä»¥åŠä½œè€…ä»¬çš„ä¸­é—´å’Œæœ€ç»ˆ TÃœLU3SFT æ··åˆã€‚\n\n\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![å›¾ 3ï¼š ä¸­é—´æ··åˆ 1ã€2 å’Œ 3 æ˜¯æ·»åŠ æ–°æ•°æ®é›†ä»¥æé«˜æ€§èƒ½çš„ç»“æœã€‚ä¸­é—´æ··åˆ 4 å’Œ 5 æ˜¯è¿è¡Œå¤šè½®å‡€åŒ–çš„ç»“æœï¼Œå¯¼è‡´æ€§èƒ½ç•¥æœ‰ä¸‹é™ã€‚](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/paper/tulu3/image9.png)\n\n\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![è¡¨ 7 TÃœLU3SFT æ¨¡å‹ä¸å¯æ¯”åŸºçº¿çš„æ€§èƒ½æ€»ç»“ã€‚ä½œè€…ä»¬æœ€ç»ˆçš„ SFT mixturesè¡¨ç°å‡ºè‰²ï¼Œå¹³å‡å¾—åˆ†é«˜äºå…¶ä»–å¯æ¯”mixturesã€‚æ‰€æœ‰æ¨¡å‹ï¼ˆåŒ…æ‹¬ TÃœLU2 SFTï¼‰å‡åœ¨ Llama 3.0 æˆ– 3.1 ä¸Šè¿›è¡Œè®­ç»ƒã€‚ä½œè€…ä»¬æœ€ç»ˆçš„ TÃ¼lu 3 70B æ¨¡å‹ç”¨äºå¸®åŠ©æ ¼å¼åŒ–æ­¤è¡¨ã€‚](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/paper/tulu3/image10.png)\n\n## å…³é”®æ•°æ®å®éªŒ\n\nåœ¨å¼€å‘æœ€ç»ˆçš„ SFT mixturesä¹‹åï¼Œä½œè€…ä»¬è¿˜è¿›è¡Œäº†ä¸€ç³»åˆ—æ§åˆ¶å®éªŒï¼Œä»¥æ¢ç´¢åœ¨æ•°æ®æ··åˆå’Œè®­ç»ƒæœŸé—´åšå‡ºçš„ä¸åŒå†³ç­–çš„é‡è¦æ€§ã€‚\n\n\n\n+ **å¤šæ ·åŒ–çš„èŠå¤©æ•°æ®ã€‚**åœ¨ä½œè€…ä»¬çš„ç»„åˆä¸­ï¼Œä½œè€…ä»¬è¿˜å¼ºè°ƒæ·»åŠ å¤šæ ·åŒ–çš„èŠå¤©æ•°æ®ï¼Œä¸»è¦æ¥è‡ª WildChatã€‚ä½œè€…ä»¬åœ¨è¡¨9ä¸­å±•ç¤ºäº†åˆ é™¤ WildChat çš„å½±å“ï¼Œä½œè€…ä»¬å‘ç°å¤§å¤šæ•°æŠ€èƒ½éƒ½å‡ºç°äº†è½»å¾®ä½†æ˜æ˜¾çš„é€€åŒ–ï¼Œæœ€æ˜æ˜¾çš„æ˜¯ Alpaca Evalï¼Œè¿™å‡¸æ˜¾äº†å¤šæ ·åŒ–ç°å®ä¸–ç•Œæ•°æ®çš„é‡è¦æ€§ã€‚\n+ **å®‰å…¨æ€§æ˜¯æ­£äº¤çš„**ã€‚ä½œè€…ä»¬å‘ç°ï¼Œä½œè€…ä»¬çš„å®‰å…¨æ€§ SFT æ•°æ®é€šå¸¸ä¸ä½œè€…ä»¬çš„å…¶ä»–æ•°æ®é›†æ­£äº¤ã€‚ä½œè€…ä»¬åœ¨è¡¨9ä¸­æŠ¥å‘Šäº†åˆ é™¤ç‰¹å®šäºå®‰å…¨æ€§çš„æ•°æ®é›†çš„æ•ˆæœï¼Œå¹¶ä¸”ä½œè€…ä»¬çœ‹åˆ°ï¼Œé™¤äº†å®‰å…¨æ€§å¹³å‡å€¼ä¹‹å¤–ï¼Œå¤§å¤šæ•°æŠ€èƒ½å¤§è‡´ä¿æŒä¸å˜ã€‚ä½œè€…ä»¬è¿˜å‘ç°ï¼Œæ·»åŠ è¯¸å¦‚ CoCoNot ä¸­çš„é‚£äº›æ„é€ æ€§Promptsæœ‰åŠ©äºé˜²æ­¢ä½œè€…ä»¬çš„æ¨¡å‹è¿‡åº¦æ‹’ç»å®‰å…¨Promptsã€‚\n+ **æ–°äººç‰©è§’è‰²æ•°æ®ã€‚**ä½œè€…ä»¬æ–°çš„äººç‰©è§’è‰²æ•°æ®é›†æ˜¯é’ˆå¯¹ç‰¹å®šæŠ€èƒ½è€Œæ„å»ºçš„ï¼šæ•°å­¦ã€ç¼–ç å’Œéµå¾ªæŒ‡ä»¤ã€‚åœ¨è¡¨9ä¸­ï¼Œä½œè€…ä»¬æ˜¾ç¤ºåˆ é™¤äººç‰©è§’è‰²æ•°æ®é›†åï¼ŒHumanEval(+)ã€GSM8Kã€MATH å’Œ IFEval ä¸Šçš„æ€§èƒ½ä¸‹é™ï¼Œæ˜¾ç¤ºäº†åˆ›å»ºå¤šæ ·åŒ–ã€ç‰¹å®šæŠ€èƒ½çš„ SFT æ•°æ®é›†çš„ä»·å€¼ã€‚é’ˆå¯¹ç‰¹å®šæŠ€èƒ½ã€‚ä½œè€…ä»¬è¿˜åœ¨è¡¨9 ä¸­å±•ç¤ºäº†é’ˆå¯¹ç‰¹å®šæŠ€èƒ½çš„å½±å“ï¼Œå…¶ä¸­ä½œè€…ä»¬å±•ç¤ºäº†åˆ é™¤æ‰€æœ‰ç‰¹å®šæ•°å­¦æ•°æ®çš„æ•ˆæœã€‚ä¸ä½œè€…ä»¬çš„æœ€ç»ˆç»„åˆç›¸æ¯”ï¼ŒGSM8K å’Œ MATH éƒ½æ˜¾ç€ä¸‹é™ï¼Œå¼ºè°ƒäº†åœ¨æ•°æ®æ”¶é›†æœŸé—´å…³æ³¨ç‰¹å®šæŠ€èƒ½çš„ç§¯æå½±å“ã€‚\n+ **é’ˆå¯¹ç‰¹å®šæŠ€èƒ½ã€‚**ä½œè€…ä»¬å¾ˆå¤§ä¸€éƒ¨åˆ†ç²¾åŠ›éƒ½é›†ä¸­åœ¨æ”¶é›†æˆ–åˆ›å»ºé’ˆå¯¹ç‰¹å®šèƒ½åŠ›çš„æ•°æ®é›†ä¸Šã€‚ä»¥æ•°å­¦æ¨ç†ä¸ºä¾‹ï¼Œä½œè€…ä»¬åœ¨è¡¨8ä¸­å±•ç¤ºäº†æ•°å­¦ç‰¹å®šæ•°æ®å¯¹ GSM8K å’Œ MATH çš„å½±å“ã€‚ä½œè€…ä»¬å‘ç°æ•°å­¦ç‰¹å®šçš„ SFT æ•°æ®æ˜¾è‘—æé«˜äº† GSM8K å’Œ MATHï¼Œæ˜¾ç¤ºäº†æœ€ç»ˆç»„åˆä¸­åŒ…å«çš„æ•°æ®çš„ä»·å€¼ã€‚\n+ **SFT æ•°æ®é‡ã€‚**åœ¨å›¾ 4 ä¸­ï¼Œä½œè€…ä»¬å±•ç¤ºäº†å¯¹ SFT ç»„åˆè¿›è¡Œåˆ†å±‚å­æŠ½æ ·çš„æ•ˆæœã€‚ä½œè€…ä»¬å‘ç°ï¼Œéšç€æ›´å¤š SFT æ•°æ®è¢«çº³å…¥ï¼Œä½œè€…ä»¬çš„æ¨¡å‹å¹³å‡æ°´å¹³ç»§ç»­æé«˜ï¼Œå¹¶ä¸”éšç€ä½œè€…ä»¬å°†æ•°æ®é‡å¢åŠ åˆ°å®Œæ•´ç»„åˆï¼Œä½œè€…ä»¬çœ‹åˆ° GSM8K ç­‰æŒ‡æ ‡çš„å·¨å¤§æ”¹è¿›ã€‚æœ‰è¶£çš„æ˜¯ï¼Œéšç€ç»„åˆä¸­çš„æ•°æ®é‡å¢åŠ ï¼ŒTruthfulQA æ€§èƒ½å®é™…ä¸Šä¼šä¸‹é™ã€‚ä½œè€…ä»¬ä¸ä¼šå°† SFT æ•°æ®å¤§å°å¢åŠ åˆ°å½“å‰ç»„åˆä¹‹å¤–ï¼Œå› ä¸ºä½œè€…ä»¬åˆ†é…äº†å…¶ä»–Promptsä»¥è¿›è¡Œåå¥½ä¼˜åŒ–ã€‚\n\n\n\n\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![è¡¨ 9 SFT æ¶ˆèæœŸé—´çš„æ€§èƒ½ï¼Œæ˜¾ç¤ºäº†å•ç‹¬åˆ é™¤å®‰å…¨ã€WildChatã€Persona å’Œæ•°å­¦æ•°æ®çš„æ•ˆæœã€‚ä½œè€…ä»¬å‘ç°ï¼š1) å¤šæ ·åŒ–çš„èŠå¤©æ•°æ®å¯¹å¤§å¤šæ•°æŠ€èƒ½éƒ½æœ‰å¥½å¤„ï¼Œæœ€æ˜æ˜¾çš„æ˜¯ Alpaca Evalï¼Œ2) å®‰å…¨æ€§èƒ½é€šå¸¸ä¸ä¸€èˆ¬æ€§èƒ½æ­£äº¤ï¼Œ3) ä½œè€…ä»¬çš„æ–° Persona æ•°æ®é›†æ”¹è¿›äº†å®ƒä»¬é’ˆå¯¹çš„æ‰€æœ‰æŠ€èƒ½ï¼Œ4) ä½¿ç”¨æ•°å­¦ä½œä¸ºæµ‹è¯•ç”¨ä¾‹ï¼Œæ·»åŠ é«˜è´¨é‡çš„æŠ€èƒ½ç‰¹å®šæ•°æ®å¯æ˜¾ç€æé«˜æŠ€èƒ½ç‰¹å®šæ€§èƒ½ã€‚](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/paper/tulu3/image11.png)\n\n\n\n## SFT  Recipe and Analyses\n\n**è®­ç»ƒè®¾ç½® **ä¸ºäº†è®­ç»ƒä½œè€…ä»¬çš„ TÃœLU 3 æ¨¡å‹ï¼Œä½œè€…ä»¬ä½¿ç”¨äº† 4 åˆ° 16 ä¸ª 8xH100 èŠ‚ç‚¹ï¼Œå¹¶è¿›è¡Œäº†é«˜é€Ÿäº’è¿ã€‚ä½œè€…ä»¬ä½¿ç”¨äº† 128 çš„batch size  å’Œ 4,096 ä¸ª token çš„æœ€å¤§åºåˆ—é•¿åº¦ã€‚ä½œè€…ä»¬è®­ç»ƒäº†ä¸¤ä¸ªæ—¶æœŸï¼Œå¯¹äº 8B æ¨¡å‹ï¼Œä½œè€…ä»¬ä½¿ç”¨ 5e-6 çš„å­¦ä¹ ç‡ï¼Œå¯¹äº 70B æ¨¡å‹ï¼Œä½œè€…ä»¬ä½¿ç”¨ 2e-6 çš„å­¦ä¹ ç‡ï¼Œè¿™æ˜¯ä½œè€…ä»¬åœ¨è¶…å‚æ•°æœç´¢åå‘ç°çš„ã€‚ä½œè€…ä»¬çš„è¶…å‚æ•°è®¾ç½®ä¹Ÿæ€»ç»“åœ¨è¡¨ 10 ä¸­ã€‚\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![è¡¨ 10 è¶…å‚æ•°è®¾ç½®](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/paper/tulu3/image12.png)\n\n\n\n### å…³é”®è®­ç»ƒå®éªŒ\n\n**åŸºç¡€æ¨¡å‹çš„é€‰æ‹©ã€‚**ä½œè€…ä»¬è¿˜ä½¿ç”¨å®Œæ•´çš„ SFT ç»„åˆæµ‹è¯•äº†è®­ç»ƒä¸åŒçš„åŸºç¡€é¢„è®­ç»ƒæ¨¡å‹å¯¹æ•°å­¦æ€§èƒ½çš„å½±å“ã€‚åœ¨è¡¨ 11 ä¸­ï¼Œä½œè€…ä»¬å±•ç¤ºäº†é€šè¿‡åœ¨ Llama 3.1 8B å’Œ 70B ä¸Šè¿›è¡Œè®­ç»ƒæ¥æ”¹å˜æ¨¡å‹å¤§å°çš„å½±å“ï¼Œä»¥åŠé€šè¿‡åœ¨ Qwen 2.5 7Bå’Œ Qwen 2.5 Math 7B ä¸Šè¿›è¡Œè®­ç»ƒæ¥æ·»åŠ ç‰¹å®šé¢†åŸŸçš„é¢„è®­ç»ƒæ•°æ®çš„å½±å“ã€‚åœ¨è¿™ä¸¤ç§æƒ…å†µä¸‹ï¼Œä½œè€…ä»¬éƒ½çœ‹åˆ° GSM8K å’Œ MATH éƒ½æœ‰äº†æ˜¾è‘—çš„æå‡ï¼Œå‡¸æ˜¾äº†æ¨¡å‹å¤§å°å’Œé¢„è®­ç»ƒæ•°æ®å¯¹äºä¸‹æ¸¸æŠ€èƒ½çš„é‡è¦æ€§ã€‚\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![è¡¨ 11 åœ¨ä½œè€…ä»¬çš„æ··åˆæ¨¡å‹ä¸Šè®­ç»ƒçš„ä¸åŒåŸºç¡€æ¨¡å‹çš„æ•°å­¦æ€§èƒ½ã€‚ä½œè€…ä»¬å‘ç° 1) åœ¨æ›´å¤§çš„æ¨¡å‹ä¸Šè®­ç»ƒå¯ä»¥è·å¾—æ›´å¥½çš„æ€§èƒ½ï¼Œ2) å³ä½¿å¯¹äºç›¸åŒå¤§å°çš„æ¨¡å‹ï¼Œæ·»åŠ ç‰¹å®šäºæŠ€èƒ½çš„é¢„è®­ç»ƒæ•°æ®ä¹Ÿå¯ä»¥æé«˜æ€§èƒ½ã€‚](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/paper/tulu3/image13.png)\n\n**èŠå¤©æ¨¡æ¿å˜åŒ–ã€‚**åœ¨åˆ›å»º TÃœLU3 æœŸé—´ï¼Œä½œè€…ä»¬æ¢ç´¢äº†æ›´æ”¹ç”¨äºæŒ‡å¯¼ç”Ÿæˆå¾®è°ƒæ¨¡å‹çš„èŠå¤©æ¨¡æ¿ã€‚ä½œè€…ä»¬å¯¹ä»¥å‰ TÃœLUç‰ˆæœ¬ä¸­ä½¿ç”¨çš„èŠå¤©æ¨¡æ¿åšäº†ä¸€äº›å°æ”¹åŠ¨ï¼Œå…·ä½“æ¥è¯´æ˜¯åˆ é™¤äº†æ¨¡æ¿æœ«å°¾çš„æ–°è¡Œï¼ˆåœ¨æ¨¡å‹å›ç­”ä¹‹å‰ï¼‰ã€‚è¡¨ 12 æ˜¾ç¤ºäº†ä½œè€…ä»¬ SFT è®¾ç½®çš„æ—©æœŸç‰ˆæœ¬ä¸­å¯¹èŠå¤©æ¨¡æ¿çš„ä¸åŒæ›´æ”¹ä¹‹é—´çš„æ€§èƒ½ã€‚ä½œè€…ä»¬å‘ç°ç”¨ eos tokenæ›¿æ¢åŠ©æ‰‹æ¶ˆæ¯æœ«å°¾çš„æ¢è¡Œç¬¦å¯ä»¥è·å¾—æœ€ä½³æ€§èƒ½ï¼Œä½†ä½œè€…ä»¬é€‰æ‹©ä¸ä½¿ç”¨å®ƒï¼Œä»¥é¿å…ä¸åè®­ç»ƒçš„pipelineä¸­çš„åç»­æ­¥éª¤ç”Ÿæˆä¸ä¸€è‡´ã€‚\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![è¡¨ 12  ä¸åŒèŠå¤©æ¨¡æ¿å¯¹ SFT æ¨¡å‹æ€§èƒ½çš„å½±å“ï¼Œä½¿ç”¨ Llama 3.0 ä¸Šçš„ä¸­é—´ SFT æ··åˆè¿›è¡Œè®­ç»ƒã€‚è™½ç„¶æ›¿æ¢æ¢è¡Œç¬¦æ•ˆæœæœ€å¥½ï¼Œä½†ä½œè€…ä»¬é€‰æ‹©ç®€å•åœ°åˆ é™¤æ¢è¡Œç¬¦ä»¥é¿å…å¤æ‚æ€§ã€‚](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/paper/tulu3/image14.png)\n\n**éšæœºseedå’Œæ¨¡å‹soupsã€‚**ä½œè€…ä»¬è¿˜æ¢ç´¢äº†åœ¨ SFT æœŸé—´æ›´æ”¹éšæœºseedï¼Œç„¶åä½¿ç”¨è¿™äº›æ¨¡å‹åˆ›å»ºæ¨¡å‹soupsã€‚åœ¨è¡¨ 13 ä¸­ï¼Œä½œè€…ä»¬å°†ä½¿ç”¨å¤šä¸ªä¸åŒseedè®­ç»ƒçš„ 8B å’Œ 70B æ¨¡å‹ä¸æœ€ä½³æ¨¡å‹soupsè¿›è¡Œäº†æ¯”è¾ƒã€‚ä½œè€…ä»¬å‘ç° SFT æ€§èƒ½å› seedçš„ä¸åŒè€Œæ˜æ˜¾ä¸åŒï¼Œè¿™å‡¸æ˜¾äº†å¤šæ¬¡è®­ç»ƒè¿è¡Œçš„é‡è¦æ€§ï¼Œå¹¶ä¸”æœ€ä½³æ¨¡å‹soupså¹¶ä¸æ€»æ˜¯ä¼˜äºæœ€ä½³å•æ¬¡è®­ç»ƒè¿è¡Œã€‚å› æ­¤ï¼Œä½œè€…ä»¬å°†æ¯ç§æ¨¡å‹å¤§å°ï¼ˆ8Bå’Œ70Bï¼‰çš„æœ€ä½³å•æ¬¡ SFT è®­ç»ƒè¿è¡Œç”¨ä½œæœ€ç»ˆçš„ SFT æ¨¡å‹ã€‚\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![è¡¨13 ä½¿ç”¨éšæœºseedçš„ 8B å’Œ 70B SFT æ¨¡å‹çš„å¹³å‡æ€§èƒ½ï¼Œå¹¶ä¸ä½¿ç”¨ä¸åŒseedè®­ç»ƒçš„æ¨¡å‹çš„æœ€ä½³æ¨¡å‹soupsè¿›è¡Œäº†æ¯”è¾ƒã€‚ä½œè€…ä»¬å‘ç°æœ€ä½³éšæœºseedä¸æœ€ä½³æ¨¡å‹soupsç›¸å½“ï¼Œå› æ­¤ä¸ºäº†ä¿æŒä¸€è‡´æ€§ï¼Œä½œè€…ä»¬ä½¿ç”¨æœ€ä½³å•æ¬¡ SFT è¿è¡Œä½œä¸ºæœ€ç»ˆçš„ SFT æ¨¡å‹ã€‚](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/paper/tulu3/image15.png)\n\n### æ‰¹é‡èšåˆ\n\nåœ¨è®­ç»ƒ Tframework å’Œåœ¨å…¶ä»–è®¾ç½®ï¼ˆä¾‹å¦‚ TPUï¼‰ä¸Šè®­ç»ƒçš„æ¨¡å‹çš„æ—©æœŸé˜¶æ®µã€‚TÃœLU 3 ä¸­ï¼Œä½œè€…ä»¬æ³¨æ„åˆ°åœ¨ä½œè€…ä»¬çš„ Open-Instruct 8ä¸Šè®­ç»ƒçš„ SFT æ¨¡å‹ä¹‹é—´å­˜åœ¨æ€§èƒ½å·®è·ã€‚ä½œè€…ä»¬å‘ç°è¿™ä¸ªé—®é¢˜ä¸»è¦æ˜¯ç”±äºTransformers å†…éƒ¨æŸå¤±èšåˆé—®é¢˜é€ æˆçš„ï¼šåœ¨ä¸è€ƒè™‘æ¢¯åº¦ç´¯ç§¯æˆ–åˆ†å¸ƒå¼è®­ç»ƒè®¾ç½®çš„æƒ…å†µä¸‹å¯¹å¡«å……æ ‡è®°ä¹‹é—´çš„æŸå¤±è¿›è¡Œå¹³å‡ã€‚\n\nè¿™é‡Œä½œè€…ä»¬ç”¨ä¸€ä¸ªä¾‹å­æ¥è¯´æ˜è¿™ä¸ªé—®é¢˜ã€‚å‡è®¾ä½œè€…ä»¬åœ¨ä¸€ä¸ªæ‰¹æ¬¡ä¸­æœ‰ä¸¤ä¸ªæ ·æœ¬,å…¶ä¸­æœ‰ $n_1$ã€$n_2$ ä¸ªéå¡«å……æ ‡è®°å’Œ $m_1$ã€$m_2$ ä¸ªå¡«å……æ ‡è®°ã€‚å¦‚æœä½œè€…ä»¬åŒæ—¶å°†ä¸¤ä¸ªæ ·æœ¬ä¼ é€’åˆ°é»˜è®¤çš„ Transformers å‰å‘ä¼ é€’ä¸­,ä½œè€…ä»¬ä¼šå¾—åˆ°:\n\n$$\nL = \\frac{l_{n1} + l_{n2}}{n_1 + n_2}\n$$\n\nå½“ä¸¤ä¸ªæ ·æœ¬åŒæ—¶é€šè¿‡Transformeræ¨¡å‹çš„å‰å‘ä¼ æ’­æ—¶,æŸå¤±å‡½æ•° L æ˜¯ä¸¤ä¸ªæ ·æœ¬çš„æŸå¤±å€¼ä¹‹å’Œé™¤ä»¥ä¸¤ä¸ªæ ·æœ¬ä¸­éå¡«å……tokensçš„æ€»æ•°ã€‚è¿™é‡Œçš„ $l_{n1}$ å’Œ $l_{n2}$ åˆ†åˆ«æ˜¯ç¬¬ä¸€ä¸ªå’Œç¬¬äºŒä¸ªæ ·æœ¬çš„æŸå¤±å€¼,å®ƒä»¬æ˜¯æ ¹æ®å„è‡ªæ ·æœ¬ä¸­çš„éå¡«å……tokensè®¡ç®—å¾—å‡ºçš„ã€‚\n\nç„¶è€Œ,å¦‚æœä½œè€…ä»¬åº”ç”¨æ¢¯åº¦ç§¯ç´¯,åˆ†åˆ«è¾“å…¥ä¸¤ä¸ªæ ·æœ¬,è®¡ç®—æŸå¤±,ç„¶åé™¤ä»¥æŸå¤±å°±ä¼šè¿™æ ·è®¡ç®—:\n\n$$\nL = \\frac{l_{n1}}{n_1} + \\frac{l_{n2}}{n_2}\n$$\n\nå½“ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯æ—¶,æ¯ä¸ªæ ·æœ¬å•ç‹¬é€šè¿‡æ¨¡å‹,åˆ†åˆ«è®¡ç®—æŸå¤±,ç„¶åå†å°†è¿™ä¸¤ä¸ªæŸå¤±å€¼å¹³å‡ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹,æ¯ä¸ªæ ·æœ¬çš„æŸå¤±å€¼æ˜¯æŒ‰ç…§å…¶éå¡«å……tokensçš„æ•°é‡æ¥åŠ æƒçš„ã€‚\n\nä¹Ÿå°±æ˜¯è¯´ï¼Œåœ¨ç¬¬äºŒç§æƒ…å†µä¸‹ï¼Œä½œè€…ä»¬å¯¹æ¯ä¸ªç¤ºä¾‹èµ‹äºˆç›¸åŒçš„æƒé‡ï¼Œè€Œåœ¨ç¬¬ä¸€ç§æƒ…å†µä¸‹ï¼Œä½œè€…ä»¬å¯¹æ¯ä¸ªæ ‡è®°èµ‹äºˆç›¸åŒçš„æƒé‡ã€‚å› æ­¤ï¼Œæ”¹å˜æ¢¯åº¦ç´¯ç§¯ä¼šå¯¹æ€§èƒ½äº§ç”Ÿå¾ˆå¤§å½±å“ï¼Œå› ä¸ºå®é™…ä¸Šä¼šæ”¹å˜æ ·æœ¬æƒé‡ã€‚ç”±äºè·¨è®¾å¤‡å¹³å‡ï¼Œåˆ†å¸ƒå¼è®­ç»ƒä¸­ä¹Ÿä¼šå‡ºç°ç±»ä¼¼çš„é—®é¢˜ã€‚\n\nä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½œè€…ä»¬é€šå¸¸é€‰æ‹©åœ¨è®­ç»ƒæ—¶ä½¿ç”¨æ€»æŸå¤±è€Œä¸æ˜¯å¹³å‡æŸå¤±ã€‚è¿™åªéœ€ä»ä¸Šè¿°æ–¹ç¨‹ä¸­åˆ é™¤åˆ†æ¯å³å¯æ¶ˆé™¤é—®é¢˜ï¼Œå¹¶éœ€è¦è°ƒæ•´å­¦ä¹ ç‡ã€‚è¿™å®é™…ä¸Šå¯¹æ‰€æœ‰æ ‡è®°èµ‹äºˆäº†ç›¸åŒçš„æƒé‡ï¼ˆä½œè€…ä»¬å‘ç°è¿™é€šå¸¸ä¼šä½¿åˆå§‹æ··åˆçš„æ€§èƒ½æ›´å¥½ï¼‰ã€‚ä½œè€…ä»¬é€šè¿‡åœ¨ TÃœLU2 SFT æ··åˆä¸Šä½¿ç”¨å„ç§å­¦ä¹ ç‡ã€æ—¶æœŸå’ŒæŸå¤±ç±»å‹å¯¹ Llama 3.0 è¿›è¡Œå¾®è°ƒæ¥éªŒè¯ä½œè€…ä»¬è®¾ç½®çš„æ€§èƒ½ï¼Œå¦‚å›¾ 5 å’Œå›¾ 6 æ‰€ç¤ºã€‚æœ€ç»ˆï¼Œä½œè€…ä»¬å‘ç°ä½¿ç”¨å­¦ä¹ ç‡ä¸º 5.00E-06 çš„æ€»æŸå¤±æ•ˆæœæœ€å¥½ã€‚ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œä½œè€…ä»¬è¿˜å‘ç°æ›´é•¿æ—¶é—´çš„è®­ç»ƒå¹¶æ²¡æœ‰å¸¦æ¥è¿›ä¸€æ­¥çš„æ”¹è¿›ï¼Œå› æ­¤ä½¿ç”¨äº† 2 ä¸ªæ—¶æœŸè¿›è¡Œè®­ç»ƒã€‚\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![å›¾ 5 ä½¿ç”¨ä¸åŒçš„æŸå¤±ç±»å‹å’Œå­¦ä¹ ç‡åœ¨TÃœLU2 mixtureä¸Šå¾®è°ƒ Llama3.0 æ—¶çš„å¹³å‡æ€§èƒ½ã€‚ä½œè€…ä»¬å‘ç° LR ä¸º 5e-6 ä¸”å¸¦æœ‰æ€»æŸå¤±çš„æ•ˆæœæœ€å¥½ã€‚](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/paper/tulu3/image18.png)\n\n\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![å›¾ 6 åœ¨ TÃœLU2 mixtureä¸Šä½¿ç”¨ sum loss å’Œ LR 5e-6 è¿›è¡ŒLlama3.0å¾®è°ƒçš„ä¸åŒæ•°é‡çš„ epoch æµ‹è¯•ã€‚ä½œè€…ä»¬å‘ç°ä½¿ç”¨ 2 ä¸ª epoch æ•ˆæœæœ€å¥½ã€‚](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/paper/tulu3/image19.png)\n\n#  Preference Finetuning \n\nå¯¹äºTÃœLU3ï¼Œä½œè€…ä»¬æ¢ç´¢äº†è®¸å¤šåå¥½å¾®è°ƒæ–¹æ³•ï¼Œç›®çš„æ˜¯æ”¹è¿›æ•´ä¸ªè¯„ä¼°å¥—ä»¶ã€‚ä½œè€…ä»¬æ¢ç´¢äº†å¤šç§è®­ç»ƒç®—æ³•ï¼Œä»ç›´æ¥åå¥½ä¼˜åŒ– (DPO) åŠå…¶è¡ç”Ÿç®—æ³•åˆ°å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œä¾‹å¦‚è¿‘ç«¯ç­–ç•¥ä¼˜åŒ– (PPO)ã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œä½œè€…ä»¬è¯¦ç»†ä»‹ç»äº†ä»äººç±»åå¥½å’Œä½œè€…ä»¬çš„ä¼˜åŒ–å™¨ä¸­å­¦ä¹ çš„é—®é¢˜è¡¨è¿°ã€‚æ¥ä¸‹æ¥ï¼Œä½œè€…ä»¬å°†è§£é‡Šå¦‚ä½•å°†ä»–ä»¬çš„Promptsè½¬æ¢ä¸ºæ¥è‡ªåœ¨çº¿ç­–ç•¥ï¼ˆTÃœLU3å¥—ä»¶ï¼‰å’Œç¦»çº¿ç­–ç•¥æ¨¡å‹ï¼ˆå…¶ä»–æŒ‡å¯¼æ¨¡å‹ï¼‰çš„åˆæˆåå¥½æ•°æ®ã€‚ä½œè€…ä»¬å±•ç¤ºäº†å¦‚ä½•ä¸ºæ„Ÿå…´è¶£çš„ç‰¹å®šæŠ€èƒ½åˆ›å»ºåå¥½æ•°æ®ï¼Œä»¥åŠå¦‚ä½•ä½¿ç”¨ DPO ç¨³å¥åœ°æ”¹è¿›ä»–ä»¬çš„æ¨¡å‹ã€‚\n\n## èƒŒæ™¯\n\nå…ˆå‰çš„ç ”ç©¶å·²å°†åå¥½æ•°æ®è®­ç»ƒç¡®ç«‹ä¸ºæé«˜æ¨¡æ‹Ÿäººç±»æˆ–åˆæˆåå¥½çš„åŸºå‡†æ¨¡å‹æ€§èƒ½çš„å…³é”®æ­¥éª¤ ã€‚å…¸å‹çš„ç¨‹åºæ˜¯ä»äººç±»æˆ–åˆæˆåé¦ˆä¸­è¿›è¡Œå¼ºåŒ–å­¦ä¹ ã€‚\n\n### è®¾ç½®\n\n#### åå¥½æ•°æ®\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![å›¾ 7ï¼šåå¥½æ•°æ®çš„pipelineã€‚](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/paper/tulu3/image20.png)\n\nå›¾ 7å±•ç¤ºäº†åå¥½æ•°æ®é›†åˆ¶ä½œçš„æµç¨‹ï¼Œä¸»è¦åˆ†ä¸ºä¸‰ä¸ªé˜¶æ®µï¼š**Prompt Selectionï¼ˆæç¤ºé€‰æ‹©ï¼‰**ã€**Response Generationï¼ˆå›ç­”ç”Ÿæˆï¼‰** å’Œ **Preference Annotationï¼ˆåå¥½æ ‡æ³¨ï¼‰**åœ¨è¿™ä¸ªé˜¶æ®µï¼Œä¼šä»ä»¥ä¸‹ä¸‰ç±»æ¥æºä¸­é€‰æ‹©æç¤ºï¼ˆPromptsï¼‰ï¼š\n\n\n\n+ Prompts used in SFTï¼ˆç›‘ç£å¾®è°ƒä¸­ä½¿ç”¨çš„æç¤ºï¼‰ï¼šç”¨äºæ¨¡å‹çš„ç›‘ç£å¾®è°ƒè®­ç»ƒçš„æ•°æ®é›†ä¸­çš„æç¤ºã€‚\n+ Prompts from datasets subsampled for SFTï¼ˆä»ç”¨äºSFTçš„æ•°æ®é›†ä¸­é‡‡æ ·çš„æç¤ºï¼‰ï¼šä»æ›´å¤§çš„è®­ç»ƒæ•°æ®é›†ä¸­æŒ‘é€‰å‡ºä¸€éƒ¨åˆ†æç¤ºã€‚\n+ New OOD promptsï¼ˆè¶…å‡ºåˆ†å¸ƒçš„æç¤ºï¼Œä¾‹å¦‚Ultrafeedbackå’ŒPersonaï¼‰ï¼šè®¾è®¡æ–°çš„ã€è¶…å‡ºæ¨¡å‹è®­ç»ƒåˆ†å¸ƒçš„æç¤ºï¼Œä»¥æµ‹è¯•æ¨¡å‹åœ¨æ–°é¢†åŸŸä¸Šçš„è¡¨ç°ã€‚\n\n\n\n**Response Generationï¼ˆå›ç­”ç”Ÿæˆï¼‰**è¿™é‡Œæåˆ°äº†ä¸€ä¸ªæ¨¡å‹æ± ï¼ŒåŒ…å«22ä¸ªä¸åŒçš„æ¨¡å‹ï¼Œå…¶ä¸­å›ç­”ç”Ÿæˆçš„è¿‡ç¨‹åŒ…æ‹¬ï¼š\n\n\n\n+ Off-policy dataï¼ˆç¦»ç­–ç•¥æ•°æ®ï¼‰ï¼šç”±å…¶ä»–æ¨¡å‹ç”Ÿæˆçš„å›ç­”ï¼ˆå¦‚Metaã€Gemmaã€æŠ€æœ¯åˆ›æ–°ç ”ç©¶æ‰€ç­‰ï¼‰ã€‚è¿™äº›æ¨¡å‹ç”Ÿæˆçš„å›ç­”å¯èƒ½ä¼šè¢«æ ‡æ³¨ä¸ºâ€œè¾ƒå·®â€æˆ–â€œè¢«æ‹’ç»â€ã€‚\n+ On-policy dataï¼ˆç­–ç•¥å†…æ•°æ®ï¼‰ï¼šç”±TÃ¼lu 3ï¼ˆSFT 8Bæˆ–SFT 70Bï¼‰ç”Ÿæˆçš„å›ç­”ï¼Œè¿™äº›å›ç­”å¯èƒ½æ˜¯é«˜è´¨é‡ã€ç¬¦åˆåå¥½çš„ç­”æ¡ˆã€‚\n\n\n\n**Preference Annotationï¼ˆåå¥½æ ‡æ³¨ï¼‰**  åœ¨è¿™ä¸ªé˜¶æ®µï¼Œä½¿ç”¨**GPT-4o**ååŠ©æ ‡æ³¨å›ç­”è´¨é‡ï¼Œå…·ä½“æ“ä½œåŒ…æ‹¬ï¼š\n\n\n\n+ æ ‡æ³¨ç»´åº¦ï¼šå¯¹æ¯ä¸ªç”Ÿæˆçš„å›ç­”ï¼Œä»ä»¥ä¸‹å››ä¸ªæ–¹é¢è¿›è¡Œè¯„åˆ†ï¼ˆ1åˆ°5åˆ†ï¼‰ï¼š\n  - Helpfulnessï¼ˆæœ‰ç”¨æ€§ï¼‰ï¼šå›ç­”æ˜¯å¦å¯¹ç”¨æˆ·æœ‰å¸®åŠ©ã€‚\n  - Instruction Followingï¼ˆæŒ‡ä»¤éµå¾ªæ€§ï¼‰ï¼šæ˜¯å¦ä¸¥æ ¼æŒ‰ç…§æç¤ºæŒ‡ä»¤è¿›è¡Œå›ç­”ã€‚\n  - Truthfulnessï¼ˆçœŸå®æ€§ï¼‰ï¼šå›ç­”å†…å®¹æ˜¯å¦çœŸå®ã€å‡†ç¡®ã€‚\n  - Honestyï¼ˆè¯šå®æ€§ï¼‰ï¼šå›ç­”æ˜¯å¦æœ‰è¯¯å¯¼æ€§æˆ–éšç’ä¿¡æ¯ã€‚\n+ Binarizeï¼ˆäºŒå€¼åŒ–ï¼‰ï¼šå°†è¯„åˆ†ç»“æœè½¬åŒ–ä¸ºâ€œChosenï¼ˆé€‰æ‹©ï¼‰â€æˆ–â€œRejectedï¼ˆæ‹’ç»ï¼‰â€ï¼š\n  - Chosenï¼šå¾—åˆ†è¾ƒé«˜çš„å›ç­”ã€‚\n  - Rejectedï¼šå¾—åˆ†è¾ƒä½çš„å›ç­”ã€‚\n\n**GPT-4o ä¸ç›´æ¥ç”Ÿæˆå›ç­”ï¼Œè€Œæ˜¯ä½œä¸ºæ ‡æ³¨åŠ©æ‰‹ï¼Œä¸ºæ¯ä¸ªå›ç­”åœ¨ä¸åŒç»´åº¦ä¸Šç»™å‡ºå…·ä½“è¯„åˆ†ã€‚**é™¤äº†åˆ¤æ–­â€œå¥½â€æˆ–â€œåâ€ï¼Œè¿˜å¯ä»¥æä¾›æ›´ç²¾ç»†çš„è´¨é‡ç»´åº¦ï¼ˆå¦‚æœ‰ç”¨æ€§ã€æŒ‡ä»¤éµå¾ªæ€§ç­‰ï¼‰ï¼Œä»¥ä¾¿åç»­æ›´ç»†ç²’åº¦åœ°ä¼˜åŒ–æ¨¡å‹ã€‚  \n\n\n\n\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![å›¾ 8 Huggingfaceä¸Šå…¬å¼€çš„TÃœLU3 åå¥½æ•°æ®é›†](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/paper/tulu3/image21.png)\n\n#### å¥–åŠ±æ¨¡å‹\n\nç»™å®šåå¥½æ•°æ®é›†,è®­ç»ƒå¥–åŠ±æ¨¡å‹ (RM) $r_{\\phi}$,ç›®æ ‡å¦‚ä¸‹:\n\n$$\n\\max_{\\phi} \\mathbb{E}_{(x,y_c,y_r)\\sim D} \\left[ \\log \\sigma(r_{\\phi}(x,y_c) - r_{\\phi}(x,y_r)) \\right]\n$$\n\n\n\n+ æ•°æ®é›† $\\mathcal{D}$ åŒ…å«äº†ä¸€äº›æç¤ºï¼ˆpromptsï¼‰ $x$ å’Œä¸¤ä¸ªå€™é€‰å›ç­” $y$ å’Œ $y'$ã€‚\n+ å¯¹äºæ¯ä¸ªæç¤º $x$ï¼Œä¸€äº›è¯„å®¡è€…ä¼šä» $y$ å’Œ $y'$ ä¸­é€‰æ‹©ä¸€ä¸ªä½œä¸ºæ›´å¥½çš„å›ç­” $y_c$ï¼Œå¦ä¸€ä¸ªä¼šè¢«æ ‡è®°ä¸ºè¢«æ‹’ç»çš„å›ç­” $y_r$ã€‚\n+ $r_{\\phi}(x, y)$ï¼šå¥–åŠ±æ¨¡å‹å¯¹äºè¾“å…¥ $x$ å’Œå›ç­” $y$ çš„è¯„åˆ†ã€‚\n+ $\\sigma(z)$ï¼šæ¿€æ´»å‡½æ•° Sigmoidï¼Œ$\\sigma(z)=\\frac{1}{1+e^{-z}}$ï¼Œå°†åˆ†æ•°å·®è½¬åŒ–ä¸ºä¸€ä¸ªæ¦‚ç‡å€¼ã€‚\n+ $(x,y_c,y_r)\\sim \\mathcal{D}$ï¼šä»åå¥½æ•°æ®é›†ä¸­é‡‡æ ·çš„ä¸€ä¸ªä¸‰å…ƒç»„ï¼Œå…¶ä¸­ $y_c$ æ˜¯é€‰æ‹©çš„å›ç­”ï¼Œ$y_r$ æ˜¯è¢«æ‹’ç»çš„å›ç­”ã€‚\n+ $r_{\\phi}(x,y_c)-r_{\\phi}(x,y_r)$ï¼šè¡¨ç¤ºå¥–åŠ±æ¨¡å‹è®¤ä¸ºé€‰æ‹©å›ç­” $y_c$ ä¸è¢«æ‹’ç»å›ç­” $y_r$ çš„åˆ†æ•°å·®ã€‚\n+ $\\log \\sigma(r_{\\phi}(x,y_c)-r_{\\phi}(x,y_r))$ï¼šè¡¨ç¤ºæ ¹æ®åˆ†æ•°å·®çš„å¯¹æ•°ä¼¼ç„¶ï¼Œæè¿°äº†æ¨¡å‹å°† $y_c$ è§†ä¸ºé€‰æ‹©å›ç­”çš„æ¦‚ç‡ï¼Œå®ƒè¶Šæ¥è¿‘ 0ï¼Œæ„å‘³ç€å¯¹åº”çš„åŸå§‹æ¦‚ç‡ $\\sigma(z)$ è¶Šé«˜ã€‚  \n\n**ä¼˜åŒ–ç›®æ ‡**ï¼šæœ€å¤§åŒ–è¿™ä¸€å¯¹æ•°ä¼¼ç„¶ï¼Œå¼ºåŒ–å¥–åŠ±æ¨¡å‹å¯¹é€‰æ‹©å›ç­”ä¸è¢«æ‹’ç»å›ç­”çš„åŒºåˆ†èƒ½åŠ›ã€‚\n\n\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![Sigmoidå‡½æ•°  ğœ ( ğ‘§ ) çš„å›¾åƒ](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/paper/tulu3/image23.png)\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![å¯¹æ•°ä¼¼ç„¶å‡½æ•°](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/paper/tulu3/image24.png)\n\n### 5.1.2\tç­–ç•¥ä¼˜åŒ–\n\n#### PPO\n\nç”¨ KL æ•£åº¦ä½œä¸ºæ­£åˆ™åŒ–é¡¹,é™åˆ¶æ¨¡å‹æ›´æ–°çš„æ­¥é•¿ã€‚æ¨¡å‹å¸Œæœ›æœ€å¤§åŒ–å¥–åŠ±(ç”Ÿæˆæ›´ç¬¦åˆäººç±»åå¥½çš„å†…å®¹),ä½†æ¨¡å‹ä¹Ÿéœ€è¦å—é™äºâ€œä¸è¦åç¦»é¢„è®­ç»ƒæ¨¡å‹å¤ªè¿œâ€,ä»¥é¿å…ç”Ÿæˆå¥‡æ€ªã€ä¸ç¨³å®šçš„å†…å®¹ã€‚KL æ•£åº¦æä¾›äº†ä¸€ä¸ªåº¦é‡å·¥å…·,$\\beta$ åˆ™å†³å®šäº†åç¦»çš„å…è®¸ç¨‹åº¦ã€‚\n\n$$\nR(x,y) = r_{\\phi}(x,y) - \\beta \\text{KL}[\\pi_{\\theta}(y|x) \\| \\pi_{\\text{ref}}(y|x)]\n$$\n\n\n\n+ $\\pi_{\\theta}(y \\mid x)$ï¼šå½“å‰è®­ç»ƒçš„è¯­è¨€æ¨¡å‹çš„ç­–ç•¥ï¼ˆç”Ÿæˆ $y$ çš„æ¦‚ç‡åˆ†å¸ƒï¼‰ã€‚\n+ $\\pi_{\\text{ref}}(y \\mid x)$ï¼šåˆå§‹å‚è€ƒç­–ç•¥ï¼ˆé¢„è®­ç»ƒæ¨¡å‹çš„ç­–ç•¥ï¼Œç”¨äºä¿æŒç”Ÿæˆç»“æœçš„ç¨³å®šæ€§ï¼‰ã€‚\n+ $\\mathrm{KL}\\big[\\pi_{\\theta}(y \\mid x)\\,\\|\\,\\pi_{\\text{ref}}(y \\mid x)\\big]$ï¼šKullbackâ€“Leiblerï¼ˆKLï¼‰æ•£åº¦ï¼Œç”¨æ¥è¡¡é‡å½“å‰ç­–ç•¥ $\\pi_\\theta$ åç¦»å‚è€ƒç­–ç•¥ $\\pi_\\text{ref}$ çš„ç¨‹åº¦ã€‚\n+ $r_\\phi(x, y)$: å¥–åŠ±æ¨¡å‹çš„è¾“å‡ºï¼Œè¡¨ç¤ºå¯¹è¾“å…¥ $x$ å’Œç”Ÿæˆç»“æœ $y$ çš„è´¨é‡è¯„åˆ†ã€‚\n+ $\\beta$: æ§åˆ¶ KL æ•£åº¦çš„æƒé‡ï¼Œå¹³è¡¡æ¨¡å‹å¯¹å¥–åŠ±æœ€å¤§åŒ–å’Œä¸å‚è€ƒç­–ç•¥ä¿æŒæ¥è¿‘ä¹‹é—´çš„å–èˆã€‚\n\n**ç›®æ ‡**ï¼š\n\n+ ç›®æ ‡æ˜¯ä¼˜åŒ–ç­–ç•¥ $\\pi_\\theta$ï¼Œä½¿å¾—ç”Ÿæˆçš„ç»“æœ $y$ åœ¨ç»™å®š $x$ æ—¶èƒ½è·å¾—æœ€é«˜çš„å¥–åŠ± $R(x,y)$ã€‚\n+ å¥–åŠ± R(x,y) è¢«åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼š\n  1. $r_\\phi(x, y)$: å¥–åŠ±æ¨¡å‹ç»™å‡ºçš„åå¥½è¯„åˆ†ã€‚\n  2. $\\beta \\text{KL}[\\pi_\\theta \\| \\pi_\\text{ref}]$: æƒ©ç½šé¡¹ï¼Œé™åˆ¶ $\\pi_\\theta$åç¦»$\\pi_\\text{ref}$ å¤ªè¿œã€‚\n\n**ä½œç”¨**ï¼š\n\n+ **å¥–åŠ±æœ€å¤§åŒ–**ï¼šé€šè¿‡ $r_\\phi(x, y)$ è®©ç­–ç•¥ç”Ÿæˆæ›´ç¬¦åˆäººç±»åå¥½çš„å†…å®¹ã€‚\n+ **ç¨³å®šæ€§æ§åˆ¶**ï¼šé€šè¿‡ KL æ•£åº¦ï¼Œç¡®ä¿æ¨¡å‹ä¸ä¼šåç¦»åˆå§‹ç­–ç•¥å¤ªè¿œï¼Œé¿å…ç”Ÿæˆè´¨é‡å´©å¡Œæˆ–å‡ºç°æç«¯è¡Œä¸ºã€‚\n+ **æƒé‡ **$\\beta$ï¼š\n+ $\\beta$ æ§åˆ¶ä¸¤éƒ¨åˆ†çš„æƒè¡¡ï¼š\n  - å¦‚æœ $\\beta$ è¾ƒå¤§ï¼Œæ¨¡å‹æ›´å€¾å‘äºä¿æŒå’Œå‚è€ƒç­–ç•¥æ¥è¿‘ã€‚\n  - å¦‚æœ $\\beta$ è¾ƒå°ï¼Œæ¨¡å‹æ›´å€¾å‘äºè¿½æ±‚å¥–åŠ±æœ€å¤§åŒ–ï¼Œä½†å¯èƒ½ä¼šå¯¼è‡´ç”Ÿæˆä¸ç¨³å®šã€‚\n\n\n\n#### DPO\n\nç›´æ¥ç”¨åå¥½æ•°æ®ä¼˜åŒ–ç­–ç•¥,é¿å…å¤§å¹…åç¦»åˆå§‹å‚è€ƒç­–ç•¥,å…¶ç­‰æ•ˆç›®æ ‡å¦‚ä¸‹:\n\n$$\n\\max_{\\theta} \\mathbb{E}_{(x,y_c,y_r)\\sim D} \\left[ \\log \\sigma \\left( \\beta \\log \\frac{\\pi_{\\theta}(y_c|x)}{\\pi_{\\text{ref}}(y_c|x)} - \\beta \\log \\frac{\\pi_{\\theta}(y_r|x)}{\\pi_{\\text{ref}}(y_r|x)} \\right) \\right]\n$$\n\n\n**è¾“å…¥æ•°æ®**ï¼š\n\n+ æ•°æ®é›†$\\mathcal{D}$åŒ…å«ä¸€å¯¹åå¥½æ ‡æ³¨ $ (y_c, y_r) $ï¼š\n  - $y_{c}$ï¼šä¼˜é€‰é¡¹ï¼ˆchosenï¼‰ã€‚\n  - $y_{r}$ï¼šéä¼˜é€‰é¡¹ï¼ˆrejectedï¼‰ã€‚\n+ $x$æ˜¯è¾“å…¥ä¸Šä¸‹æ–‡ã€‚\n\n**ç›®æ ‡å‡½æ•°çš„æ ¸å¿ƒ**ï¼š\n\n+ åˆ†æ•°å·®ï¼šåˆ†æ•°çš„è®¡ç®—åŸºäºæ¨¡å‹ $\\pi_\\theta$ å’Œå‚è€ƒç­–ç•¥ $\\pi_\\text{ref}$ çš„å¯¹æ•°æ¯”å€¼ï¼ˆå³å¯¹æ•°æ¦‚ç‡æ¯”ï¼‰ã€‚ä¼˜é€‰é¡¹ $y_c$ å’Œéä¼˜é€‰é¡¹ $y_r$ çš„åˆ†æ•°å·®å®šä¹‰ä¸ºï¼š\n  - $\\Delta = \\beta \\log \\frac{\\pi_\\theta(y_c\\mid x)}{\\pi_\\text{ref}(y_c\\mid x)} - \\beta \\log \\frac{\\pi_\\theta(y_r\\mid x)}{\\pi_\\text{ref}(y_r\\mid x)}.$\n  - $\\beta$ æ˜¯ä¸€ä¸ªæƒé‡å‚æ•°ï¼Œç”¨äºè°ƒæ•´ç­–ç•¥å’Œå‚è€ƒç­–ç•¥ä¹‹é—´çš„åç¦»ç¨‹åº¦ã€‚\n\n\n\nä¸Šé¢çš„ $\\Delta$ å¯è¿›ä¸€æ­¥ç®€åŒ–,æœ€ç»ˆä¸º:\n\n$$\n\\log \\pi_{\\theta}(y_c|x) = \\sum_{t=1}^{T_c} \\log \\pi_{\\theta}(y_{c,t}|x, y_{c,1:t-1})\n$$\n\nå…¶ä¸­,å‡è®¾ $y_c$ æ˜¯ç”±å¤šä¸ª token ç»„æˆçš„åºåˆ—: $y = (y_1, y_2, \\ldots, y_T)$,é‚£ä¹ˆæ¡ä»¶æ¦‚ç‡å¯ä»¥è¢«åˆ†è§£ä¸º:\n\n$$\n\\pi_{\\theta}(y|x) = \\prod_{t=1}^{T} \\pi_{\\theta}(y_t|x, y_{1:t-1})\n$$\n\nåœ¨ç”Ÿæˆç¬¬ tä¸ª token $y_t$ æ—¶,æ¨¡å‹ä¸ä»…å‚è€ƒè¾“å…¥ x,è¿˜å‚è€ƒä¹‹å‰å·²ç»ç”Ÿæˆçš„ token $y_{1},\\ldots,y_{t-1}$ã€‚\n\n\nåœ¨ DPO çš„è¿‡ç¨‹ä¸­ï¼Œå¸Œæœ›æ¨¡å‹å­¦ä¼šå¯¹å¥½çš„å›ç­” $y_c$ èµ‹äºˆ **æ›´é«˜çš„æ¦‚ç‡**ï¼Œä¹Ÿå°±æ˜¯ $\\pi_\\theta(y_c\\mid x)$ æ›´å¤§ã€‚åŒæ—¶ï¼Œå¯¹å·®çš„å›ç­” $y_r$ èµ‹äºˆ **æ›´ä½çš„æ¦‚ç‡**ï¼Œä¹Ÿå°±æ˜¯ $\\pi_\\theta(y_r\\mid x)$ æ›´å°ã€‚åœ¨ä¼˜åŒ–æ¨¡å‹å‚æ•° $\\theta$ çš„è¿‡ç¨‹ä¸­ï¼Œé€æ­¥å­¦ä¹ ä»è¾“å…¥ $x$ åˆ°ä¼˜è´¨è¾“å‡º $y$ çš„æ˜ å°„å…³ç³»ï¼Œå³ä¼˜åŒ– $\\pi_\\theta(y\\mid x)$ çš„åˆ†å¸ƒï¼Œä½¿å…¶æ›´è´´åˆåå¥½æ•°æ®ï¼Œé€æ­¥è®© **ä¼˜è´¨å›ç­”çš„ç”Ÿæˆæ¦‚ç‡** $\\pi_\\theta(y_c\\mid x)$ è¶…è¿‡åŠ£è´¨å›ç­”çš„ç”Ÿæˆæ¦‚ç‡ $\\pi_\\theta(y_r\\mid x)$ã€‚\n\n\n\n#### Length-Normalized DPO\n\nä½œè€…åœ¨ä¸Šè¿°DPOçš„åŸºç¡€ä¸Š,è¿›ä¸€æ­¥åŠ å…¥äº†å½’ä¸€åŒ–æ¥æ¶ˆé™¤,å› å›ç­”çš„åºåˆ—é•¿åº¦(å¯¹æ¯”æ¥è¯´å¾ˆé•¿çš„è¯)å¸¦æ¥çš„æ¦‚ç‡åå¥½å½±å“ã€‚\n\n$$\n\\max_{\\theta} \\mathbb{E}_{(x,y_c,y_r)\\sim D} \\left[ \\log \\sigma \\left( \\beta \\frac{1}{|y_c|} \\log \\frac{\\pi_{\\theta}(y_c|x)}{\\pi_{\\text{ref}}(y_c|x)} - \\beta \\frac{1}{|y_r|} \\log \\frac{\\pi_{\\theta}(y_r|x)}{\\pi_{\\text{ref}}(y_r|x)} \\right) \\right]\n$$\n\nå…¶ä¸­,å‡è®¾ $y_c$ æ˜¯ç”±å¤šä¸ª token ç»„æˆçš„åºåˆ—: $y = (y_1, y_2, \\ldots, y_T)$,é‚£ä¹ˆæ¡ä»¶æ¦‚ç‡å¯ä»¥è¢«åˆ†è§£ä¸º:\n\n$$\n\\pi_{\\theta}(y|x) = \\prod_{t=1}^{T} \\pi_{\\theta}(y_t|x, y_{1:t-1})\n$$\n\nå…¶å¯¹æ•°æ¦‚ç‡ä¸º:\n\n$$\n\\log \\pi_{\\theta}(y|x) = \\sum_{t=1}^{T} \\log \\pi_{\\theta}(y_t|x, y_{1:t-1})\n$$\n\n\n\n+ è¾ƒé•¿çš„åºåˆ— y ä¼šç´¯ç§¯æ›´å¤šçš„æ¦‚ç‡é¡¹ï¼Œå³ç´¯ç§¯æ›´å¤šçš„å¯¹æ•°å€¼ï¼Œå³ä½¿å•ä¸ªè¯çš„æ¦‚ç‡è¾ƒä½ï¼Œå…¶æ•´ä½“å¯¹æ•°æ¦‚ç‡å¯èƒ½ä»ç„¶è¾ƒé«˜ã€‚å› æ­¤ï¼Œè¾ƒé•¿çš„åºåˆ—å¯èƒ½ä¼šåœ¨ä¼˜åŒ–ç›®æ ‡ä¸­è·å¾—æ›´å¤§çš„å¾—åˆ†ï¼Œè¿›è€Œè¢«æ¨¡å‹ä¼˜å…ˆé€‰æ‹©ã€‚\n\n\n\n####  DOPå’ŒLength-Normalized DPO çš„åŒºåˆ«\n\n\n**é•¿åº¦å½’ä¸€åŒ–**ï¼š\n\n+ åœ¨åˆ†æ•°è®¡ç®—ä¸­,åŠ å…¥äº†é•¿åº¦å½’ä¸€åŒ–é¡¹ $\\frac{1}{|y|}$,åˆ†åˆ«å¯¹ $y_c$ å’Œ $y_r$ çš„åˆ†æ•°è¿›è¡Œé•¿åº¦è°ƒæ•´ã€‚\n+ ç›´è§‚ç†è§£ï¼šè¾ƒé•¿çš„è¾“å‡ºåºåˆ—é€šå¸¸ä¼šç´¯ç§¯æ›´å¤§çš„å¯¹æ•°æ¦‚ç‡ï¼Œä»è€Œå¯èƒ½äº§ç”Ÿé•¿åº¦åå·®ã€‚é•¿åº¦å½’ä¸€åŒ–å¯ä»¥å‡è½»è¿™ç§åå·®ã€‚\n\n**ä¼˜åŒ–ç›®æ ‡**ï¼š\n\n+ åœ¨ DPO çš„åŸºç¡€ä¸Šï¼Œå¼•å…¥é•¿åº¦å½’ä¸€åŒ–ï¼Œé€‚é…æ›´å¹¿æ³›çš„äººç±»åå¥½æ ‡æ³¨æ•°æ®ï¼Œç‰¹åˆ«æ˜¯åœ¨è¾“å‡ºé•¿åº¦å·®å¼‚è¾ƒå¤§çš„æƒ…å†µä¸‹ã€‚\n\n\n\n#### DPO å’Œ Length-Normalized DPO çš„ç‰¹ç‚¹\n\n\n**DPO**ï¼š\n\n+ ä¸éœ€è¦æ˜¾å¼åˆ©ç”¨è®­ç»ƒå¥–åŠ±æ¨¡å‹è¯„åˆ†ï¼Œç›´æ¥ä¼˜åŒ–ç­–ç•¥ $ \\pi_\\theta $ã€‚\n+ é€šè¿‡åˆ†æ•°å·® $\\Delta$è¡¨è¾¾åå¥½å…³ç³»ã€‚\n+ ç®€æ´é«˜æ•ˆï¼Œä½†å¯èƒ½å—è¾“å‡ºé•¿åº¦åå·®å½±å“ã€‚\n\n**Length-Normalized DPO**ï¼š\n\n+ åœ¨ DPO åŸºç¡€ä¸ŠåŠ å…¥é•¿åº¦å½’ä¸€åŒ–ï¼Œå‡è½»æ¨¡å‹ç”Ÿæˆåå¥½è¾ƒé•¿è¾“å‡ºçš„å€¾å‘ã€‚\n+ æ›´åŠ é€‚é…åŒ…å«é•¿åº¦åå·®çš„æ ‡æ³¨æ•°æ®ã€‚\n\n\n\n#### DPOå’ŒPPOå¯¹æ¯”\n\n| å¯¹æ¯”ç»´åº¦         | DPO                        | PPO                                        |\n| ---------------- | -------------------------- | ------------------------------------------ |\n| å¦éœ€è¦å¥–åŠ±æ¨¡å‹   | ä¸éœ€è¦ï¼ˆç›´æ¥ç”¨åå¥½å¯¹ï¼‰     | éœ€è¦è®­ç»ƒä¸€ä¸ªå¥–åŠ±æ¨¡å‹                       |\n| è®­ç»ƒå¤æ‚åº¦       | è¾ƒä½ï¼ˆåªä¼˜åŒ–ç­–ç•¥æ¨¡å‹ï¼‰     | è¾ƒé«˜ï¼ˆéœ€è¦ä¼˜åŒ–ç­–ç•¥ã€å¥–åŠ±ã€ä»·å€¼ç­‰å¤šä¸ªç»„ä»¶ï¼‰ |\n| ä¾èµ–å¼ºåŒ–å­¦ä¹      | ä¸éœ€è¦                     | éœ€è¦                                       |\n| å¯¹äººç±»åå¥½çš„åˆ©ç”¨ | æ›´ç›´æ¥ï¼ˆé€šè¿‡æ¦‚ç‡å¯¹æ¯”ï¼‰     | é—´æ¥ï¼ˆé€šè¿‡å¥–åŠ±æ¨¡å‹è¯„ä¼°ï¼‰                   |\n| å®ç°éš¾åº¦         | å®ç°ç®€å•                   | å®ç°å¤æ‚                                   |\n| KL æ§åˆ¶          | å†…ç½®åœ¨åå¥½å¯¹æ¯”ä¸­ï¼ˆæ›´ç›´è§‚ï¼‰ | éœ€è¦æ˜¾å¼æ§åˆ¶ KL æƒ©ç½šé¡¹                     |\n\n\n## TÃœLU3åå¥½æ•°æ®\n\n### ä»Promptsåˆ°åå¥½æ•°æ®\n\næ ¹æ® Â§3 ä¸­çš„Promptsï¼Œä½œè€…ä»¬é€šè¿‡è°ƒæ•´å’Œæ”¹è¿›åå¥½æ•°æ®çš„pipelineåˆ›å»ºç¬¦åˆç­–ç•¥çš„åå¥½æ•°æ® ( ğ‘¥,ğ‘¦,ğ‘¦ â€²,ğ‘™ğ‘ğ‘ğ‘’ğ‘™ ) ã€‚ä½œè€…ä»¬çš„æ—©æœŸå®éªŒè¡¨æ˜ï¼Œè¯¥æµç¨‹åœ¨åˆ›å»ºåå¥½æ•°æ®æ–¹é¢å…·æœ‰ä¼˜åŠ¿ï¼Œå¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„åˆæˆåå¥½æ•°æ®é›†ã€‚ä½œè€…ä»¬çš„æ•°æ®åˆ›å»ºæµç¨‹ï¼ˆå¦‚å›¾ 7 æ‰€ç¤ºï¼‰åŒ…æ‹¬ä¸‰ä¸ªé˜¶æ®µï¼šPromptsé€‰æ‹©ã€ä»æ¨¡å‹æ± ç”Ÿæˆå›ç­”ä»¥åŠä½¿ç”¨ LLM-as-a-judge è¿›è¡Œåå¥½æ³¨é‡Šä»¥åˆ›å»ºï¼ˆåå¥½ã€æ‹’ç»ï¼‰å¯¹ã€‚\n\n+ **ç¬¬ 1 é˜¶æ®µï¼šPromptsé€‰æ‹©**ã€‚å‡†å¤‡æ•°æ®é›†ä»¥è¿›è¡Œåå¥½å¾®è°ƒçš„ç¬¬ä¸€æ­¥æ˜¯é€‰æ‹©Promptsæˆ–ç”¨æˆ·æŒ‡ä»¤ä»¥ç”Ÿæˆå›ç­”å¹¶è·å–åå¥½ã€‚é‰´äºè¡¨ 6 ä¸­çš„Promptsé›†ï¼Œä½œè€…ä»¬ç²¾å¿ƒæŒ‘é€‰äº†ä½œè€…ä»¬çš„é€‰æ‹©ï¼Œä»¥åŒ…æ‹¬ SFT æœŸé—´ä½¿ç”¨çš„Promptsï¼Œä»¥åŠä»ç›¸åŒæ¥æºæŠ½æ ·ä½†æœªç”¨äº SFT çš„Promptsã€‚ä½œè€…ä»¬è¿˜åŒ…æ‹¬æ¥è‡ªå…¶ä»–æ¥æºçš„Promptsï¼Œä¾‹å¦‚æ²¡æœ‰ TruthfulQA å®ä¾‹çš„ Ultrafeedback ç‰ˆæœ¬ï¼Œæˆ–è€…é€šè¿‡å‘Promptsæ·»åŠ æ–°çš„ IF çº¦æŸã€‚\n+ **ç¬¬ 2 é˜¶æ®µï¼šå›ç­”ç”Ÿæˆã€‚**å¯¹äºç»™å®šçš„Promptsï¼Œä½œè€…ä»¬ä»æ¨¡å‹æ± ä¸­éšæœºæŠ½å–å››ä¸ªæ¨¡å‹æ¥ç”Ÿæˆå›ç­”ã€‚ä½œè€…ä»¬çš„æ¨¡å‹é€‰æ‹©å—åˆ° Ultrafeedback pipelineçš„å¯å‘ï¼Œè¯¥pipelineç”±å¼€æºå’Œä¸“æœ‰æ¨¡å‹ç»„æˆï¼Œè¿™äº›æ¨¡å‹åœ¨å‚æ•°å¤§å°å’Œæ¨¡å‹ç³»åˆ—ä¸Šæœ‰æ‰€ä¸åŒã€‚ä½œè€…ä»¬é€šè¿‡ä½¿ç”¨æŸäº›æ¨¡å‹çš„æœ€æ–°ç‰ˆæœ¬ï¼ˆLlama 2 â†’ Llama 3.1ï¼‰æ¥æ›´æ–° Ultrafeedback çš„æ¨¡å‹æ± ï¼Œæ·»åŠ æ€§èƒ½æœ€ä½³çš„æ¨¡å‹ä»¥å¢åŠ æ± å¤§å°ï¼Œå¹¶ç”¨å¼€æºæ›¿ä»£æ–¹æ¡ˆæ›¿æ¢å½“å‰æ— æ³•è®¿é—®çš„æ¨¡å‹ï¼ˆä¾‹å¦‚ WizardLMï¼‰ã€‚æœ€åï¼Œä½œè€…ä»¬è¿˜é€šè¿‡ä» TÃœLU SFT æ¨¡å‹ä¸­æŠ½æ ·å®Œæˆæ¥åŒ…å«åœ¨çº¿ç­–ç•¥æ•°æ®ã€‚ä½œè€…ä»¬é€šè¿‡æ·»åŠ ä¸€ç³»åˆ—Promptsæ¥å®ç°è¿™ä¸€ç‚¹ï¼Œå…¶ä¸­ä¸€ä¸ªå›ç­”æ¥è‡ªåœ¨çº¿ç­–ç•¥æ¨¡å‹ï¼Œå¦ä¸€ä¸ªå›ç­”æ¥è‡ªéç­–ç•¥æ¨¡å‹ã€‚\n+ **ç¬¬ 3 é˜¶æ®µï¼šåå¥½æ³¨é‡Š**ã€‚åœ¨ä¸ºæ¯ä¸ªPromptsç”Ÿæˆå››ä¸ªå›ç­”åï¼Œä½œè€…ä»¬ä½¿ç”¨ LLM-as-a-judgeï¼Œç‰¹åˆ«æ˜¯ GPT-4o-2024-0806ï¼Œä»å››ä¸ªä¸åŒæ–¹é¢å¯¹æ¯ä¸ªå›ç­”ä» 1 åˆ° 5 è¿›è¡Œè¯„åˆ†ï¼šæœ‰å¸®åŠ©æ€§ã€éµå¾ªæŒ‡ç¤ºã€è¯šå®å’ŒçœŸå®æ€§ã€‚\n\n### TÃœLU3åå¥½ç»„åˆ\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![è¡¨ 14ï¼šä½œè€…ä»¬å¯¹ TÃœLU3 8B DPO å’Œ TÃœLU3 70B DPOçš„æœ€ä½³åå¥½æ•°æ®é›†ç»„åˆçš„æ€»ç»“ã€‚IF æ˜¯â€œInstruction Followingâ€çš„ç¼©å†™ã€‚](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/paper/tulu3/image32.png)\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![è¡¨ 15 æ˜¾ç¤ºäº†åå¥½æ•°æ®é›†çš„åŒ…å«æˆ–æ’é™¤å¦‚ä½•å½±å“å¹³å‡æ€§èƒ½ã€‚](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/paper/tulu3/image33.png)\n\nä½œè€…ä»¬ä¸º 8b å’Œ 70b æ¨¡å‹é€‰æ‹©äº†æœ€ç»ˆçš„åå¥½ç»„åˆï¼Œè¿™å¯ä»¥æœ€å¤§é™åº¦åœ°æé«˜å¼€å‘è¯„ä¼°çš„å¹³å‡è¡¨ç°ï¼ŒåŒæ—¶åœ¨ç›®æ ‡æŠ€èƒ½æ–¹é¢ä¹Ÿè¡¨ç°å‡ºè‰²ã€‚å¤§å¤šæ•°åå¥½æ•°æ®ç»„åˆæ¶ˆèéƒ½æ˜¯é’ˆå¯¹ 8b æ¨¡å‹è¿è¡Œçš„ï¼Œä½œè€…ä»¬ä»ç”¨äº SFT çš„Promptså¼€å§‹ï¼Œç”Ÿæˆåœ¨ç­–ç•¥å’Œç¦»ç­–ç•¥åå¥½æ•°æ®ï¼Œä»è€Œäº§ç”Ÿ 96911 ä¸ªï¼ˆæ‹’ç»ç­–ç•¥ï¼‰å’Œ 19444 ä¸ªï¼ˆæ¥å—ç­–ç•¥ï¼‰åå¥½å®ä¾‹ã€‚æ ¹æ®è¿™ä¸ªåå¥½åŸºç¡€ï¼Œä½œè€…ä»¬å‘ç»„åˆä¸­æ·»åŠ å…¶ä»–Promptsæºï¼Œä»¥åŠè¿™äº›æ·»åŠ å¦‚ä½•å½±å“ä¸‹æ¸¸è¯„ä¼°æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹è¯¸å¦‚ç²¾ç¡®æŒ‡ä»¤éµå¾ªã€æ•°å­¦å’Œ alpacaeval ä¸Šçš„ä¸€èˆ¬èŠå¤©è¡¨ç°ç­‰æŠ€èƒ½ã€‚æ€»ä¹‹ï¼Œä½œè€…ä»¬çš„åå¥½ç»„åˆæ¥è‡ªä¸åŒçš„Promptsæºï¼Œä¾‹å¦‚ SFT æ•°æ®ã€WildChat å’Œ Persona IFã€‚å®ƒåŒ…æ‹¬ SFT è®­ç»ƒæœŸé—´çœ‹åˆ°çš„Promptsï¼Œä¹ŸåŒ…æ‹¬æ–°çš„ã€æœªè§è¿‡çš„Promptsã€‚æœ€åï¼Œå®ƒåŒ…å«åœ¨çº¿å’Œç¦»çº¿ç­–ç•¥å®Œæˆçš„æ··åˆã€‚\n\n### æ•°æ®æ¶ˆèçš„ä¸»è¦å‘ç°\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["NVIDIA","V100","è®ºæ–‡è§£è¯»","tulu3"],"categories":["è®ºæ–‡è§£è¯»","tulu3"]},{"title":"ms-swiftæ¡†æ¶å¾®è°ƒæµ‹è¯•","url":"/2026/01/08/LLM/è®­ç»ƒæ¡†æ¶/ms-swiftæ¡†æ¶/","content":"### ms-swift æ¡†æ¶å¾®è°ƒ\n\n#### ç¯å¢ƒæ­å»º\n\n#### è®­ç»ƒè„šæœ¬\n\n##### åŸºäºæ”¿ä¼ç±»æ•°æ®é›†çš„ qwen2.5-7B-Ins-lora å¾®è°ƒ\n\n```bash\n# 22GB\nCUDA_VISIBLE_DEVICES=0,1,2,3 \\\nswift sft \\\n    --model /mnt/model/Qwen/Qwen2.5-7B-Instruct \\\n    --train_type lora \\\n    --dataset /mnt/ms-swift/data/train.jsonl \\\n    --torch_dtype float16 \\\n    --num_train_epochs 6 \\\n    --per_device_train_batch_size 1 \\\n    --per_device_eval_batch_size 1 \\\n    --learning_rate 1e-4 \\\n    --lora_rank 8 \\\n    --lora_alpha 32 \\\n    --target_modules all-linear \\\n    --gradient_accumulation_steps 1 \\\n    --eval_steps 50 \\\n    --save_steps 50 \\\n    --save_total_limit 5 \\\n    --logging_steps 1 \\\n    --max_length 2048 \\\n    --output_dir /mnt/ms-swift/output \\\n    --system 'ä½ æ˜¯ä¸€ä¸ªè‹å·æ”¿ä¼é—®ç­”å°åŠ©æ‰‹' \\\n    --warmup_ratio 0.05 \\\n    --dataloader_num_workers 4 \\\n    --model_author swift \\\n    --model_name swift-qwen2.5-7b\n```\n\n##### åŸºäºæ”¿ä¼ç±»æ•°æ®é›†çš„ qwen2.5-0.5B-Ins-å…¨å‚å¾®è°ƒ\n\n```bash\n# 76GiB\nCUDA_VISIBLE_DEVICES=0,1,2,3 \\\nswift sft \\\n    --model /mnt/model/Qwen2.5-0.5B-Instruct \\\n    --train_type full \\\n    --dataset /mnt/ms-swift/data/train.jsonl \\\n    --torch_dtype float32 \\\n    --num_train_epochs 6 \\\n    --per_device_train_batch_size 1 \\\n    --per_device_eval_batch_size 1 \\\n    --learning_rate 1e-5 \\\n    --gradient_accumulation_steps 16 \\\n    --eval_steps 100 \\\n    --save_steps 100 \\\n    --save_total_limit 5 \\\n    --logging_steps 1 \\\n    --max_length 2048 \\\n    --output_dir /mnt/ms-swift/output \\\n    --system 'You are a helpful assistant.' \\\n    --warmup_ratio 0.05 \\\n    --dataloader_num_workers 4 \\\n    --model_author swift \\\n    --model_name swift-qwen2.5-0.5b\n\n```\n\n#### è®­ç»ƒ\n\n##### æ—¥å¿—\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/train_framework/ms-swift/image1.png)\n\n##### æ˜¾å­˜å ç”¨æƒ…å†µ\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/train_framework/ms-swift/image2.png)\n\n##### loss æ›²çº¿\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/train_framework/ms-swift/image3.png)\n\n#### æ¨ç†æµ‹è¯•\n\n##### å¼€å¯ swift web ç•Œé¢æœåŠ¡\n\n```bash\nswift web-ui --lang zh --server_port 16686\n```\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/train_framework/ms-swift/image4.png)\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/train_framework/ms-swift/image5.png)\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/train_framework/ms-swift/image6.png)<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/train_framework/ms-swift/image7.png)\n\n\n\n\n\n","tags":["æ¨¡å‹å¾®è°ƒ","NVIDIA","V100","ms-swift"],"categories":["æ¨¡å‹å¾®è°ƒ","ms-swift"]},{"title":"vllm+mindieæ¨ç†å®è·µ","url":"/2026/01/08/LLM/æ¨ç†/vllm+mindieæ¨ç†å®è·µ/","content":"\n## vllm\n\n### é•œåƒ\n\n```bash\nregistry.cn-shanghai.aliyuncs.com/aliyun_repository_wxb/repository_wxb:vllm\næˆ–\nregistry.paas/library/ray-vllm-inference:v2.0\n```\n\n### å®¹å™¨\n\n```bash\ndocker run -it \\\n--name vllm-wxb \\\n--gpus all \\\n--network host -p 8010:8010 \\\n--shm-size 11g \\\n-v /mnt/users/wangxiangbo/:/mnt \\\n-v /usr/local/cuda-12.2:/usr/local/cuda-12.2 \\\n-w /mnt \\\nregistry.cn-shanghai.aliyuncs.com/aliyun_repository_wxb/repository_wxb:vllm\n```\n\n### DeepSeek-R1-Distill-Qwen-1.5B\n\n#### å¼€å¯vllmæ¨ç†æœåŠ¡\n\nä¸ºäº†æ¢ç©¶æ‰€éœ€çš„æœ€ä½GPUæ˜¾å­˜å ç”¨ï¼Œgpu-memory-utilizationä»0.1å¼€å§‹æµ‹è¯•ã€‚\n\n```bash\npython3 -m vllm.entrypoints.openai.api_server \\\n--host 0.0.0.0 --port 8010 \\\n--gpu-memory-utilization 0.1 \\\n--max-model-len=1024 \\\n--model /mnt/model/deepseek-ai/DeepSeek-R1-Distill-Qwen-1___5B \\\n--trust-remote-code \\\n--dtype float16 \\\n--tensor-parallel-size 1\n```\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/reasoning/vllm/image1.png)\n\n```bash\npython3 -m vllm.entrypoints.openai.api_server \\\n--host 0.0.0.0 --port 8010 \\\n--gpu-memory-utilization 0.2 \\\n--max-model-len=1024 \\\n--model /mnt/model/deepseek-ai/DeepSeek-R1-Distill-Qwen-1___5B \\\n--trust-remote-code \\\n--dtype float16 \\\n--tensor-parallel-size 1\n```\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/reasoning/vllm/image2.png)\n\n#### apiæµ‹è¯•\n\n```bash\ncurl \"http://127.0.0.1:8010/v1/chat/completions\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\n\"model\": \"/mnt/model/deepseek-ai/DeepSeek-R1-Distill-Qwen-1___5B\",\n\"messages\": [\n    {\n        \"role\": \"user\",\n        \"content\": \"I like Beijing, because\"\n    }\n],\n\"max_tokens\":512,\n\"presence_penalty\": 1.2,\n\"frequency_penalty\": 1.0,\n\"temperature\": 0.7,\n\"top_p\": 0.9\n}'\n```\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/reasoning/vllm/image3.png)\n\n#### evalscopeå‹æµ‹\n\n##### evalscopeå®‰è£…\n\n```bash\n#å®‰è£…eval-scopeæµ‹è¯•ç¯å¢ƒï¼Œä½¿ç”¨æºç å®‰è£…\ngit clone https://github.com/modelscope/evalscope.git\npip install -e .\n```\n\n##### å¯åŠ¨å‹æµ‹æœåŠ¡\n\n:::tips\nå‚è€ƒeval-scopeæ–‡æ¡£ï¼š[https://evalscope.readthedocs.io/zh-cn/latest/user_guides/stress_test/parameters.html](https://evalscope.readthedocs.io/zh-cn/latest/user_guides/stress_test/parameters.html)\n\n:::\n\n```bash\nevalscope perf --url 'http://127.0.0.1:8010/v1/chat/completions' \\\n--parallel 10 \\\n--model '/mnt/model/deepseek-ai/DeepSeek-R1-Distill-Qwen-1___5B' \\\n--log-every-n-query 10 \\\n--read-timeout=120 \\\n--max-tokens 512 \\\n--dataset-path '/mnt/script/open_qa.jsonl' \\\n-n 30 \\\n--max-prompt-length 12800 \\\n--api openai \\\n--stream \\\n--stop '<ï½œendâ–ofâ–sentenceï½œ>' \\\n--dataset openqa \\\n--debug\n```\n\n### DeepSeek-R1-Distill-Qwen-7B\n\n```bash\npython3 -m vllm.entrypoints.openai.api_server \\\n--host 0.0.0.0 --port 8010 \\\n--gpu-memory-utilization 0.2 \\\n--max-model-len=1024 \\\n--model /mnt/model/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B/deepseek_qwen_hf \\\n--trust-remote-code \\\n--dtype float16 \\\n--tensor-parallel-size 1\n```\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/reasoning/vllm/image4.png)\n\n```bash\npython3 -m vllm.entrypoints.openai.api_server \\\n--host 0.0.0.0 --port 8010 \\\n--gpu-memory-utilization 0.5 \\\n--max-model-len=1024 \\\n--model /mnt/model/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B/deepseek_qwen_hf \\\n--trust-remote-code \\\n--dtype float16 \\\n--tensor-parallel-size 1\n```\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/reasoning/vllm/image5.png)\n\n### DeepSeek-R1-Distill-Llama-8B\n\n```bash\npython3 -m vllm.entrypoints.openai.api_server \\\n--host 0.0.0.0 --port 8010 \\\n--gpu-memory-utilization 0.5 \\\n--max-model-len=1024 \\\n--model /mnt/model/deepseek-ai/DeepSeek-R1-Distill-Llama-8B \\\n--trust-remote-code \\\n--dtype float16 \\\n--tensor-parallel-size 1\n```\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/reasoning/vllm/image6.png)\n\n```bash\npython3 -m vllm.entrypoints.openai.api_server \\\n--host 0.0.0.0 --port 8010 \\\n--gpu-memory-utilization 0.6 \\\n--max-model-len=1024 \\\n--model /mnt/model/deepseek-ai/DeepSeek-R1-Distill-Llama-8B \\\n--trust-remote-code \\\n--dtype float16 \\\n--tensor-parallel-size 1\n```\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/reasoning/vllm/image7.png)\n\n### DeepSeek-R1-Distill-Qwen-14B\n\n```bash\npython3 -m vllm.entrypoints.openai.api_server \\\n--host 0.0.0.0 --port 8010 \\\n--gpu-memory-utilization 0.4 \\\n--max-model-len=1024 \\\n--model /mnt/model/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B \\\n--trust-remote-code \\\n--dtype float16 \\\n--tensor-parallel-size 2\n```\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/reasoning/vllm/image8.png)\n\n```bash\npython3 -m vllm.entrypoints.openai.api_server \\\n--host 0.0.0.0 --port 8010 \\\n--gpu-memory-utilization 0.5 \\\n--max-model-len=1024 \\\n--model /mnt/model/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B \\\n--trust-remote-code \\\n--dtype float16 \\\n--tensor-parallel-size 2\n```\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/reasoning/vllm/image9.png)\n\n### DeepSeek-R1-Distill-Qwen-32B\n\n```bash\npython3 -m vllm.entrypoints.openai.api_server \\\n--host 0.0.0.0 --port 8010 \\\n--gpu-memory-utilization 0.5 \\\n--max-model-len=1024 \\\n--model /mnt/model/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B \\\n--trust-remote-code \\\n--dtype float16 \\\n--tensor-parallel-size 4\n```\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/reasoning/vllm/image10.png)\n\n```bash\npython3 -m vllm.entrypoints.openai.api_server \\\n--host 0.0.0.0 --port 8010 \\\n--gpu-memory-utilization 0.6 \\\n--max-model-len=1024 \\\n--model /mnt/model/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B \\\n--trust-remote-code \\\n--dtype float16 \\\n--tensor-parallel-size 4\n```\n\n\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/reasoning/vllm/image11.png)\n\n### å‹æµ‹ç»“æœ\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/reasoning/vllm/yace.png)\n\n\n## mindie\n\n### é•œåƒ\n\n```bash\naiops-8af5363b.ecis.huhehaote-1.cmecloud.cn/public/mindie-develop-inference-model:1.0.rc3-pytorch2.1.0-py3.10-npu-cann8.0.rc3-ubuntu22.04\n```\n\n### å®¹å™¨\n\n```bash\nsudo docker run --name mindie-wxb -dit --net=host --shm-size=100g \\\n--privileged=true \\\n-w /workspace \\\n--device=/dev/davinci_manager \\\n--device=/dev/hisi_hdc \\\n--device=/dev/devmm_svm \\\n--entrypoint=bash \\\n-v /usr/local/Ascend/driver:/usr/local/Ascend/driver \\\n-v /usr/local/dcmi:/usr/local/dcmi \\\n-v /usr/local/bin/npu-smi:/usr/local/bin/npu-smi \\\n-v /usr/local/sbin:/usr/local/sbin \\\n-v /as-sharedata-1/wangxiangbo/mindie:/workspace \\\n-v /mnt/weight-1:/job \\\n-v /usr/share/zoneinfo/Asia/Shanghai:/etc/localtime \\\n-e http_proxy=$http_proxy \\\n-e https_proxy=$https_proxy \\\naiops-8af5363b.ecis.huhehaote-1.cmecloud.cn/public/mindie-develop-inference-model:1.0.rc3-pytorch2.1.0-py3.10-npu-cann8.0.rc3-ubuntu22.04\n```\n\n### æ¿€æ´»ç¯å¢ƒ\n\n```bash\nsource /usr/local/Ascend/nnal/atb/set_env.sh\nsource /usr/local/Ascend/mindie/set_env.sh\nsource /usr/local/Ascend/ascend-toolkit/set_env.sh\nsource /usr/local/Ascend/llm_model/set_env.sh\n```\n\n### configæ¨ç†é…ç½®ä¿®æ”¹\n\n```bash\nvim /usr/local/Ascend/mindie/latest/mindie-service/conf/config.json\n```\n\n```json\n{\n  \"Version\": \"1.0.0\",\n  \"LogConfig\": {\n    \"logLevel\": \"Info\",\n    \"logFileSize\": 20,\n    \"logFileNum\": 20,\n    \"logPath\": \"logs/mindservice.log\"\n  },\n  \"ServerConfig\": {\n    \"ipAddress\": \"10.208.200.67\",\n    \"managementIpAddress\": \"127.0.0.2\",\n    \"port\": 16384,\n    \"managementPort\": 1026,\n    \"metricsPort\": 1027,\n    \"allowAllZeroIpListening\": false,\n    \"maxLinkNum\": 1000,\n    \"httpsEnabled\": false,\n    \"fullTextEnabled\": false,\n    \"tlsCaPath\": \"security/ca/\",\n    \"tlsCaFile\": [\n      \"ca.pem\"\n    ],\n    \"tlsCert\": \"security/certs/server.pem\",\n    \"tlsPk\": \"security/keys/server.key.pem\",\n    \"tlsPkPwd\": \"security/pass/key_pwd.txt\",\n    \"tlsCrl\": \"security/certs/server_crl.pem\",\n    \"managementTlsCaFile\": [\n      \"management_ca.pem\"\n    ],\n    \"managementTlsCert\": \"security/certs/management/server.pem\",\n    \"managementTlsPk\": \"security/keys/management/server.key.pem\",\n    \"managementTlsPkPwd\": \"security/pass/management/key_pwd.txt\",\n    \"managementTlsCrl\": \"security/certs/management/server_crl.pem\",\n    \"kmcKsfMaster\": \"tools/pmt/master/ksfa\",\n    \"kmcKsfStandby\": \"tools/pmt/standby/ksfb\",\n    \"inferMode\": \"standard\",\n    \"interCommTLSEnabled\": false,\n    \"interCommPort\": 1121,\n    \"interCommTlsCaFile\": \"security/grpc/ca/ca.pem\",\n    \"interCommTlsCert\": \"security/grpc/certs/server.pem\",\n    \"interCommPk\": \"security/grpc/keys/server.key.pem\",\n    \"interCommPkPwd\": \"security/grpc/pass/key_pwd.txt\",\n    \"interCommTlsCrl\": \"security/certs/server_crl.pem\",\n    \"openAiSupport\": \"vllm\"\n  },\n  \"BackendConfig\": {\n    \"backendName\": \"mindieservice_llm_engine\",\n    \"modelInstanceNumber\": 1,\n    \"npuDeviceIds\": [\n      [\n        0\n      ]\n    ],\n    \"tokenizerProcessNumber\": 8,\n    \"multiNodesInferEnabled\": false,\n    \"multiNodesInferPort\": 1120,\n    \"interNodeTLSEnabled\": true,\n    \"interNodeTlsCaFile\": \"security/grpc/ca/ca.pem\",\n    \"interNodeTlsCert\": \"security/grpc/certs/server.pem\",\n    \"interNodeTlsPk\": \"security/grpc/keys/server.key.pem\",\n    \"interNodeTlsPkPwd\": \"security/grpc/pass/mindie_server_key_pwd.txt\",\n    \"interNodeTlsCrl\": \"security/grpc/certs/server_crl.pem\",\n    \"interNodeKmcKsfMaster\": \"tools/pmt/master/ksfa\",\n    \"interNodeKmcKsfStandby\": \"tools/pmt/standby/ksfb\",\n    \"ModelDeployConfig\": {\n      \"maxSeqLen\": 2048,\n      \"maxInputTokenLen\": 2048,\n      \"truncation\": false,\n      \"ModelConfig\": [\n        {\n          \"modelInstanceType\": \"Standard\",\n          \"modelName\": \"deepseek-r1-distill-qwen-7b\",\n          \"modelWeightPath\": \"/job/huggingface/DeepSeek-R1-Distill-qwen-7B\",\n          \"worldSize\": 1,\n          \"cpuMemSize\": 5,\n          \"npuMemSize\": 1,\n          \"backendType\": \"atb\"\n        }\n      ]\n    },\n    \"ScheduleConfig\": {\n      \"templateType\": \"Standard\",\n      \"templateName\": \"Standard_LLM\",\n      \"cacheBlockSize\": 128,\n      \"maxPrefillBatchSize\": 50,\n      \"maxPrefillTokens\": 48000,\n      \"prefillTimeMsPerReq\": 150,\n      \"prefillPolicyType\": 0,\n      \"decodeTimeMsPerReq\": 50,\n      \"decodePolicyType\": 0,\n      \"maxBatchSize\": 200,\n      \"maxIterTimes\": 512,\n      \"maxPreemptCount\": 0,\n      \"supportSelectBatch\": false,\n      \"maxQueueDelayMicroseconds\": 5000\n    }\n  }\n}\n\n```\n\n\n\n### å¯åŠ¨æ¨ç†æœåŠ¡\n\n#### å¢åŠ æƒé™\n\n```bash\nCONFIG_FILE=/usr/local/Ascend/mindie/latest/mindie-service/conf/config.json\nmodelWeightPath=/job/huggingface/DeepSeek-R1-Distill-qwen-7B\nchmod -R 640 $modelWeightPath\nchmod 640 $modelWeightPath\nchmod 640 $CONFIG_FILE\n```\n\n#### å¯åŠ¨æ¨ç†\n\n```bash\ncd /usr/local/Ascend/mindie/latest/mindie-service\n\nnohup ./bin/mindieservice_daemon > output.log 2>&1 &\n\ntail -f output.log\n```\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/reasoning/vllm/image12.png)\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/reasoning/vllm/image13.png)\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/reasoning/vllm/image14.png)\n\n\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/reasoning/vllm/image15.png)\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/reasoning/vllm/image16.png)\n\n### evalscopeå‹æµ‹\n\n#### evalscopeå®‰è£…\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/reasoning/vllm/image17.png)\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/reasoning/vllm/image18.png)\n\n#### å¯åŠ¨å‹æµ‹æœåŠ¡\n\n\n\n\n\n\n\n\n\n","tags":["NVIDIA","V100","æ¨¡å‹æ¨ç†","æ˜‡è…¾","910B","vllm+mindie"],"categories":["æ¨¡å‹æ¨ç†","vllm+mindie"]},{"title":"åŸºäºEasy-Datasetçš„å¾‹æ‰€æ•°æ®é›†å¤„ç†","url":"/2026/01/08/LLM/å®¢æˆ·æ”¯æ’‘/æŸå¾‹æ‰€å¤§æ¨¡å‹å¾®è°ƒ/åŸºäºEasy-Datasetçš„å¾‹æ‰€æ•°æ®é›†å¤„ç†/","content":"\n### ç¯å¢ƒ\n\n```bash\ngit clone https://github.com/ConardLi/easy-dataset.git\ncd easy-dataset\nnpm install\nnpm run build\nnpm run start\n```\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/law/easydataset/image1.png)\n\n### æ¨¡å‹æµ‹è¯•\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/law/easydataset/image2.png)\n\n\n\n\n\n","tags":["æ•°æ®é›†å¤„ç†","æ˜‡è…¾","910B","Easy-Dataset"],"categories":["æ•°æ®é›†å¤„ç†","Easy-Dataset"]},{"title":"åŸºäºllama-factoryçš„æ³•å¾‹æ¨¡å‹å¾®è°ƒ","url":"/2026/01/08/LLM/å®¢æˆ·æ”¯æ’‘/æŸå¾‹æ‰€å¤§æ¨¡å‹å¾®è°ƒ/åŸºäºllama-factoryçš„å¾‹æ‰€æ¨¡å‹å¾®è°ƒ/","content":"\n## æ•°æ®é›†\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/law/finetune/image1.png)\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/law/finetune/image2.png)\n\n## å¾®è°ƒ\n\n### lora\n\n#### deepseek-r1-distill-qwen-7b\n\n##### è®­ç»ƒ log\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/law/finetune/image3.png)\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/law/finetune/image4.png)\n\n##### loss æ›²çº¿\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/law/finetune/image5.png)\n\n##### lora ä¼˜åŒ–å™¨ä¸æƒé‡åˆå¹¶\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/law/finetune/image6.png)\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/law/finetune/image7.png)\n\n#### qwen3-8b\n\n##### è®­ç»ƒ log\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/law/finetune/image8.png)\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/law/finetune/image9.png)\n\n\n\n##### loss æ›²çº¿\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/law/finetune/image10.png)\n\n##### lora ä¼˜åŒ–å™¨ä¸æƒé‡åˆå¹¶\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/law/finetune/image11.png)\n\n<!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼š -->\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/llm/law/finetune/image12.png)\n\n## æ¨ç†\n\n\n\n","tags":["æ¨¡å‹å¾®è°ƒ","æ˜‡è…¾","910B","llama-factory"],"categories":["æ¨¡å‹å¾®è°ƒ","llama-factory"]},{"title":"2.1 æ•°æ®é›†å¤„ç†","url":"/2025/11/13/æ¨¡å‹è®­ç»ƒè°ƒä¼˜/NVIDIA/Deepseek-R1-Distill-Qwen-7b/2.1 Deepseek-7Bæ•°æ®é›†å¤„ç†/","content":"#### ä¸‹è½½åˆå§‹æ•°æ®é›†\n1. ä¸‹è½½WuDaoCorpora2.0å¼€æºæ•°æ®é›†åˆ°/mnt/workspace/llama3-datasetså·¥ä½œç›®å½•ä¸‹\n\n```bash\nwget https://atp-modelzoo.oss-cn-hangzhou.aliyuncs.com/release/datasets/WuDaoCorpus2.0_base_sample.tgz\ntar zxvf WuDaoCorpus2.0_base_sample.tgz \n```\n\n#### Megatron-LMé¢„è®­ç»ƒæ•°æ®æ¸…æ´—\nmmapæ•°æ®æ˜¯ä¸€ç§é¢„å…ˆæ‰§è¡Œtokenizeå¤„ç†çš„æ•°æ®æ ¼å¼ï¼Œå¯ä»¥æå¤§å‡å°‘è®­ç»ƒå¾®è°ƒè¿‡ç¨‹ä¸­ç­‰å¾…æ•°æ®è¯»å…¥çš„æ—¶é—´ï¼Œå½“æ•°æ®é‡æå¤§æ—¶ï¼Œä¼˜åŠ¿æ˜¾è‘—ã€‚\n\n```bash\n#! /bin/bash\nset -ex\n# è¯·åœ¨æ­¤å¤„è®¾ç½®åŸå§‹æ•°æ®æ‰€åœ¨è·¯å¾„\ndata_dir=/mnt/users/wangxiangbo/dataset/WuDaoCorpus2.0_base_sample\n\n#å¼€å§‹æ•°æ®æ¸…æ´—æµç¨‹\ndataset_dir=$(dirname $data_dir)\nmkdir -p ${dataset_dir}/cleaned_wudao_dataset\ncd ${dataset_dir}/cleaned_wudao_dataset\nwget https://atp-modelzoo-wlcb-pai.oss-cn-wulanchabu.aliyuncs.com/release/models/pai-megatron-patch/llama2-codes/preprocess_wudao2.py\n# æ­¤å¤„ä¸ä¸Šä¸€èŠ‚ä¸åŒï¼Œå¢åŠ äº†keyå‚æ•°è®¾ä¸ºtext\npython3 preprocess_wudao2.py -i ${data_dir} -o ${dataset_dir}/cleaned_wudao_dataset -k text -p 32\n\n# åˆå¹¶æ¸…æ´—åçš„æ•°æ®\nmkdir ${dataset_dir}/wudao\ncd ${dataset_dir}/wudao\nfind ${dataset_dir}/cleaned_wudao_dataset -name \"*.json\" -exec cat {} + > ${dataset_dir}/wudao/merged_wudao_cleaned.json\nrm -rf ${dataset_dir}/cleaned_wudao_dataset\n```\n\nè„šæœ¬æ‰§è¡Œå®Œæˆåï¼Œä¼šå¾—åˆ°ä¸€ä¸ªåˆå¹¶çš„jsonæ•°æ®é›†æ ¼å¼\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/deepseek/image1.png)\n\n#### æ‰§è¡Œä¸‹æ–¹çš„å¤„ç†æ•°æ®è„šæœ¬\n```bash\n#! /bin/bash\nSTART_TIME=$SECONDS\n\nMEGATRON_PATCH_PATH=/data/code\nMEGATRON_PATH=${MEGATRON_PATCH_PATH}/Megatron-LM\n\nexport PYTHONPATH=${MEGATRON_PATH}:${MEGATRON_PATCH_PATH}:$PYTHONPATH\n\ninput_data_dir=/mnt/dataset/wudao/merged_wudao_cleaned.json\ntokenizer=DeepseekTokenizer\njson_keys=text\noutput_data_dir=/data/code/temp/deepseek/deepseek-datasets\nload_dir=/data/code/temp/deepseek/deepseek-ckpt\nTOKENIZER_PATH=/data/code/temp/deepseek/deepseek-ckpt\n\nINPUT=\"${input_data_dir}\"\n\nif [ $tokenizer = \"Qwen2Tokenizer\" ]; then\n  python preprocess_data_megatron.py \\\n  --input ${INPUT} \\\n  --output-prefix ${output_data_dir}/mmap_qwen2_datasets \\\n  --patch-tokenizer-type Qwen2Tokenizer \\\n  --json-keys ${json_keys} \\\n  --load ${load_dir} \\\n  --workers 2 \\\n  --partitions 2 \\\n  --keep-sequential-samples \\\n  --append-eod\n\nelif [ $tokenizer = \"DeepSeekV2Tokenizer\" ]; then\n  python preprocess_data_megatron.py \\\n  --input ${INPUT} \\\n  --output-prefix ${output_data_dir}/mmap_deepseekv2_datasets \\\n  --patch-tokenizer-type DeepSeekV2Tokenizer \\\n  --json-keys ${json_keys} \\\n  --load ${load_dir} \\\n  --workers 8 \\\n  --partitions 1 \\\n  --keep-sequential-samples \\\n  --append-eod\n\nelif [ $tokenizer = \"LLamaTokenizer\" ]; then\n  python preprocess_data_megatron.py \\\n  --tokenizer-model $TOKENIZER_PATH \\\n  --input ${INPUT} \\\n  --output-prefix ${output_data_dir}/mmap_llama_datasets \\\n  --patch-tokenizer-type LLamaTokenizer \\\n  --load ${load_dir} \\\n  --workers 16 \\\n  --partitions 1 \\\n  --keep-sequential-samples \\\n  --append-eod\n\nelif [ $tokenizer = \"DeepseekTokenizer\" ]; then\n  python preprocess_data_megatron.py \\\n  --tokenizer-model $TOKENIZER_PATH \\\n  --input ${INPUT} \\\n  --output-prefix ${output_data_dir}/mmap_deepseek_datasets \\\n  --patch-tokenizer-type LLamaTokenizer \\\n  --load ${load_dir} \\\n  --workers 16 \\\n  --partitions 1 \\\n  --keep-sequential-samples \\\n  --append-eod\n\nelif [ $tokenizer = \"LLama2Tokenizer\" ]; then\n  python preprocess_data_megatron.py \\\n  --tokenizer-model $TOKENIZER_PATH \\\n  --extra-vocab-size 0 \\\n  --input ${INPUT} \\\n  --output-prefix ${output_data_dir}/mmap_llama2_datasets \\\n  --patch-tokenizer-type LLama2Tokenizer \\\n  --load ${load_dir} \\\n  --workers 16 \\\n  --partitions 1 \\\n  --keep-sequential-samples \\\n  --append-eod\n\nelif [ $tokenizer = \"LLama3Tokenizer\" ]; then\n  python preprocess_data_megatron.py \\\n  --input ${INPUT} \\\n  --output-prefix ${output_data_dir}/mmap_llama3_datasets \\\n  --patch-tokenizer-type LLama3Tokenizer \\\n  --load ${load_dir} \\\n  --workers 16 \\\n  --partitions 1 \\\n  --keep-sequential-samples \\\n  --append-eod\n\nfi\n\nELAPSED_TIME=$(($SECONDS - $START_TIME))\necho \"$(($ELAPSED_TIME/60)) min $(($ELAPSED_TIME%60)) sec\"\n```\n\nåœ¨python preprocess_data_megatron.pyä¸­ï¼ŒåŠ å…¥DeepseekTokenizerï¼Œæ­¤å¤–è¿˜éœ€è¦åœ¨/data/code/megatron_patch/tokenizer/__init__.pyä¸­åŠ å…¥DeepseekTokenizeré…ç½®ã€‚\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/deepseek/image2.png)\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/deepseek/image3.png)\n\n#### æ•°æ®å¤„ç†å®Œæˆ\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/deepseek/image4.png)\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/deepseek/image5.png)\n\n","tags":["V100","æ¨¡å‹é€‚é…","Nvidia","Deepseek","Megatron-LM"],"categories":["æ¨¡å‹é€‚é…","NVIDIA"]},{"title":"2.3 Deepseek-7Bæƒé‡è½¬æ¢","url":"/2025/11/13/æ¨¡å‹è®­ç»ƒè°ƒä¼˜/NVIDIA/Deepseek-R1-Distill-Qwen-7b/2.3 Deepseek-7Bæƒé‡è½¬æ¢/","content":"#### Hg-Coreæƒé‡è½¬æ¢\n##### huggingfaceå¼€æºæƒé‡å‡†å¤‡\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/deepseek/image17.png)\n\n##### æƒé‡è½¬æ¢è„šæœ¬\n```bash\n#!/bin/bash\n\nexport CUDA_VISIBLE_DEVICES=0\nexport CUDA_DEVICE_MAX_CONNECTIONS=1\nSTART_TIME=$SECONDS\nMASTER_ADDR=localhost\nMASTER_PORT=6666\n\nMODEL_SIZE=7B\nHG_CKPT_PATH=/mnt/model/deepseek-ai/deepseek-llm-7b-base\nMEGATRON_PATCH_PATH=/data/code/\nMEGATRON_PATH=${MEGATRON_PATCH_PATH}/Megatron-LM\nexport PYTHONPATH=${MEGATRON_PATH}:${MEGATRON_PATCH_PATH}:$PYTHONPATH\nSOURCE_CKPT_PATH=/mnt/model/deepseek-ai/deepseek-llm-7b-base\nTARGET_CKPT_PATH=/mnt/model/deepseek-ai/deepseek-llm-7b-core\nTP=4\nPP=1\nEXTRA_VOCAB_SIZE=2400\nNUM_EXPERTS=0\nEXPERTS_TOPK=0\nEP=0\nNUM_EXPERT_SPLITS=0\nmg2hf=false\n\nif [ $MODEL_SIZE = 7B ]; then\n\nNUM_LAYERS=30\nHIDDEN_SIZE=4096\nNUM_ATTN_HEADS=32\nINTERMEDIATE_SIZE=11008\nNUM_KV_HEADS=32\nVOCAB_SIZE=102400\nROPE_THETA=10000\nRMS_NORM_EPS=1e-6\ngqa_options=\"\"\n\nfi\n\nif [ $NUM_EXPERT_SPLITS -gt 0 ]; then\n\nINTERMEDIATE_SIZE=$(( ${INTERMEDIATE_SIZE} / ${NUM_EXPERT_SPLITS}))\n\nfi\n\nif [ $NUM_EXPERTS -gt 0 ]; then\n    expert_options=\"\n                --moe-router-topk ${EXPERTS_TOPK} \\\n                --num-experts ${NUM_EXPERTS} \\\n                --expert-model-parallel-size 1 \\\n                --target_expert_model_parallel_size ${EP} \\\n                --num_expert_split_size ${NUM_EXPERT_SPLITS} \\\n    \"\nfi\n\nif [ $mg2hf = true ]; then\n    convert_options=\"\n                --convert_checkpoint_from_megatron_to_transformers\n    \"\nelif [ $mg2hf = false ]; then\n    convert_options=\"\"\nfi\n\n\n\nDISTRIBUTED_ARGS=\"--nproc_per_node 1 --nnodes 1 --node_rank 0 --master_addr $MASTER_ADDR --master_port $MASTER_PORT\"\n\nif [ $MODEL_SIZE != 70B ]; then\n\ntorchrun ${DISTRIBUTED_ARGS} hf2mcore.py \\\n    --load_path ${SOURCE_CKPT_PATH} \\\n    --save_path ${TARGET_CKPT_PATH} \\\n    --tokenizer-model ${HG_CKPT_PATH} \\\n    --huggingface_model_path ${HG_CKPT_PATH} \\\n    --megatron-path ${MEGATRON_PATH} \\\n    --target_tensor_model_parallel_size ${TP} \\\n    --target_pipeline_model_parallel_size ${PP} \\\n    --micro-batch-size 1 \\\n    --fp16 \\\n    --swiglu \\\n    --num-layers ${NUM_LAYERS} \\\n    --hidden-size ${HIDDEN_SIZE} \\\n    --ffn-hidden-size ${INTERMEDIATE_SIZE} \\\n    --norm-epsilon ${RMS_NORM_EPS}\\\n    --num-attention-heads ${NUM_ATTN_HEADS} \\\n    --max-position-embeddings 4096 \\\n    --seq-length 1 \\\n    --no-async-tensor-model-parallel-allreduce \\\n    --patch-tokenizer-type DeepseekTokenizer \\\n    --extra-vocab-size ${EXTRA_VOCAB_SIZE} \\\n    --untie-embeddings-and-output-weights \\\n    --no-rope-fusion \\\n    --use-rotary-position-embeddings \\\n    --rotary-base ${ROPE_THETA} \\\n    --transformer-impl transformer_engine \\\n    --disable-bias-linear \\\n    --normalization RMSNorm \\\n    --use-mcore-models \\\n    --attention-dropout 0.0 \\\n    --hidden-dropout 0.0 \\\n    ${expert_options} \\\n    ${convert_options} \\\n    ${gqa_options}\n\nelse\npython hf2mcore_70b.py \\\n  --load ${HG_CKPT_PATH} \\\n  --megatron-path ${MEGATRON_PATH} \\\n  --load_path ${SOURCE_CKPT_PATH} \\\n  --save_path ${TARGET_CKPT_PATH} \\\n  --target_params_dtype bf16 \\\n  --target_tensor_model_parallel_size ${TP} \\\n  --target_pipeline_model_parallel_size ${PP} \\\n${convert_options} \\\n\nfi\n\nELAPSED_TIME=$(($SECONDS - $START_TIME))\necho \"$(($ELAPSED_TIME/60)) min $(($ELAPSED_TIME%60)) sec\"\n```\n\n##### tokenizeré…ç½®\nåœ¨/data/code/megatron_patch/tokenizer/__init__.pyä¸­åŠ å…¥Deepseeké…ç½®\n\n```python\nelif args.patch_tokenizer_type == 'DeepseekTokenizer':\n        from megatron.core.datasets.megatron_tokenizer import MegatronTokenizer\n        class _DeepseekTokenizer(MegatronTokenizer):\n            def __init__(self, tokenizer_path, extra_vocab_size):\n                super().__init__(tokenizer_path)\n                self.tokenizer = AutoTokenizer.from_pretrained(\n                    tokenizer_path,\n                    padding_side=\"right\",\n                    use_fast=False,\n                    trust_remote_code=True,\n                )\n                self.extra_vocab_size = extra_vocab_size\n\n            def __call__(self, text, return_tensors=None,\n                         padding=None, max_length=None, truncation=None, add_special_tokens=True):\n\n                return self.tokenizer(text, return_tensors=return_tensors, padding=padding,\n                        max_length=max_length, truncation=truncation, add_special_tokens=add_special_tokens)\n\n            @property\n            def vocab_size(self):\n                return self.tokenizer.vocab_size + self.extra_vocab_size\n\n            @property\n            def vocab(self):\n                return self.tokenizer.encoder\n\n            @property\n            def inv_vocab(self):\n                return self.tokenizer.decoder\n\n            def tokenize(self, text):\n                return self.tokenizer.encode(text)\n\n            def detokenize(self, token_ids):\n                return self.tokenizer.decode(token_ids)\n\n            @property\n            def eod(self):\n                return self.tokenizer.eos_token_id\n\n            @property\n            def eos_token(self):\n                return self.tokenizer.eos_token\n\n            @property\n            def pad_token_id(self):\n                return self.tokenizer.pad_token_id\n\n            @property\n            def eos_token_id(self):\n                return self.tokenizer.eos_token_id\n\n        tokenizer = _DeepseekTokenizer(args.tokenizer_model, args.extra_vocab_size)\n        # tokenizer = _DeepseekTokenizer(args.load, args.extra_vocab_size)\n        args.padded_vocab_size = tokenizer.vocab_size\n```\n\n##### hf2mcore.pyä¿®æ”¹\nåœ¨/data/code/toolkits/model_checkpoints_convertor/deepseek_core/hf2mcore.pyä¸­ä¿®æ”¹å¯¼åŒ…ä½ç½®\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/deepseek/image18.png)\n\n##### æ‰§è¡Œè½¬æ¢è„šæœ¬ï¼Œè½¬æ¢æµç¨‹\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/deepseek/image19.png)\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/deepseek/image20.png)\n\n##### è½¬æ¢ç»“æŸï¼Œå¾—åˆ°coreæƒé‡\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/deepseek/image21.png)\n\n#### coreæƒé‡çš„æ¨ç†ç»“æœéªŒè¯\n##### coreæƒé‡æ¨ç†ç»“æœ\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/deepseek/image22.png)\n\n##### huggingfaceæƒé‡æ¨ç†ç»“æœ\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/deepseek/image23.png)\n\n\n\n","tags":["V100","æ¨¡å‹é€‚é…","Nvidia","Deepseek","Megatron-LM"],"categories":["æ¨¡å‹é€‚é…","NVIDIA"]},{"title":"2.2 Deepseek-7Bé¢„è®­ç»ƒé€‚é…","url":"/2025/11/13/æ¨¡å‹è®­ç»ƒè°ƒä¼˜/NVIDIA/Deepseek-R1-Distill-Qwen-7b/2.2 Deepseek-7Bé¢„è®­ç»ƒé€‚é…/","content":"#### é¢„è®­ç»ƒç‰©æ–™åŠä»£ç å‡†å¤‡\n##### Deepseek-7Bçš„Tokenizerä¸‹è½½\nä½ç½®ä½äº/data/code/temp/deepseek/deepseek-ckpt\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/deepseek/image6.png)\n\n##### æ•°æ®é›†å‡†å¤‡\nä½ç½®ä½äº/data/code/temp/deepseek/deepseek-datasets\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/deepseek/image7.png)\n\n##### pretrain_mcore_deepseek.shé¢„è®­ç»ƒè„šæœ¬\n```bash\n\nexport NCCL_P2P_DISABLE=1\nexport NCCL_DEBUG=INFO\nexport NCCL_SOCKET_IFNAME=eth0\nexport GLOO_SOCKET_IFNAME=eth0\nexport CUDA_DEVICE_MAX_CONNECTIONS=1\nexport CUDA_VISIBLE_DEVICES=0,1,2,3\n\nMEGATRON_PATCH_PATH=/data/code \nMEGATRON_PATH=${MEGATRON_PATCH_PATH}/Megatron-LM\n\nexport PYTHONPATH=${MEGATRON_PATH}:${MEGATRON_PATCH_PATH}:$PYTHONPATH\n\nNNODES=2\nNODE_RANK=0\nGPUS_PER_NODE=4\nMASTER_ADDR=192.168.0.22\nMASTER_PORT=29500\n\nDISTRIBUTED_ARGS=\"--nproc_per_node $GPUS_PER_NODE --nnodes $NNODES --node_rank $NODE_RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\"\n\nMODEL_SIZE=7B\nBATCH_SIZE=1\nGLOBAL_BATCH_SIZE=8\nLR=1e-5\nMIN_LR=1e-6\nSEQ_LEN=1024\nPAD_LEN=1024\nEXTRA_VOCAB_SIZE=0\nPR=fp16\nTP=4\nPP=1\nAC=sel\nDO=true\nFL=false\nSP=true\nTE=true\nMOE=false\nSAVE_INTERVAL=1000\nDATASET_PATH=/data/code/temp/deepseek/deepseek-datasets/mmap_deepseek_datasets_text_document\n#PRETRAIN_CHECKPOINT_PATH=none\nTOKENIZER_PATH=/data/code/temp/deepseek/deepseek-ckpt\nTRAIN_TOKENS=10000000\nWARMUP_TOKENS=0\nOUTPUT_BASEPATH=/data/code/temp/output/deepseek/pretrain_output\n\nif [ $MODEL_SIZE = 7B ]; then\n\nNUM_LAYERS=32\nHIDDEN_SIZE=4096\nNUM_ATTN_HEADS=32\nINTERMEDIATE_SIZE=11008\nMAX_POSITION_EMBEDDINGS=4096\n\ngqa_options=\"\"\n\n\nfi\n\nif [ $AC = full ]; then\n    activation_checkpoint_options=\" \\\n\t\t    --recompute-method uniform \\\n\t\t    --recompute-granularity full\"\nelif [ $AC = sel ]; then\n    activation_checkpoint_options=\" \\\n        --recompute-activations\"\nelif [ $AC = none ]; then\n    activation_checkpoint_options=\" \\\n    \"\nfi\n\nif [ $PR = fp16 ]; then\n    pr_options=\" \\\n\t\t    --fp16 \\\n            --apply-query-key-layer-scaling\"\n    export NVTE_APPLY_QK_LAYER_SCALING=1\nelif [ $PR = bf16 ]; then\n    pr_options=\" \\\n        --bf16\"\nelif [ $PR = fp8 ]; then\n    pr_options=\" \\\n        --bf16 \\\n        --fp8-hybrid \\\n        --fp8-amax-compute-algo max \\\n        --fp8-amax-history-len 1024 \\\n        --transformer-impl transformer_engine\"\nfi\n\nif [ $DO = true ]; then\n    do_options=\" \\\n\t\t    --use-distributed-optimizer\"\n\nelif [ $DO = false ]; then\n    do_options=\" \\\n                    \"\nfi\n\nif [ $FL = true ]; then\n    flash_options=\" \\\n\t\t    --use-flash-attn\"\n\nelif [ $FL = false ]; then\n    flash_options=\" \\\n                    \"\nfi\n\nif [ $TE = true ]; then\n    te_options=\" \\\n\t\t    --transformer-impl transformer_engine\"\n\nelif [ $TE = false ]; then\n    te_options=\" \\\n                    \"\nfi\n\n\nif [ $MOE = true ]; then\n    moe_options=\" \\\n\t\t    --moe-router-topk 1 \\\n\t\t    --num-experts 4 \\\n\t\t    --expert-model-parallel-size 2\"\n\nelif [ $MOE = false ]; then\n    moe_options=\" \\\n                    \"\nfi\n\nif [ $SP = true ] && [ $TP -gt 1 ]; then\n    sp_options=\" \\\n\t\t    --sequence-parallel\"\n\nelif [ $SP = false ]; then\n    sp_options=\" \\\n                    \"\nfi\n\nif [ $PRETRAIN_CHECKPOINT_PATH != none ]; then\n    load_options=\" \\\n            --load $PRETRAIN_CHECKPOINT_PATH\"\nfi\n\nTRAIN_ITERS=$(( ${TRAIN_TOKENS} / ${GLOBAL_BATCH_SIZE} / ${SEQ_LEN} ))\nLR_WARMUP_ITERS=$(( ${WARMUP_TOKENS}  / ${GLOBAL_BATCH_SIZE} / ${SEQ_LEN} ))\nLR_DECAY_ITERS=$(( ${TRAIN_TOKENS} /  ${GLOBAL_BATCH_SIZE} / ${SEQ_LEN} ))\n\nNAME=\"${ENV}-pretrain-mcore-deepseek-${MODEL_SIZE}-lr-${LR}-bs-${BATCH_SIZE}-seqlen-${SEQ_LEN}-pr-${PR}-tp-${TP}-pp-${PP}-ac-${AC}-do-${DO}-sp-${SP}-moe-${MOE}-tt-${TRAIN_TOKENS}-wt-${WARMUP_TOKENS}\"\nmkdir -p \"${OUTPUT_BASEPATH}/tensorboard/\"\nmkdir -p \"${OUTPUT_BASEPATH}/checkpoint/\"\nmkdir -p \"${OUTPUT_BASEPATH}/log/\"\ncurrent_time=$(date \"+%Y.%m.%d-%H.%M.%S\")\nTENSORBOARD_DIR=\"${OUTPUT_BASEPATH}/tensorboard/${NAME}_${current_time}\"\nmkdir -p ${TENSORBOARD_DIR}\n\nSAVED_PRETRAIN_CHECKPOINT_PATH=\"${OUTPUT_BASEPATH}/checkpoint/${NAME}\"\n\nmegatron_options=\"  \\\n        --tokenizer-model $TOKENIZER_PATH \\\n        --save ${SAVED_PRETRAIN_CHECKPOINT_PATH} \\\n        --data-path ${DATASET_PATH} \\\n        --lr ${LR} \\\n        --min-lr ${MIN_LR} \\\n        --lr-decay-style linear \\\n        --adam-beta1 0.9 \\\n        --adam-beta2 0.95 \\\n        --weight-decay 0.1 \\\n        --clip-grad 1.0 \\\n        --init-method-std 0.006 \\\n        --attention-dropout 0.0 \\\n        --hidden-dropout 0.0  \\\n        --lr-decay-iters ${LR_DECAY_ITERS} \\\n        --lr-warmup-iters ${LR_WARMUP_ITERS} \\\n        --train-iters ${TRAIN_ITERS} \\\n        --split 99,1,0 \\\n        --micro-batch-size ${BATCH_SIZE} \\\n        --global-batch-size ${GLOBAL_BATCH_SIZE} \\\n        --num-layers ${NUM_LAYERS} \\\n        --hidden-size ${HIDDEN_SIZE} \\\n        --num-attention-heads ${NUM_ATTN_HEADS} \\\n        --ffn-hidden-size ${INTERMEDIATE_SIZE} \\\n        --seq-length ${SEQ_LEN} \\\n        --max-position-embeddings ${MAX_POSITION_EMBEDDINGS} \\\n        --max-padding-length ${PAD_LEN} \\\n        --log-throughput \\\n        --log-interval 1 \\\n        --eval-interval 10000 \\\n        --eval-iters 10 \\\n        --save-interval ${SAVE_INTERVAL} \\\n        --tensorboard-queue-size 1 \\\n        --tensorboard-dir ${TENSORBOARD_DIR} \\\n        --log-timers-to-tensorboard \\\n        --log-batch-size-to-tensorboard \\\n        --log-validation-ppl-to-tensorboard \\\n        --tensor-model-parallel-size ${TP} \\\n        --pipeline-model-parallel-size ${PP} \\\n        --no-load-optim \\\n        --no-load-rng \\\n        --num-workers 8 \\\n        --seed 1234 \\\n        --extra-vocab-size ${EXTRA_VOCAB_SIZE} \\\n        --patch-tokenizer-type DeepseekTokenizer \\\n        --dataset LLama-Pretrain-Idxmap \\\n        --swiglu \\\n        --normalization RMSNorm \\\n        --norm-epsilon 1e-05 \\\n        --use-rotary-position-embeddings \\\n        --no-rope-fusion \\\n        --position-embedding-type rope \\\n        --untie-embeddings-and-output-weights \\\n        --disable-bias-linear \\\n        --rotary-base 10000 \\\n        --use-mcore-models \n        \"\nLOG_SAVE=\"/data/code/temp/output/deepseek/pretrain_output/log/\"${current_time}-deepseek-${NODE_RANK}.log\"\" \nrun_cmd=\"torchrun $DISTRIBUTED_ARGS pretrain_mcore_deepseek.py\n ${megatron_options} ${pr_options} ${load_options} ${te_options} ${activation_checkpoint_options} ${do_options} ${flash_options} ${sp_options} ${gqa_options} ${moe_options} > ${LOG_SAVE} 2>&1\"\n\necho ${run_cmd}\neval ${run_cmd}\nset +x\n```\n\n##### pretrain_mcore_deepseek.pyè®­ç»ƒä»£ç \n```python\n# Copyright (c) 2023 Alibaba PAI and Nvidia Megatron-LM Team.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport os\nimport torch\nfrom torch import Tensor\nfrom functools import partial\nfrom typing import Union\n\nfrom megatron import get_args\nfrom megatron import get_timers\nfrom megatron.core import mpu, tensor_parallel\nfrom megatron.core.enums import ModelType\nimport megatron.model\nfrom megatron.utils import (\n    get_batch_on_this_tp_rank,\n    get_batch_on_this_cp_rank,\n    average_losses_across_data_parallel_group\n)\nfrom megatron.core.datasets.blended_megatron_dataset_builder import BlendedMegatronDatasetBuilder\nfrom megatron.training import pretrain\nfrom megatron.core.datasets.gpt_dataset import GPTDatasetConfig\nfrom megatron.core.datasets.gpt_dataset import GPTDataset\n# from megatron.core.models.gpt import GPTModel\nfrom megatron.core.transformer.spec_utils import import_module\nfrom megatron.arguments import core_transformer_config_from_args\n\nfrom megatron_patch.model.deepseek_core.model import GPTModel\nfrom megatron_patch.data import build_pretrain_dataset_from_original\nfrom megatron_patch.data.utils import get_batch_on_this_tp_rank_original\nfrom megatron_patch.tokenizer import get_tokenizer, build_tokenizer\nfrom megatron_patch.arguments import get_patch_args\nfrom megatron_patch.model.deepseek_core.transformer_config import DeepseekTransformerConfig\nfrom megatron_patch.model.deepseek_core.layer_specs import get_gpt_layer_with_transformer_engine_spec\n\nimport torch._dynamo\ntorch._dynamo.config.suppress_errors = True\n\ndef model_provider(\n    pre_process=True, post_process=True\n) -> Union[GPTModel, megatron.model.GPTModel]:\n    \"\"\"Builds the model.\n\n    If you set the use_mcore_models to True, it will return the mcore GPT model and if not the legacy GPT model.\n\n    Args:\n        pre_process (bool, optional): Set to true if you need to compute embedings. Defaults to True.\n        post_process (bool, optional): Set to true if you need to want to compute output logits/loss. Defaults to True.\n\n\n    Returns:\n        Union[GPTModel, megatron.model.GPTModel]: The returned model\n    \"\"\"\n    args = get_args()\n    build_tokenizer(args)\n    config = core_transformer_config_from_args(args, DeepseekTransformerConfig)\n    #config = core_transformer_config_from_args(get_args())\n    if args.use_mcore_models:\n        if args.spec is not None:\n            transformer_layer_spec = import_module(args.spec)\n        else:\n            transformer_layer_spec = get_gpt_layer_with_transformer_engine_spec(args.num_experts, args.moe_grouped_gemm)\n        model = GPTModel(\n            config=config,\n            transformer_layer_spec=transformer_layer_spec,\n            vocab_size=args.padded_vocab_size,\n            max_sequence_length=args.max_position_embeddings,\n            pre_process=pre_process,\n            post_process=post_process,\n            fp16_lm_cross_entropy=args.fp16_lm_cross_entropy,\n            parallel_output=True,\n            share_embeddings_and_output_weights=not args.untie_embeddings_and_output_weights,\n            position_embedding_type=args.position_embedding_type,\n            rotary_percent=args.rotary_percent,\n            rotary_base=args.rotary_base,\n        )\n    return model\n\n\ndef get_batch(data_iterator):\n    \"\"\"Generate a batch.\"\"\"\n\n    # TODO: this is pretty hacky, find a better way\n    if (not mpu.is_pipeline_first_stage()) and (not mpu.is_pipeline_last_stage()):\n        return None, None, None, None, None\n\n    args = get_args()\n\n    if \"-Raw\" in args.dataset:\n        # get batches based on the TP rank you are on\n        batch = get_batch_on_this_tp_rank_original(data_iterator)\n        # slice batch along sequence dimension for context parallelism\n        batch = get_batch_on_this_cp_rank(batch)\n\n    elif \"-Idxmap\" in args.dataset:\n        # get batches based on the TP rank you are on\n        batch = get_batch_on_this_tp_rank(data_iterator)\n        # slice batch along sequence dimension for context parallelism\n        batch = get_batch_on_this_cp_rank(batch)\n\n    else:\n        raise ValueError(\"please set correct --dataset \")\n\n    return batch.values()\n\n\ndef loss_func(loss_mask: Tensor, output_tensor: Tensor):\n    \"\"\"Loss function.\n\n    Args:\n        loss_mask (Tensor): Used to mask out some portions of the loss\n        output_tensor (Tensor): The tensor with the losses\n    \"\"\"\n    args = get_args()\n\n    losses = output_tensor.float()\n    loss_mask = loss_mask.view(-1).float()\n    if args.context_parallel_size > 1:\n        loss = torch.cat([torch.sum(losses.view(-1) * loss_mask).view(1), loss_mask.sum().view(1)])\n        torch.distributed.all_reduce(loss, group=mpu.get_context_parallel_group())\n        loss = loss[0] / loss[1]\n    else:\n        loss = torch.sum(losses.view(-1) * loss_mask) / loss_mask.sum()\n\n    # Check individual rank losses are not NaN prior to DP all-reduce.\n    if args.check_for_nan_in_loss_and_grad:\n        global_rank = torch.distributed.get_rank()\n        assert not loss.isnan(), (\n            f'Rank {global_rank}: found NaN in local forward loss calculation. '\n            f'Device: {torch.cuda.current_device()}, node: {os.uname()[1]}'\n        )\n\n    # Reduce loss for logging.\n    averaged_loss = average_losses_across_data_parallel_group([loss])\n\n    return loss * args.context_parallel_size, {'lm loss': averaged_loss[0]}\n\n\ndef forward_step(data_iterator, model):\n    \"\"\"Forward step.\"\"\"\n    timers = get_timers()\n\n    # Get the batch.\n    timers('batch-generator', log_level=2).start()\n    tokens, labels, loss_mask, attention_mask, position_ids = get_batch(\n        data_iterator)\n    timers('batch-generator').stop()\n\n    output_tensor = model(tokens, position_ids, attention_mask,\n                          labels=labels)\n\n    return output_tensor, partial(loss_func, loss_mask)\n\n\n\ndef is_dataset_built_on_rank():\n    return (mpu.is_pipeline_first_stage() or mpu.is_pipeline_last_stage()) and mpu.get_tensor_model_parallel_rank() == 0\n\ndef core_gpt_dataset_config_from_args(args):\n    tokenizer = get_tokenizer()\n    return GPTDatasetConfig(\n        is_built_on_rank=is_dataset_built_on_rank,\n        random_seed=args.seed,\n        sequence_length=args.seq_length,\n        blend=args.data_path,\n        split=args.split,\n        path_to_cache=args.data_cache_path,\n        reset_attention_mask=args.reset_attention_mask,\n        eod_mask_loss=args.eod_mask_loss,\n        eod_id=tokenizer.eod\n    )\n\ndef train_valid_test_datasets_provider(train_val_test_num_samples):\n    \"\"\"Build train, valid, and test datasets.\"\"\"\n    args = get_args()\n    if \"-Raw\" in args.dataset:\n                train_ds, valid_ds, test_ds = \\\n                                    build_pretrain_dataset_from_original(args.dataset)\n    else:\n        train_ds, valid_ds, test_ds = BlendedMegatronDatasetBuilder(\n            GPTDataset,\n            train_val_test_num_samples,\n            core_gpt_dataset_config_from_args(args)\n        ).build()\n\n    return train_ds, valid_ds, test_ds\n\n\n\nif __name__ == \"__main__\":\n    train_valid_test_datasets_provider.is_distributed = True\n    pretrain(\n        train_valid_test_datasets_provider,\n        model_provider,\n        ModelType.encoder_or_decoder,\n        forward_step,\n        extra_args_provider=get_patch_args,\n    )\n```\n\n##### åœ¨/data/code/megatron_patch/modelåœ¨åŠ å…¥deepseek_coreçš„ç›¸å…³é…ç½®\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/deepseek/image8.png)\n\n##### DeepseekTokenizeré…ç½®\nåœ¨/data/code/megatron_patch/tokenizer/__init__.pyä¸‹åŠ å…¥DeepseekTokenizeré…ç½®\n\n```python\nelif args.patch_tokenizer_type == 'DeepseekTokenizer':\n        from megatron.core.datasets.megatron_tokenizer import MegatronTokenizer\n        class _DeepseekTokenizer(MegatronTokenizer):\n            def __init__(self, tokenizer_path, extra_vocab_size):\n                super().__init__(tokenizer_path)\n                self.tokenizer = AutoTokenizer.from_pretrained(\n                    tokenizer_path,\n                    padding_side=\"right\",\n                    use_fast=False,\n                    trust_remote_code=True,\n                )\n                self.extra_vocab_size = extra_vocab_size\n\n            def __call__(self, text, return_tensors=None,\n                         padding=None, max_length=None, truncation=None, add_special_tokens=True):\n\n                return self.tokenizer(text, return_tensors=return_tensors, padding=padding,\n                        max_length=max_length, truncation=truncation, add_special_tokens=add_special_tokens)\n\n            @property\n            def vocab_size(self):\n                return self.tokenizer.vocab_size + self.extra_vocab_size\n\n            @property\n            def vocab(self):\n                return self.tokenizer.encoder\n\n            @property\n            def inv_vocab(self):\n                return self.tokenizer.decoder\n\n            def tokenize(self, text):\n                return self.tokenizer.encode(text)\n\n            def detokenize(self, token_ids):\n                return self.tokenizer.decode(token_ids)\n\n            @property\n            def eod(self):\n                return self.tokenizer.eos_token_id\n\n            @property\n            def eos_token(self):\n                return self.tokenizer.eos_token\n\n            @property\n            def pad_token_id(self):\n                return self.tokenizer.pad_token_id\n\n            @property\n            def eos_token_id(self):\n                return self.tokenizer.eos_token_id\n\n        tokenizer = _DeepseekTokenizer(args.tokenizer_model, args.extra_vocab_size)\n        args.padded_vocab_size = tokenizer.vocab_size\n```\n\n##### å¯åŠ¨é¢„è®­ç»ƒk8sçš„yaml\n```yaml\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: deepseek-core\n  namespace: deepseek\nspec:\n  selector:\n    matchLabels:\n      app: deepseek-core\n  template:\n    metadata:\n      labels:\n        app: deepseek-core\n    spec:\n      hostNetwork: true\n      nodeSelector:\n        deepseek: deepseek-7B  \n      containers:\n      - name: deepseek\n        image: registry.paas/cmss/nemo:24.05_v1.1\n        imagePullPolicy: IfNotPresent\n        resources:\n         limits:\n           nvidia.com/gpu: 4\n         requests:\n           nvidia.com/gpu: 4\n        command:\n              - \"/bin/bash\"\n              - \"-c\"\n              - |\n                cd /data/code/temp/conf/deepseek_core/pretrain &&\n                bash setRank.sh &&\n                cd /data/ &&\n                bash pretrain_mcore_deepseek.sh\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - mountPath: /data/code\n          name: code   \n        - mountPath: /etc/localtime\n          name: localtime\n        - mountPath: /dev/shm\n          name: dshm\n      volumes:\n      - name: code\n        hostPath:\n          path: /mnt/users/lihai/distribute/core/megatron-core\n      - name: localtime\n        hostPath:\n          path: /etc/localtime\n      - name: dshm\n        emptyDir:\n          medium: Memory\n          sizeLimit: 20G\n\n```\n\n##### setRank.sh\n```bash\n#!/bin/bash\n\norigin_shell=\"/data/code/examples/deepseek_core/pretrain_mcore_deepseek.sh\"\n\nconf_dir=\"/data/code/temp/conf/\"\n\nlocal_dir=\"/data/\"\n\nshell_name=pretrain_mcore_deepseek.sh\n\n## å¤åˆ¶è„šæœ¬åˆ°/workspaceä¸‹\ncp $origin_shell $local_dir\n\n\n## è¯»å–hostfile\nreadarray -t ips < <(grep -vE '^[[:space:]]*$' \"$conf_dir\"hostfile-67)\n\n## è·å–rank0 IP\nrank0_ip=$(echo \"${ips[0]}\" | tr -d '[:space:]')\n\nnodes=${#ips[@]}\n\n## è·å–hostfileä¸­é…ç½®çš„IPå‰ç¼€\n## ä½¿ç”¨cutæå–IPåœ°å€çš„å‰ä¸‰ä¸ªæ•°å­—éƒ¨åˆ†\nip_prefix=$(echo \"${ips[0]}\" | cut -d '.' -f 1-3)\n\n## è·å–æœ¬æœºIP\nip=$(hostname -I | grep -oE \"$ip_prefix\\.[0-9]+\")\n\n\n# åˆå§‹åŒ–rank\nnode_rank=-1\n\n# éå†æ•°ç»„\nfor i in \"${!ips[@]}\"; do\n    # ä½¿ç”¨trå‘½ä»¤å»é™¤ç©ºç™½å­—ç¬¦\n    clean_string=$(echo \"${ips[$i]}\" | tr -d '[:space:]')\n    if [[ \"$clean_string\" == \"$ip\" ]]; then\n        node_rank=$i\n        break\n    fi\ndone\n\nif [ $node_rank -ne -1 ]; then\n    ## ä¿®æ”¹è„šæœ¬ä¸­MASTER_ADDR\n    sed -i \"s/^MASTER_ADDR=.*/MASTER_ADDR=$rank0_ip/\" $local_dir$shell_name\n\n    ## ä¿®æ”¹NNODES\n    sed -i \"s/^NNODES=.*/NNODES=$nodes/\" $local_dir$shell_name\n\n    ## ä¿®æ”¹NODE_RANK\n    sed -i \"s/^NODE_RANK=.*/NODE_RANK=$node_rank/\" $local_dir$shell_name\nfi\n\n```\n\n#### å¤šæœºå¤šå¡æ‹‰èµ·æµ‹è¯•\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/deepseek/image9.png)\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/deepseek/image10.png)\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/deepseek/image11.png)\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/deepseek/image12.png)\n\n#### æ–­ç‚¹ç»­è®­æµ‹è¯•\n#### lossæ›²çº¿å¯¹æ¯”å®éªŒ\n##### patchæ¡†æ¶è®­ç»ƒä»£ç å‡†å¤‡\n###### patchçš„é¢„è®­ç»ƒyaml\n```yaml\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: deepseek-core\n  namespace: deepseek\nspec:\n  selector:\n    matchLabels:\n      app: deepseek-core\n  template:\n    metadata:\n      labels:\n        app: deepseek-core\n    spec:\n      hostNetwork: true\n      nodeSelector:\n        deepseek: deepseek-7B\n      containers:\n        - name: deepseek\n          image: registry.paas/library/megatron-lm:v1\n          imagePullPolicy: IfNotPresent\n          resources:\n            limits:\n              nvidia.com/gpu: 4\n            requests:\n              nvidia.com/gpu: 4\n          command:\n            - \"/bin/bash\"\n            - \"-c\"\n            - |\n              cd /data/code/examples/deepseek/conf && \n              bash setRank-patch.sh &&\n              cd /data/ &&\n              bash pretrain_patch_deepseek.sh\n          securityContext:\n            privileged: true\n          volumeMounts:\n            - mountPath: /data/code\n              name: code\n            - mountPath: /etc/localtime\n              name: localtime\n            - mountPath: /dev/shm\n              name: dshm\n      volumes:\n        - name: code\n          hostPath:\n            path: /mnt/users/wangxiangbo/Pai-Megatron-Patch\n        - name: localtime\n          hostPath:\n            path: /etc/localtime\n        - name: dshm\n          emptyDir:\n            medium: Memory\n            sizeLimit: 20G\n```\n\n###### patchçš„é¢„è®­ç»ƒè„šæœ¬\n```shell\n#!/bin/bash\n#sh run_pretrain_megatron_deepseek.sh dsw /workspace/Pai-Megatron-Patch 7B 1 8 1e-5 1e-6 2048 2048 0 bf16 1 1 sel true true true false 100000 /mnt/deepseek-datasets/wudao_llamabpe_text_document /mnt/deepseek-ckpts/Llama-2-7b-hf-to-mg-tp1-pp1/ 10000000000 100000000 /mnt/output_patch_test\nexport NCCL_P2P_DISABLE=1\n#export NCCL_DEBUG=INFO\nexport NCCL_SOCKET_IFNAME=eth0\nexport GLOO_SOCKET_IFNAME=eth0\nexport CUDA_DEVICE_MAX_CONNECTIONS=1\nexport CUDA_VISIBLE_DEVICES=0,1,2,3\n\nMEGATRON_PATCH_PATH=/data/code \nMEGATRON_PATH=${MEGATRON_PATCH_PATH}/Megatron-LM-231007\nexport PYTHONPATH=${MEGATRON_PATH}:${MEGATRON_PATCH_PATH}:$PYTHONPATH\n\nNNODES=2\nNODE_RANK=0\nGPUS_PER_NODE=4\nMASTER_ADDR=192.168.0.22\nMASTER_PORT=8889\n\n\n\nDISTRIBUTED_ARGS=\"--nproc_per_node $GPUS_PER_NODE --nnodes $NNODES --node_rank $NODE_RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\"\n\nMODEL_SIZE=7B\nBATCH_SIZE=1\nGLOBAL_BATCH_SIZE=8\nLR=1e-5\nMIN_LR=1e-6\nSEQ_LEN=1024\nPAD_LEN=1024\nEXTRA_VOCAB_SIZE=0\nPR=fp16\nTP=4\nPP=1\nAC=sel\nDO=true\nFL=false\nSP=true\nTE=false\nSAVE_INTERVAL=1000\nDATASET_PATH=/data/code/examples/deepseek/dataset/wudao_deepseekbpe_text_document\nPRETRAIN_CHECKPOINT_PATH=/data/code/examples/deepseek/ckpt\nTRAIN_TOKENS=10000000\nWARMUP_TOKENS=0\nOUTPUT_BASEPATH=/data/code/examples/deepseek/output/pretrain_output\n\n\nif [ $MODEL_SIZE = 7B ]; then\n\nNUM_LAYERS=30\nHIDDEN_SIZE=4096\nNUM_ATTN_HEADS=32\nINTERMEDIATE_SIZE=11008\n\ngqa_options=\"\"\n\n\nfi\n\nif [ $AC = full ]; then\n    activation_checkpoint_options=\" \\\n\t\t    --recompute-method uniform \\\n\t\t    --recompute-granularity full\"\nelif [ $AC = sel ]; then\n    activation_checkpoint_options=\" \\\n        --recompute-activations\"\nelif [ $AC = none ]; then\n    activation_checkpoint_options=\" \\\n                    \"\nfi\n\nif [ $PR = fp16 ]; then\n    pr_options=\" \\\n\t\t    --fp16\"\nelif [ $PR = bf16 ]; then\n    pr_options=\" \\\n        --bf16\"\nelif [ $PR = fp8 ]; then\n    pr_options=\" \\\n        --bf16\n        --fp8-hybrid \\\n        --fp8-amax-compute-algo max \\\n        --fp8-amax-history-len 1024 \\\n        --transformer-impl transformer_engine\"\nfi\n\nif [ $DO = true ]; then\n    do_options=\" \\\n\t\t    --use-distributed-optimizer\"\n\nelif [ $DO = false ]; then\n    do_options=\" \\\n                    \"\nfi\n\nif [ $FL = true ]; then\n    flash_options=\" \\\n\t\t    --use-flash-attn\"\n\nelif [ $FL = false ]; then\n    flash_options=\" \\\n                    \"\nfi\n\nif [ $TE = true ]; then\n    te_options=\" \\\n\t\t    --transformer-impl transformer_engine\"\n\nelif [ $TE = false ]; then\n    te_options=\" \\\n                    \"\nfi\n\nif [ $SP = true ] && [ $TP -gt 1 ]; then\n    sp_options=\" \\\n\t\t    --sequence-parallel\"\n\nelif [ $SP = false ]; then\n    sp_options=\" \\\n                    \"\nfi\n\nif [ $PRETRAIN_CHECKPOINT_PATH != none ]; then\n    load_options=\" \\\n            --load $PRETRAIN_CHECKPOINT_PATH\"\nfi\n\nTRAIN_ITERS=$(( ${TRAIN_TOKENS} / ${GLOBAL_BATCH_SIZE} / ${SEQ_LEN} ))\nLR_WARMUP_ITERS=$(( ${WARMUP_TOKENS}  / ${GLOBAL_BATCH_SIZE} / ${SEQ_LEN} ))\nLR_DECAY_ITERS=$(( ${TRAIN_TOKENS} /  ${GLOBAL_BATCH_SIZE} / ${SEQ_LEN} ))\n\nNAME=\"${ENV}-pretrain-patch-deepseek-${MODEL_SIZE}-lr-${LR}-bs-${BATCH_SIZE}-seqlen-${SEQ_LEN}-pr-${PR}-tp-${TP}-pp-${PP}-ac-${AC}-do-${DO}-sp-${SP}-tt-${TRAIN_TOKENS}-wt-${WARMUP_TOKENS}\"\nmkdir -p \"${OUTPUT_BASEPATH}/tensorboard/\"\nmkdir -p \"${OUTPUT_BASEPATH}/checkpoint/\"\nmkdir -p \"${OUTPUT_BASEPATH}/log/\"\ncurrent_time=$(date \"+%Y.%m.%d-%H.%M.%S\")\nTENSORBOARD_DIR=\"${OUTPUT_BASEPATH}/tensorboard/${NAME}_${current_time}\"\nmkdir -p ${TENSORBOARD_DIR}\n\nSAVED_PRETRAIN_CHECKPOINT_PATH=\"${OUTPUT_BASEPATH}/checkpoint/${NAME}\"\n\nmegatron_options=\"  \\\n        --save ${SAVED_PRETRAIN_CHECKPOINT_PATH} \\\n        --split 99,1,0 \\\n        --train-data-path ${DATASET_PATH}\n        --lr ${LR} \\\n        --min-lr ${MIN_LR} \\\n        --lr-decay-style linear \\\n        --adam-beta1 0.9 \\\n        --adam-beta2 0.95 \\\n        --weight-decay 0.1 \\\n        --clip-grad 1.0 \\\n        --init-method-std 0.006 \\\n        --lr-decay-iters ${LR_DECAY_ITERS} \\\n        --lr-warmup-iters ${LR_WARMUP_ITERS} \\\n        --train-iters ${TRAIN_ITERS} \\\n        --micro-batch-size ${BATCH_SIZE} \\\n        --global-batch-size ${GLOBAL_BATCH_SIZE} \\\n        --num-layers ${NUM_LAYERS} \\\n        --hidden-size ${HIDDEN_SIZE} \\\n        --num-attention-heads ${NUM_ATTN_HEADS} \\\n        --ffn-hidden-size ${INTERMEDIATE_SIZE} \\\n        --seq-length ${SEQ_LEN} \\\n        --max-position-embeddings ${SEQ_LEN} \\\n        --log-interval 1 \\\n        --eval-interval 10000 \\\n        --eval-iters 10 \\\n        --save-interval ${SAVE_INTERVAL} \\\n        --tensorboard-queue-size 1 \\\n        --tensorboard-dir ${TENSORBOARD_DIR} \\\n        --log-timers-to-tensorboard \\\n        --log-batch-size-to-tensorboard \\\n        --log-validation-ppl-to-tensorboard \\\n        --tensor-model-parallel-size ${TP} \\\n        --pipeline-model-parallel-size ${PP} \\\n        --dataset LLama-Pretrain-Idxmap \\\n        --no-load-optim \\\n        --no-load-rng \\\n        --num-workers 8 \\\n        --seed 1234 \\\n        --max-padding-length ${PAD_LEN} \\\n        --extra-vocab-size ${EXTRA_VOCAB_SIZE} \\\n        --patch-tokenizer-type LLamaTokenizer \\\n        --swiglu \\\n        --normalization RMSNorm \\\n        --use-llama2-rotary-position-embeddings \\\n        --position-embedding-type rope \\\n        --untie-embeddings-and-output-weights \\\n        --rotary-base 10000 \\\n        --rotary-scale-factor 4 \\\n        --loss-scale 16384 \\\n        --disable-bias-linear\n        \"\n#--no-query-key-layer-scaling \\\n#/data/code/examples/llama2/pretrain_megatron_llama.py\nLOG_SAVE=\"/data/code/examples/deepseek/output/pretrain_output/log/\"${current_time}-deepseek-patch-${NODE_RANK}.log\"\" \nrun_cmd=\"torchrun $DISTRIBUTED_ARGS /data/code/examples/llama2/pretrain_megatron_llama.py\n ${megatron_options} ${pr_options} ${load_options} ${te_options} ${activation_checkpoint_options} ${do_options} ${flash_options} ${sp_options} ${gqa_options} > ${LOG_SAVE} 2>&1\"\n\necho ${run_cmd}\neval ${run_cmd}\nset +x\n\n```\n\n###### patchçš„é¢„è®­ç»ƒsetrank\n```shell\n#!/bin/bash\n\norigin_shell=\"/data/code/examples/deepseek/pretrain_patch_deepseek.sh\"\n\nconf_dir=\"/data/code/examples/deepseek/conf/\"\n\nlocal_dir=\"/data/\"\n\nshell_name=pretrain_patch_deepseek.sh\n\n## å¤åˆ¶è„šæœ¬åˆ°/workspaceä¸‹\ncp $origin_shell $local_dir\n\n\n## è¯»å–hostfile\nreadarray -t ips < <(grep -vE '^[[:space:]]*$' \"$conf_dir\"hostfile)\n\n## è·å–rank0 IP\nrank0_ip=$(echo \"${ips[0]}\" | tr -d '[:space:]')\n\nnodes=${#ips[@]}\n\n## è·å–hostfileä¸­é…ç½®çš„IPå‰ç¼€\n## ä½¿ç”¨cutæå–IPåœ°å€çš„å‰ä¸‰ä¸ªæ•°å­—éƒ¨åˆ†\nip_prefix=$(echo \"${ips[0]}\" | cut -d '.' -f 1-3)\n\n## è·å–æœ¬æœºIP\nip=$(hostname -I | grep -oE \"$ip_prefix\\.[0-9]+\")\n\n\n# åˆå§‹åŒ–rank\nnode_rank=-1\n\n# éå†æ•°ç»„\nfor i in \"${!ips[@]}\"; do\n    # ä½¿ç”¨trå‘½ä»¤å»é™¤ç©ºç™½å­—ç¬¦\n    clean_string=$(echo \"${ips[$i]}\" | tr -d '[:space:]')\n    if [[ \"$clean_string\" == \"$ip\" ]]; then\n        node_rank=$i\n        break\n    fi\ndone\n\nif [ $node_rank -ne -1 ]; then\n    ## ä¿®æ”¹è„šæœ¬ä¸­MASTER_ADDR\n    sed -i \"s/^MASTER_ADDR=.*/MASTER_ADDR=$rank0_ip/\" $local_dir$shell_name\n\n    ## ä¿®æ”¹NNODES\n    sed -i \"s/^NNODES=.*/NNODES=$nodes/\" $local_dir$shell_name\n\n    ## ä¿®æ”¹NODE_RANK\n    sed -i \"s/^NODE_RANK=.*/NODE_RANK=$node_rank/\" $local_dir$shell_name\nfi\n```\n\n##### patchæ¡†æ¶é¢„è®­ç»ƒæµ‹è¯•\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/deepseek/image13.png)\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/deepseek/image14.png)\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/deepseek/image15.png)\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/deepseek/image16.png)\n\n","tags":["V100","æ¨¡å‹é€‚é…","Nvidia","Deepseek","Megatron-LM"],"categories":["æ¨¡å‹é€‚é…","NVIDIA"]},{"title":"A100é›†ç¾¤6æœº48å¡-åŸºäºk8sçš„Colossal-AI llama2 70Bè®­ç»ƒæ“ä½œæ–‡æ¡£","url":"/2025/11/13/æ¨¡å‹è®­ç»ƒè°ƒä¼˜/NVIDIA/Llama2/A100é›†ç¾¤6æœº48å¡-åŸºäºk8sçš„Colossal-AI llama2 70Bè®­ç»ƒæ“ä½œæ–‡æ¡£/","content":"<font style=\"color:#DF2A3F;background-color:#28d837;font-weight: bold;\">æ³¨ï¼šè¯¥é¡¹ç›®ä¸ºæœ¬äººæ”¯æ’‘å®¢æˆ·é¡¹ç›®ï¼Œæ–‡æ¡£å†…æ¶‰åŠåˆ°çš„å®¢æˆ·ã€è®¾å¤‡ä¿¡æ¯ç­‰å·²è„±æ•å¤„ç†ã€‚</font>\n### åŸºç¡€ç¯å¢ƒè¯´æ˜\n#### æ¦‚è¿°\næ¨¡å‹åç§°: Colossal-AI llama2 70B  \næ¨¡å‹å‚æ•°: 70Bå‚æ•°  \nç¡¬ä»¶éœ€æ±‚: 6å°æœåŠ¡å™¨ï¼Œæ¯å°æœåŠ¡å™¨é…å¤‡8å¼ NVIDIA A100 GPU\n\n#### ç¡¬ä»¶é…ç½®\nGPUå‹å·: NVIDIA A100  \nGPUæ•°é‡: 6å°æœåŠ¡å™¨ x 8å¼ /å° = 48å¼ GPU  \nå†…å­˜å®¹é‡: æ¯å¼ A100 GPUæ‹¥æœ‰80GBæ˜¾å­˜  \nCPU: Intel(R) Xeon(R) Gold 5218R CPU @ 2.10GHzï¼Œx86_64  \nå­˜å‚¨: é«˜é€ŸSSDå­˜å‚¨ï¼Œç”¨äºæ•°æ®è¯»å†™  \nç½‘ç»œ: é«˜é€Ÿç½‘ç»œè¿æ¥ï¼Œæ”¯æŒå¤šæœºè®­ç»ƒ\n\n#### GPUç¯å¢ƒè¯´æ˜\né©±åŠ¨ç‰ˆæœ¬: 470.141.03  \nCUDAç‰ˆæœ¬: CUDA 11.4  \nNvidia-smiç‰ˆæœ¬ï¼š470.141.03  \nNCCL: ç”¨äºå¤šGPUå’Œå¤šèŠ‚ç‚¹é€šä¿¡\næŒä¹…æ€§æ¨¡å¼: Persistence-Ml\nåŠŸç‡ä½¿ç”¨ä¸Šé™: åŠŸç‡ä¸Šé™ä¸º400W\næ˜¾å­˜ï¼šæ˜¾å­˜æ€»é‡ä¸º81920MiB (80GB)\n\n#### è½¯ä»¶ç¯å¢ƒ\næ“ä½œç³»ç»Ÿ: Linux (CentOS Linux 7 (Core))  \nPythonç‰ˆæœ¬: Python 3.8 æˆ–æ›´é«˜ç‰ˆæœ¬  \nä¾èµ–åº“:  \nPyTorch 2.1  \nColossal-AI: æ”¯æŒ70Bå‚æ•°æ¨¡å‹ç‰ˆæœ¬  \nå…¶ä»–ä¾èµ–: NumPy, SciPy, Pandasç­‰\n\n#### æ¨¡å‹å‚æ•°å¤§å°\nå‚æ•°æ€»æ•°: 70B  \næ¨¡å‹å ç”¨å†…å­˜: ç”±äºGPUæ˜¾å­˜å ç”¨ä¼šæ ¹æ®æ¨¡å‹çš„å‚æ•°é‡ã€æ¨¡å‹çš„å†…å­˜å ç”¨ã€è®­ç»ƒæ—¶çš„batch sizeã€å¹¶è¡Œä¼˜åŒ–æŠ€æœ¯ç­‰ä¸åŒè€Œå‘ç”Ÿå˜åŒ–ï¼Œ</font>ç°å‚æ•°æœªå®šï¼Œæš‚ä¸èƒ½é‡åŒ–GPUå ç”¨æƒ…å†µã€‚\n\n### æ¨¡å‹è®­ç»ƒæµç¨‹\n<font style=\"background-color:#c50e0e;\">æ³¨ï¼šç”±äºxxx.xx.xx.141æœºå™¨æ—¥å¸¸æœ‰ä¸šåŠ¡åœ¨è·‘ï¼Œæ— æ³•ç©ºé—²å‡ºå®Œæ•´çš„8å—gpuèµ„æºï¼Œæ•…ä»¥ä¸‹æœ€å¤šä»¥</font>**<font style=\"color:#cddf2a;background-color:#c50e0e;\">5æœº40å¡</font>**<font style=\"background-color:#c50e0e;\">æ¥æ‹‰èµ·è®­ç»ƒã€‚</font>\n\n#### æŸ¥çœ‹A100æœºå™¨çš„ipä¿¡æ¯\n`cat /root/a100.txt`\n\n#### æŸ¥çœ‹å¾…è®­ç»ƒèŠ‚ç‚¹çš„GPUå ç”¨æƒ…å†µ\né€šè¿‡137æœºå™¨ï¼Œåˆ†åˆ«sshè¿›å…¥ä»¥ä¸Š6å°æœºå™¨ï¼ˆå·²è®¾ç½®å…å¯†ç™»å½•ï¼‰ï¼ŒæŸ¥çœ‹å¯¹åº”æœºå™¨çš„gpuä½¿ç”¨æƒ…å†µ`nvidia-smi`ã€ç½‘å¡é…ç½®ä¿¡æ¯`ifconfig`ç­‰ã€‚\n\nç¤ºä¾‹ä¸€ï¼š\n\n`ssh root@xxx.xx.xx.141` sshè¿›å…¥æœºå™¨141\n\n`nvidia-smi`141æœºå™¨çš„gpuå·²ç»è¢«å ç”¨ï¼Œè‹¥æ˜¯æœ‰éœ€æ±‚è¦ä½¿ç”¨è¯¥æœºå™¨ï¼Œéœ€è¦æå‰æ²Ÿé€š\n\n`exit` ä»141æœºå™¨é€€å‡ºåˆ°137æœºå™¨ä¸Š\n\nç¤ºä¾‹äºŒï¼š\n\n`ssh root@xxx.xx.xx.78`\n\n`nvidia-smi` 78æœºå™¨çš„gpuæ²¡æœ‰è¢«ä½¿ç”¨ï¼Œå¯ä»¥è¿›è¡Œæ¨¡å‹è®­ç»ƒä»»åŠ¡\n\n#### ç‰©æ–™å‡†å¤‡å·¥ä½œ\n<font style=\"background-color:#c50e0e;\">æ‰€æœ‰çš„ç‰©æ–™ä½ç½®å­˜å‚¨åœ¨xxx.xx.xx137æœºå™¨ä¸Šçš„</font>`/home/disk_sdb0/llama2`<font style=\"background-color:#c50e0e;\">ä¸‹ã€‚</font>\n\nç‰©æ–™åŒ…å«åŸå§‹æ•°æ®é›†æ–‡ä»¶å¤¹`raw_data`ï¼Œç¦»çº¿åˆ‡åˆ†å®Œæˆçš„æ•°æ®é›†æ–‡ä»¶å¤¹`datas`ã€é•œåƒ`llama2-70b.tar`ã€70Bæ¨¡å‹æƒé‡`Llama-2-70b-hf`ã€13Bæ¨¡å‹æƒé‡`Llama-2-13b-hf`ã€7Bæ¨¡å‹æƒé‡`Llama-2-7b-hf`ã€k8sæ‹‰èµ·é¢„è®­ç»ƒçš„é…ç½®æ–‡ä»¶`llama2-70b-test.yaml`ã€k8sæ‹‰èµ·å¾®è°ƒè®­ç»ƒçš„é…ç½®æ–‡ä»¶`llama2-70b-finetune.yaml`ï¼Œé¢„è®­ç»ƒ/å¾®è°ƒçš„è®­ç»ƒä»£ç `train.py`ã€é¢„è®­ç»ƒçš„é…ç½®è„šæœ¬`train.example.sh`ã€å¾®è°ƒè®­ç»ƒçš„é…ç½®è„šæœ¬`finetune.example.sh`ã€èŠ‚ç‚¹ipçš„ä¿¡æ¯é…ç½®æ–‡ä»¶`hostfile.txt`ï¼Œæ­¤å¤–è¿˜éœ€è¦åˆ›å»ºä¸€ä¸ªç›®å½•`output`æ¥å­˜æ”¾è®­ç»ƒè¿‡ç¨‹ä¸­çš„è¾“å‡ºæ—¥å¿—åŠcheckpointä¿¡æ¯`mkdir output`ã€‚\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Llama2/image1.png)\n\n#### è®­ç»ƒç¯å¢ƒé…ç½®å‡†å¤‡\n##### /etc/hostsé…ç½®\n6å°æœºå™¨éƒ½éœ€è¦å¯¹`vim /etc/hosts`æ–‡ä»¶è¿›è¡Œä¿®æ”¹ï¼ŒåŠ å…¥å¯¹åº”çš„<font style=\"color:rgba(0, 0, 0, 0.85);\"> IP åœ°å€å’Œä¸å…¶å¯¹åº”çš„ä¸»æœºåæˆ–åŸŸåçš„æ˜ å°„å…³ç³»ï¼Œä»¥æ­¤ä¿è¯å„ä¸»æœºä¹‹é—´é€šä¿¡æ­£å¸¸ã€‚æ­¤å¤–ï¼Œè¿˜éœ€è¦åŠ å…¥ç™¾åº¦é•œåƒä»“åº“åœ°å€çš„ipæ˜ å°„ã€‚å¦åˆ™ä¼šæŠ¥socketé€šä¿¡é”™è¯¯ã€‚</font>\n\n<font style=\"color:#DF2A3F;background-color:#c50e0e;\">socket.gaierror: [Errno -2] Name or service not known</font>\n\n```plain\nxxx.xx.xx.103 xxx.xx.xx..baidu.com\nxxx.xx.xx137 xxx-xx-xx-xxx-137\nxxx.xx.xx.78 xxx-xx-xx-78.XXX-stack.com\nxxx.xx.xx.79 xxx-xx-xx-79.XXX-stack.com\nxxx.xx.xx.80 xxx-xx-xx-80.XXX-stack.com\nxxx.xx.xx.141 xxx-xx-xx-141.XXX-stack.com\nxxx.xx.xx.142 xxx-xx-xx-142.XXX-stack.com\nxxx.xx.xx.143 xxx-xx-xx-143.XXX-stack.com\n```\n\n##### k8så‘½åç©ºé—´åˆ›å»º\nå› ä¸ºæœªä½¿ç”¨ç™¾åº¦çš„æµ‹è¯•å¹³å°æ¥æ‹‰è®­ç»ƒï¼Œé€šè¿‡k8sæ¥æ‹‰èµ·ï¼Œæ‰€ä»¥éœ€è¦è‡ªå®šä¹‰ä¸€ä¸ª`namespace`ï¼Œå¹¶åœ¨æ”¹nsä¸‹å¯åŠ¨podæ‹‰èµ·è®­ç»ƒä»»åŠ¡ã€‚è¯¥nséœ€è¦ä¸`llama2-70b-test.yaml`ä¸­çš„`namespace: llama2-70b-test`å¯¹åº”ã€‚\n\n`kubectl create namespace llama2-70b-test`\n\n`kubectl get ns`\n\n##### é•œåƒpushè‡³ä»“åº“\né•œåƒéœ€pushåˆ°ç™¾åº¦æŒ‡å®šçš„ä»“åº“ä¸­\n\nå°†é•œåƒloadä¹‹åï¼Œå¹¶å°†é•œåƒpushè‡³ <font style=\"background-color:#c50e0e;\">xxx.xx.xx..baidu.com </font>ä»“åº“ä¸­ã€‚\n\n        1. `docker load -i llama2-70b.tar`\n        2. `docker images`\n        3. `docker tag 9cb8e972304f xxx.xx.xx..baidu.com/public/llama2-70b:v1.0`\n        4. `docker login xxx.xx.xx..baidu.com -u admin -p XXXXXXX`\n        5. `docker push xxx.xx.xx..baidu.com/public/llama2-70b:v1.0`\n\n#####   hostfileé…ç½®\né€šè¿‡sshç™»å½•åˆ°5å°æœºå™¨ï¼ŒæŸ¥çœ‹æ˜¯å¦æœ‰gpuå ç”¨ï¼Œæ‹‰èµ·è®­ç»ƒæ—¶è¦ä¿è¯èŠ‚ç‚¹çš„8ä¸ªgpuéƒ½æ²¡æœ‰è¢«å ç”¨ã€‚å°†ç©ºé—²çš„æœºå™¨bond4çš„ipå†™å…¥åˆ°hostfileä¸­ã€‚bond4çš„ipåœ°å€å¯ä»¥é€šè¿‡`ifconfig`æ¥è¿›è¡ŒæŸ¥çœ‹ï¼Œæœ‰çš„æœºå™¨ä½¿ç”¨çš„æ˜¯ä»¥å¤ªç½‘eth0çš„ipé…ç½®ã€‚\n\n```plain\nxxx.xx.xx.142\nxxx.xx.xx.143\nxxx.xx.xx.78\nxxx.xx.xx.79\nxxx.xx.xx.80\n```\n\n#####  è®­ç»ƒè„šæœ¬\nä¿®æ”¹é¢„è®­ç»ƒå¯åŠ¨çš„è„šæœ¬`train.example.sh`ï¼Œç½‘å¡çš„socketé€šä¿¡é…ç½®è¦ä¿®æ”¹ä¸ºbond4ï¼Œå¹¶åœ¨æ‹‰èµ·çš„è®­ç»ƒçš„èŠ‚ç‚¹ä¸­é€‰å–ä¸€ä¸ªä½œä¸ºmatserä¸»èŠ‚ç‚¹`--master_addr`\n\n```bash\n#!/bin/bash\n\n# NCCL IB environment variables\nexport NCCL_IB_HCA=mlx5_1:1,mlx5_2:1,mlx5_3:1,mlx5_4:1\nexport NCCL_IB_DISABLE=0\nexport NCCL_SOCKET_IFNAME=bond4\nexport NCCL_IB_GID_INDEX=3\nexport NCCL_IB_TIMEOUT=23\nexport NCCL_IB_RETRY_CNT=7\nexport OMP_NUM_THREADS=8\n\nPROJECT_NAME=\"llama2-70b-pt\"\nPARENT_SAVE_DIR=\"/opt/tmp/ColossalAI/output/save/\"\nPARENT_TENSORBOARD_DIR=\"/opt/tmp/ColossalAI/output/tensorboard/\"\nPARENT_CONFIG_FILE=\"/opt/tmp/ColossalAI/output/config/\"\nPRETRAINED_MODEL_PATH=\"/opt/tmp/ColossalAI/datas/weight/Llama-2-7b-hf\"\ndeclare -a dataset=(\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00000\"\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00001\"\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00002\"\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00003\"\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00004\"\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00005\"\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00006\"\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00007\"\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00008\"\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00009\"\n)\n\nTIMESTAMP=$(date +%Y-%m-%d-%H-%M-%S)\nFULL_PROJECT_NAME=\"${PROJECT_NAME}-${TIMESTAMP}\"\nSAVE_DIR=\"${PARENT_SAVE_DIR}${FULL_PROJECT_NAME}\"\nTENSORBOARD_DIR=\"${PARENT_TENSORBOARD_DIR}${FULL_PROJECT_NAME}\"\nCONFIG_FILE=\"${PARENT_CONFIG_FILE}${FULL_PROJECT_NAME}.json\"\n\ncolossalai run --nproc_per_node 8 --hostfile hostfile.txt --master_addr xxx.xx.xx.78 --master_port 30015 train.py \\\n    --pretrained $PRETRAINED_MODEL_PATH \\\n    --dataset ${dataset[@]} \\\n    --plugin \"gemini_auto\" \\\n    --save_interval 400 \\\n    --save_dir $SAVE_DIR \\\n    --tensorboard_dir $TENSORBOARD_DIR \\\n    --config_file $CONFIG_FILE \\\n    --num_epochs 1 \\\n    --micro_batch_size 1 \\\n    --lr 1e-4 \\\n    --mixed_precision \"fp16\" \\\n    --grad_clip 1.0 \\\n    --weight_decay 0.01 \\\n    --warmup_steps 100 \\\n    --use_grad_checkpoint \\\n    --max_length 4096 \\\n    --accumulation_steps 1 \\\n    --pad_token \"unk\"\n```\n\n#####  å¯åŠ¨k8sçš„yaml\nä¿®æ”¹k8sæ‹‰èµ·çš„é…ç½®æ–‡ä»¶`llama2-70b-test.yaml`\n\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: llama2-70b-test\n  name: llama2-70b-pt # Deployment çš„åç§°\nspec:\n  replicas: 2 # å‰¯æœ¬æ•°é‡\n  selector:\n    matchLabels:\n      app: llama2-70b-pt\n  template:\n    metadata:\n      labels:\n        app: llama2-70b-pt\n    spec:\n      hostNetwork: true\n      containers:\n      - name: llama2-70b-container # å®¹å™¨çš„åç§°\n        image: xxx.xx.xx..baidu.com/public/llama2-70b:v1.0\n        imagePullPolicy: IfNotPresent\n        command: [\"/bin/bash\", \"-c\"]\n        args: [\"cd /opt/tmp/ColossalAI/applications/Colossal-LLaMA/ && chmod +x start.sh && ./start.sh && chmod +x train.example.sh && ./train.example.sh\"] # å¯åŠ¨å®¹å™¨åæ‰§è¡Œçš„å‘½ä»¤ï¼Œåˆ‡æ¢ç›®å½•å¹¶è¿è¡Œè®­ç»ƒè„šæœ¬\n        resources:\n          limits:\n            nvidia.com/gpu: 8 # é™åˆ¶ä½¿ç”¨ 8 ä¸ª GPUï¼Œæ ¹æ®å®é™…æƒ…å†µè°ƒæ•´\n          requests:\n            nvidia.com/gpu: 8\n        volumeMounts:\n        - name: colossalai-orgdataset\n          mountPath: /opt/tmp/ColossalAI/datas/org_dataset # å°†å®¹å™¨å†…æ•°æ®ç›®å½•æŒ‚è½½\n        - name: colossalai-weight\n          mountPath: /opt/tmp/ColossalAI/datas/weight/Llama-2-7b-hf # å°†å®¹å™¨å†…æƒé‡ç›®å½•æŒ‚è½½\n        - name: colossalai-train\n          mountPath: /opt/tmp/ColossalAI/applications/Colossal-LLaMA/train.py\n          subPath: train.py\n          readOnly: true # è¡¨ç¤ºå°†æŒ‚è½½çš„æ–‡ä»¶è®¾ç½®ä¸ºåªè¯»æ¨¡å¼ï¼Œè¿™æ„å‘³ç€å®¹å™¨å†…çš„è¿›ç¨‹åªèƒ½è¯»å–æ–‡ä»¶ï¼Œè€Œä¸èƒ½ä¿®æ”¹å®ƒ\n        - name: colossalai-output\n          mountPath: /opt/tmp/ColossalAI/output # å°†å®¹å™¨å†…è¾“å‡ºç›®å½•æŒ‚è½½\n        - name: host-script\n          mountPath: /opt/tmp/ColossalAI/applications/Colossal-LLaMA/hostfile.txt  # å°†å®¹å™¨å†…hostfile\n          subPath: hostfile.txt\n          readOnly: true # è¡¨ç¤ºå°†æŒ‚è½½çš„æ–‡ä»¶è®¾ç½®ä¸ºåªè¯»æ¨¡å¼ï¼Œè¿™æ„å‘³ç€å®¹å™¨å†…çš„è¿›ç¨‹åªèƒ½è¯»å–æ–‡ä»¶ï¼Œè€Œä¸èƒ½ä¿®æ”¹å®ƒ\n        - name: train-script\n          mountPath: /opt/tmp/ColossalAI/applications/Colossal-LLaMA/train.example.sh  # å®¹å™¨å†…train_example.sh\n          subPath: train.example.sh\n        - name: shm-volume\n          mountPath: /dev/shm\n      nodeSelector:\n        model: llama2-70b\n      volumes:\n      - name: colossalai-orgdataset\n        hostPath:\n          path: /home/disk_sdb0/llama2/datas/org_dataset # å®¿ä¸»æœºä¸­ ColossalAI æ•°æ®çš„è·¯å¾„\n          type: Directory\n      - name: colossalai-weight\n        hostPath:\n          path: /home/disk_sdb0/llama2/Llama-2-70b-hf # å®¿ä¸»æœºä¸­ ColossalAI æƒé‡çš„è·¯å¾„\n          type: Directory\n      - name: colossalai-train\n        hostPath:\n          path: /home/disk_sdb0/llama2\n          type: Directory\n      - name: colossalai-output\n        hostPath:\n          path: /home/disk_sdb0/llama2/output # å®¿ä¸»æœºä¸­ ColossalAI è¾“å‡ºçš„è·¯å¾„\n          type: Directory\n      - name: host-script\n        hostPath:\n          path: /home/disk_sdb0/llama2 # å®¿ä¸»æœºä¸­åŒ…å«è®­ç»ƒè„šæœ¬çš„è·¯å¾„\n          type: Directory\n      - name: train-script\n        hostPath:\n          path: /home/disk_sdb0/llama2 # å®¿ä¸»æœºä¸­åŒ…å«è®­ç»ƒè„šæœ¬çš„è·¯å¾„\n          type: Directory\n      - name: shm-volume\n        emptyDir:\n          medium: Memory\n          sizeLimit: 8Gi\n```\n\n#####  nodeèŠ‚ç‚¹æ‰“æ ‡ç­¾\nç»™å¾…æ‹‰èµ·è®­ç»ƒçš„nodeæ‰“ä¸Šæ ‡ç­¾ï¼ˆé¦–å…ˆéœ€è¦ç¡®è®¤å¾…æ‹‰èµ·è®­ç»ƒçš„nodeçš„çŠ¶æ€æ˜¯å¦Readyï¼‰\n\næ‰“æ ‡ç­¾æ—¶ï¼Œå…¶ä¸­çš„model=llama2-70bå¯¹åº”çš„æ˜¯llama2-70b-test.yamlæ–‡ä»¶ä¸­çš„nodeSelectoréƒ¨åˆ†ï¼Œéœ€ä¿æŒä¸€è‡´ã€‚\n\n`kubectl label nodes xxx-xx-xx-141.XXX-stack.com model=llama2-70b`\n\n`kubectl label nodes xxx-xx-xx-142.XXX-stack.com model=llama2-70b`\n\n`kubectl label nodes xxx-xx-xx-143.XXX-stack.com model=llama2-70b`\n\n`kubectl label nodes xxx-xx-xx-78.XXX-stack.com model=llama2-70b`\n\n`kubectl label nodes xxx-xx-xx-79.XXX-stack.com model=llama2-70b`\n\n`kubectl label nodes xxx-xx-xx-80.XXX-stack.com model=llama2-70b`\n\n#####  è®­ç»ƒç‰©æ–™ä¼ è¾“ä¸åŒæ­¥\nå› ä¸ºå¤šæœºæ‹‰èµ·è®­ç»ƒæ—¶ï¼Œæ¯ä¸ªnodeèŠ‚ç‚¹éƒ½éœ€è¦æœ‰ä¸€ä»½è®­ç»ƒæ‰€éœ€çš„ç‰©æ–™ï¼ˆæƒé‡ã€æ•°æ®é›†ã€è®­ç»ƒè„šæœ¬ç­‰æ–‡ä»¶ï¼‰ï¼Œæ•…éœ€è¦é€šè¿‡`rsync`æˆ–`scp`å‘½ä»¤å°†137æœºå™¨ä¸Šçš„ç‰©æ–™æ–‡ä»¶ä¼ è¾“è‡³å¾…è®­ç»ƒçš„èŠ‚ç‚¹ä¸­ã€‚(é™¤å»å¯åŠ¨k8sæ‰€éœ€çš„`llama2-70b-test.yaml`é…ç½®æ–‡ä»¶è¦åœ¨matserä¸»èŠ‚ç‚¹ä¸Šï¼Œå…¶ä½™çš„æ‰€æœ‰ç‰©æ–™åœ¨å¾…è®­ç»ƒçš„nodeçš„åŒè·¯å¾„ä¸­`/home/disk_sdb0/llama2`éƒ½éœ€è¦åŒæ­¥æ‹·è´ä¸€ä»½)\n\n137èŠ‚ç‚¹ä¼ è¾“è‡³79èŠ‚ç‚¹çš„ç¤ºä¾‹ï¼š\n\n`scp -r /home/disk_sdb0/llama2/Llama-2-70b-hf root@xxx.xx.xx.79:/home/disk_sdb0/llama2/Llama-2-70b-hf`\n\n`scp -r /home/disk_sdb0/llama2/datas root@xxx.xx.xx.79:/home/disk_sdb0/llama2/datas`\n\n`scp -r /home/disk_sdb0/llama2/output root@xxx.xx.xx.79:/home/disk_sdb0/llama2/output`\n\n`scp -r /home/disk_sdb0/llama2/hostfile.txt root@xxx.xx.xx.79:/home/disk_sdb0/llama2`\n\n`scp -r /home/disk_sdb0/llama2/train.py root@xxx.xx.xx.79:/home/disk_sdb0/llama2`\n\n`scp -r /home/disk_sdb0/llama2/train.example.sh root@xxx.xx.xx.79:/home/disk_sdb0/llama2`\n\n#### è®­ç»ƒæ‹‰èµ·\næ‰“å®Œæ ‡ç­¾ä¹‹åï¼Œæ³¨æ„åˆ‡æ¢è‡³`cd /home/disk_sdb0/llama2`ï¼Œapplyå¯åŠ¨è®­ç»ƒè„šæœ¬ã€‚\n\n`kubectl apply -f llama2-70b-test.yaml` å¯åŠ¨yamlã€‚\n\n`kubectl get pod -n llama2-70b-test -owide` æŸ¥çœ‹nsä¸ºllama2-70b-testä¸‹çš„podä¿¡æ¯ã€‚\n\n`kubectl describe pod -n llama2-70b-test xxx` æŸ¥çœ‹æ¯ä¸ªæ­£åœ¨è¿è¡Œçš„podä¿¡æ¯ï¼Œç”¨æ¥è¿½è¸ªpodçš„è¿è¡ŒçŠ¶æ€ï¼Œçœ‹æ˜¯å¦æœ‰erroræŠ¥é”™ã€‚\n\n`kubectl logs xxx -n llama2-70b-test -f` å®æ—¶è·Ÿè¸ªpodçš„è®­ç»ƒæ—¥å¿—ï¼ˆæœ€ç»ˆçš„è®­ç»ƒæ—¥å¿—ä¼šåœ¨è®¾å®šçš„ä¸»èŠ‚ç‚¹masterä¸Šæ‰“å°ï¼‰ã€‚\n\n`kubectl delete -f llama2-70b-test.yaml`åˆ é™¤yamlåï¼Œå°†ç»ˆæ­¢è®­ç»ƒä»»åŠ¡ã€‚\n\n### æ¨¡å‹è®­ç»ƒæµ‹è¯•è®°å½•\n#### æŠ¥é”™è®°å½•\n##### nvidia driver ä¸ cudaç‰ˆæœ¬é—®é¢˜\nï¼ˆnvidia driver 470 å’Œ cuda11.4ç‰ˆæœ¬è¿‡ä½ï¼Œæ•…ä¸€ç›´è°ƒä¸åˆ°æœºå™¨GPUçš„èµ„æºï¼Œæ‰€ä»¥åœ¨å¹¶è¡Œç­–ç•¥zeroå’Œgeminiæ—¶å€™ä¼šå»è°ƒåº¦CPUçš„èµ„æºï¼Œç„¶åCPUæ’‘ä¸èµ·æ¥ï¼Œç›´æ¥å°±downæ‰äº†ï¼‰<font style=\"background-color:#c50e0e;\">è¯¥é”™è¯¯é€šè¿‡å‡çº§nvidia driverè‡³525.125.06ï¼Œcudaå‡çº§ä¸º12.0æ—¶ï¼Œé—®é¢˜è§£å†³ã€‚</font>\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Llama2/image2.png)\n\n##### dockerå®¹å™¨æ‹‰èµ·æµ‹è¯•é—®é¢˜\nå°è¯•é€šè¿‡è¯¥é•œåƒrunä¸€ä¸ªå®¹å™¨æ¥æµ‹è¯•ï¼Œç”±äºç¼ºå¤±<font style=\"color:#000000;\">nvidia-container-toolkitï¼Œåç»­å®‰è£…å®Œæˆåï¼Œå†æ¬¡runï¼Œå‘ç°--gpus all æœªèƒ½è°ƒç”¨ï¼ˆnvidiaé©±åŠ¨å¤ªä½å¯¼è‡´ï¼‰ã€‚å»æ‰--gpus allä¹‹åï¼Œå®¹å™¨å¯åŠ¨åï¼Œè¯†åˆ«ä¸åˆ°GPUã€‚</font>\n\n`dpkg -l | grep nvidia-container-toolkit` æŸ¥çœ‹æ˜¯å¦å®‰è£…äº†<font style=\"color:#000000;\">nvidia-container-toolkit</font>\n\n##### A100éœ€è¦nvidia-fabricmanageræ”¯æŒ\né©±åŠ¨å‡çº§å®Œæˆåï¼Œåœ¨xxx.xx.xx.78æœºå™¨ä¸Šå°è¯•æ‹‰èµ·å•æœº8å¡çš„llama2-7Bæ¨¡å‹çš„é¢„è®­ç»ƒï¼ŒæŠ¥äº†é”™è¯¯ç»æŸ¥é˜…èµ„æ–™åå‘ç°<font style=\"background-color:#c50e0e;\">A100éœ€è¦nvidia-fabricmanageræ”¯æŒï¼Œåç»­å®‰è£…å¯¹åº”nvidia driveré©±åŠ¨525.125.06ä¸€è‡´çš„nvidia-fabricmanageråæˆåŠŸæ‹‰èµ·è®­ç»ƒã€‚</font>\n\né”™è¯¯è§£å†³å‚è€ƒåšå®¢ï¼š[https://www.cnblogs.com/huadongw/p/16504137.html](https://www.cnblogs.com/huadongw/p/16504137.html)\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Llama2/image3.png)\n\nå•æœº8å¡çš„llama2-7Bçš„é¢„è®­ç»ƒæˆåŠŸæ‹‰èµ·\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Llama2/image4.png)\n\n##### 5æœº40å¡é¢„è®­ç»ƒæ—¶å­˜åœ¨æŸè¿›ç¨‹éšæœºå ç”¨gpuèµ„æºé—®é¢˜\nåœ¨æ‹‰èµ·5æœº40å¡æ—¶ï¼Œä¸€ç›´å­˜åœ¨ä¸€ä¸ªnsä¸ºsingle-gpuçš„podè¢«è°ƒåº¦å¹¶å ç”¨ä¸€ä¸ªgpuèµ„æºï¼ˆåˆ é™¤ä¹‹åä¼šéšæœºåœ¨6å°æœºå™¨ä¸Šå ç”¨ä¸€ä¸ªgpuï¼‰\n\n`kubectl describe node xxx-xx-xx-142.XXX-stack.com`æŸ¥çœ‹142èŠ‚ç‚¹æƒ…å†µ\n\næ­£å¸¸æƒ…å†µä¸‹ï¼Œä¸€å°æœºå™¨çš„8å°gpuéƒ½å¤„äºç©ºé—²çŠ¶æ€ä¸‹ï¼Œnvidia.com/gpuçš„å ç”¨åº”è¯¥æ˜¯0\n\n<font style=\"background-color:#c50e0e;\">è§£å†³æ–¹æ³•ï¼šåˆ é™¤æ‰å¯åŠ¨è¯¥podçš„å¯¹åº”çš„labelï¼ˆgpu-a100ï¼‰å¹¶åˆ é™¤æ‰è¯¥pod</font>\n\n`kubectl label nodes xxx-xx-xx-141.XXX-stack.com gpu-`\n\n`kubectl label nodes xxx-xx-xx-142.XXX-stack.com gpu-`\n\n`kubectl label nodes xxx-xx-xx-143.XXX-stack.com gpu-`\n\n`kubectl label nodes xxx-xx-xx-78.XXX-stack.com gpu-`\n\n`kubectl label nodes xxx-xx-xx-79.XXX-stack.com gpu-`\n\n`kubectl label nodes xxx-xx-xx-80.XXX-stack.com gpu-`\n\n#### è®­ç»ƒæ‹‰èµ·æµ‹è¯•\n##### é¢„è®­ç»ƒ\n###### llama2-13B 2æœº16å¡\n1. å¯åŠ¨k8sçš„yamlé…ç½®æ–‡ä»¶\n\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: llama2-70b-test\n  name: llama2-70b-pt # Deployment çš„åç§°\nspec:\n  replicas: 2 # å‰¯æœ¬æ•°é‡\n  selector:\n    matchLabels:\n      app: llama2-70b-pt\n  template:\n    metadata:\n      labels:\n        app: llama2-70b-pt\n    spec:\n      hostNetwork: true\n      containers:\n      - name: llama2-70b-container # å®¹å™¨çš„åç§°\n        image: xxx.xx.xx..baidu.com/public/llama2-70b:v1.0\n        imagePullPolicy: IfNotPresent\n        command: [\"/bin/bash\", \"-c\"]\n        args: [\"cd /opt/tmp/ColossalAI/applications/Colossal-LLaMA/ && chmod +x train.example.sh && ./train.example.sh\"] # å¯åŠ¨å®¹å™¨åæ‰§è¡Œçš„å‘½ä»¤ï¼Œåˆ‡æ¢ç›®å½•å¹¶è¿è¡Œè®­ç»ƒè„šæœ¬\n        resources:\n          limits:\n            nvidia.com/gpu: 8 # é™åˆ¶ä½¿ç”¨ 8 ä¸ª GPUï¼Œæ ¹æ®å®é™…æƒ…å†µè°ƒæ•´\n          requests:\n            nvidia.com/gpu: 8\n        volumeMounts:\n        - name: colossalai-weight\n          mountPath: /opt/tmp/ColossalAI/datas/weight/Llama-2-7b-hf # å°†å®¹å™¨å†…æƒé‡ç›®å½•æŒ‚è½½\n        - name: colossalai-train\n          mountPath: /opt/tmp/ColossalAI/applications/Colossal-LLaMA/train.py\n          subPath: train.py\n          readOnly: true # è¡¨ç¤ºå°†æŒ‚è½½çš„æ–‡ä»¶è®¾ç½®ä¸ºåªè¯»æ¨¡å¼ï¼Œè¿™æ„å‘³ç€å®¹å™¨å†…çš„è¿›ç¨‹åªèƒ½è¯»å–æ–‡ä»¶ï¼Œè€Œä¸èƒ½ä¿®æ”¹å®ƒ\n        - name: colossalai-output\n          mountPath: /opt/tmp/ColossalAI/output # å°†å®¹å™¨å†…è¾“å‡ºç›®å½•æŒ‚è½½\n        - name: host-script\n          mountPath: /opt/tmp/ColossalAI/applications/Colossal-LLaMA/hostfile.txt  # å°†å®¹å™¨å†…hostfile\n          subPath: hostfile.txt\n          readOnly: true # è¡¨ç¤ºå°†æŒ‚è½½çš„æ–‡ä»¶è®¾ç½®ä¸ºåªè¯»æ¨¡å¼ï¼Œè¿™æ„å‘³ç€å®¹å™¨å†…çš„è¿›ç¨‹åªèƒ½è¯»å–æ–‡ä»¶ï¼Œè€Œä¸èƒ½ä¿®æ”¹å®ƒ\n        - name: train-script\n          mountPath: /opt/tmp/ColossalAI/applications/Colossal-LLaMA/train.example.sh  # å®¹å™¨å†…train_example.sh\n          subPath: train.example.sh\n        - name: shm-volume\n          mountPath: /dev/shm\n      nodeSelector:\n        model: llama2-70b\n      volumes:\n      - name: colossalai-weight\n        hostPath:\n          path: /home/disk_sdb0/llama2/Llama-2-13b-hf # å®¿ä¸»æœºä¸­ ColossalAI æƒé‡çš„è·¯å¾„\n          type: Directory\n      - name: colossalai-train\n        hostPath:\n          path: /home/disk_sdb0/llama2\n          type: Directory\n      - name: colossalai-output\n        hostPath:\n          path: /home/disk_sdb0/llama2/output # å®¿ä¸»æœºä¸­ ColossalAI è¾“å‡ºçš„è·¯å¾„\n          type: Directory\n      - name: host-script\n        hostPath:\n          path: /home/disk_sdb0/llama2 # å®¿ä¸»æœºä¸­åŒ…å«è®­ç»ƒè„šæœ¬çš„è·¯å¾„\n          type: Directory\n      - name: train-script\n        hostPath:\n          path: /home/disk_sdb0/llama2 # å®¿ä¸»æœºä¸­åŒ…å«è®­ç»ƒè„šæœ¬çš„è·¯å¾„\n          type: Directory\n      - name: train-script\n        hostPath:\n          path: /home/disk_sdb0/llama2 # å®¿ä¸»æœºä¸­åŒ…å«è®­ç»ƒè„šæœ¬çš„è·¯å¾„\n          type: Directory\n      - name: shm-volume\n        emptyDir:\n          medium: Memory\n          sizeLimit: 8Gi\n```\n\n2. è®­ç»ƒè„šæœ¬\n\n```bash\n#!/bin/bash\n\n# NCCL IB environment variables\nexport NCCL_IB_HCA=mlx5_1:1,mlx5_2:1,mlx5_3:1,mlx5_4:1\nexport NCCL_IB_DISABLE=0\nexport NCCL_SOCKET_IFNAME=bond4\nexport NCCL_IB_GID_INDEX=3\nexport NCCL_IB_TIMEOUT=23\nexport NCCL_IB_RETRY_CNT=7\nexport OMP_NUM_THREADS=8\n\nPROJECT_NAME=\"llama2-70b-pt\"\nPARENT_SAVE_DIR=\"/opt/tmp/ColossalAI/output/save/\"\nPARENT_TENSORBOARD_DIR=\"/opt/tmp/ColossalAI/output/tensorboard/\"\nPARENT_CONFIG_FILE=\"/opt/tmp/ColossalAI/output/config/\"\nPRETRAINED_MODEL_PATH=\"/opt/tmp/ColossalAI/datas/weight/Llama-2-7b-hf\"\ndeclare -a dataset=(\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00000\"\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00001\"\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00002\"\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00003\"\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00004\"\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00005\"\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00006\"\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00007\"\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00008\"\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00009\"\n)\n\nTIMESTAMP=$(date +%Y-%m-%d-%H-%M-%S)\nFULL_PROJECT_NAME=\"${PROJECT_NAME}-${TIMESTAMP}\"\nSAVE_DIR=\"${PARENT_SAVE_DIR}${FULL_PROJECT_NAME}\"\nTENSORBOARD_DIR=\"${PARENT_TENSORBOARD_DIR}${FULL_PROJECT_NAME}\"\nCONFIG_FILE=\"${PARENT_CONFIG_FILE}${FULL_PROJECT_NAME}.json\"\n\ncolossalai run --nproc_per_node 8 --hostfile hostfile.txt --master_addr xxx.xx.xx.78 --master_port 30015 train.py \\\n    --pretrained $PRETRAINED_MODEL_PATH \\\n    --dataset ${dataset[@]} \\\n    --plugin \"gemini_auto\" \\\n    --save_interval 400 \\\n    --save_dir $SAVE_DIR \\\n    --tensorboard_dir $TENSORBOARD_DIR \\\n    --config_file $CONFIG_FILE \\\n    --num_epochs 1 \\\n    --micro_batch_size 8 \\\n    --lr 1e-4 \\\n    --mixed_precision \"fp16\" \\\n    --grad_clip 1.0 \\\n    --weight_decay 0.01 \\\n    --warmup_steps 100 \\\n    --use_grad_checkpoint \\\n    --max_length 512 \\\n    --accumulation_steps 1 \\\n    --pad_token \"unk\"\n```\n\n3. hostfile.txt\n\n```plain\nxxx.xx.xx.78\nxxx.xx.xx.79\n```\n\n4. è®­ç»ƒæ‹‰èµ·æˆªå›¾\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Llama2/image5.png)\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Llama2/image6.png)\n\n\n5. 78ï¼Œ79æ˜¾å­˜å ç”¨æƒ…å†µ\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Llama2/image7.png)\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Llama2/image8.png)\n\n###### llama2-70B 2æœº16å¡\n1. å‚æ•°é…ç½®\n\n| micro_batch_size | max_length | plugin | mixed_precision | tflops |\n| --- | --- | --- | --- | --- |\n| 8 | 512 | gemini_auto | fp16 | 64.4685 |\n\n\n2. å¯åŠ¨k8sçš„yamlé…ç½®æ–‡ä»¶\n\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: llama2-70b-test\n  name: llama2-70b-pt # Deployment çš„åç§°\nspec:\n  replicas: 2 # å‰¯æœ¬æ•°é‡\n  selector:\n    matchLabels:\n      app: llama2-70b-pt\n  template:\n    metadata:\n      labels:\n        app: llama2-70b-pt\n    spec:\n      hostNetwork: true\n      containers:\n      - name: llama2-70b-container # å®¹å™¨çš„åç§°\n        image: xxx.xx.xx..baidu.com/public/llama2-70b:v1.0\n        imagePullPolicy: IfNotPresent\n        command: [\"/bin/bash\", \"-c\"]\n        args: [\"cd /opt/tmp/ColossalAI/applications/Colossal-LLaMA/ && chmod +x train.example.sh && ./train.example.sh\"] # å¯åŠ¨å®¹å™¨åæ‰§è¡Œçš„å‘½ä»¤ï¼Œåˆ‡æ¢ç›®å½•å¹¶è¿è¡Œè®­ç»ƒè„šæœ¬\n        resources:\n          limits:\n            nvidia.com/gpu: 8 # é™åˆ¶ä½¿ç”¨ 4 ä¸ª GPUï¼Œæ ¹æ®å®é™…æƒ…å†µè°ƒæ•´\n          requests:\n            nvidia.com/gpu: 8\n        volumeMounts:\n        - name: colossalai-weight\n          mountPath: /opt/tmp/ColossalAI/datas/weight/Llama-2-7b-hf # å°†å®¹å™¨å†…æƒé‡ç›®å½•æŒ‚è½½\n        - name: colossalai-train\n          mountPath: /opt/tmp/ColossalAI/applications/Colossal-LLaMA/train.py\n          subPath: train.py\n          readOnly: true # è¡¨ç¤ºå°†æŒ‚è½½çš„æ–‡ä»¶è®¾ç½®ä¸ºåªè¯»æ¨¡å¼ï¼Œè¿™æ„å‘³ç€å®¹å™¨å†…çš„è¿›ç¨‹åªèƒ½è¯»å–æ–‡ä»¶ï¼Œè€Œä¸èƒ½ä¿®æ”¹å®ƒ\n        - name: colossalai-output\n          mountPath: /opt/tmp/ColossalAI/output # å°†å®¹å™¨å†…è¾“å‡ºç›®å½•æŒ‚è½½\n        - name: host-script\n          mountPath: /opt/tmp/ColossalAI/applications/Colossal-LLaMA/hostfile.txt  # å°†å®¹å™¨å†…hostfile\n          subPath: hostfile.txt\n          readOnly: true # è¡¨ç¤ºå°†æŒ‚è½½çš„æ–‡ä»¶è®¾ç½®ä¸ºåªè¯»æ¨¡å¼ï¼Œè¿™æ„å‘³ç€å®¹å™¨å†…çš„è¿›ç¨‹åªèƒ½è¯»å–æ–‡ä»¶ï¼Œè€Œä¸èƒ½ä¿®æ”¹å®ƒ\n        - name: train-script\n          mountPath: /opt/tmp/ColossalAI/applications/Colossal-LLaMA/train.example.sh  # å®¹å™¨å†…train_example.sh\n          subPath: train.example.sh\n        - name: profiler-script\n          mountPath: /opt/tmp/ColossalAI/applications/Colossal-LLaMA/performance_evaluator.py  # å®¹å™¨å†…train_example.sh\n          subPath: performance_evaluator.py\n        - name: shm-volume\n          mountPath: /dev/shm\n      nodeSelector:\n        model: llama2-70b\n      volumes:\n      - name: colossalai-weight\n        hostPath:\n          path: /home/disk_sdb0/llama2/Llama-2-70b-hf # å®¿ä¸»æœºä¸­ ColossalAI æƒé‡çš„è·¯å¾„\n          type: Directory\n      - name: colossalai-train\n        hostPath:\n          path: /home/disk_sdb0/llama2\n          type: Directory\n      - name: colossalai-output\n        hostPath:\n          path: /home/disk_sdb0/llama2/output # å®¿ä¸»æœºä¸­ ColossalAI è¾“å‡ºçš„è·¯å¾„\n          type: Directory\n      - name: host-script\n        hostPath:\n          path: /home/disk_sdb0/llama2 # å®¿ä¸»æœºä¸­åŒ…å«è®­ç»ƒè„šæœ¬çš„è·¯å¾„\n          type: Directory\n      - name: train-script\n        hostPath:\n          path: /home/disk_sdb0/llama2 # å®¿ä¸»æœºä¸­åŒ…å«è®­ç»ƒè„šæœ¬çš„è·¯å¾„\n          type: Directory\n      - name: profiler-script\n        hostPath:\n            path: /home/disk_sdb0/llama2 # å®¿ä¸»æœºä¸­åŒ…å«è®­ç»ƒè„šæœ¬çš„è·¯å¾„\n            type: Directory\n      - name: shm-volume\n        emptyDir:\n          medium: Memory\n          sizeLimit: 8Gi\n```\n\n3. è®­ç»ƒè„šæœ¬\n\n```bash\n#!/bin/bash\n\n# NCCL IB environment variables\nexport NCCL_IB_HCA=mlx5_1:1,mlx5_2:1,mlx5_3:1,mlx5_4:1\nexport NCCL_IB_DISABLE=0\nexport NCCL_SOCKET_IFNAME=bond4\nexport NCCL_IB_GID_INDEX=3\nexport NCCL_IB_TIMEOUT=23\nexport NCCL_IB_RETRY_CNT=7\nexport OMP_NUM_THREADS=8\n\nPROJECT_NAME=\"llama2-70b-pt\"\nPARENT_SAVE_DIR=\"/opt/tmp/ColossalAI/output/save/\"\nPARENT_TENSORBOARD_DIR=\"/opt/tmp/ColossalAI/output/tensorboard/\"\nPARENT_CONFIG_FILE=\"/opt/tmp/ColossalAI/output/config/\"\nPRETRAINED_MODEL_PATH=\"/opt/tmp/ColossalAI/datas/weight/Llama-2-7b-hf\"\ndeclare -a dataset=(\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00000\"\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00001\"\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00002\"\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00003\"\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00004\"\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00005\"\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00006\"\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00007\"\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00008\"\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00009\"\n)\n\nTIMESTAMP=$(date +%Y-%m-%d-%H-%M-%S)\nFULL_PROJECT_NAME=\"${PROJECT_NAME}-${TIMESTAMP}\"\nSAVE_DIR=\"${PARENT_SAVE_DIR}${FULL_PROJECT_NAME}\"\nTENSORBOARD_DIR=\"${PARENT_TENSORBOARD_DIR}${FULL_PROJECT_NAME}\"\nCONFIG_FILE=\"${PARENT_CONFIG_FILE}${FULL_PROJECT_NAME}.json\"\n\ncolossalai run --nproc_per_node 8 --hostfile hostfile.txt --master_addr xxx.xx.xx.78 --master_port 30015 train.py \\\n    --pretrained $PRETRAINED_MODEL_PATH \\\n    --dataset ${dataset[@]} \\\n    --plugin \"gemini_auto\" \\\n    --save_interval 400 \\\n    --save_dir $SAVE_DIR \\\n    --tensorboard_dir $TENSORBOARD_DIR \\\n    --config_file $CONFIG_FILE \\\n    --num_epochs 1 \\\n    --micro_batch_size 8 \\\n    --lr 1e-4 \\\n    --mixed_precision \"fp16\" \\\n    --grad_clip 1.0 \\\n    --weight_decay 0.01 \\\n    --warmup_steps 100 \\\n    --use_grad_checkpoint \\\n    --max_length 512 \\\n    --accumulation_steps 1 \\\n    --pad_token \"unk\"\n```\n\n4. hostfile.txt\n\n```plain\nxxx.xx.xx.78\nxxx.xx.xx.79\n```\n\n5. è®­ç»ƒæ‹‰èµ·æˆªå›¾\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Llama2/image9.png)\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Llama2/image10.png)\n\n6. 78ï¼Œ79æ˜¾å­˜å ç”¨æƒ…å†µ\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Llama2/image11.png)\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Llama2/image12.png)\n\n###### llama2-70B 5æœº40å¡\n1. é¢„è®­ç»ƒæ•°æ®é›†\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Llama2/image13.png)\n\nç”±äºæ¨¡å‹éœ€è¦å¯¹é€šè¿‡è„šæœ¬å¯¹rawåŸå§‹æ•°æ®é›†è¿›è¡Œåˆ‡åˆ†ï¼Œè¿™ä¸ªæ­¥éª¤ä¼šç‰¹åˆ«è€—æ—¶ï¼Œä¼šéšç€æ•°æ®é›†å¤§å°çš„å¢åŠ è€Œå¢åŠ åˆ‡åˆ†æ—¶é•¿ï¼Œç”±äºæ¯æ¬¡æ‹‰èµ·è®­ç»ƒæ—¶éƒ½éœ€è¦åˆ‡åˆ†å¹¶æ¶ˆè€—å¾ˆå¤šæ—¶é—´ï¼Œæ‰€ä»¥é‡‡ç”¨äº†<font style=\"background-color:#c50e0e;\">ç¦»çº¿åˆ‡åˆ†çš„æ–¹å¼å°†æ•°æ®é›†ç¦»çº¿åˆ‡åˆ†å¥½å¹¶ç›´æ¥æŒ‚è½½è¯»å–ä½¿ç”¨</font>ã€‚\n\n<font style=\"background-color:#c50e0e;\">ç¦»çº¿åˆ‡åˆ†å¥½çš„æ•°æ®é›†æ–‡ä»¶å…±211Gï¼Œå…¶ä¸­ä¼šå°†åŸå§‹æ•°æ®é›†åˆ‡åˆ†æˆ10ä»½å¹¶ä¸ºarrowæ ¼å¼æ–‡ä»¶</font>ã€‚\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Llama2/image14.png)\n\n2. å¯åŠ¨k8sçš„yamlé…ç½®æ–‡ä»¶\n\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: llama2-70b-test\n  name: llama2-70b-pt # Deployment çš„åç§°\nspec:\n  replicas: 5 # å‰¯æœ¬æ•°é‡\n  selector:\n    matchLabels:\n      app: llama2-70b-pt\n  template:\n    metadata:\n      labels:\n        app: llama2-70b-pt\n    spec:\n      hostNetwork: true\n      containers:\n      - name: llama2-70b-container # å®¹å™¨çš„åç§°\n        image: xxx.xx.xx..baidu.com/public/llama2-70b:v1.0\n        imagePullPolicy: IfNotPresent\n        command: [\"/bin/bash\", \"-c\"]\n        args: [\"cd /opt/tmp/ColossalAI/applications/Colossal-LLaMA/ && chmod +x train.example.sh && ./train.example.sh\"] # å¯åŠ¨å®¹å™¨åæ‰§è¡Œçš„å‘½ä»¤ï¼Œåˆ‡æ¢ç›®å½•å¹¶è¿è¡Œè®­ç»ƒè„šæœ¬\n        resources:\n          limits:\n            nvidia.com/gpu: 8 # é™åˆ¶ä½¿ç”¨ 8 ä¸ª GPUï¼Œæ ¹æ®å®é™…æƒ…å†µè°ƒæ•´\n          requests:\n            nvidia.com/gpu: 8\n        volumeMounts:\n        - name: colossalai-orgdataset\n          mountPath: /opt/tmp/ColossalAI/datas/org_dataset # å°†å®¹å™¨å†…æ•°æ®ç›®å½•æŒ‚è½½\n        - name: colossalai-predataset\n          mountPath: /opt/tmp/ColossalAI/datas/pre_dataset2\n        - name: colossalai-weight\n          mountPath: /opt/tmp/ColossalAI/datas/weight/Llama-2-7b-hf # å°†å®¹å™¨å†…æƒé‡ç›®å½•æŒ‚è½½\n        - name: colossalai-train\n          mountPath: /opt/tmp/ColossalAI/applications/Colossal-LLaMA/train.py\n          subPath: train.py\n          readOnly: true # è¡¨ç¤ºå°†æŒ‚è½½çš„æ–‡ä»¶è®¾ç½®ä¸ºåªè¯»æ¨¡å¼ï¼Œè¿™æ„å‘³ç€å®¹å™¨å†…çš„è¿›ç¨‹åªèƒ½è¯»å–æ–‡ä»¶ï¼Œè€Œä¸èƒ½ä¿®æ”¹å®ƒ\n        - name: colossalai-output\n          mountPath: /opt/tmp/ColossalAI/output # å°†å®¹å™¨å†…è¾“å‡ºç›®å½•æŒ‚è½½\n        - name: host-script\n          mountPath: /opt/tmp/ColossalAI/applications/Colossal-LLaMA/hostfile.txt  # å°†å®¹å™¨å†…hostfile\n          subPath: hostfile.txt\n          readOnly: true # è¡¨ç¤ºå°†æŒ‚è½½çš„æ–‡ä»¶è®¾ç½®ä¸ºåªè¯»æ¨¡å¼ï¼Œè¿™æ„å‘³ç€å®¹å™¨å†…çš„è¿›ç¨‹åªèƒ½è¯»å–æ–‡ä»¶ï¼Œè€Œä¸èƒ½ä¿®æ”¹å®ƒ\n        - name: train-script\n          mountPath: /opt/tmp/ColossalAI/applications/Colossal-LLaMA/train.example.sh  # å®¹å™¨å†…train_example.sh\n          subPath: train.example.sh\n        - name: shm-volume\n          mountPath: /dev/shm\n      nodeSelector:\n        model: llama2-70b\n      volumes:\n      - name: colossalai-orgdataset\n        hostPath:\n          path: /home/disk_sdb0/llama2/datas/org_dataset # å®¿ä¸»æœºä¸­ ColossalAI æ•°æ®çš„è·¯å¾„\n          type: Directory\n      - name: colossalai-predataset\n        hostPath:\n          path: /home/disk_sdb0/llama2/datas/pre_dataset2\n          type: Directory\n      - name: colossalai-weight\n        hostPath:\n          path: /home/disk_sdb0/llama2/Llama-2-70b-hf # å®¿ä¸»æœºä¸­ ColossalAI æƒé‡çš„è·¯å¾„\n          type: Directory\n      - name: colossalai-train\n        hostPath:\n          path: /home/disk_sdb0/llama2\n          type: Directory\n      - name: colossalai-output\n        hostPath:\n          path: /home/disk_sdb0/llama2/output # å®¿ä¸»æœºä¸­ ColossalAI è¾“å‡ºçš„è·¯å¾„\n          type: Directory\n      - name: host-script\n        hostPath:\n          path: /home/disk_sdb0/llama2 # å®¿ä¸»æœºä¸­åŒ…å«è®­ç»ƒè„šæœ¬çš„è·¯å¾„\n          type: Directory\n      - name: train-script\n        hostPath:\n          path: /home/disk_sdb0/llama2 # å®¿ä¸»æœºä¸­åŒ…å«è®­ç»ƒè„šæœ¬çš„è·¯å¾„\n          type: Directory\n      - name: profiler-script\n        hostPath:\n            path: /home/disk_sdb0/llama2 # å®¿ä¸»æœºä¸­åŒ…å«è®­ç»ƒè„šæœ¬çš„è·¯å¾„\n            type: Directory\n      - name: shm-volume\n        emptyDir:\n          medium: Memory\n          sizeLimit: 8Gi\n```\n\n3. è®­ç»ƒè„šæœ¬\n\n```bash\n#!/bin/bash\n\n# NCCL IB environment variables\nexport NCCL_IB_HCA=mlx5_1:1,mlx5_2:1,mlx5_3:1,mlx5_4:1\nexport NCCL_IB_DISABLE=0\nexport NCCL_SOCKET_IFNAME=bond4\nexport NCCL_IB_GID_INDEX=3\nexport NCCL_IB_TIMEOUT=23\nexport NCCL_IB_RETRY_CNT=7\nexport OMP_NUM_THREADS=8\n\nPROJECT_NAME=\"llama2-70b-pt\"\nPARENT_SAVE_DIR=\"/opt/tmp/ColossalAI/output/save/\"\nPARENT_TENSORBOARD_DIR=\"/opt/tmp/ColossalAI/output/tensorboard/\"\nPARENT_CONFIG_FILE=\"/opt/tmp/ColossalAI/output/config/\"\nPRETRAINED_MODEL_PATH=\"/opt/tmp/ColossalAI/datas/weight/Llama-2-7b-hf\"\ndeclare -a dataset=(\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00000\"\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00001\"\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00002\"\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00003\"\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00004\"\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00005\"\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00006\"\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00007\"\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00008\"\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00009\"\n)\n\nTIMESTAMP=$(date +%Y-%m-%d-%H-%M-%S)\nFULL_PROJECT_NAME=\"${PROJECT_NAME}-${TIMESTAMP}\"\nSAVE_DIR=\"${PARENT_SAVE_DIR}${FULL_PROJECT_NAME}\"\nTENSORBOARD_DIR=\"${PARENT_TENSORBOARD_DIR}${FULL_PROJECT_NAME}\"\nCONFIG_FILE=\"${PARENT_CONFIG_FILE}${FULL_PROJECT_NAME}.json\"\n\ncolossalai run --nproc_per_node 8 --hostfile hostfile.txt --master_addr xxx.xx.xx.142 --master_port 30015 train.py \\\n    --pretrained $PRETRAINED_MODEL_PATH \\\n    --dataset ${dataset[@]} \\\n    --plugin \"gemini_auto\" \\\n    --save_interval 1600 \\\n    --save_dir $SAVE_DIR \\\n    --tensorboard_dir $TENSORBOARD_DIR \\\n    --config_file $CONFIG_FILE \\\n    --num_epochs 1 \\\n    --micro_batch_size 16 \\\n    --lr 1e-4 \\\n    --mixed_precision \"fp16\" \\\n    --grad_clip 1.0 \\\n    --weight_decay 0.01 \\\n    --warmup_steps 100 \\\n    --use_grad_checkpoint \\\n    --max_length 512 \\\n    --accumulation_steps 1 \\\n    --pad_token \"unk\"\n```\n\n4. hostfile.txt\n\n```plain\nxxx.xx.xx.142\nxxx.xx.xx.143\nxxx.xx.xx.78\nxxx.xx.xx.79\nxxx.xx.xx.80\n```\n\n5. å‚æ•°é…ç½®è°ƒä¼˜\n\n| micro_batch_size | max_length | plugin | mixed_precision | tflops |\n| --- | --- | --- | --- | --- |\n| 1 | 512 | gemini_auto | fp16 | 10.8231 |\n| 2 | 512 | gemini_auto | fp16 | 20.4685 |\n| 4 | 512 | gemini_auto | fp16 | 45.6885 |\n| 8 | 512 | gemini_auto | fp16 | 78.6885 |\n| **16** | **512** | **gemini_auto** | **fp16** | **136.5975** |\n| 16 | 512  | zero2 | fp16 | OOM |\n| 16 | 512 | 3d | fp16 | OOM |\n| 1 | 1024 | gemini_auto | fp16 | OOM |\n| 4 | 2048 | gemini_auto | fp16 | OOM |\n| 16 | 1024 | gemini_auto | fp16 | OOM |\n\n\n6. è®­ç»ƒæ‹‰èµ·æˆªå›¾\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Llama2/image15.png)\n\næ€»ä½“step1519\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Llama2/image16.png)\n\n7. 142ï¼Œ143ï¼Œ78ï¼Œ79ï¼Œ80çš„GPUæ˜¾å­˜å ç”¨\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Llama2/image17.png)\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Llama2/image18.png)\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Llama2/image19.png)\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Llama2/image20.png)\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Llama2/image21.png)\n\n8. XXXå¹³å°ç›‘æ§\n\n6å°æœºå™¨çš„GPUæ€§èƒ½ç›‘æ§\næ¶‰åŠå®¢æˆ·ä¿¡æ¯ï¼Œå›¾ç‰‡ç•¥å»ã€‚\nå•æœºå™¨141çš„GPUæ€§èƒ½ç›‘æ§\næ¶‰åŠå®¢æˆ·ä¿¡æ¯ï¼Œå›¾ç‰‡ç•¥å»ã€‚\n\n9. æ–­ç‚¹ç»­è®­\n\n7.4æ—¥æ™šä¸Šç”±äº142ã€143ã€78ã€79ã€80äº”å°æœºå™¨çš„sshæ²¡æœ‰è®¾ç½®å…å¯†ç™»å½•ï¼Œæ¨¡å‹é¢„è®­ç»ƒè¿‡ç¨‹ä¸­åœ¨ä¸»èŠ‚ç‚¹142ä¿å­˜çš„checkpointæ–‡ä»¶ä¸èƒ½åŠæ—¶åŒæ­¥ç»™å…¶ä»–143ã€78ã€79ã€80å››ä¸ªèŠ‚ç‚¹ï¼Œæ•…å¯¼è‡´äº†è®­ç»ƒä¸­æ–­ï¼Œç°äº”å°æœºå™¨çš„sshå·²äº’ç›¸å…å¯†ï¼Œcheckpointä¿¡æ¯å¯ä»¥é€šè¿‡ä¸»èŠ‚ç‚¹142æ¥ä¸‹å‘å…±äº«ã€‚\n\nä¹‹åè®¾ç½®è¯»å–æ–­ç‚¹400æ­¥åä¿å­˜çš„checkpointä¸æƒé‡ä¿¡æ¯ï¼Œæ‹‰èµ·è®­ç»ƒæ—¶ä¼šä»ç¬¬400æ­¥å¼€å§‹ç»§ç»­è®­ç»ƒã€‚\n\nåŠ å…¥`--load_checkpoint $PARENT_LOAD_DIR \\`å‚æ•°ï¼Œè®¾å®šåŠ è½½çš„checkpointä½ç½®`PARENT_LOAD_DIR=\"/opt/tmp/ColossalAI/output/save/llama2-70b-pt-2024-07-03-14-11-44/epoch-0_step-400\"`\n\n```bash\n#!/bin/bash\n\n# NCCL IB environment variables\nexport NCCL_IB_HCA=mlx5_1:1,mlx5_2:1,mlx5_3:1,mlx5_4:1\nexport NCCL_IB_DISABLE=0\nexport NCCL_SOCKET_IFNAME=bond4\nexport NCCL_IB_GID_INDEX=3\nexport NCCL_IB_TIMEOUT=23\nexport NCCL_IB_RETRY_CNT=7\nexport OMP_NUM_THREADS=8\n\nPROJECT_NAME=\"llama2-70b-pt\"\nPARENT_SAVE_DIR=\"/opt/tmp/ColossalAI/output/save/\"\nPARENT_LOAD_DIR=\"/opt/tmp/ColossalAI/output/save/llama2-70b-pt-2024-07-03-14-11-44/epoch-0_step-400\"\nPARENT_TENSORBOARD_DIR=\"/opt/tmp/ColossalAI/output/tensorboard/\"\nPARENT_CONFIG_FILE=\"/opt/tmp/ColossalAI/output/config/\"\nPRETRAINED_MODEL_PATH=\"/opt/tmp/ColossalAI/datas/weight/Llama-2-7b-hf\"\ndeclare -a dataset=(\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00000\"\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00001\"\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00002\"\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00003\"\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00004\"\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00005\"\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00006\"\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00007\"\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00008\"\n    \"/opt/tmp/ColossalAI/datas/pre_dataset2/arrow/part-00009\"\n)\n\nTIMESTAMP=$(date +%Y-%m-%d-%H-%M-%S)\nFULL_PROJECT_NAME=\"${PROJECT_NAME}-${TIMESTAMP}\"\nSAVE_DIR=\"${PARENT_SAVE_DIR}${FULL_PROJECT_NAME}\"\nTENSORBOARD_DIR=\"${PARENT_TENSORBOARD_DIR}${FULL_PROJECT_NAME}\"\nCONFIG_FILE=\"${PARENT_CONFIG_FILE}${FULL_PROJECT_NAME}.json\"\n\ncolossalai run --nproc_per_node 8 --hostfile hostfile.txt --master_addr xxx.xx.xx.142 --master_port 30015 train.py \\\n    --pretrained $PRETRAINED_MODEL_PATH \\\n    --dataset ${dataset[@]} \\\n    --plugin \"gemini_auto\" \\\n    --save_interval 1600 \\\n    --save_dir $SAVE_DIR \\\n    --load_checkpoint $PARENT_LOAD_DIR \\\n    --tensorboard_dir $TENSORBOARD_DIR \\\n    --config_file $CONFIG_FILE \\\n    --num_epochs 1 \\\n    --micro_batch_size 16 \\\n    --lr 1e-4 \\\n    --mixed_precision \"fp16\" \\\n    --grad_clip 1.0 \\\n    --weight_decay 0.01 \\\n    --warmup_steps 100 \\\n    --use_grad_checkpoint \\\n    --max_length 512 \\\n    --accumulation_steps 1 \\\n    --pad_token \"unk\"\n```\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Llama2/image22.png)\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Llama2/image23.png)\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Llama2/image24.png)\n\n8. é¢„è®­ç»ƒç»“æŸ\n\nç»“æŸåä¼šåœ¨è®¾å®šçš„ä¸»èŠ‚ç‚¹142ä¸Šç”Ÿæˆå¯¹åº”æƒé‡æ–‡ä»¶\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Llama2/image25.png)\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Llama2/image26.png)\n\n\n#####  å¾®è°ƒ\n###### llama2-70B 5æœº40å¡\n1. æ•°æ®é›†å‡†å¤‡\n\nå¾®è°ƒæ•°æ®é›†å‚ç…§Colossalaiå®˜ç½‘è¦æ±‚çš„æ•°æ®å¯¹è¯æ ¼å¼è¿›è¡Œå‡†å¤‡\n\næ•°æ®æ ·å¼\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Llama2/image27.png)\n\næ•°æ®é›†çš„ç¦»çº¿åˆ‡åˆ†ï¼Œéœ€è¦é€šè¿‡kubectlè¿›å…¥podå†…æ‰§è¡Œåˆ‡åˆ†è„šæœ¬`prepare_sft_dataset.py`è¿›è¡Œåˆ‡åˆ†\n\n```bash\n#!/bin/bash\npython3 prepare_sft_dataset.py \\\n--data_input_dirs \"/opt/tmp/ColossalAI/applications/Colossal-LLaMA/data\" \\\n--tokenizer_dir \"/opt/tmp/ColossalAI/datas/weight/Llama-2-7b-hf\" \\\n--data_output_dirs \"/opt/tmp/ColossalAI/applications/Colossal-LLaMA/sftdata\" \\\n--max_length 4096 \\\n--num_spliced_dataset_bins 10 \\\n--llama_version 2\n```\n\næ‰§è¡Œåˆ‡åˆ†è„šæœ¬åï¼Œå¼€å§‹è¿›è¡Œåˆ‡åˆ†ï¼Œä¼šå°†åŸå§‹æ•°æ®é›†æ ¼å¼jsonlè½¬ä¸ºarrowæ ¼å¼\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Llama2/image28.png)\n\n`tar -cvf sftdata.tar sftdata` å‹ç¼©åˆ‡åˆ†å¥½çš„æ•°æ®é›†sftdata\n\n`kubectl cp llama2-70b-test/llama2-70b-pt-f5877d7c9-n7448:/opt/tmp/ColossalAI/applications/Colossal-LLaMA/sftdata.tar /home/disk_sdb0/llama2/sftdata.tar`é€šè¿‡`kubectl cp`å°†å‹ç¼©å¥½çš„sftdata.tarä¼ è¾“è‡³å®¿ä¸»æœº137ä¸Š\n\n`tar -xvf sftdata.tar`è§£å‹\n\nåˆ‡åˆ†å¥½çš„æ•°æ®é›†ä¸º52G\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Llama2/image29.png)\n\n2. å¯åŠ¨k8sçš„yamlçš„é…ç½®æ–‡ä»¶\n\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: llama2-70b-test\n  name: llama2-70b-pt # Deployment çš„åç§°\nspec:\n  replicas: 5 # å‰¯æœ¬æ•°é‡\n  selector:\n    matchLabels:\n      app: llama2-70b-pt\n  template:\n    metadata:\n      labels:\n        app: llama2-70b-pt\n    spec:\n      hostNetwork: true\n      containers:\n      - name: llama2-70b-container # å®¹å™¨çš„åç§°\n        image: xxx.xx.xx..baidu.com/public/llama2-70b:v1.0\n        imagePullPolicy: IfNotPresent\n        command: [\"/bin/bash\", \"-c\"]\n        args: [\"cd /opt/tmp/ColossalAI/applications/Colossal-LLaMA/ && chmod +x finetune.example.sh && ./finetune.example.sh\"] # å¯åŠ¨å®¹å™¨åæ‰§è¡Œçš„å‘½ä»¤ï¼Œåˆ‡æ¢ç›®å½•å¹¶è¿è¡Œè®­ç»ƒè„šæœ¬\n        resources:\n          limits:\n            nvidia.com/gpu: 8 # é™åˆ¶ä½¿ç”¨ 8 ä¸ª GPUï¼Œæ ¹æ®å®é™…æƒ…å†µè°ƒæ•´\n          requests:\n            nvidia.com/gpu: 8\n        volumeMounts:\n        - name: colossalai-sftdataset\n          mountPath: /opt/tmp/ColossalAI/datas/sftdata\n        - name: colossalai-weight\n          mountPath: /opt/tmp/ColossalAI/datas/weight/Llama-2-7b-hf # å°†å®¹å™¨å†…æƒé‡ç›®å½•æŒ‚è½½\n        - name: colossalai-train\n          mountPath: /opt/tmp/ColossalAI/applications/Colossal-LLaMA/train.py\n          subPath: train.py\n          readOnly: true # è¡¨ç¤ºå°†æŒ‚è½½çš„æ–‡ä»¶è®¾ç½®ä¸ºåªè¯»æ¨¡å¼ï¼Œè¿™æ„å‘³ç€å®¹å™¨å†…çš„è¿›ç¨‹åªèƒ½è¯»å–æ–‡ä»¶ï¼Œè€Œä¸èƒ½ä¿®æ”¹å®ƒ\n        - name: colossalai-output\n          mountPath: /opt/tmp/ColossalAI/output # å°†å®¹å™¨å†…è¾“å‡ºç›®å½•æŒ‚è½½\n        - name: host-script\n          mountPath: /opt/tmp/ColossalAI/applications/Colossal-LLaMA/hostfile.txt  # å°†å®¹å™¨å†…hostfile\n          subPath: hostfile.txt\n          readOnly: true # è¡¨ç¤ºå°†æŒ‚è½½çš„æ–‡ä»¶è®¾ç½®ä¸ºåªè¯»æ¨¡å¼ï¼Œè¿™æ„å‘³ç€å®¹å™¨å†…çš„è¿›ç¨‹åªèƒ½è¯»å–æ–‡ä»¶ï¼Œè€Œä¸èƒ½ä¿®æ”¹å®ƒ\n        - name: finetune-script\n          mountPath: /opt/tmp/ColossalAI/applications/Colossal-LLaMA/finetune.example.sh  # å®¹å™¨å†…finetune.example.sh\n          subPath: finetune.example.sh\n        - name: shm-volume\n          mountPath: /dev/shm\n      nodeSelector:\n        model: llama2-70b\n      volumes:\n      - name: colossalai-sftdataset\n        hostPath:\n          path: /home/disk_sdb0/llama2/datas/sftdata\n          type: Directory\n      - name: colossalai-weight\n        hostPath:\n          path: /home/disk_sdb0/llama2/Llama-2-70b-hf # å®¿ä¸»æœºä¸­ ColossalAI æƒé‡çš„è·¯å¾„\n          type: Directory\n      - name: colossalai-train\n        hostPath:\n          path: /home/disk_sdb0/llama2\n          type: Directory\n      - name: colossalai-output\n        hostPath:\n          path: /home/disk_sdb0/llama2/output # å®¿ä¸»æœºä¸­ ColossalAI è¾“å‡ºçš„è·¯å¾„\n          type: Directory\n      - name: host-script\n        hostPath:\n          path: /home/disk_sdb0/llama2 # å®¿ä¸»æœºä¸­åŒ…å«è®­ç»ƒè„šæœ¬çš„è·¯å¾„\n          type: Directory\n      - name: finetune-script\n        hostPath:\n          path: /home/disk_sdb0/llama2 # å®¿ä¸»æœºä¸­åŒ…å«è®­ç»ƒè„šæœ¬çš„è·¯å¾„\n          type: Directory\n      - name: shm-volume\n        emptyDir:\n          medium: Memory\n          sizeLimit: 8Gi\n```\n\n3. å¾®è°ƒè„šæœ¬\n\n```bash\n#!/bin/bash\n\n# NCCL IB environment variables\nexport NCCL_IB_HCA=mlx5_1:1,mlx5_2:1,mlx5_3:1,mlx5_4:1\nexport NCCL_IB_DISABLE=0\nexport NCCL_SOCKET_IFNAME=bond4\nexport NCCL_IB_GID_INDEX=3\nexport NCCL_IB_TIMEOUT=23\nexport NCCL_IB_RETRY_CNT=7\nexport OMP_NUM_THREADS=8\n#export NCCL_P2P_DISABLE=1\nexport NCCL_DEBUG=INFO\n\nPROJECT_NAME=\"llama2-70b-ft\"\nPARENT_SAVE_DIR=\"/opt/tmp/ColossalAI/output/save/\"\nPARENT_TENSORBOARD_DIR=\"/opt/tmp/ColossalAI/output/tensorboard/\"\nPARENT_CONFIG_FILE=\"/opt/tmp/ColossalAI/output/config/\"\nPRETRAINED_MODEL_PATH=\"/opt/tmp/ColossalAI/datas/weight/Llama-2-7b-hf\"\ndeclare -a dataset=(\n    \"/opt/tmp/ColossalAI/datas/sftdata/arrow/part-00000\"\n    \"/opt/tmp/ColossalAI/datas/sftdata/arrow/part-00001\"\n    \"/opt/tmp/ColossalAI/datas/sftdata/arrow/part-00002\"\n    \"/opt/tmp/ColossalAI/datas/sftdata/arrow/part-00003\"\n    \"/opt/tmp/ColossalAI/datas/sftdata/arrow/part-00004\"\n    \"/opt/tmp/ColossalAI/datas/sftdata/arrow/part-00005\"\n    \"/opt/tmp/ColossalAI/datas/sftdata/arrow/part-00006\"\n    \"/opt/tmp/ColossalAI/datas/sftdata/arrow/part-00007\"\n    \"/opt/tmp/ColossalAI/datas/sftdata/arrow/part-00008\"\n    \"/opt/tmp/ColossalAI/datas/sftdata/arrow/part-00009\"\n)\n\nTIMESTAMP=$(date +%Y-%m-%d-%H-%M-%S)\nFULL_PROJECT_NAME=\"${PROJECT_NAME}-${TIMESTAMP}\"\nSAVE_DIR=\"${PARENT_SAVE_DIR}${FULL_PROJECT_NAME}\"\nTENSORBOARD_DIR=\"${PARENT_TENSORBOARD_DIR}${FULL_PROJECT_NAME}\"\nCONFIG_FILE=\"${PARENT_CONFIG_FILE}${FULL_PROJECT_NAME}.json\"\n\ncolossalai run --nproc_per_node 8 --hostfile hostfile.txt --master_addr xxx.xx.xx.142 --master_port 30013 train.py \\\n    --pretrained $PRETRAINED_MODEL_PATH \\\n    --dataset ${dataset[@]} \\\n    --plugin \"gemini\" \\\n    --save_interval 400 \\\n    --save_dir $SAVE_DIR \\\n    --tensorboard_dir $TENSORBOARD_DIR \\\n    --config_file $CONFIG_FILE \\\n    --num_epochs 1 \\\n    --accumulation_steps 1 \\\n    --micro_batch_size 1 \\\n    --lr 5e-5 \\\n    --mixed_precision \"bf16\" \\\n    --grad_clip 1.0 \\\n    --weight_decay 0.01 \\\n    --warmup_steps 100 \\\n    --use_grad_checkpoint \\\n    --use_neft \\\n    --pad_token \"eos\"\n```\n\n4. hostfile.txt\n\n```plain\nxxx.xx.xx.142\nxxx.xx.xx.143\nxxx.xx.xx.78\nxxx.xx.xx.79\nxxx.xx.xx.80\n```\n\n5. æ‹‰èµ·å¾®è°ƒè®­ç»ƒ\n\n```bash\n#æŸ¥çœ‹podçš„è¯¦ç»†ä¿¡æ¯\nkubectl get pod -n llama2-70b-test -owide\n#åˆ é™¤å¯åŠ¨å¾®è°ƒè®­ç»ƒçš„yaml\nkubectl delete -f llama2-70b-finetune.yaml\n#å¯åŠ¨å¾®è°ƒè®­ç»ƒçš„yaml\nkubectl apply -f llama2-70b-finetune.yaml\n#æŸ¥çœ‹podæ—¥å¿—\nkubectl logs -n llama2-70b-test llama2-70b-pt-7b5884d87c-pmd76 -f\n#æŸ¥çœ‹podçŠ¶æ€ä¿¡æ¯\nkubectl describe pod -n llama2-70b-test llama2-70b-pt-6599d788c7-7nngz\n```\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Llama2/image30.png)\n\n6. å‚æ•°é…ç½®åŠè°ƒä¼˜\n\n| micro_batch_size | accumulation_steps | plugin | mixed_precision | tflops |\n| --- | --- | --- | --- | --- |\n| 1 | 1 | gemini | bf16 | 38.8488 |\n| 4 | 1 | gemini | bf16 | OOM |\n| 8 | 1 | gemini | bf16 | OOM |\n| 1 | 1 | gemini_auto | bf16 | OOM |\n| 8 | 1 | gemini_auto | bf16 | OOM |\n| 16 | 1 | gemini_auto | bf16 | OOM |\n| 1 | 1 | zero2 | bf16 | OOM |\n| 1 | 1 | 3d | bf16 | OOM |\n| 1 | 4 | gemini | bf16 | OOM |\n| 1 | 8 | gemini | bf16 | OOM |\n\n\n7. 142ï¼Œ143ï¼Œ78ï¼Œ79ï¼Œ80çš„GPUæ˜¾å­˜å ç”¨\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Llama2/image31.png)\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Llama2/image32.png)\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Llama2/image33.png)  \n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Llama2/image34.png)\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Llama2/image35.png)\n\n8. å¤‡æ³¨\n\nåœ¨æ‹‰èµ·å¾®è°ƒè®­ç»ƒæ—¶ï¼Œå°è¯•è°ƒæ•´äº†è®­ç»ƒå‚æ•°micro_batch_sizeã€accumulation_stepsã€å¹¶è¡Œç­–ç•¥geminiã€gemini_autoã€zero2ç­‰å‚æ•°æ¥å°½é‡ç¼©å°æ€»çš„è¿­ä»£stepæ­¥æ•°ï¼ˆæ•°æ®é›†çš„å¤§å°ä¹Ÿä¼šå½±å“stepæ•°ï¼‰ï¼Œä½†å°è¯•å¢åŠ äº†micro_batch_sizeç­‰å‚æ•°åï¼Œå‘ç°è®­ç»ƒä¼šæ‹‰ä¸èµ·æ¥ï¼ˆout of memoryï¼‰ï¼Œå½“å‰5æœº40å¡å¯ä»¥æˆåŠŸæ‹‰èµ·çš„å‚æ•°åªèƒ½å°†micro_batch_sizeè°ƒæ•´ä¸º1ï¼Œaccumulation_stepsä¸º1ã€å¹¶è¡Œç­–ç•¥ä¸ºgeminiï¼Œæ€»çš„è¿­ä»£æ­¥æ•°ä¸º<font style=\"color:#DF2A3F;\">35132</font>æ­¥ï¼ˆ<font style=\"background-color:#c50e0e;\">æ¯æ­¥è¿­ä»£è€—æ—¶éœ€è¦3åˆ†é’Ÿå·¦å³ï¼Œ</font><font style=\"color:rgb(6, 6, 7);background-color:#c50e0e;\">åœ¨æ¯ä¸€æ­¥è¿­ä»£ä¸­ï¼Œé¦–å…ˆè¿›è¡Œå‰å‘ä¼ æ’­æ¥è®¡ç®—é¢„æµ‹è¾“å‡ºå’ŒæŸå¤±ï¼Œç„¶åè¿›è¡Œåå‘ä¼ æ’­æ¥è®¡ç®—æ¢¯åº¦ï¼Œæœ€åæ ¹æ®æ¢¯åº¦æ›´æ–°æ¨¡å‹å‚æ•°ã€‚æ¯ä¸ªæ‰¹æ¬¡éƒ½ä¼šè¿›è¡Œä¸€æ¬¡æ¢¯åº¦å’ŒæŸå¤±çš„è®¡ç®—ï¼Œç›´åˆ°å®Œæˆä¸€ä¸ªepochçš„è®­ç»ƒã€‚</font>ï¼‰\n\nç±»ä¼¼å‚ç…§æŸæ¨¡å‹175Bï¼ˆåƒå¡è§„æ¨¡ï¼‰çš„æ‹‰èµ·çš„è®­ç»ƒè¿›åº¦ï¼Œæ€»çš„è¿­ä»£æ­¥æ•°ä¸º<font style=\"color:#DF2A3F;\">574833ã€‚</font>\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Llama2/image36.png)\n\nç±»ä¼¼å‚ç…§æŸæ¨¡å‹57Bï¼ˆåƒå¡è§„æ¨¡ï¼‰çš„æ‹‰èµ·è®­ç»ƒè¿›åº¦ï¼Œæ€»çš„è¿­ä»£æ­¥æ•°<font style=\"color:#DF2A3F;\">574636ã€‚</font>\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Llama2/image37.png)\n\n<font style=\"background-color:#c50e0e;\">æ•…å®Œæˆæ•´å¥—å¤§æ¨¡å‹çš„è®­ç»ƒä¼šæŒç»­è¾ƒé•¿çš„è®­ç»ƒå‘¨æœŸ</font>ï¼Œå¹¶åœ¨ç°æœ‰çš„å¡æ•°é™åˆ¶ä¸Šï¼Œåœ¨çŸ­æœŸå†…å®ç°æ‰€æœ‰æµç¨‹å­˜åœ¨éš¾åº¦ã€‚\n\n### ç»“è®ºä¸è¯´æ˜\n#### ç°æœ‰ç¯å¢ƒè®­ç»ƒæ¨¡å‹å‚æ•°å¤§å°åŠæ˜¾å­˜å ç”¨\nç°æœ‰çš„5æœº40å¡é¢„è®­ç»ƒ/å¾®è°ƒllama2-70Bï¼Œæ¨¡å‹å‚æ•°åŠæ˜¾å­˜å ç”¨å¦‚ä¸‹è¡¨æ ¼æ‰€ç¤ºï¼ˆ<font style=\"background-color:#c50e0e;\">æ³¨ï¼šç”±äºxxx.xx.xx.141æœºå™¨æ—¥å¸¸æœ‰ä¸šåŠ¡åœ¨è·‘ï¼Œæ— æ³•ç©ºé—²å‡ºå®Œæ•´çš„8å—gpuèµ„æºï¼Œæ•…æœ€å¤šä»¥</font>**<font style=\"color:#DF2A3F;background-color:#c50e0e;\">5æœº40å¡</font>**<font style=\"background-color:#c50e0e;\">æ¥æ‹‰èµ·è®­ç»ƒã€‚</font>ï¼‰\n\n| | æ¨¡å‹å‚æ•° | æœºå™¨ | GPUå¡ | æ˜¾å­˜å ç”¨ | GPUåˆ©ç”¨ç‡ |\n| --- | --- | --- | --- | --- | --- |\n| é¢„è®­ç»ƒ | 70B | 142 | 0 | 77886MiB/81920MiB | 99% |\n| | | | 1 | 77898MiB/81920MiB | 99% |\n| | | | 2 | 77898MiB/81920MiB | 99% |\n| | | | 3 | 77898MiB/81920MiB | 99% |\n| | | | 4 | 79946MiB/81920MiB | 99% |\n| | | | 5 | 77898MiB/81920MiB | 99% |\n| | | | 6 | 77898MiB/81920MiB | 99% |\n| | | | 7 | 77874MiB/81920MiB | 100% |\n| | | 143 | 0 | 77886MiB/81920MiB | 100% |\n| | | | 1 | 77898MiB/81920MiB | 100% |\n| | | | 2 | 77898MiB/81920MiB | 100% |\n| | | | 3 | 77898MiB/81920MiB | 99% |\n| | | | 4 | 77898MiB/81920MiB | 99% |\n| | | | 5 | 77886MiB/81920MiB | 99% |\n| | | | 6 | 77898MiB/81920MiB | 99% |\n| | | | 7 | 77886MiB/81920MiB | 99% |\n| | | 78 | 0 | 78764MiB/81920MiB | 99% |\n| | | | 1 | 78776MiB/81920MiB | 99% |\n| | | | 2 | 78776MiB/81920MiB | 99% |\n| | | | 3 | 78776MiB/81920MiB | 99% |\n| | | | 4 | 78776MiB/81920MiB | 100% |\n| | | | 5 | 78776MiB/81920MiB | 100% |\n| | | | 6 | 78776MiB/81920MiB | 100% |\n| | | | 7 | 78764MiB/81920MiB | 99% |\n| | | 79 | 0 | 77886MiB/81920MiB | 99% |\n| | | | 1 | 77898MiB/81920MiB | 99% |\n| | | | 2 | 77886MiB/81920MiB | 99% |\n| | | | 3 | 77898MiB/81920MiB | 100% |\n| | | | 4 | 77898MiB/81920MiB | 99% |\n| | | | 5 | 77898MiB/81920MiB | 99% |\n| | | | 6 | 77898MiB/81920MiB | 100% |\n| | | | 7 | 77886MiB/81920MiB | 100% |\n| | | 80 | 0 | 77886MiB/81920MiB | 99% |\n| | | | 1 | 77898MiB/81920MiB | 99% |\n| | | | 2 | 79948MiB/81920MiB | 99% |\n| | | | 3 | 77898MiB/81920MiB | 99% |\n| | | | 4 | 78350MiB/81920MiB | 99% |\n| | | | 5 | 79386MiB/81920MiB | 99% |\n| | | | 6 | 79374MiB/81920MiB | 100% |\n| | | | 7 | 78338MiB/81920MiB | 99% |\n| å¾®è°ƒ | 70B | 142 | 0 | 53278MiB/81920MiB | 100% |\n| | | | 1 | 52160MiB/81920MiB | 100% |\n| | | | 2 | 53660MiB/81920MiB | 100% |\n| | | | 3 | 53164MiB/81920MiB | 100% |\n| | | | 4 | 52382MiB/81920MiB | 100% |\n| | | | 5 | 53260MiB/81920MiB | 100% |\n| | | | 6 | 53660MiB/81920MiB | 100% |\n| | | | 7 | 54652MiB/81920MiB | 100% |\n| | | 143 | 0 | 53494MiB/81920MiB | 100% |\n| | | | 1 | 53254MiB/81920MiB | 100% |\n| | | | 2 | 53950MiB/81920MiB | 100% |\n| | | | 3 | 53172MiB/81920MiB | 100% |\n| | | | 4 | 67234MiB/81920MiB | 100% |\n| | | | 5 | 53212MiB/81920MiB | 100% |\n| | | | 6 | 53160MiB/81920MiB | 100% |\n| | | | 7 | 53604MiB/81920MiB | 100% |\n| | | 78 | 0 | 51978MiB/81920MiB | 100% |\n| | | | 1 | 51992MiB/81920MiB | 100% |\n| | | | 2 | 51410MiB/81920MiB | 100% |\n| | | | 3 | 51492MiB/81920MiB | 100% |\n| | | | 4 | 51992MiB/81920MiB | 100% |\n| | | | 5 | 51488MiB/81920MiB | 100% |\n| | | | 6 | 52154MiB/81920MiB | 100% |\n| | | | 7 | 47638MiB/81920MiB | 100% |\n| | | 79 | 0 | 48468MiB/81920MiB | 100% |\n| | | | 1 | 49280MiB/81920MiB | 100% |\n| | | | 2 | 49182MiB/81920MiB | 100% |\n| | | | 3 | 48980MiB/81920MiB | 100% |\n| | | | 4 | 49160MiB/81920MiB | 100% |\n| | | | 5 | 49966MiB/81920MiB | 100% |\n| | | | 6 | 49160MiB/81920MiB | 100% |\n| | | | 7 | 49858MiB/81920MiB | 100% |\n| | | 80 | 0 | 49366MiB/81920MiB | 100% |\n| | | | 1 | 48740MiB/81920MiB | 100% |\n| | | | 2 | 49400MiB/81920MiB | 99% |\n| | | | 3 | 47470MiB/81920MiB | 99% |\n| | | | 4 | 36662MiB/81920MiB | 100% |\n| | | | 5 | 37262MiB/81920MiB | 100% |\n| | | | 6 | 37660MiB/81920MiB | 99% |\n| | | | 7 | 37148MiB/81920MiB | 100% |\n\n\n#### AIå¹³å°è®­ç»ƒå¯è§†åŒ–åˆ†æèƒ½åŠ›\n4.1ä¸­æè¿°çš„å…³äºGPUçš„æ˜¾å­˜ä½¿ç”¨åŠåˆ©ç”¨ç‡æƒ…å†µï¼Œä¸»è¦æ˜¯é€šè¿‡`nvidia-smi`NVIDIAæä¾›çš„å‘½ä»¤è¡Œå·¥å…·ç›‘æ§åˆ†æGPUè®¾å¤‡ä¿¡æ¯ï¼Œå…¶ä¸­çš„ä¿¡æ¯åŒ…æ‹¬\n\n1. GPU åˆ©ç”¨ç‡ï¼ˆGPU-Utilï¼‰ï¼šæ˜¾ç¤º GPU æ ¸å¿ƒçš„åˆ©ç”¨ç‡ç™¾åˆ†æ¯”ã€‚\n2. æ˜¾å­˜ä½¿ç”¨æƒ…å†µï¼ˆMemory-Usageï¼‰ï¼šæ˜¾ç¤º GPU å½“å‰æ˜¾å­˜çš„ä½¿ç”¨é‡/æ€»æ˜¾å­˜é‡ã€‚\n3. åŠŸè€—ï¼ˆPwr:Usage/Capï¼‰ï¼šæ˜¾ç¤º GPU çš„å½“å‰/æœ€å¤§åŠŸè€—ã€‚\n4. æ¸©åº¦ï¼ˆGPU Temperatureï¼‰ï¼šæ˜¾ç¤º GPU çš„å½“å‰æ¸©åº¦ã€‚\n5. è¿›ç¨‹ IDï¼ˆPIDï¼‰ï¼šæ˜¾ç¤ºå½“å‰ä½¿ç”¨ GPU çš„è¿›ç¨‹çš„è¿›ç¨‹ IDã€‚\n6. è¿›ç¨‹åç§°ï¼šæ˜¾ç¤ºä½¿ç”¨ GPU çš„è¿›ç¨‹çš„åç§°ã€‚\n7. ä½¿ç”¨ GPU çš„åº”ç”¨ç¨‹åºï¼šæ˜¾ç¤ºå“ªäº›åº”ç”¨ç¨‹åºæ­£åœ¨ä½¿ç”¨ GPUã€‚\n8. GPU å‹å·ï¼šæ˜¾ç¤º GPU çš„å‹å·å’Œç‰ˆæœ¬ä¿¡æ¯ã€‚\n9. é©±åŠ¨ç‰ˆæœ¬ï¼šæ˜¾ç¤ºå½“å‰å®‰è£…çš„ NVIDIA é©±åŠ¨ç‰ˆæœ¬ã€‚\n10. CUDA ç‰ˆæœ¬ï¼šæ˜¾ç¤ºå½“å‰å®‰è£…çš„ CUDA ç‰ˆæœ¬ã€‚\n11. ECC çŠ¶æ€ï¼šæ˜¾ç¤ºé”™è¯¯æ ¡æ­£ç ï¼ˆECCï¼‰çš„çŠ¶æ€ã€‚\n\nå¯¹æ¯”XXXç›‘æ§å¹³å°çš„æ•°æ®ï¼Œä¸¤è€…åœ¨GPUæ˜¾å­˜ä½¿ç”¨å’ŒGPUåˆ©ç”¨ç‡ä¸Šå¯èƒ½ä¼šå­˜åœ¨å·®å¼‚ï¼Œç”±äº`nvidia-smi`æ˜¯å®æ—¶ç›‘æ§å½“å‰æ—¶é—´ä¸‹çš„GPUä¿¡æ¯ï¼ŒXXXç›‘æ§å¹³å°çš„ä¿¡æ¯ä¸`nvidia-smi`ç›‘æ§ä¿¡æ¯å­˜åœ¨æ—¶é—´å·®ï¼Œæ•…å­˜åœ¨æŸäº›æ•°æ®ä¸åŒæ­¥ï¼Œè¿™ä¹Ÿåœ¨åˆç†çš„èŒƒå›´å†…ã€‚\n\nXXXç›‘æ§å¹³å°åŒ…å«äº†å„æœºå™¨çš„å•ä¸ªGPUçš„æ˜¾å­˜ä½¿ç”¨ã€GPUåˆ©ç”¨ç‡ã€æ¸©åº¦ã€åŠŸè€—ç­‰ä¿¡æ¯ï¼ŒåŸºæœ¬è¦†ç›–äº†æ¨¡å‹è®­ç»ƒç›‘æ§æ‰€éœ€çš„ä¸€äº›æŒ‡æ ‡ã€‚æ­¤å¤–ï¼ŒXXXä¸­è¿˜æ˜¾ç¤ºäº†GPUçš„æ—¶é’Ÿé¢‘ç‡ï¼Œä¹Ÿä»£è¡¨äº†GPUæ€§èƒ½çš„å…³é”®æŒ‡æ ‡ã€‚\n\nXXXç›‘æ§å¹³å°å¯ä»¥è¿›ä¸€æ­¥ç›‘æ§æœºé—´ç½‘å¡çš„é€šä¿¡å¸¦å®½ã€æœºå†…å•å‘é€šä¿¡å¸¦å®½ã€Leafå±‚/spineå±‚äº¤æ¢æœºä¿¡æ¯ã€æ¨¡å‹è®­ç»ƒå‚æ•°ç­‰ç­‰å¤§æ¨¡å‹è®­ç»ƒçš„ç‰©ç†å±‚ä¸è½¯ä»¶å±‚ä¿¡æ¯ã€‚\n\n#### ç”¨æˆ·çš„æ˜“ç”¨æ€§,é•¿æ—¶é—´è®­ç»ƒ,ä»»åŠ¡æ–­ç‚¹,ç›‘æ§å‘Šè­¦,è‡ªåŠ¨åŒ–æ‹‰èµ·\n1. æœ¬æ¬¡è®­ç»ƒé‡‡ç”¨k8sçš„æ–¹å¼æ¥ç®¡ç†å’Œæ‹‰èµ·é›†ç¾¤podèŠ‚ç‚¹ï¼Œå…¶ä¸­æ¶‰åŠåˆ°ä¸€äº›æ‹‰èµ·k8sçš„yamlé…ç½®æ–‡ä»¶ã€ä»¥åŠé›†ç¾¤æœºå™¨çš„sshé€šä¿¡é…ç½®ã€etc/hostsä¸»æœºipåæ˜ å°„é…ç½®ã€æ ‡ç­¾ç®¡ç†ç­‰æ­¥éª¤ï¼Œå¯èƒ½éœ€è¦ç”¨æˆ·ç†Ÿæ‚‰å¹¶æ“ä½œã€‚æ­¤å¤–ï¼Œæœºå™¨çš„é©±åŠ¨ç¯å¢ƒå¯ä»¥æŒ‰æœŸæ›´æ–°è¿­ä»£ï¼Œä»¥æ­¤é€‚åº”å’ŒåŒ¹é…æœ€æ–°ç³»åˆ—å¤§æ¨¡å‹è®­ç»ƒæ‰€éœ€è¦çš„æ–°ç‰¹æ€§ã€‚\n2. æœ¬æ¬¡é¢„è®­ç»ƒä»»åŠ¡é•¿è¾¾70h+ï¼Œå…¶ä¸­å­˜åœ¨è®­ç»ƒä¸­æ–­é—®é¢˜ï¼Œå½“å‰çš„æ–¹æ³•æ˜¯é€šè¿‡æ‰‹åŠ¨æ‹‰èµ·å’Œåˆ©ç”¨è®­ç»ƒè„šæœ¬ä¸­save_intervalçš„é—´éš”æ­¥æ•°ä¿å­˜çš„checkpointä¿¡æ¯æ¥æ¢å¤è‡³é—´éš”æ­¥æ•°çš„è®­ç»ƒçŠ¶æ€ã€‚\n3. è®­ç»ƒçš„ç›‘æ§å‘Šè­¦å¯ä»¥é€šè¿‡kubectlå‘½ä»¤æŸ¥çœ‹pod`kubectl describe pod`ã€node`kubectl describe node`ã€è®­ç»ƒæ—¥å¿—`kubectl logs`é‡Œçš„é”™è¯¯ä¿¡æ¯è¿›è¡Œæ’é”™å¤„ç†ã€‚\n4. è‡ªåŠ¨åŒ–æ‹‰èµ·å¯èƒ½éœ€è¦EKIï¼ˆk8sç®¡ç†ï¼‰å¹³å°ä¸PyTorchJob æ”¯æŒï¼ŒEKIå¯ä»¥è‡ªåŠ¨åŒ–å¤„ç†podèŠ‚ç‚¹å¼‚å¸¸å¹¶è‡ªåŠ¨æ‹‰èµ·æ–°çš„èŠ‚ç‚¹ã€‚\n\n","tags":["æ¨¡å‹è®­ç»ƒè°ƒä¼˜","Nvidia","Llama2","A100","Colossal-AI"],"categories":["æ¨¡å‹è®­ç»ƒè°ƒä¼˜","NVIDIA"]},{"title":"2.4 Deepseek-7Bå¾®è°ƒé€‚é…","url":"/2025/11/13/æ¨¡å‹è®­ç»ƒè°ƒä¼˜/NVIDIA/Deepseek-R1-Distill-Qwen-7b/2.4 Deepseek-7Bå¾®è°ƒé€‚é…/","content":"#### å¾®è°ƒç‰©æ–™åŠä»£ç å‡†å¤‡\n##### æ•°æ®é›†å‡†å¤‡\n/data/code/temp/deepseek/deepseek-datasets/alpaca_zh-deepseek-train.json\n\n/data/code/temp/deepseek/deepseek-datasets/alpaca_zh-deepseek-valid.json\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/deepseek/image24.png)\n\n##### å¾®è°ƒè„šæœ¬\n```shell\n#!/bin/bash\nexport NCCL_P2P_DISABLE=1\n#export NCCL_DEBUG=INFO\nexport NCCL_SOCKET_IFNAME=eth0\nexport GLOO_SOCKET_IFNAME=eth0\nexport CUDA_DEVICE_MAX_CONNECTIONS=1\nexport CUDA_VISIBLE_DEVICES=0,1,2,3\n\nMEGATRON_PATCH_PATH=/data/code\nMEGATRON_PATH=${MEGATRON_PATCH_PATH}/Megatron-LM\n\nexport PYTHONPATH=${MEGATRON_PATH}:${MEGATRON_PATCH_PATH}:$PYTHONPATH\n\nNNODES=2\nNODE_RANK=0\nGPUS_PER_NODE=4\nMASTER_ADDR=192.168.0.65\nMASTER_PORT=8889\n\nDISTRIBUTED_ARGS=\"--nproc_per_node $GPUS_PER_NODE --nnodes $NNODES --node_rank $NODE_RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\"\n\n\nMODEL_SIZE=7B\nBATCH_SIZE=1\nGLOBAL_BATCH_SIZE=8 \nLR=1e-5\nMIN_LR=1e-6\nSEQ_LEN=1024\nPAD_LEN=1024\nEXTRA_VOCAB_SIZE=2400\nPR=fp16\nTP=4\nPP=1\nAC=sel\nDO=true\nFL=false\nSP=true\nTE=true\nMOE=false\nSAVE_INTERVAL=1000\nDATASET_PATH=/data/code/temp/deepseek/deepseek-datasets/alpaca_zh-deepseek-train.json\nVALID_DATASET_PATH=/data/code/temp/deepseek/deepseek-datasets/alpaca_zh-deepseek-valid.json\nPRETRAIN_CHECKPOINT_PATH=/data/code/temp/deepseek/deepseek-ckpt\nTOKENIZER_PATH=/data/code/temp/deepseek/deepseek-ckpt\nTRAIN_TOKENS=100000000   \nWARMUP_TOKENS=10000\nOUTPUT_BASEPATH=/data/code/temp/output/deepseek/finetune_output\n\n\nif [ $MODEL_SIZE = 7B ]; then\n\nNUM_LAYERS=30\nHIDDEN_SIZE=4096\nNUM_ATTN_HEADS=32\nINTERMEDIATE_SIZE=11008\nMAX_POSITION_EMBEDDINGS=4096\n\ngqa_options=\"\"\n\nfi\n\nif [ $AC = full ]; then\n    activation_checkpoint_options=\" \\\n\t\t    --recompute-method uniform \\\n\t\t    --recompute-granularity full\"\nelif [ $AC = sel ]; then\n    activation_checkpoint_options=\" \\\n        --recompute-activations\"\nelif [ $AC = none ]; then\n    activation_checkpoint_options=\" \\\n                    \"\nfi\n\nif [ $PR = fp16 ]; then\n    pr_options=\" \\\n\t\t    --fp16 \\\n            --apply-query-key-layer-scaling\"\n    export NVTE_APPLY_QK_LAYER_SCALING=1\nelif [ $PR = bf16 ]; then\n    pr_options=\" \\\n        --bf16\"\nelif [ $PR = fp8 ]; then\n    pr_options=\" \\\n        --bf16 \\\n        --fp8-hybrid \\\n        --fp8-amax-compute-algo max \\\n        --fp8-amax-history-len 1024 \\\n        --transformer-impl transformer_engine\"\nfi\n\nif [ $DO = true ]; then\n    do_options=\" \\\n\t\t    --use-distributed-optimizer\"\n\nelif [ $DO = false ]; then\n    do_options=\" \\\n                    \"\nfi\n\nif [ $FL = true ]; then\n    flash_options=\" \\\n\t\t    --use-flash-attn\"\n\nelif [ $FL = false ]; then\n    flash_options=\" \\\n                    \"\nfi\n\nif [ $TE = true ]; then\n    te_options=\" \\\n\t\t    --transformer-impl transformer_engine\"\n\nelif [ $TE = false ]; then\n    te_options=\" \\\n                    \"\nfi\n\nif [ $MOE = true ]; then\n    moe_options=\" \\\n\t\t    --moe-router-topk 1 \\\n\t\t    --num-experts 4 \\\n\t\t    --moe-aux-loss-coeff 1e-2 \\\n\t\t    --expert-model-parallel-size 2\"\n\nelif [ $MOE = false ]; then\n    moe_options=\" \\\n                    \"\nfi\n\nif [ $SP = true ] && [ $TP -gt 1 ]; then\n    sp_options=\" \\\n\t\t    --sequence-parallel\"\n\nelif [ $SP = false ]; then\n    sp_options=\" \\\n                    \"\nfi\n\nif [ $PRETRAIN_CHECKPOINT_PATH != none ]; then\n    load_options=\" \\\n            --load $PRETRAIN_CHECKPOINT_PATH\"\nfi\n\nTRAIN_ITERS=$(( ${TRAIN_TOKENS} / ${GLOBAL_BATCH_SIZE} / ${SEQ_LEN} ))\nLR_WARMUP_ITERS=$(( ${WARMUP_TOKENS}  / ${GLOBAL_BATCH_SIZE} / ${SEQ_LEN} ))\nLR_DECAY_ITERS=$(( ${TRAIN_TOKENS} /  ${GLOBAL_BATCH_SIZE} / ${SEQ_LEN} ))\n# LR_DECAY_ITERS=$((${TRAIN_ITERS} - ${LR_WARMUP_ITERS}))\n\nNAME=\"${ENV}-finetune-mcore-deepseek-${MODEL_SIZE}-lr-${LR}-bs-${BATCH_SIZE}-seqlen-${SEQ_LEN}-pr-${PR}-tp-${TP}-pp-${PP}-ac-${AC}-do-${DO}-sp-${SP}-tt-${TRAIN_TOKENS}-wt-${WARMUP_ITERS}\"\nmkdir -p \"${OUTPUT_BASEPATH}/tensorboard/\"\nmkdir -p \"${OUTPUT_BASEPATH}/checkpoint/\"\nmkdir -p \"${OUTPUT_BASEPATH}/log/\"\ncurrent_time=$(date \"+%Y.%m.%d-%H.%M.%S\")\nTENSORBOARD_DIR=\"${OUTPUT_BASEPATH}/tensorboard/${NAME}_${current_time}\"\nmkdir -p ${TENSORBOARD_DIR}\n\nSAVED_PRETRAIN_CHECKPOINT_PATH=\"${OUTPUT_BASEPATH}/checkpoint/${NAME}\"\n\nmegatron_options=\"  \\\n        --tokenizer-model ${TOKENIZER_PATH} \\\n        --save ${SAVED_PRETRAIN_CHECKPOINT_PATH} \\\n        --split 99,1,0 \\\n        --train-data-path ${DATASET_PATH} \\\n        --valid-data-path ${VALID_DATASET_PATH} \\\n        --test-data-path ${VALID_DATASET_PATH} \\\n        --lr ${LR} \\\n        --min-lr ${MIN_LR} \\\n        --lr-decay-style linear \\\n        --adam-beta1 0.9 \\\n        --adam-beta2 0.95 \\\n        --weight-decay 0.1 \\\n        --clip-grad 1.0 \\\n        --init-method-std 0.006 \\\n        --dataloader-type cyclic \\\n        --lr-decay-iters ${LR_DECAY_ITERS} \\\n        --lr-warmup-iters ${LR_WARMUP_ITERS} \\\n        --train-iters ${TRAIN_ITERS} \\\n        --micro-batch-size ${BATCH_SIZE} \\\n        --global-batch-size ${GLOBAL_BATCH_SIZE} \\\n        --num-layers ${NUM_LAYERS} \\\n        --hidden-size ${HIDDEN_SIZE} \\\n        --num-attention-heads ${NUM_ATTN_HEADS} \\\n        --ffn-hidden-size ${INTERMEDIATE_SIZE} \\\n        --seq-length ${SEQ_LEN} \\\n        --max-position-embeddings ${MAX_POSITION_EMBEDDINGS} \\\n        --max-padding-length ${PAD_LEN} \\\n        --log-interval 1 \\\n        --eval-interval 10000 \\\n        --eval-iters 10 \\\n        --save-interval ${SAVE_INTERVAL} \\\n        --tensorboard-queue-size 1 \\\n        --tensorboard-dir ${TENSORBOARD_DIR} \\\n        --log-timers-to-tensorboard \\\n        --log-batch-size-to-tensorboard \\\n        --log-validation-ppl-to-tensorboard \\\n        --tensor-model-parallel-size ${TP} \\\n        --pipeline-model-parallel-size ${PP} \\\n        --no-load-optim \\\n        --no-load-rng \\\n        --num-workers 8 \\\n        --seed 1234 \\\n        --extra-vocab-size ${EXTRA_VOCAB_SIZE} \\\n        --patch-tokenizer-type DeepseekTokenizer \\\n        --dataset LLama-Pretrain-Raw \\\n        --swiglu \\\n        --normalization RMSNorm \\\n        --use-rotary-position-embeddings \\\n        --no-rope-fusion \\\n        --position-embedding-type rope \\\n        --untie-embeddings-and-output-weights \\\n        --disable-bias-linear \\\n        --use-mcore-models \\\n        --rotary-base 10000 \\\n        --attention-dropout 0.0 \\\n        --hidden-dropout 0.0 \\\n        --norm-epsilon 1e-05 \\\n        --eod-mask-loss \\\n        --log-throughput \\\n        --loss-scale 2048      \n        \"\n        # --loss-scale 2048  \n\nLOG_SAVE=\"/data/code/temp/output/deepseek/finetune_output/log/\"${current_time}-deepseek-finetune-${NODE_RANK}.log\"\" \nrun_cmd=\"torchrun $DISTRIBUTED_ARGS /data/code/examples/deepseek_core/pretrain_mcore_deepseek.py\n ${megatron_options} ${pr_options} ${load_options} ${te_options} ${activation_checkpoint_options} ${do_options} ${flash_options} ${sp_options} ${gqa_options} ${moe_options} > ${LOG_SAVE} 2>&1\"\n\necho ${run_cmd}\neval ${run_cmd}\nset +x\n```\n\n##### å¾®è°ƒyaml\n```yaml\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: deepseek-core\n  namespace: deepseek\nspec:\n  selector:\n    matchLabels:\n      app: deepseek-core\n  template:\n    metadata:\n      labels:\n        app: deepseek-core\n    spec:\n      hostNetwork: true\n      nodeSelector:\n        deepseek: deepseek-7B\n      containers:\n        - name: deepseek\n          image: registry.paas/library/megatron-lm:v1\n          imagePullPolicy: IfNotPresent\n          resources:\n            limits:\n              nvidia.com/gpu: 4\n            requests:\n              nvidia.com/gpu: 4\n          command:\n            - \"/bin/bash\"\n            - \"-c\"\n            - |\n              cd /data/code/temp/conf/deepseek_core/finetune &&\n              bash setRank.sh &&\n              cd /data/ &&\n              bash finetune_mcore_deepseek.sh\n          securityContext:\n            privileged: true\n          volumeMounts:\n            - mountPath: /data/code\n              name: code\n            - mountPath: /etc/localtime\n              name: localtime\n            - mountPath: /dev/shm\n              name: dshm\n            - name: weight\n              mountPath: /data/code/temp/deepseek/deepseek-ckpt/\n      volumes:\n        - name: code\n          hostPath:\n            path: /mnt/users/lihai/distribute/core/megatron-core\n        - name: weight\n          hostPath:\n            path: /mnt/users/wangxiangbo/model/deepseek-ai/deepseek-llm-7b-core\n        - name: localtime\n          hostPath:\n            path: /etc/localtime\n        - name: dshm\n          emptyDir:\n            medium: Memory\n            sizeLimit: 20G\n\n```\n\n##### setrank\n```shell\n#!/bin/bash\n\norigin_shell=\"/data/code/examples/deepseek_core/finetune_mcore_deepseek.sh\"\n\nconf_dir=\"/data/code/temp/conf/\"\n\nlocal_dir=\"/data/\"\n\nshell_name=finetune_mcore_deepseek.sh\n\n## å¤åˆ¶è„šæœ¬åˆ°/workspaceä¸‹\ncp $origin_shell $local_dir\n\n\n## è¯»å–hostfile\nreadarray -t ips < <(grep -vE '^[[:space:]]*$' \"$conf_dir\"hostfile-23)\n\n## è·å–rank0 IP\nrank0_ip=$(echo \"${ips[0]}\" | tr -d '[:space:]')\n\nnodes=${#ips[@]}\n\n## è·å–hostfileä¸­é…ç½®çš„IPå‰ç¼€\n## ä½¿ç”¨cutæå–IPåœ°å€çš„å‰ä¸‰ä¸ªæ•°å­—éƒ¨åˆ†\nip_prefix=$(echo \"${ips[0]}\" | cut -d '.' -f 1-3)\n\n## è·å–æœ¬æœºIP\nip=$(hostname -I | grep -oE \"$ip_prefix\\.[0-9]+\")\n\n\n# åˆå§‹åŒ–rank\nnode_rank=-1\n\n# éå†æ•°ç»„\nfor i in \"${!ips[@]}\"; do\n    # ä½¿ç”¨trå‘½ä»¤å»é™¤ç©ºç™½å­—ç¬¦\n    clean_string=$(echo \"${ips[$i]}\" | tr -d '[:space:]')\n    if [[ \"$clean_string\" == \"$ip\" ]]; then\n        node_rank=$i\n        break\n    fi\ndone\n\nif [ $node_rank -ne -1 ]; then\n    ## ä¿®æ”¹è„šæœ¬ä¸­MASTER_ADDR\n    sed -i \"s/^MASTER_ADDR=.*/MASTER_ADDR=$rank0_ip/\" $local_dir$shell_name\n\n    ## ä¿®æ”¹NNODES\n    sed -i \"s/^NNODES=.*/NNODES=$nodes/\" $local_dir$shell_name\n\n    ## ä¿®æ”¹NODE_RANK\n    sed -i \"s/^NODE_RANK=.*/NODE_RANK=$node_rank/\" $local_dir$shell_name\nfi\n\n\n```\n\n#### å¤šæœºå¤šå¡æ‹‰èµ·æµ‹è¯•\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/deepseek/image25.png)\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/deepseek/image26.png)\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/deepseek/image27.png)\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/deepseek/image28.png)\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/deepseek/image29.png)\n\n#### æ–­ç‚¹ç»­è®­æµ‹è¯•\n#### lossæ›²çº¿å¯¹æ¯”\n##### hugging-patchæƒé‡è½¬æ¢\n###### patchè½¬æ¢è„šæœ¬\n```bash\n#!/bin/bash\n\nset -e\nSTART_TIME=$SECONDS\n\nMEGATRON_PATH=/data/code/\nexport PYTHONPATH=$PYTHONPATH:${MEGATRON_PATH}:${MEGATRON_PATH}/Megatron-LM-231007\nSOURCE_CKPT_PATH=/mnt/deepseek-ai/deepseek-llm-7b-base\nTARGET_CKPT_PATH=/mnt/deepseek-ai/deepseek-llm-7b-patch\nTP=4\nPP=1\nMN=llama-7b #llama-7b, llama-13b, llama-30b, llama-65b, llama2-7b, llama2-13b, llama2-70b\nEXTRA_VOCAB_SIZE=2400\nmg2hf=false\n\nif [ $mg2hf = true ]; then\n    do_options=\"\n                --convert_checkpoint_from_megatron_to_transformers\n    \"\nelif [ $mg2hf = false ]; then\n    do_options=\"\"\nfi\n\n\npython hf2megatron.py \\\n    --load_path ${SOURCE_CKPT_PATH} \\\n    --save_path ${TARGET_CKPT_PATH} \\\n    --target_params_dtype fp16 \\\n    --megatron-path ${MEGATRON_PATH} \\\n    --target_tensor_model_parallel_size ${TP} \\\n    --target_pipeline_model_parallel_size ${PP} \\\n    --model_name ${MN} \\\n    --extra_num_vocabs ${EXTRA_VOCAB_SIZE} \\\n${do_options}\n\nELAPSED_TIME=$(($SECONDS - $START_TIME))\necho \"$(($ELAPSED_TIME/60)) min $(($ELAPSED_TIME%60)) sec\"\n\n```\n\n###### patchæƒé‡è½¬æ¢è¿‡ç¨‹\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/deepseek/image30.png)\n\n###### å¾—åˆ°è½¬æˆpatchçš„æƒé‡\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/deepseek/image31.png)\n\n##### patchæ¡†æ¶å¾®è°ƒä»£ç å‡†å¤‡\n###### patchçš„å¾®è°ƒyaml\n```yaml\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: deepseek-core\n  namespace: deepseek\nspec:\n  selector:\n    matchLabels:\n      app: deepseek-core\n  template:\n    metadata:\n      labels:\n        app: deepseek-core\n    spec:\n      hostNetwork: true\n      nodeSelector:\n        deepseek: deepseek-7B\n      containers:\n        - name: deepseek\n          image: registry.paas/library/megatron-lm:v1\n          imagePullPolicy: IfNotPresent\n          resources:\n            limits:\n              nvidia.com/gpu: 4\n            requests:\n              nvidia.com/gpu: 4\n          command:\n            - \"/bin/bash\"\n            - \"-c\"\n            - |\n              cd /data/code/examples/deepseek/conf &&\n              bash setRank.sh &&\n              cd /data/ &&\n              bash finetune_patch_deepseek.sh\n          securityContext:\n            privileged: true\n          volumeMounts:\n            - mountPath: /data/code\n              name: code\n            - mountPath: /etc/localtime\n              name: localtime\n            - mountPath: /dev/shm\n              name: dshm\n            - name: weight\n              mountPath: /data/code/examples/deepseek/ckpt/\n      volumes:\n        - name: code\n          hostPath:\n            path: /mnt/users/wangxiangbo/Pai-Megatron-Patch\n        - name: weight\n          hostPath:\n            path: /mnt/users/wangxiangbo/model/deepseek-ai/deepseek-llm-7b-patch\n        - name: localtime\n          hostPath:\n            path: /etc/localtime\n        - name: dshm\n          emptyDir:\n            medium: Memory\n            sizeLimit: 20G\n\n```\n\n###### patchçš„å¾®è°ƒè„šæœ¬\n```python\n#!/bin/bash\n#sh run_pretrain_megatron_deepseek.sh dsw /workspace/Pai-Megatron-Patch 7B 1 8 1e-5 1e-6 2048 2048 0 bf16 1 1 sel true true true false 100000 /mnt/deepseek-datasets/wudao_llamabpe_text_document /mnt/deepseek-ckpts/Llama-2-7b-hf-to-mg-tp1-pp1/ 10000000000 100000000 /mnt/output_patch_test\nexport NCCL_P2P_DISABLE=1\n#export NCCL_DEBUG=INFO\nexport NCCL_SOCKET_IFNAME=eth0\nexport GLOO_SOCKET_IFNAME=eth0\nexport CUDA_DEVICE_MAX_CONNECTIONS=1\nexport CUDA_VISIBLE_DEVICES=0,1,2,3\n\nMEGATRON_PATCH_PATH=/data/code \nMEGATRON_PATH=${MEGATRON_PATCH_PATH}/Megatron-LM-231007\nexport PYTHONPATH=${MEGATRON_PATH}:${MEGATRON_PATCH_PATH}:$PYTHONPATH\n\nNNODES=2\nNODE_RANK=0\nGPUS_PER_NODE=4\nMASTER_ADDR=192.168.0.65\nMASTER_PORT=8889\n\n\n\nDISTRIBUTED_ARGS=\"--nproc_per_node $GPUS_PER_NODE --nnodes $NNODES --node_rank $NODE_RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\"\n\nMODEL_SIZE=7B\nBATCH_SIZE=1\nGLOBAL_BATCH_SIZE=8\nLR=1e-5\nMIN_LR=1e-6\nSEQ_LEN=1024\nPAD_LEN=1024\nEXTRA_VOCAB_SIZE=4800\nPR=fp16\nTP=4\nPP=1\nAC=sel\nDO=true\nFL=false\nSP=true\nTE=false\nSAVE_INTERVAL=1000\nDATASET_PATH=/data/code/examples/deepseek/dataset/alpaca_zh-deepseek-train.json\nVALID_DATASET_PATH=/data/code/examples/deepseek/dataset/alpaca_zh-deepseek-valid.json\nPRETRAIN_CHECKPOINT_PATH=/data/code/examples/deepseek/ckpt\nTRAIN_ITERS=10000\nLR_WARMUP_ITERS=0\nOUTPUT_BASEPATH=/data/code/examples/deepseek/output/finetune_output\n\n\nif [ $MODEL_SIZE = 7B ]; then\n\nNUM_LAYERS=30\nHIDDEN_SIZE=4096\nNUM_ATTN_HEADS=32\nINTERMEDIATE_SIZE=11008\n\ngqa_options=\"\"\n\nfi\n\nif [ $AC = full ]; then\n    activation_checkpoint_options=\" \\\n\t\t    --recompute-method uniform \\\n\t\t    --recompute-granularity full \\\n            --recompute-num-layers ${NUM_LAYERS}\"\nelif [ $AC = sel ]; then\n    activation_checkpoint_options=\" \\\n        --recompute-activations\"\nelif [ $AC = none ]; then\n    activation_checkpoint_options=\" \\\n                    \"\nfi\n\nif [ $PR = fp16 ]; then\n    pr_options=\" \\\n\t\t    --fp16\"\nelif [ $PR = bf16 ]; then\n    pr_options=\" \\\n        --bf16\"\nelif [ $PR = fp8 ]; then\n    pr_options=\" \\\n        --bf16\n        --fp8-hybrid \\\n        --fp8-amax-compute-algo max \\\n        --fp8-amax-history-len 1024 \\\n        --transformer-impl transformer_engine\"\nfi\n\nif [ $DO = true ]; then\n    do_options=\" \\\n\t\t    --use-distributed-optimizer\"\n\nelif [ $DO = false ]; then\n    do_options=\" \\\n                    \"\nfi\n\nif [ $FL = true ]; then\n    flash_options=\" \\\n\t\t    --use-flash-attn\"\n\nelif [ $FL = false ]; then\n    flash_options=\" \\\n                    \"\nfi\n\nif [ $TE = true ]; then\n    te_options=\" \\\n\t\t    --transformer-impl transformer_engine\"\n\nelif [ $TE = false ]; then\n    te_options=\" \\\n                    \"\nfi\n\nif [ $SP = true ] && [ $TP -gt 1 ]; then\n    sp_options=\" \\\n\t\t    --sequence-parallel\"\n\nelif [ $SP = false ]; then\n    sp_options=\" \\\n                    \"\nfi\n\nif [ $PRETRAIN_CHECKPOINT_PATH != none ]; then\n    load_options=\" \\\n            --load $PRETRAIN_CHECKPOINT_PATH\"\nfi\n\nLR_DECAY_ITERS=$(( ${TRAIN_ITERS} - ${LR_WARMUP_ITERS}))\n\nNAME=\"${ENV}-finetune-patch-deepseek-${MODEL_SIZE}-lr-${LR}-bs-${BATCH_SIZE}-seqlen-${SEQ_LEN}-pr-${PR}-tp-${TP}-pp-${PP}-ac-${AC}-do-${DO}-sp-${SP}-tt-${TRAIN_TOKENS}-wt-${WARMUP_TOKENS}\"\nmkdir -p \"${OUTPUT_BASEPATH}/tensorboard/\"\nmkdir -p \"${OUTPUT_BASEPATH}/checkpoint/\"\nmkdir -p \"${OUTPUT_BASEPATH}/log/\"\ncurrent_time=$(date \"+%Y.%m.%d-%H.%M.%S\")\nTENSORBOARD_DIR=\"${OUTPUT_BASEPATH}/tensorboard/${NAME}_${current_time}\"\nmkdir -p ${TENSORBOARD_DIR}\n\nSAVED_PRETRAIN_CHECKPOINT_PATH=\"${OUTPUT_BASEPATH}/checkpoint/${NAME}\"\n\nmegatron_options=\"  \\\n        --save ${SAVED_PRETRAIN_CHECKPOINT_PATH} \\\n        --split 99,1,0 \\\n        --train-data-path ${DATASET_PATH} \\\n        --valid-data-path ${VALID_DATASET_PATH} \\\n        --test-data-path ${VALID_DATASET_PATH} \\\n        --lr ${LR} \\\n        --min-lr ${MIN_LR} \\\n        --lr-decay-style linear \\\n        --adam-beta1 0.9 \\\n        --adam-beta2 0.95 \\\n        --weight-decay 0.1 \\\n        --clip-grad 1.0 \\\n        --init-method-std 0.006 \\\n        --dataloader-type cyclic \\\n        --lr-decay-iters ${LR_DECAY_ITERS} \\\n        --lr-warmup-iters ${LR_WARMUP_ITERS} \\\n        --train-iters ${TRAIN_ITERS} \\\n        --micro-batch-size ${BATCH_SIZE} \\\n        --global-batch-size ${GLOBAL_BATCH_SIZE} \\\n        --num-layers ${NUM_LAYERS} \\\n        --hidden-size ${HIDDEN_SIZE} \\\n        --num-attention-heads ${NUM_ATTN_HEADS} \\\n        --ffn-hidden-size ${INTERMEDIATE_SIZE} \\\n        --seq-length ${SEQ_LEN} \\\n        --max-position-embeddings ${SEQ_LEN} \\\n        --log-interval 1 \\\n        --eval-interval 10000 \\\n        --eval-iters 10 \\\n        --save-interval ${SAVE_INTERVAL} \\\n        --tensorboard-queue-size 1 \\\n        --tensorboard-dir ${TENSORBOARD_DIR} \\\n        --log-timers-to-tensorboard \\\n        --log-batch-size-to-tensorboard \\\n        --log-validation-ppl-to-tensorboard \\\n        --tensor-model-parallel-size ${TP} \\\n        --pipeline-model-parallel-size ${PP} \\\n        --dataset LLama-Pretrain-Raw \\\n        --no-save-optim \\\n        --no-load-optim \\\n        --no-load-rng \\\n        --num-workers 8 \\\n        --seed 1234 \\\n        --max-padding-length ${PAD_LEN} \\\n        --extra-vocab-size ${EXTRA_VOCAB_SIZE} \\\n        --patch-tokenizer-type LLamaTokenizer \\\n        --swiglu \\\n        --normalization RMSNorm \\\n        --use-llama2-rotary-position-embeddings \\\n        --position-embedding-type rope \\\n        --untie-embeddings-and-output-weights \\\n        --rotary-base 10000 \\\n        --rotary-scale-factor 4 \\\n        --loss-scale 2048 \\\n        --disable-bias-linear\n        \"\nLOG_SAVE=\"/data/code/examples/deepseek/output/finetune_output/log/\"${current_time}-deepseek-patch-${NODE_RANK}.log\"\" \nrun_cmd=\"torchrun $DISTRIBUTED_ARGS /data/code/examples/llama2/pretrain_megatron_llama.py\n ${megatron_options} ${pr_options} ${load_options} ${te_options} ${activation_checkpoint_options} ${do_options} ${flash_options} ${sp_options} ${gqa_options} > ${LOG_SAVE} 2>&1\"\n\necho ${run_cmd}\neval ${run_cmd}\nset +x\n```\n\n###### patchçš„å¾®è°ƒsetrank\n```shell\n#!/bin/bash\n\norigin_shell=\"/data/code/examples/deepseek/finetune_patch_deepseek.sh\"\n\nconf_dir=\"/data/code/examples/deepseek/conf/\"\n\nlocal_dir=\"/data/\"\n\nshell_name=finetune_patch_deepseek.sh\n\n## å¤åˆ¶è„šæœ¬åˆ°/workspaceä¸‹\ncp $origin_shell $local_dir\n\n\n## è¯»å–hostfile\nreadarray -t ips < <(grep -vE '^[[:space:]]*$' \"$conf_dir\"hostfile)\n\n## è·å–rank0 IP\nrank0_ip=$(echo \"${ips[0]}\" | tr -d '[:space:]')\n\nnodes=${#ips[@]}\n\n## è·å–hostfileä¸­é…ç½®çš„IPå‰ç¼€\n## ä½¿ç”¨cutæå–IPåœ°å€çš„å‰ä¸‰ä¸ªæ•°å­—éƒ¨åˆ†\nip_prefix=$(echo \"${ips[0]}\" | cut -d '.' -f 1-3)\n\n## è·å–æœ¬æœºIP\nip=$(hostname -I | grep -oE \"$ip_prefix\\.[0-9]+\")\n\n\n# åˆå§‹åŒ–rank\nnode_rank=-1\n\n# éå†æ•°ç»„\nfor i in \"${!ips[@]}\"; do\n    # ä½¿ç”¨trå‘½ä»¤å»é™¤ç©ºç™½å­—ç¬¦\n    clean_string=$(echo \"${ips[$i]}\" | tr -d '[:space:]')\n    if [[ \"$clean_string\" == \"$ip\" ]]; then\n        node_rank=$i\n        break\n    fi\ndone\n\nif [ $node_rank -ne -1 ]; then\n    ## ä¿®æ”¹è„šæœ¬ä¸­MASTER_ADDR\n    sed -i \"s/^MASTER_ADDR=.*/MASTER_ADDR=$rank0_ip/\" $local_dir$shell_name\n\n    ## ä¿®æ”¹NNODES\n    sed -i \"s/^NNODES=.*/NNODES=$nodes/\" $local_dir$shell_name\n\n    ## ä¿®æ”¹NODE_RANK\n    sed -i \"s/^NODE_RANK=.*/NODE_RANK=$node_rank/\" $local_dir$shell_name\nfi\n\n```\n\n##### patchæ¡†æ¶å¾®è°ƒæµ‹è¯•\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/deepseek/image32.png)\n\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/deepseek/image33.png)\n\n","tags":["V100","æ¨¡å‹é€‚é…","Nvidia","Deepseek","Megatron-LM"],"categories":["æ¨¡å‹é€‚é…","NVIDIA"]},{"title":"2.5 pytorchjob+ekiæ–­ç‚¹ç»­è®­","url":"/2025/11/13/æ¨¡å‹è®­ç»ƒè°ƒä¼˜/NVIDIA/Deepseek-R1-Distill-Qwen-7b/2.5 pytorchjob+ekiæ–­ç‚¹ç»­è®­/","content":"#### ç¯å¢ƒå‡†å¤‡\npytorchjobè®­ç»ƒç¯å¢ƒå·²ç”±å°ç»„åŒäº‹æ­å»ºå®Œæˆ\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/deepseek/image34.png)\n\n#### ä»£ç å‡†å¤‡\n##### æ–­ç‚¹ç»­è®­yaml\néœ€è¦æ³¨æ„çš„æ˜¯ï¼Œä¸èƒ½è®¾å®šè‡ªå®šä¹‰çš„namespaceï¼Œéœ€è¦åœ¨defaultä¸‹å¯åŠ¨pod\n\n```yaml\napiVersion: \"ai.cmss.chinamobile.com/v1alpha1\"\nkind: PyTorchJob\nmetadata:\n  name: deepseek-core\n  labels:\n    service: deepseek-core\nspec:\n  nprocPerNode: \"4\"\n  pytorchReplicaSpecs:\n    Master:\n      replicas: 1\n      template:\n        metadata:\n          labels:\n            app: ckpt\n        spec:\n          nodeSelector:\n            model-ckpt: deepseek-master\n          restartPolicy: Always\n          hostNetwork: true\n          dnsPolicy: ClusterFirstWithHostNet\n          affinity:\n            podAntiAffinity:\n              requiredDuringSchedulingIgnoredDuringExecution:\n                - labelSelector:\n                    matchExpressions:\n                      - key: app\n                        operator: In\n                        values:\n                          - ckpt\n                  topologyKey: \"kubernetes.io/hostname\"\n          containers:\n            - name: pytorch\n              image: registry.paas/library/megatron-lm:v1\n              imagePullPolicy: IfNotPresent\n              securityContext:\n                capabilities:\n                  add:\n                    - SYS_ADMIN\n              resources:\n                limits:\n                  nvidia.com/gpu: 4 # Request access to all GPU\n                requests:\n                  nvidia.com/gpu: 4\n              env:\n                - name: OMP_NUM_THREADS\n                  value: \"4\"\n              command:\n                - \"/bin/bash\"\n                - \"-c\"\n                - |\n                  cd /data/code/temp/conf/deepseek_core/pretrain &&\n                  bash SetRank.sh &&\n                  cd /data/ &&\n                  bash pretrain_ckpt_deepseek.sh\n              volumeMounts:\n                - mountPath: /data/code\n                  readOnly: false\n                  name: code\n                - name: shm-volume\n                  mountPath: /dev/shm\n                - name: pod-gpu-resources\n                  mountPath: /tmp\n                  readOnly: false\n          volumes:\n            - name: code\n              hostPath:\n                path: /mnt/users/lihai/distribute/core/megatron-core\n            - name: shm-volume\n              emptyDir:\n                medium: Memory\n                sizeLimit: 1G\n            - name: pod-gpu-resources\n              hostPath:\n                path: /var/lib/kubelet/pod-resources\n          schedulerName: ai-scheduler\n\n    Worker:\n      replicas: 1\n      restartPolicy: OnFailure\n      template:\n        metadata:\n          labels:\n            app: ckpt\n        spec:\n          nodeSelector:\n            model-ckpt: deepseek-worker\n          restartPolicy: Always\n          hostNetwork: true\n          dnsPolicy:\n            ClusterFirstWithHostNet\n            #affinty:\n            #podAntiAffinity:\n            # requiredDuringSchedulingIgnoredDuringExecution:\n            # - labelSelector:\n            #     matchExpressions:\n            #     - key: app\n            #       operator: In\n            #       values:\n            #       - ckpt\n            #   topologyKey: \"kubernetes.io/hostname\"\n          containers:\n            - name: pytorch\n              image: registry.paas/library/megatron-lm:v1\n              imagePullPolicy: IfNotPresent\n              # workingDir: /workspace/model/glm3/chatglm3/finetune_demo\n              securityContext:\n                capabilities:\n                  add:\n                    - SYS_ADMIN\n              resources:\n                limits:\n                  nvidia.com/gpu: 4 # Request access to all GPU\n                requests:\n                  nvidia.com/gpu: 4\n              env:\n                - name: OMP_NUM_THREADS\n                  value: \"4\"\n              command:\n                - \"/bin/bash\"\n                - \"-c\"\n                - |\n                  cd /data/code/temp/conf/deepseek_core/pretrain &&\n                  bash SetRank.sh &&\n                  cd /data/ &&\n                  bash pretrain_ckpt_deepseek.sh\n              volumeMounts:\n                - mountPath: /data/code\n                  readOnly: false\n                  name: code\n                - name: shm-volume\n                  mountPath: /dev/shm\n                - name: pod-gpu-resources\n                  mountPath: /tmp\n                  readOnly: false\n          volumes:\n            - name: code\n              hostPath:\n                path: /mnt/users/lihai/distribute/core/megatron-core\n                type: Directory\n            - name: shm-volume\n              emptyDir:\n                medium: Memory\n                sizeLimit: 1G\n            - name: pod-gpu-resources\n              hostPath:\n                path: /var/lib/kubelet/pod-resources\n          schedulerName: ai-scheduler\n\n```\n\n##### setrank\n```shell\n#!/bin/bash\n\norigin_shell=\"/data/code/examples/deepseek_core/pretrain_ckpt_deepseek.sh\"\n\nconf_dir=\"/data/code/temp/conf/\"\n\nlocal_dir=\"/data/\"\n\nshell_name=pretrain_ckpt_deepseek.sh\n\n## å¤åˆ¶è„šæœ¬åˆ°/workspaceä¸‹\ncp $origin_shell $local_dir\n\n\n## è¯»å–hostfile\nreadarray -t ips < <(grep -vE '^[[:space:]]*$' \"$conf_dir\"hostfile-236)\n\n## è·å–rank0 IP\nrank0_ip=$(echo \"${ips[0]}\" | tr -d '[:space:]')\n\nnodes=${#ips[@]}\n\n## è·å–hostfileä¸­é…ç½®çš„IPå‰ç¼€\n## ä½¿ç”¨cutæå–IPåœ°å€çš„å‰ä¸‰ä¸ªæ•°å­—éƒ¨åˆ†\nip_prefix=$(echo \"${ips[0]}\" | cut -d '.' -f 1-3)\n\n## è·å–æœ¬æœºIP\nip=$(hostname -I | grep -oE \"$ip_prefix\\.[0-9]+\")\n\n\n# åˆå§‹åŒ–rank\nnode_rank=-1\n\n# æ‰“å°è°ƒè¯•ä¿¡æ¯\necho \"æœ¬æœºIP: $ip\"\necho \"rank0 IP: $rank0_ip\"\necho \"æ‰€æœ‰èŠ‚ç‚¹IP: ${ips[@]}\"\n\n# éå†æ•°ç»„\n# for i in \"${!ips[@]}\"; do\n#     # ä½¿ç”¨trå‘½ä»¤å»é™¤ç©ºç™½å­—ç¬¦\n#     clean_string=$(echo \"${ips[$i]}\" | tr -d '[:space:]')\n#     if [[ \"$clean_string\" == \"$ip\" ]]; then\n#         node_rank=$i\n#         break\n#     fi\n# done\n\n# TODO æµ‹è¯•æ–­ç‚¹ç»­è®­\nfor i in \"${!ips[@]}\"; do\n    clean_string=$(echo \"${ips[$i]}\" | tr -d '[:space:]')\n    if [[ \"$clean_string\" == \"$ip\" ]]; then\n        if [[ \"$ip\" == \"$rank0_ip\" ]]; then\n            node_rank=0\n        else\n            node_rank=1\n        fi\n        break\n    fi\ndone\n\n# æ‰“å°è°ƒè¯•ä¿¡æ¯\necho \"è®¾ç½®çš„NODE_RANK: $node_rank\"\n\nif [ $node_rank -ne -1 ]; then\n    ## ä¿®æ”¹è„šæœ¬ä¸­MASTER_ADDR\n    sed -i \"s/^MASTER_ADDR=.*/MASTER_ADDR=$rank0_ip/\" $local_dir$shell_name\n\n    ## ä¿®æ”¹NNODES\n    # sed -i \"s/^NNODES=.*/NNODES=$nodes/\" $local_dir$shell_name\n\n    ## ä¿®æ”¹NODE_RANK\n    sed -i \"s/^NODE_RANK=.*/NODE_RANK=$node_rank/\" $local_dir$shell_name\nfi\n\n```\n\n##### hostfile\nå¤šæœºèŠ‚ç‚¹æ•…éšœéœ€è¦é€‰å–3ä¸ªèŠ‚ç‚¹æ¥æ¨¡æ‹Ÿï¼Œå…¶ä¸­2å°ç”¨æ¥æ‹‰èµ·è®­ç»ƒï¼Œä¹‹åæ¨¡æ‹Ÿå…¶ä¸­1å°å‘ç”Ÿæ•…éšœï¼Œä¹‹åå†è°ƒåº¦åˆ°å¦ä¸€ä¸ªå¤‡ç”¨æœºå™¨ä¸Šç»§ç»­è®­ç»ƒã€‚\n\nå…¶ä¸­å°†192.168.0.65ä½œä¸ºmasterèŠ‚ç‚¹ï¼Œ192.168.0.20å’Œ192.168.0.63ä½œä¸ºworkerèŠ‚ç‚¹ã€‚\n\n```plain\n192.168.0.65\n192.168.0.20\n192.168.0.63\n```\n\n#### èŠ‚ç‚¹æ•…éšœå®è·µ\n##### è®­ç»ƒæ‹‰èµ·\n```bash\nkubectl apply -f deepseek-ckpt.yaml\nkubectl get node -owide\nkubectl get pod -owide\n```\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/deepseek/image35.png)\n\nå¯ä»¥çœ‹å‡ºè®­ç»ƒå†åœ¨masterèŠ‚ç‚¹192.168.0.65å’ŒworkerèŠ‚ç‚¹192.168.0.63ä¸Šæ‹‰èµ·ã€‚\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/deepseek/image36.png)\n\n##### ckptä¿å­˜\næŒç»­è®­ç»ƒï¼Œå¹¶åœ¨interval50æ­¥ä¿å­˜ckptä¿¡æ¯ï¼Œä¹‹åç»§ç»­è®­ç»ƒ\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/deepseek/image37.png)\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/deepseek/image38.png)\n\n##### æ¨¡æ‹ŸèŠ‚ç‚¹æ•…éšœ\nè¿›å…¥192.168.0.63æœºå™¨ï¼Œæ¨¡æ‹ŸèŠ‚ç‚¹æ•…éšœï¼Œåœæ‰k8sæœåŠ¡\n\n```bash\nsystemctl stop kubelet\n```\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/deepseek/image39.png)\n\nåœæ‰ååœ¨k8sçš„masterèŠ‚ç‚¹æŸ¥çœ‹nodeçŠ¶æ€ï¼Œæ˜¯å¦ä¸ºNotReady\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/deepseek/image40.png)\n\næ­¤æ—¶192.168.0.63å·²ç»å‡ºç°æ•…éšœï¼Œå†å»æŸ¥çœ‹æ‹‰èµ·è®­ç»ƒçš„podä¿¡æ¯\n\nç”±äº192.168.0.63å‡ºç°æ•…éšœï¼Œpytorchjobä¼šæ ¹æ®hostfileçš„èŠ‚ç‚¹ä¿¡æ¯ï¼Œå†é‡æ–°å°è¯•è°ƒåº¦åˆ°å¦å¤–çš„æœºå™¨ä¸Š192.168.0.20ï¼Œå¯ä»¥çœ‹å‡ºåœ¨192.168.0.20é‡æ–°è¿›è¡Œäº†Initã€PodInitializingã€Runningçš„è¿‡ç¨‹ã€‚\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/deepseek/image41.png)\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/deepseek/image42.png)\n\n##### æŸ¥çœ‹ç»­è®­log\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/deepseek/image43.png)\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/deepseek/image44.png)\n\nè‡³æ­¤ï¼ŒèŠ‚ç‚¹æ•…éšœæ–­ç‚¹ç»­è®­å®è·µå®Œæˆã€‚\n\næ¨¡æ‹Ÿå®Œæˆåï¼Œé‡æ–°å°†192.168.0.63èŠ‚ç‚¹æ¢å¤\n\n```bash\nsystemctl start kubelet\n```\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/deepseek/image45.png)\n\n\n\n#### \n\n\n","tags":["V100","æ¨¡å‹é€‚é…","Nvidia","Deepseek","Megatron-LM"],"categories":["æ¨¡å‹é€‚é…","NVIDIA"]},{"title":"Tulu3-8B-åè®­ç»ƒå®è·µ","url":"/2025/11/12/æ¨¡å‹è®­ç»ƒè°ƒä¼˜/NVIDIA/Tulu3/Tulu3-8B-åè®­ç»ƒå®è·µ/","content":"# è®­ç»ƒç¯å¢ƒ\n## é•œåƒ\n```bash\nregistry.cn-shanghai.aliyuncs.com/aliyun_repository_wxb/repository_wxb:tulu3\n```\n\né•œåƒä¸­å·²åŒ…å«tulu3åè®­ç»ƒæ‰€éœ€è¦çš„æ‰€æœ‰ä¾èµ–ç¯å¢ƒã€‚\n\n## ä»£ç ç»“æ„\n```bash\n/mnt/users/wangxiangbo/model/tulu3/open-instruct-main\n```\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image1.png)\n\n### data\nåŒ…å«äº†`sft`ã€`dpo`ã€`rlvr`æ‰€éœ€çš„æ•°æ®é›†\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image2.png)\n\n`eval`ç›¸å…³\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image3.png)\n\n### scripts/configs\nè®­ç»ƒè„šæœ¬\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image4.png)\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image5.png)\n\n```bash\ntulu3_sft.sh #tulu3 sftå•æœºè„šæœ¬\n```\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image6.png)\n\n```bash\nhostfile\nhostfile-12\nsetRank.sh\ntulu3_dpo.sh #å¤šæœºdpoè„šæœ¬\ntulu3_dpo_single.sh #å•æœº4å¡dpoè„šæœ¬\ntulu3_dpo.yaml #å¤šæœºyaml\ntulu3_sft.sh #å¤šæœºsftè„šæœ¬\n```\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image7.png)\n\n```bash\ntulu3_rlvr_single.sh #tulu3 rlvrå•æœºè„šæœ¬\n```\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image8.png)\n\n```bash\nloss_plot.py #lossæ›²çº¿ç»˜å›¾è„šæœ¬\n```\n\n### open_instruct\nsftã€dpoã€rlvrç›¸å…³è®­ç»ƒä»£ç \n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image9.png)\n\n\n\n## sftå®è·µ\n### å•æœº4å¡æµ‹è¯•\n#### sftæ•°æ®é›†\nsftæ•°æ®é›†é‡‡ç”¨tulu3å®˜ç½‘æä¾›çš„æ•°æ®é›†\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image10.png)\n\nsftæ•°æ®é›†æ ·ä¾‹ï¼š\n\n```json\n{\"id\":\"oasst1_2644\",\"messages\":[{\"content\":\"æœ‰ç¼“è§£ç¤¾äº¤ææƒ§ç—‡çš„å®ç”¨æ–¹æ³•å—ï¼Ÿ\",\"role\":\"user\"},{\"content\":\"ä»¥ä¸‹æ˜¯ä¸€äº›å®ç”¨çš„æ–¹æ³•ï¼Œå¯èƒ½æœ‰åŠ©äºç¼“è§£ç¤¾äº¤ææƒ§ç—‡ï¼š\\n\\n1.  å¯»æ±‚ä¸“ä¸šå¸®åŠ©ï¼šå¯»æ±‚å¿ƒç†åŒ»ç”Ÿæˆ–å¿ƒç†æ²»ç–—å¸ˆçš„å¸®åŠ©æ˜¯ç¼“è§£ç¤¾äº¤ææƒ§ç—‡çš„æœ€ä½³æ–¹æ³•ä¹‹ä¸€ã€‚ä¸“ä¸šçš„æ²»ç–—å¸ˆå¯ä»¥å¸®åŠ©ä½ è¯†åˆ«å’Œå¤„ç†ææƒ§çš„æºå¤´ï¼Œå¹¶æä¾›æœ‰æ•ˆçš„æ²»ç–—æ–¹æ¡ˆã€‚\\n\\n2. ç»ƒä¹ æ·±å‘¼å¸å’Œæ”¾æ¾æŠ€å·§ï¼šå½“ä½ æ„Ÿåˆ°ç„¦è™‘å’Œç´§å¼ æ—¶ï¼Œå°è¯•é€šè¿‡æ·±å‘¼å¸å’Œæ”¾æ¾æŠ€å·§æ¥å¸®åŠ©ä½ å†·é™ä¸‹æ¥ã€‚æ·±å‘¼å¸å¯ä»¥å¸®åŠ©ä½ å‡è½»èº«ä½“ä¸Šçš„å‹åŠ›å’Œç´§å¼ æ„Ÿï¼Œä»è€Œä½¿ä½ æ›´æ”¾æ¾å’Œé•‡å®šã€‚\\n\\n3. å­¦ä¹ ç§¯ææ€è€ƒï¼šé¿å…æ¶ˆæçš„è‡ªæˆ‘å¯¹è¯ï¼Œä¾‹å¦‚â€œæˆ‘ä¼šå¤±è´¥â€ã€â€œæˆ‘ä¸è¡Œâ€ç­‰ç­‰ã€‚æ”¹å˜è‡ªå·±çš„æ€è€ƒæ–¹å¼ï¼Œå°è¯•ä»¥ç§¯æã€è‡ªä¿¡çš„æ€åº¦é¢å¯¹ç¤¾äº¤åœºåˆã€‚\\n\\n4.  æ¡å–æŸ”æ€§æ–¹æ³•ï¼šç‚ºäº†å°æŠ—ç„¦æ…®ç—‡ç‹€ï¼Œå»ºè­°ä½¿ç”¨ä¸€äº›æ–¹æ³•ä¾†æé†’ä½ çš„èº«é«”æ˜¯å®‰å…¨çš„ï¼Œä¾‹å¦‚ï¼š  \\n\\nï¼Š å‘¼å¸è¨“ç·´ï¼ˆç”¨é¼»å­æ·±æ·±çš„å¸ä¸€å£æ°£å†ç”¨å˜´å·´å°‡æ°£æ…¢æ…¢åœ°åå‡ºï¼Œç•¶ä½ å°ˆæ³¨åœ¨åæ°£æ™‚ï¼Œä½ å°±æœƒè¢«å¸¶å‡ºæŠµæŠ—æˆ–é€ƒé¿çš„æƒ…ç·’ä¸­ã€‚ï¼‰ \\n\\n ï¼Š å°ˆæ³¨æ–¼ç¾åœ¨ï¼ˆé€™éº¼åšè®“ä½ èƒ½å¤ å°ˆæ³¨æ–¼è‡ªå·±æ‰€ç¶“æ­·çš„æ¯åˆ†æ¯ç§’ã€‚è©¦è‘—èªªå‡ºä½ ç¾åœ¨èƒ½çœ‹è¦‹ã€èåˆ°ã€ç¢°è§¸åˆ°ä¸¦è½å¾—åˆ°çš„æ±è¥¿ï¼Œæˆ–æ˜¯ååœ¨æ¤…å­ä¸Šä¸¦æ„Ÿå—è‡ªå·±çš„è…³è§¸ç¢°åœ°é¢çš„æ„Ÿè¦ºï¼Œæˆ–èº«é«”æ­£è¢«æ”¯æ’è‘—çš„æ„Ÿè¦ºã€‚ï¼‰\\n\\n5. çµ¦è‡ªå·±ä¸€é»å¾å®¹ï¼šåœ¨éæ¸¡æ™‚æœŸç·´ç¿’è‡ªæˆ‘åŒæƒ…ï¼Œä¸¦æé†’è‡ªå·±æ„Ÿåˆ°ä¸ç¢ºå®šèˆ‡ä¸å®‰æ˜¯å¾ˆæ­£å¸¸çš„ã€‚\\n\\nè¿™äº›æ–¹æ³•å¯ä»¥å¸®åŠ©ä½ ç¼“è§£ç¤¾äº¤ææƒ§ç—‡ï¼Œä½†ä¸åŒçš„äººå¯èƒ½éœ€è¦ä¸åŒçš„æ–¹æ³•å’Œæ²»ç–—æ–¹æ¡ˆã€‚å¦‚æœä½ æ„Ÿåˆ°ä¸¥é‡çš„ç„¦è™‘å’Œææƒ§ï¼Œè¯·åŠæ—¶å¯»æ±‚ä¸“ä¸šå¸®åŠ©ã€‚\",\"role\":\"assistant\"},{\"content\":\"å¥½å§ï¼Œå¯æ˜¯æˆ‘è¦å»å“ªè£¡å°‹æ±‚å°ˆæ¥­å¹«åŠ©ï¼Ÿ\",\"role\":\"user\"},{\"content\":\"æ‚¨å¯ä»¥å…ˆåƒè€ƒç¾åœ‹ç²¾ç¥ç–¾ç—…è¨ºæ–·æ¨™æº– **DSM-5** ä¸­çš„6é»æ¨™æº–ï¼Œæˆ–è€…é€²è¡Œä¸€äº›å°ˆæ¥­çš„å¿ƒç†æ¸¬è©¦ã€‚å¦‚æœæ‚¨ç¬¦åˆé€™äº›æ¨™å‡†æˆ–æ¸¬è©¦çµæœé¡¯ç¤ºæ‚¨æœ‰ç¤¾äº¤ææ‡¼ç—‡ï¼Œæ‚¨æ‡‰å„˜æ—©å°‹æ±‚å°ˆæ¥­çš„å¹«åŠ©ã€‚\\n\\nå°‹æ±‚å°ˆæ¥­å¹«åŠ©çš„é€”å¾‘æœ‰ä»¥ä¸‹å¹¾ç¨®ï¼š\\n\\n- **è«®è©¢é†«ç”Ÿæˆ–å¿ƒç†å¥åº·å°ˆå®¶**ã€‚ä»–å€‘å¯ä»¥ç‚ºæ‚¨æä¾›è¨ºæ–·ï¼Œè—¥ç‰©æ²»ç™‚ï¼Œå¿ƒç†æ²»ç™‚ç­‰æœå‹™ã€‚\\n- **åƒåŠ å¿ƒç†è«®è©¢æˆ–æ²»ç™‚æ©Ÿæ§‹**ã€‚é€™äº›æ©Ÿæ§‹é€šå¸¸æœ‰å°ˆæ¥­çš„å¿ƒç†è«®è©¢å¸«æˆ–æ²»ç™‚å¸«ï¼Œå¯ä»¥ç‚ºæ‚¨æä¾›å€‹äººæˆ–åœ˜é«”çš„å¿ƒç†è«®è©¢æˆ–æ²»ç™‚æœå‹™ã€‚\\n- **åŠ å…¥äº’åŠ©å°çµ„æˆ–ç¤¾å€**ã€‚é€™äº›å°çµ„æˆ–ç¤¾å€é€šå¸¸ç”±æœ‰ç›¸åŒæˆ–é¡ä¼¼å•é¡Œçš„äººçµ„æˆï¼Œå¯ä»¥ç‚ºæ‚¨æä¾›æ”¯æŒï¼Œé¼“å‹µï¼Œäº¤æµå’Œåˆ†äº«çš„å¹³å°ã€‚\\n\\nä»¥ä¸Šæ˜¯æˆ‘ç‚ºæ‚¨æœç´¢åˆ°çš„ä¸€äº›ä¿¡æ¯ï¼Œå¸Œæœ›å°æ‚¨æœ‰æ‰€å¹«åŠ©ã€‚å¦‚æœæ‚¨é‚„æœ‰å…¶ä»–å•é¡Œï¼Œæ­¡è¿ç¹¼çºŒæå•ã€‚\",\"role\":\"assistant\"}],\"source\":\"ai2-adapt-dev\\/oasst1_converted\"}\n```\n\nç”±äºæ˜¯.parquetæ ¼å¼æ•°æ®ï¼Œè½¬æˆjsonåä¸€å…±æœ‰93wæ¡æ•°æ®ã€‚\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image11.png)\n\nç”±äºæœºå™¨æ•°é‡æœ‰é™ï¼Œè®­ç»ƒå…¶å®Œæ•´æ•°æ®é›†éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œæ•…å°†.parquetè½¬ä¸ºjsonåå°†æ•°æ®é›†ç¼©å‡è‡³5kæ¡ï¼Œå¹¶å†æ¬¡è½¬å›.parquetæ ¼å¼æ•°æ®ã€‚\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image12.png)\n\n#### å•æœºè„šæœ¬é…ç½®\n```bash\nexport CUDA_VISIBLE_DEVICES=0,1,2,3\nexport WANDB_MODE=disabled\ncurrent_time=$(date \"+%Y.%m.%d-%H.%M.%S\")\nLOG_SAVE=\"/mnt/open-instruct-main/output/sft/${current_time}-tulu3-sft.log\"\nMODEL_SIZE=8B\nNUM_GPUS=4\nBATCH_SIZE_PER_GPU=2\nTOTAL_BATCH_SIZE=8\nGRADIENT_ACC_STEPS=$(($TOTAL_BATCH_SIZE/($NUM_GPUS * $BATCH_SIZE_PER_GPU)))\necho \"Training llama model ${MODEL_SIZE} using $NUM_GPUS GPUs, $BATCH_SIZE_PER_GPU batch size per GPU, $GRADIENT_ACC_STEPS gradient accumulation steps\"\n\naccelerate launch \\\n    --mixed_precision fp16 \\\n    --num_machines 1 \\\n    --num_processes $NUM_GPUS \\\n    --use_deepspeed \\\n    --deepspeed_config_file /mnt/open-instruct-main/configs/ds_configs/stage3_offloading_accelerate.conf \\\n    /mnt/open-instruct-main/open_instruct/finetune.py \\\n    --model_name_or_path /mnt/LLM-Research/Meta-Llama-31-8B \\\n    --tokenizer_name /mnt/LLM-Research/Meta-Llama-31-8B \\\n    --use_slow_tokenizer \\\n    --train_file /mnt/open-instruct-main/data/sft_data_json/sft_dataset_5k.json \\\n    --max_seq_length 4096 \\\n    --preprocessing_num_workers 4 \\\n    --per_device_train_batch_size $BATCH_SIZE_PER_GPU \\\n    --gradient_accumulation_steps $GRADIENT_ACC_STEPS \\\n    --learning_rate 2e-5 \\\n    --lr_scheduler_type linear \\\n    --warmup_ratio 0.03 \\\n    --weight_decay 0. \\\n    --num_train_epochs 1 \\\n    --output_dir /mnt/open-instruct-main/output/sft \\\n    --gradient_checkpointing true \\\n    --report_to none \\\n    --use_flash_attn false 2>&1 | tee -a \"$LOG_SAVE\"\n```\n\nä¸ºäº†å°½å¯èƒ½åœ°è¿˜åŸtulu3åŸè®ºæ–‡çš„å®éªŒç»“æœï¼Œå…¶ä¸­éƒ¨åˆ†è¶…å‚ä¸è®ºæ–‡ä¸­æœ€ä¼˜ä¿æŒä¸€è‡´ã€‚\n\n`--max_seq_length 4096`\n\n`--learning_rate 2e-5`\n\n`--lr_scheduler_type linear`\n\n`--warmup_ratio 0.03`\n\nå…¶ä¸­çš„æ¨¡å‹æƒé‡åˆ©ç”¨llama3.1-8B-baseæ¨¡å‹ã€‚\n\n#### è®­ç»ƒæµ‹è¯•\n##### è®­ç»ƒç»“æŸ\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image13.png)\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image14.png)\n\n| èµ„æºç±»å‹ | åˆ©ç”¨ç‡ | å†…å­˜/æ˜¾å­˜å ç”¨é‡ |\n| :---: | :---: | :---: |\n| CPU | 53.2% | 80.7% |\n| GPU | 85.5% | 66.4% |\n\n\n##### lossæ›²çº¿\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image15.png)\n\n##### eval\nllama3.1-8Bé€šè¿‡tulu3æä¾›çš„sftæ•°æ®é›†ï¼ˆåˆ å‡è‡³5kæ¡ï¼‰åï¼Œå¾—åˆ°çš„tulu3_sftæƒé‡\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image16.png)\n\n| ç±»åˆ« | Llama-31-8B | tulu3-sft-weight | Llama-31-Tulu-3-8B-SFT |\n| :---: | :---: | :---: | :---: |\n| å¹³å‡å‡†ç¡®ç‡ | 0.6014 | 0.5729 | **<font style=\"color:#DF2A3F;\">0.6356</font>** |\n| å­ç±»åˆ«å‡†ç¡®ç‡ | - | - | **<font style=\"color:#000000;\">-</font>** |\n| æ•°å­¦ | 0.4098 | 0.3778 | **0.4192** |\n| å¥åº· | 0.6561 | 0.6183 | **0.6720** |\n| ç‰©ç† | 0.5063 | 0.4891 | **0.5328** |\n| å•†ä¸š | 0.7643 | 0.7346 | **0.8101** |\n| ç”Ÿç‰© | 0.7555 | 0.6982 | **0.7775** |\n| åŒ–å­¦ | 0.4851 | 0.4851 | **0.5186** |\n| è®¡ç®—æœºç§‘å­¦ | 0.5752 | 0.5194 | **0.6092** |\n| ç»æµ | 0.5930 | 0.5809 | **0.6213** |\n| å·¥ç¨‹ | 0.5517 | 0.5172 | **0.5517** |\n| å“²å­¦ | 0.4881 | 0.4627 | **0.5775** |\n| å…¶ä»– | 0.6524 | 0.6532<font style=\"color:#000000;\">â¬†</font> | **0.7090** |\n| å†å² | 0.7452 | 0.7172 | **0.7774** |\n| åœ°ç† | 0.7323 | 0.7273 | **0.7677** |\n| æ”¿æ²» | 0.7546 | 0.7099 | **0.7762** |\n| å¿ƒç†å­¦ | 0.7174 | 0.6845 | **0.7485** |\n| æ–‡åŒ– | **0.8102** | 0.7440 | 0.7922 |\n| æ³•å¾‹ | 0.4878 | 0.4589 | **0.5020** |\n| ç±»åˆ«å‡†ç¡®ç‡ | - | - | - |\n| STEM | 0.5192 | 0.4864 | **0.5394** |\n| äººæ–‡å­¦ç§‘ | 0.5388 | 0.5116 | **0.5887** |\n| ç¤¾ä¼šç§‘å­¦ | 0.7062 | 0.6740 | **0.7296** |\n| å…¶ä»–ï¼ˆå•†ä¸šã€å¥åº·ç­‰ï¼‰ | 0.6693 | 0.6465 | **0.7039** |\n\n\n##### evalç»“æœåˆ†æ\n+ SFTåæƒé‡çš„å¹³å‡å‡†ç¡®ç‡: 0.5729\n+ SFTå‰æƒé‡çš„å¹³å‡å‡†ç¡®ç‡: 0.6014\n\næ•´ä½“å¹³å‡å‡†ç¡®ç‡ä¸‹é™äº† ~2.85%ã€‚\n\nåŸå› ï¼šæœ¬æ¬¡å®éªŒï¼ˆç”±äºæœºå™¨ç¯å¢ƒé™åˆ¶ï¼‰å°†åŸå§‹çš„tulu3 SFTæ•°æ®é›†ï¼ˆ93wï¼‰åˆ å‡åˆ°5kæ¡ï¼Œå¯¼è‡´æ¨¡å‹æœªèƒ½å……åˆ†å­¦ä¹ å„ä¸ªé¢†åŸŸçš„çŸ¥è¯†å’Œä»»åŠ¡ç‰¹æ€§ï¼Œæ³›åŒ–èƒ½åŠ›ä¸‹é™ã€‚\n\n## dpoå®è·µ\n### å•æœº4å¡æµ‹è¯•\n#### åå¥½æ•°æ®é›†\nåå¥½æ•°æ®é›†é‡‡ç”¨tulu3å®˜ç½‘æä¾›çš„æ•°æ®é›†ã€‚\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image17.png)\n\nåå¥½æ•°æ®é›†æ ·ä¾‹ï¼š\n\n```json\n{\"id\":\"allenai\\/tulu-3-sft-reused-off-policy_0\",\"prompt\":\"Peter has 5 cages with rabbits (the cages are arranged in a row). It is known that there is at least one rabbit in each cage. We will call two rabbits neighbors if they are either in the same cage or in adjacent cages. It turned out that each rabbit has either 3 or 7 neighbors. How many rabbits are in the central cage?\",\"chosen\":[{\"content\":\"Peter has 5 cages with rabbits (the cages are arranged in a row). It is known that there is at least one rabbit in each cage. We will call two rabbits neighbors if they are either in the same cage or in adjacent cages. It turned out that each rabbit has either 3 or 7 neighbors. How many rabbits are in the central cage?\",\"role\":\"user\"},{\"content\":\"Here's how to solve this problem:\\n\\n**Understanding the Information**\\n\\n* **Each rabbit has 3 or 7 neighbors:** This means there must be a pattern in how the rabbits are distributed within the cages.\\n* **At least one rabbit in each cage:**  We can't have cages without any rabbits.\\n\\n**Reasoning**\\n\\n* **Corner Cages:**  Rabbits in the corner cages (cages 1 and 5) can only have 3 neighbors (two adjacent cages and one within their own cage).\\n* **Middle Cages:** Rabbits in the middle cages (cages 2, 3, and 4) must have 7 neighbors to balance out the setup. \\n\\n**The Solution**\\n\\nSince rabbits in the middle cages need 7 neighbors, and there's at least one rabbit in each cage, the central cage (cage 3) must have **4 rabbits**. \\n\\n\\n\\nLet me know if you'd like to explore other logic puzzles! \\n\",\"role\":\"assistant\"}],\"rejected\":[{\"content\":\"Peter has 5 cages with rabbits (the cages are arranged in a row). It is known that there is at least one rabbit in each cage. We will call two rabbits neighbors if they are either in the same cage or in adjacent cages. It turned out that each rabbit has either 3 or 7 neighbors. How many rabbits are in the central cage?\",\"role\":\"user\"},{\"content\":\"The central cage has the same number of rabbits as any other cage, so it also has either 3 or 7 neighbors.\\nThere are (at most) 7 rabbits in the central cage and (at most) 3 rabbits in any cage on either side. Hence, there are (at most) 7 rabbits in each of those cages. The total number of rabbits in the 5 cages is (at most) 5 * 7 + 1 = 36 + 1 = 37.\\nOne cage must have exactly the right number of neighbors, but two cages cannot have the right number.\\nIf each cage has exactly 3 neighbors, the total number of rabbits in all 5 cages is 1 + 5 * 3 = 16\\nIf each cage has exactly 7 neighbors, the total number of rabbits in all 5 cages is 1 + 5 * 7 = 32\\nNow that we know there are at most 36 rabbits, we can safely conclude that there is 1 rabbit in the central cage, that there are 5 cages with 3 rabbits each and one cage with 7 rabbits and that the central cage has 3 neighbors.\\nThe central cage has exactly 3 rabbits and 3 neighbors.\\nIn the other 4 cages, there are (at most) 5 * 3 = 15 rabbits.\\nIn the other 5 cages, there are (at least) 32 â€“ 16 = 16 rabbits.\",\"role\":\"assistant\"}],\"source\":\"allenai\\/tulu-3-sft-reused-off-policy\"}\n```\n\nç”±äºæ˜¯.parquetæ ¼å¼æ•°æ®ï¼Œè½¬æˆjsonåä¸€å…±æœ‰67wæ¡æ•°æ®ã€‚\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image18.png)\n\nç”±äºæœºå™¨æ•°é‡æœ‰é™ï¼Œè®­ç»ƒå…¶å®Œæ•´æ•°æ®é›†éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œæ•…å°†.parquetè½¬ä¸ºjsonåå°†æ•°æ®é›†ç¼©å‡è‡³5kæ¡ï¼Œå¹¶å†æ¬¡è½¬å›.parquetæ ¼å¼æ•°æ®ã€‚\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image19.png)\n\n#### å•æœºè„šæœ¬é…ç½®\nå•æœºè„šæœ¬ï¼Œéƒ¨åˆ†é…ç½®OOMï¼Œé‡‡ç”¨deepseedä¸­zero3ä»¥åŠcpu_offloadingï¼Œå¼€å¯æ¢¯åº¦ç´¯ç§¯ã€‚\n\n```bash\n# you need 8 GPUs for full finetuning\nexport CUDA_VISIBLE_DEVICES=0,1,2,3\nexport WANDB_MODE=disabled\n\nNUM_GPUS=4\nBATCH_SIZE_PER_GPU=1\nTOTAL_BATCH_SIZE=8\nGRADIENT_ACC_STEPS=$(($TOTAL_BATCH_SIZE/$NUM_GPUS/$BATCH_SIZE_PER_GPU))\ncurrent_time=$(date \"+%Y.%m.%d-%H.%M.%S\")\nLOG_SAVE=\"/mnt/open-instruct-main/output/dpo/${current_time}-tulu3-dpo.log\"\necho \"Training model using $NUM_GPUS GPUs, $BATCH_SIZE_PER_GPU batch size per GPU, $GRADIENT_ACC_STEPS gradient accumulation steps\"\n\n#stage3_no_offloading_accelerate.conf\naccelerate launch \\\n    --mixed_precision fp16 \\\n    --num_machines 1 \\\n    --num_processes $NUM_GPUS \\\n    --use_deepspeed \\\n    --deepspeed_config_file /mnt/open-instruct-main/configs/ds_configs/stage3_offloading_accelerate.conf \\\n    /mnt/open-instruct-main/open_instruct/dpo_tune.py \\\n    --model_name_or_path /mnt/LLM-Research/Llama-31-Tulu-3-8B-SFT \\\n    --use_flash_attn  false\\\n    --gradient_checkpointing \\\n    --tokenizer_name /mnt/LLM-Research/Llama-31-Tulu-3-8B-SFT \\\n    --use_slow_tokenizer \\\n    --dataset_name /mnt/open-instruct-main/data/dpo_data_5k \\\n    --max_seq_length 2048 \\\n    --preprocessing_num_workers 4 \\\n    --per_device_train_batch_size $BATCH_SIZE_PER_GPU \\\n    --gradient_accumulation_steps $GRADIENT_ACC_STEPS \\\n    --learning_rate 5e-7 \\\n    --lr_scheduler_type linear \\\n    --warmup_ratio 0.1 \\\n    --weight_decay 0. \\\n    --num_train_epochs 1 \\\n    --output_dir /mnt/open-instruct-main/output/dpo \\\n    --with_tracking False \\\n    --logging_steps 1 2>&1 | tee -a \"$LOG_SAVE\"\n```\n\nä¸ºäº†å°½å¯èƒ½åœ°è¿˜åŸtulu3åŸè®ºæ–‡çš„å®éªŒç»“æœï¼Œå…¶ä¸­éƒ¨åˆ†è¶…å‚ä¸è®ºæ–‡ä¸­æœ€ä¼˜ä¿æŒä¸€è‡´ã€‚\n\n`--max_seq_length 2048`\n\n`--learning_rate 5e-7`\n\n`--lr_scheduler_type linear`\n\n`--warmup_ratio 0.1`\n\nå…¶ä¸­çš„æ¨¡å‹æƒé‡åˆ©ç”¨tulu3å¼€æºçš„ç»è¿‡llama3.1-8B sftå¾—åˆ°çš„æƒé‡ã€‚\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image20.png)\n\n#### è®­ç»ƒæµ‹è¯•\n##### å…³é—­cpu_offloading\næ³¨ï¼šå…³é—­cpu_offloadingä¹‹åï¼Œè¿­ä»£10æ­¥å·¦å³ä¼šOOM\n\n\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image21.png)\n\n| èµ„æºç±»å‹ | åˆ©ç”¨ç‡ | å†…å­˜/æ˜¾å­˜å ç”¨é‡ |\n| :---: | :---: | :---: |\n| CPU | 16.5% | 12.1% |\n| GPU | 100% | 93.6% |\n\n\n##### å¼€å¯cpu_offloading\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image22.png)\n\n| èµ„æºç±»å‹ | åˆ©ç”¨ç‡ | å†…å­˜/æ˜¾å­˜å ç”¨é‡ |\n| :---: | :---: | :---: |\n| CPU | 55.0% | 58.2% |\n| GPU | 85.8% | 68.7% |\n\n\n##### è®­ç»ƒå®Œæˆ\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image23.png)\n\nå¾—åˆ°çš„dpoæƒé‡\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image24.png)\n\n##### lossæ›²çº¿\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image25.png)\n\n##### eval\nè¯„æµ‹æ•°æ®é›†é‡‡ç”¨MMLUï¼Œä¸€ä¸ªåŒ…å«æ¥è‡ªå„ä¸ªçŸ¥è¯†é¢†åŸŸçš„å¤šé¡¹é€‰æ‹©é¢˜çš„å·¨å¤§å¤šä»»åŠ¡æµ‹è¯•ã€‚ æµ‹è¯•æ¶µç›–äº†äººæ–‡å­¦ç§‘ã€ç¤¾ä¼šç§‘å­¦ã€è‡ªç„¶ç§‘å­¦ä»¥åŠå…¶ä»–å¯¹æŸäº›äººæ¥è¯´é‡è¦çš„å­¦ä¹ é¢†åŸŸã€‚ æ•°æ®é›†ä¸­çš„é—®é¢˜æ˜¯ç”±ç ”ç©¶ç”Ÿå’Œæœ¬ç§‘ç”Ÿä»åœ¨çº¿å…è´¹èµ„æºä¸­æ‰‹åŠ¨æ”¶é›†çš„ã€‚è¿™åŒ…æ‹¬ç ”ç©¶ç”Ÿå…¥å­¦è€ƒè¯•å’Œç¾å›½åŒ»å­¦æ‰§ç…§è€ƒè¯•ç­‰è€ƒè¯•çš„ç»ƒä¹ é¢˜ã€‚è¿˜åŒ…æ‹¬ä¸ºæœ¬ç§‘ç”Ÿè¯¾ç¨‹è®¾è®¡çš„é¢˜ç›®ï¼Œä»¥åŠä¸ºç‰›æ´¥å¤§å­¦å‡ºç‰ˆç¤¾ä¹¦ç±è¯»è€…è®¾è®¡çš„é¢˜ç›®ã€‚ ä¸€äº›ä»»åŠ¡æ¶µç›–ä¸€ä¸ªä¸»é¢˜ï¼Œå¦‚å¿ƒç†å­¦ï¼Œä½†éš¾åº¦çº§åˆ«ç‰¹å®šï¼Œä¾‹å¦‚â€œåˆé˜¶â€ã€â€œé«˜ä¸­â€ã€â€œå¤§å­¦â€æˆ–â€œä¸“ä¸šâ€ã€‚ ä¾‹å¦‚ï¼Œâ€œä¸“ä¸šå¿ƒç†å­¦â€ä»»åŠ¡å€Ÿé‰´äº†å¿ƒç†å­¦ä¸“ä¸šå®è·µè€ƒè¯•çš„å…è´¹ç»ƒä¹ é¢˜ä¸­çš„é—®é¢˜ï¼Œè€Œâ€œé«˜ä¸­å¿ƒç†å­¦â€ä»»åŠ¡åˆ™åŒ…å«ç±»ä¼¼é«˜çº§ Placement å¿ƒç†å­¦è€ƒè¯•ä¸­çš„é—®é¢˜ã€‚\n\n:::tips\nMMLUæ•°æ®é›†æ ·ä¾‹å¦‚ä¸‹ï¼Œæ‘˜è‡ªMMLUè®ºæ–‡[https://arxiv.org/abs/2009.03300](https://arxiv.org/abs/2009.03300)\n\n:::\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image26.png)\n\negï¼šä»¥ä¸‹æ˜¯MMLUä¸Š<font style=\"color:rgb(0,0,0);\">College Biologyç±»é—®é¢˜åŠç­”æ¡ˆ</font>ï¼š\n\n```plain\n\"Based on the characteristic population curves that result from plotting population growth of a species, the most effective means of controlling the mosquito population is to\",\nmaintain the population at a point corresponding to the midpoint of its logistic curve,\nopt for zero population control once the K value of the curve has been reached,\nreduce the carrying capacity cif the environment to lower the K value,\nincrease the mortality rate,\nC\n```\n\negï¼šä»¥ä¸‹æ˜¯`dpo_weight`åœ¨MMLUä¸Š<font style=\"color:rgb(0,0,0);\">College Biologyç±»é—®é¢˜çš„å›ç­”</font>ï¼š\n\n```plain\n0,1,2,3,4,5,correct,choiceA_probs,choiceB_probs,choiceC_probs,choiceD_probs\n\"Based on the characteristic population curves that result from plotting population growth of a species, the most effective means of controlling the mosquito population is to\",\nmaintain the population at a point corresponding to the midpoint of its logistic curve,\nopt for zero population control once the K value of the curve has been reached,\nreduce the carrying capacity cif the environment to lower the K value,\nincrease the mortality rate,\nC,\nTrue,\n0.07324660569429398,\n0.0071399579755961895,\n0.6528399586677551,\n0.1929791122674942\n```\n\n\n\næœ¬æ¬¡dpoåå¾—åˆ°çš„æƒé‡`dpo_weight`å¯¹æ¯”tulu3å¼€æºçš„sftæƒé‡`Llama-31-Tulu-3-8B-SFT`ã€‚\n\n`Llama-31-Tulu-3-8B-SFT`åœ¨MMLUä¸Šçš„è¡¨ç°ï¼š\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image27.png)\n\n`dpo_weight`åœ¨MMLUä¸Šçš„è¡¨ç°ï¼š\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image28.png)\n\n| ç±»åˆ« | Llama-31-8B | Llama-31-Tulu-3-8B-SFT | dpo_weight | Llama-31-Tulu-3-8B-DPO |\n| :---: | :---: | :---: | :---: | :---: |\n| å¹³å‡å‡†ç¡®ç‡ | 0.6014 | 0.6356 | **<font style=\"color:#DF2A3F;\">0.6377</font>**â¬† | 0.6352 |\n| å­ç±»åˆ«å‡†ç¡®ç‡ | - | **<font style=\"color:#000000;\">-</font>** | **<font style=\"color:#000000;\">-</font>** | - |\n| æ•°å­¦ | 0.4098 | 0.4192 | **0.4352**â¬† | 0.4258 |\n| å¥åº· | 0.6561 | 0.6720 | 0.6726â¬† | **0.6915** |\n| ç‰©ç† | 0.5063 | 0.5328 | **0.5500**â¬† | 0.5391 |\n| å•†ä¸š | 0.7643 | **0.8101** | 0.7941 | 0.7849 |\n| ç”Ÿç‰© | 0.7555 | 0.7775 | **0.7775**â¬† | 0.7731 |\n| åŒ–å­¦ | 0.4851 | 0.5186 | 0.5182 | **0.5248** |\n| è®¡ç®—æœºç§‘å­¦ | 0.5752 | 0.6092 | **0.6189**â¬† | 0.6117 |\n| ç»æµ | 0.5930 | 0.6213 | 0.6173 | **0.6429** |\n| å·¥ç¨‹ | 0.5517 | 0.5517 | **0.5655**â¬† | 0.5586 |\n| å“²å­¦ | 0.4881 | **0.5775** | 0.5626 | 0.5388 |\n| å…¶ä»– | 0.6524 | 0.7090 | **0.7107**â¬† | 0.7082 |\n| å†å² | 0.7452 | 0.7774 | **0.7828**â¬† | 0.7720 |\n| åœ°ç† | 0.7323 | 0.7677 | 0.7778â¬† | **0.7778** |\n| æ”¿æ²» | 0.7546 | 0.7762 | **0.7793**â¬† | 0.7762 |\n| å¿ƒç†å­¦ | 0.7174 | 0.7485 | **0.7519**â¬† | 0.7476 |\n| æ–‡åŒ– | **0.8102** | 0.7922 | 0.7892 | 0.8042 |\n| æ³•å¾‹ | 0.4878 | 0.5020 | **0.5133**â¬† | 0.5156 |\n| çˆ¶ç±»åˆ«å‡†ç¡®ç‡ | - | - | **-** | - |\n| STEM | 0.5192 | 0.5394 | **0.5507**â¬† | 0.5437 |\n| äººæ–‡å­¦ç§‘ | 0.5388 | **0.5887** | 0.5877 | 0.5762 |\n| ç¤¾ä¼šç§‘å­¦ | 0.7062 | 0.7296 | 0.7309â¬† | **0.7364** |\n| å…¶ä»–ï¼ˆå•†ä¸šã€å¥åº·ã€æ‚é¡¹ï¼‰ | 0.6693 | 0.7039 | 0.7027 | **0.7101** |\n\n\n### dpoä»£ç å®ç°åˆ†æ\n#### Length-Normalized DPO çš„å®ç°\n##### `_get_batch_logps` å‡½æ•°  \ntulu3è®ºæ–‡ä¸­è¯´æ˜äº†ï¼Œtulu3-8Bçš„dpoä½¿ç”¨äº†é•¿åº¦å½’ä¸€åŒ–çš„DPOï¼ˆLength-Normalized DPOï¼‰ï¼Œä»¥æ­¤æ¥æ¶ˆé™¤<font style=\"color:#000000;background-color:#F1A2AB;\">å› å›ç­”çš„åºåˆ—é•¿åº¦ï¼ˆå¯¹æ¯”æ¥è¯´å¾ˆé•¿çš„è¯ï¼‰å¸¦æ¥çš„æ¦‚ç‡åå¥½å½±å“ã€‚</font> å½“ `average_log_prob=True` æ—¶ï¼Œä¼šå°†æ¯ä¸ª token çš„ log æ¦‚ç‡è¿›è¡Œå¹³å‡å¤„ç†ï¼Œå®ç°åºåˆ—é•¿åº¦å½’ä¸€åŒ–ã€‚ å¦‚æœ`average_log_prob=False`ï¼Œåˆ™æ˜¯ç›´æ¥æ±‚å’Œã€‚\n\nä»£ç å…·ä½“å®ç°å¦‚ä¸‹ï¼š\n\n```python\ndef _get_batch_logps(\n    logits: torch.FloatTensor, labels: torch.LongTensor, average_log_prob: bool = False\n) -> torch.FloatTensor:\n    # ç¡®ä¿logitså’Œlabelsçš„å½¢çŠ¶åœ¨é™¤äº†æœ€åä¸€ä¸ªç»´åº¦å¤–æ˜¯ç›¸åŒçš„ã€‚\n    assert logits.shape[:-1] == labels.shape\n    # ä¸¤è¡Œä»£ç åˆ†åˆ«å¯¹labelså’Œlogitsè¿›è¡Œåˆ‡ç‰‡æ“ä½œï¼Œå»æ‰äº†æ¯ä¸ªåºåˆ—çš„ç¬¬ä¸€ä¸ªå’Œæœ€åä¸€ä¸ªå…ƒç´ ã€‚\n    labels = labels[:, 1:].clone()\n    logits = logits[:, :-1, :]\n    # è¿™è¡Œä»£ç åˆ›å»ºäº†ä¸€ä¸ªæ©ç loss_maskï¼Œç”¨äºæ ‡è¯†å“ªäº›æ ‡ç­¾ä¸æ˜¯-100ï¼ˆå³ä¸æ˜¯è¦è¢«å¿½ç•¥çš„æ ‡ç­¾ï¼‰ã€‚\n    loss_mask = labels != -100\n\n    # è¿™è¡Œä»£ç å°†labelsä¸­å€¼ä¸º-100çš„å…ƒç´ æ›¿æ¢ä¸º0ï¼Œå› ä¸ºåœ¨PyTorchä¸­ï¼Œ0å¯ä»¥ä½œä¸ºæ— æ•ˆç´¢å¼•ã€‚\n    labels[labels == -100] = 0\n\n    # è®¡ç®—æ¯ä¸ªtokençš„å¯¹æ•°æ¦‚ç‡ã€‚é¦–å…ˆå¯¹logitsåº”ç”¨log_softmaxå‡½æ•°ï¼Œç„¶ååœ¨æœ€åä¸€ä¸ªç»´åº¦ä¸Šä½¿ç”¨torch.gatheræ ¹æ®labelsç´¢å¼•æ¥é€‰æ‹©å¯¹åº”çš„å¯¹æ•°æ¦‚ç‡ã€‚\n    per_token_logps = torch.gather(logits.log_softmax(-1), dim=2, index=labels.unsqueeze(2)).squeeze(2)\n\n    # æ ¹æ®average_log_probçš„å€¼å†³å®šè¿”å›å€¼ã€‚å¦‚æœaverage_log_probä¸ºTrueï¼Œåˆ™è¿”å›æ¯ä¸ªæ ·æœ¬çš„å¹³å‡å¯¹æ•°æ¦‚ç‡ï¼›å¦åˆ™ï¼Œè¿”å›æ¯ä¸ªæ ·æœ¬çš„å¯¹æ•°æ¦‚ç‡ä¹‹å’Œ\n    if average_log_prob:\n        return (per_token_logps * loss_mask).sum(-1) / loss_mask.sum(-1)\n    else:\n        return (per_token_logps * loss_mask).sum(-1)\n```\n\n:::tips\n<font style=\"color:rgba(0, 0, 0, 0.85);\">å‡½æ•°_get_batch_logpsç”¨äºè®¡ç®—ç»™å®šæ ‡ç­¾ï¼ˆlabelsï¼‰åœ¨ç»™å®šçš„æ¨¡å‹è¾“å‡ºï¼ˆlogitsï¼‰ä¸‹çš„å¯¹æ•°æ¦‚ç‡ï¼ˆlog probabilitiesï¼‰ã€‚</font>\n\n<font style=\"color:rgba(0, 0, 0, 0.85);\">å‚æ•°è¯´æ˜ï¼š</font>\n\n+ <font style=\"color:rgba(0, 0, 0, 0.85);\">logits</font><font style=\"color:rgba(0, 0, 0, 0.85);\">ï¼šæ¨¡å‹çš„è¾“å‡ºï¼ˆæœªå½’ä¸€åŒ–çš„ï¼‰ã€‚å½¢çŠ¶ä¸º</font><font style=\"color:rgba(0, 0, 0, 0.85);\">(batch_size, sequence_length, vocab_size)</font><font style=\"color:rgba(0, 0, 0, 0.85);\">ï¼Œå…¶ä¸­</font><font style=\"color:rgba(0, 0, 0, 0.85);\">batch_size</font><font style=\"color:rgba(0, 0, 0, 0.85);\">æ˜¯æ‰¹æ¬¡å¤§å°ï¼Œ</font><font style=\"color:rgba(0, 0, 0, 0.85);\">sequence_length</font><font style=\"color:rgba(0, 0, 0, 0.85);\">æ˜¯åºåˆ—é•¿åº¦ï¼Œ</font><font style=\"color:rgba(0, 0, 0, 0.85);\">vocab_size</font><font style=\"color:rgba(0, 0, 0, 0.85);\">æ˜¯è¯æ±‡è¡¨çš„å¤§å°ã€‚</font>\n+ <font style=\"color:rgba(0, 0, 0, 0.85);\">labels</font><font style=\"color:rgba(0, 0, 0, 0.85);\">ï¼šè¦è®¡ç®—å¯¹æ•°æ¦‚ç‡çš„æ ‡ç­¾ã€‚å€¼ä¸º-100çš„æ ‡ç­¾æ ‡è®°å°†è¢«å¿½ç•¥ã€‚å½¢çŠ¶ä¸º</font><font style=\"color:rgba(0, 0, 0, 0.85);\">(batch_size, sequence_length)</font><font style=\"color:rgba(0, 0, 0, 0.85);\">ã€‚</font>\n+ <font style=\"color:rgba(0, 0, 0, 0.85);\">average_log_prob</font><font style=\"color:rgba(0, 0, 0, 0.85);\">ï¼šä¸€ä¸ªå¸ƒå°”å€¼ï¼Œé»˜è®¤ä¸º</font><font style=\"color:rgba(0, 0, 0, 0.85);\">False</font><font style=\"color:rgba(0, 0, 0, 0.85);\">ã€‚å¦‚æœä¸º</font><font style=\"color:rgba(0, 0, 0, 0.85);\">True</font><font style=\"color:rgba(0, 0, 0, 0.85);\">ï¼Œåˆ™è¿”å›æ¯ä¸ªï¼ˆæœªè¢«æ©ç çš„ï¼‰tokençš„å¹³å‡å¯¹æ•°æ¦‚ç‡ï¼›å¦‚æœä¸º</font><font style=\"color:rgba(0, 0, 0, 0.85);\">False</font><font style=\"color:rgba(0, 0, 0, 0.85);\">ï¼Œåˆ™è¿”å›ï¼ˆæœªè¢«æ©ç çš„ï¼‰tokençš„å¯¹æ•°æ¦‚ç‡ä¹‹å’Œã€‚</font>\n\n<font style=\"color:rgba(0, 0, 0, 0.85);\">è¿”å›å€¼ï¼š</font>\n\n+ <font style=\"color:rgba(0, 0, 0, 0.85);\">è¿”å›ä¸€ä¸ªå½¢çŠ¶ä¸º</font><font style=\"color:rgba(0, 0, 0, 0.85);\">(batch_size,)</font><font style=\"color:rgba(0, 0, 0, 0.85);\">çš„å¼ é‡ï¼ŒåŒ…å«ç»™å®šæ ‡ç­¾åœ¨ç»™å®šlogitsä¸‹çš„å¯¹æ•°æ¦‚ç‡çš„å¹³å‡å€¼æˆ–æ€»å’Œã€‚</font>\n\n<font style=\"color:rgba(0, 0, 0, 0.85);\">è¯¥å‡½æ•°æ˜¯ç”¨æ¥è®¡ç®—æ¨¡å‹é¢„æµ‹çš„æ¦‚ç‡ï¼Œå¹¶æ ¹æ®æ ‡ç­¾æ¥ç¡®å®šå“ªäº›é¢„æµ‹æ˜¯æœ‰æ•ˆçš„ï¼ˆå³æ ‡ç­¾å€¼ä¸ä¸º-100ï¼‰ã€‚å¦‚æœaverage_log_probå‚æ•°ä¸ºTrueï¼Œåˆ™å‡½æ•°è¿”å›çš„æ˜¯å¹³å‡å¯¹æ•°æ¦‚ç‡ï¼›å¦‚æœä¸ºFalseï¼Œåˆ™è¿”å›çš„æ˜¯æ€»å’Œã€‚</font>\n\n:::\n\n##### `concatenated_forward` å‡½æ•°  \n åœ¨è®­ç»ƒä¸­ï¼Œ`concatenated_forward` è´Ÿè´£å¯¹æ¨¡å‹çš„ `logps` è¿›è¡Œè®¡ç®—ï¼š  \n\n```python\ndef concatenated_forward(\n    model: nn.Module,\n    batch: Dict[str, Union[List, torch.LongTensor]],\n    average_log_prob: bool = False,\n    output_router_logits: bool = False,\n) -> Tuple[torch.FloatTensor, torch.FloatTensor]:\n    concatenated_batch = concatenated_inputs(batch)\n    if output_router_logits:\n        outputs = model(\n            input_ids=concatenated_batch[\"concatenated_input_ids\"],\n            attention_mask=concatenated_batch[\"concatenated_attention_mask\"],\n            output_router_logits=True,\n        )\n        logits = outputs.logits.to(torch.float32)\n        aux_loss = outputs.aux_loss\n    else:\n        logits = model(\n            input_ids=concatenated_batch[\"concatenated_input_ids\"],\n            attention_mask=concatenated_batch[\"concatenated_attention_mask\"],\n        ).logits.to(torch.float32)\n        aux_loss = None\n    all_logps = _get_batch_logps(logits, concatenated_batch[\"concatenated_labels\"], average_log_prob=average_log_prob)\n    chosen_logps = all_logps[: batch[\"chosen_input_ids\"].shape[0]]\n    rejected_logps = all_logps[batch[\"chosen_input_ids\"].shape[0] :]\n    return chosen_logps, rejected_logps, aux_loss\n```\n\n å‚æ•° `average_log_prob` æ˜¯ä»ä¸»è„šæœ¬`dpo_tune.py`ä¸­ä¼ é€’çš„ï¼Œå½“è®¾ç½®ä¸º `True` æ—¶ï¼Œå¯ç”¨é•¿åº¦å½’ä¸€åŒ–ã€‚  \n\n##### `dpo_loss` å‡½æ•°  \n`dpo_loss` ä¸­è®¡ç®— logits çš„å·®å€¼ï¼š  \n\n```python\npi_logratios = policy_chosen_logps - policy_rejected_logps\nref_logratios = reference_chosen_logps - reference_rejected_logps\nlogits = pi_logratios - ref_logratios\n```\n\n å¦‚æœ `average_log_prob=True`ï¼Œåˆ™ `policy_chosen_logps` å’Œ `policy_rejected_logps` éƒ½æ˜¯å½’ä¸€åŒ–çš„å€¼ï¼Œä»è€Œå½±å“æœ€ç»ˆçš„ logits å’ŒæŸå¤±è®¡ç®—ã€‚  \n\n##### æ§åˆ¶å‚æ•°  \n åœ¨ä¸»è„šæœ¬dpo_tune.pyä¸­ï¼Œé€šè¿‡ä»¥ä¸‹ä»£ç æ§åˆ¶æ˜¯å¦å¯ç”¨é•¿åº¦å½’ä¸€åŒ–ï¼š  \n\n```python\naverage_log_prob_loss_types = [\"simpo\", \"dpo_norm\"]\naverage_log_prob = args.dpo_loss_type in average_log_prob_loss_types\n```\n\n å½“ `dpo_loss_type` è®¾ç½®ä¸º `\"dpo_norm\"` æ—¶ï¼Œ`average_log_prob`å½’ä¸€åŒ–è¢«å¯ç”¨ï¼Œè¿›è€Œåœ¨ `_get_batch_logps` å’Œ `concatenated_forward` ä¸­è§¦å‘é•¿åº¦å½’ä¸€åŒ–é€»è¾‘ã€‚  \n\n## rlvrå®è·µ\n### å•æœº4å¡æµ‹è¯•\n####  è®­ç»ƒæ•°æ®é›†\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image29.png)\n\n.parquetè½¬ä¸ºjsonåçš„æ•°æ®é›†æ ·ä¾‹ï¼š\n\n```json\n{\"messages\":[{\"content\":\"Question: Find the domain of the expression $\\\\frac{\\\\sqrt{x-2}}{\\\\sqrt{5-x}}$.}\\nAnswer:The expressions inside each square root must be non-negative.\\nTherefore, $x-2 \\\\ge 0$, so $x\\\\ge2$, and $5 - x \\\\ge 0$, so $x \\\\le 5$.\\nAlso, the denominator cannot be equal to zero, so $5-x>0$, which gives $x<5$.\\nTherefore, the domain of the expression is $\\\\boxed{[2,5)}$.\\n\\nQuestion: If $\\\\det \\\\mathbf{A} = 2$ and $\\\\det \\\\mathbf{B} = 12,$ then find $\\\\det (\\\\mathbf{A} \\\\mathbf{B}).$\\nAnswer:We have that $\\\\det (\\\\mathbf{A} \\\\mathbf{B}) = (\\\\det \\\\mathbf{A})(\\\\det \\\\mathbf{B}) = (2)(12) = \\\\boxed{24}.$\\n\\nQuestion: Terrell usually lifts two 20-pound weights 12 times. If he uses two 15-pound weights instead, how many times must Terrell lift them in order to lift the same total weight?\\nAnswer:If Terrell lifts two 20-pound weights 12 times, he lifts a total of $2\\\\cdot 12\\\\cdot20=480$ pounds of weight.  If he lifts two 15-pound weights instead for $n$ times, he will lift a total of $2\\\\cdot15\\\\cdot n=30n$ pounds of weight.  Equating this to 480 pounds, we can solve for $n$: \\\\begin{align*}\\n30n&=480\\\\\\\\\\n\\\\Rightarrow\\\\qquad n&=480\\/30=\\\\boxed{16}\\n\\\\end{align*}\\n\\nQuestion: If the system of equations\\n\\n\\\\begin{align*}\\n6x-4y&=a,\\\\\\\\\\n6y-9x &=b.\\n\\\\end{align*}has a solution $(x, y)$ where $x$ and $y$ are both nonzero, find $\\\\frac{a}{b},$ assuming $b$ is nonzero.\\nAnswer:If we multiply the first equation by $-\\\\frac{3}{2}$, we obtain\\n\\n$$6y-9x=-\\\\frac{3}{2}a.$$Since we also know that $6y-9x=b$, we have\\n\\n$$-\\\\frac{3}{2}a=b\\\\Rightarrow\\\\frac{a}{b}=\\\\boxed{-\\\\frac{2}{3}}.$$\\n\\nQuestion: What is the modulo $13$ residue of $247+5 \\\\cdot 39 + 7 \\\\cdot 143 +4 \\\\cdot 15?$\",\"role\":\"user\"}],\"ground_truth\":\"8\",\"dataset\":\"MATH\",\"constraint_type\":null,\"constraint\":null}\n```\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image30.png)\n\n#### éªŒè¯æ•°æ®é›†\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image31.png)\n\n```json\n{\"messages\":[{\"content\":\"Question: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\\nAnswer:There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. So the answer is 6.\\n\\nQuestion: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\\nAnswer:There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. So the answer is 5.\\n\\nQuestion: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\\nAnswer:Originally, Leah had 32 chocolates. Her sister had 42. So in total they had 32 + 42 = 74. After eating 35, they had 74 - 35 = 39. So the answer is 39.\\n\\nQuestion: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did Jason give to Denny?\\nAnswer:Jason started with 20 lollipops. Then he had 12 after giving some to Denny. So he gave Denny 20 - 12 = 8. So the answer is 8.\\n\\nQuestion: Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does he have now?\\nAnswer:Shawn started with 5 toys. If he got 2 toys each from his mom and dad, then that is 4 more toys. 5 + 4 = 9. So the answer is 9.\\n\\nQuestion: There were nine computers in the server room. Five more computers were installed each day, from monday to thursday. How many computers are now in the server room?\\nAnswer:There were originally 9 computers. For each of 4 days, 5 more computers were added. So 5 * 4 = 20 computers were added. 9 + 20 is 29. So the answer is 29.\\n\\nQuestion: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf balls did he have at the end of wednesday?\\nAnswer:Michael started with 58 golf balls. After losing 23 on tuesday, he had 58 - 23 = 35. After losing 2 more, he had 35 - 2 = 33 golf balls. So the answer is 33.\\n\\nQuestion: Olivia has $23. She bought five bagels for $3 each. How much money does she have left?\\nAnswer:Olivia had 23 dollars. 5 bagels for 3 dollars each will be 5 x 3 = 15 dollars. So she has 23 - 15 dollars left. 23 - 15 is 8. So the answer is 8.\\n\\nQuestion: A robe takes 2 bolts of blue fiber and half that much white fiber.  How many bolts in total does it take?\",\"role\":\"user\"}],\"ground_truth\":\"3\",\"dataset\":\"gsm8k\"}\n{\"messages\":[{\"content\":\"Question: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\\nAnswer:There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. So the answer is 6.\\n\\nQuestion: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\\nAnswer:There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. So the answer is 5.\\n\\nQuestion: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\\nAnswer:Originally, Leah had 32 chocolates. Her sister had 42. So in total they had 32 + 42 = 74. After eating 35, they had 74 - 35 = 39. So the answer is 39.\\n\\nQuestion: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did Jason give to Denny?\\nAnswer:Jason started with 20 lollipops. Then he had 12 after giving some to Denny. So he gave Denny 20 - 12 = 8. So the answer is 8.\\n\\nQuestion: Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does he have now?\\nAnswer:Shawn started with 5 toys. If he got 2 toys each from his mom and dad, then that is 4 more toys. 5 + 4 = 9. So the answer is 9.\\n\\nQuestion: There were nine computers in the server room. Five more computers were installed each day, from monday to thursday. How many computers are now in the server room?\\nAnswer:There were originally 9 computers. For each of 4 days, 5 more computers were added. So 5 * 4 = 20 computers were added. 9 + 20 is 29. So the answer is 29.\\n\\nQuestion: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf balls did he have at the end of wednesday?\\nAnswer:Michael started with 58 golf balls. After losing 23 on tuesday, he had 58 - 23 = 35. After losing 2 more, he had 35 - 2 = 33 golf balls. So the answer is 33.\\n\\nQuestion: Olivia has $23. She bought five bagels for $3 each. How much money does she have left?\\nAnswer:Olivia had 23 dollars. 5 bagels for 3 dollars each will be 5 x 3 = 15 dollars. So she has 23 - 15 dollars left. 23 - 15 is 8. So the answer is 8.\\n\\nQuestion: Josh decides to try flipping a house.  He buys a house for $80,000 and then puts in $50,000 in repairs.  This increased the value of the house by 150%.  How much profit did he make?\",\"role\":\"user\"}],\"ground_truth\":\"70000\",\"dataset\":\"gsm8k\"}\n```\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image32.png)\n\n#### å•æœºè„šæœ¬é…ç½®\n```bash\nexport WANDB_MODE=disabled\nexport PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n\ncurrent_time=$(date \"+%Y.%m.%d-%H.%M.%S\")\nLOG_SAVE=\"/mnt/open-instruct-main/output/rlvr/${current_time}-tulu3-rlvr.log\"\n\npython /mnt/open-instruct-main/open_instruct/ppo_vllm_thread_ray_gtrl.py \\\n    --dataset_mixer '{\"/mnt/open-instruct-main/data/gsm8k_math_ground_truth_mixed\": 1.0}' \\\n    --dataset_train_splits train \\\n    --dataset_eval_mixer '{\"/mnt/open-instruct-main/data/gsm8k_math_ground_truth\": 1.0}' \\\n    --dataset_eval_splits test \\\n    --max_token_length 2048 \\\n    --max_prompt_token_length 2048 \\\n    --response_length 2048 \\\n    --model_name_or_path /mnt/LLM-Research/Llama-31-Tulu-3-8B-DPO \\\n    --reward_model_path /mnt/LLM-Research/LLama-31-Tulu3-8B-RM \\\n    --non_stop_penalty \\\n    --stop_token eos \\\n    --temperature 1.0 \\\n    --ground_truths_key ground_truth \\\n    --chat_template tulu \\\n    --sft_messages_key messages \\\n    --learning_rate 3e-7 \\\n    --total_episodes 10000000 \\\n    --penalty_reward_value -10.0 \\\n    --deepspeed_stage 3 \\\n    --per_device_train_batch_size 1 \\\n    --local_rollout_forward_batch_size 1 \\\n    --local_mini_batch_size 16 \\\n    --local_rollout_batch_size 16 \\\n    --actor_num_gpus_per_node 3 \\\n    --vllm_tensor_parallel_size 2 \\\n    --beta 0.05 \\\n    --apply_verifiable_reward true \\\n    --output_dir /mnt/open-instruct-main/output/rlvr \\\n    --seed 3 \\\n    --num_evals 3 \\\n    --save_freq 100 \\\n    --reward_model_multiplier 0.0 \\\n    --gradient_checkpointing \\\n    --with_tracking False 2>&1 | tee -a \"$LOG_SAVE\"\n```\n\nä¸ºäº†å°½å¯èƒ½åœ°è¿˜åŸtulu3åŸè®ºæ–‡çš„å®éªŒç»“æœï¼Œå…¶ä¸­éƒ¨åˆ†è¶…å‚ä¸è®ºæ–‡ä¸­æœ€ä¼˜ä¿æŒä¸€è‡´ã€‚\n\n`--max_token_length 2048`\n\n`--max_prompt_token_length 2048` \n\n`--response_length 2048`\n\n`--learning_rate 3e-7`\n\n`--penalty_reward_value -10.0`\n\n`--reward_model_multiplier 0.0`\n\nå…¶ä¸­çš„æ¨¡å‹æƒé‡åˆ©ç”¨tulu3å¼€æºçš„ç»è¿‡tulu3-sft dpoå¾—åˆ°çš„Llama-31-Tulu-3-8B-DPOæƒé‡ï¼Œå¥–åŠ±æ¨¡å‹é‡‡ç”¨tulu3å¼€æºçš„LLama-31-Tulu3-8B-RMã€‚\n\n#### è®­ç»ƒæµ‹è¯•\nåŠ è½½ckptæ—¶ä¸€ç›´å¡ä½ä¸åŠ¨ï¼Œå°šæœªè§£å†³ã€‚\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Tulu3/image33.png)\n\n","tags":["V100","æ¨¡å‹è®­ç»ƒè°ƒä¼˜","Nvidia","Tulu3"],"categories":["æ¨¡å‹è®­ç»ƒè°ƒä¼˜","NVIDIA"]},{"title":"å‰ç«¯1_è°ƒç”¨apiæ¥å£çš„å†™æ³•","url":"/2025/11/06/å‰ç«¯/å‰ç«¯1_è°ƒç”¨apiæ¥å£çš„å†™æ³•/","content":"\n### Getè¯·æ±‚å†™æ³•\n#### 1. çœ‹Parametersä¸­æ˜¯å¦æœ‰éœ€è¦å¸¦å‚æ•°ï¼Œå…¶ä¸­`Authorization`ä¸ºæˆæƒè®¤è¯çš„tokenå¯ä»¥ä¸ç”¨è€ƒè™‘ã€‚\n1.1 è‹¥æ˜¯æ²¡æœ‰å…¶ä½™çš„å‚æ•°é™å®šï¼Œé‚£ä¹ˆSyncRequestFuncType<è¯·æ±‚å‚æ•°ç±»å‹,å“åº”è¿”å›å‚æ•°ç±»å‹>ï¼Œç¬¬ä¸€ä¸ªå‚æ•°å°±ä¸ºvoidæˆ–è€…undefinedã€‚è¿”å›ç±»å‹å¯ä»¥ä½¿ç”¨anyï¼Œç­‰è·å–åˆ°å“åº”å‚æ•°ä¹‹åï¼Œåœ¨å¯¹å…¶é€šè¿‡Interface/typeè¿›è¡Œæ˜ç¡®ã€‚\n\n```javascript\nexport const getApi: SyncRequestFuncType<\nvoid,\nresponseType\n> = () => {\nreturn javaAxios({\n method: \"get\",\n url: \"xxx/xxxx\",\n});\n};\n```\n\n1.2 è‹¥æ˜¯æœ‰å…¶ä½™å‚æ•°é™å®šï¼Œè¿™æ—¶éœ€è¦ç®­å¤´å‡½æ•°ä¸­éœ€è¦å¸¦ç€paramsæ¥è¿›è¡Œè¯·æ±‚ï¼Œä¸”reuturnä¸­ä¹Ÿéœ€è¦å°†paramså¸¦ç€ã€‚\n\n\t1.2.1 `å•ä¸ªå‚æ•°`ï¼Œä¾‹å¦‚idï¼Œè¿™æ—¶åœ¨è¯·æ±‚å‚æ•°ç±»å‹ä¸­ï¼Œéœ€è¦æ˜ç¡®å‡ºè¯·æ±‚å‚æ•°çš„ç±»å‹<{id:string},responseType>ï¼Œè¿™æ—¶è¯·æ±‚å‚æ•°çš„ç±»å‹ä¸ºå¯¹è±¡{}çš„å½¢å¼ï¼Œå¯ä»¥ç›´æ¥åœ¨å°–æ‹¬å·ä¸­å†™å‡ºæ¥ï¼Œä¹Ÿå¯ä»¥é€šè¿‡å¼•å…¥å®šä¹‰çš„Interface/typeç±»å‹æ¥å†™<IdType,responseType>ã€‚\n\n```javascript\nexport const getApi: SyncRequestFuncType<\n {id:string},\n void\n> = (params) => {\nreturn javaAxios({\n method: \"get\",\n url: \"xxx/xxxx\",\n params,\n});\n};\n```\n\n\t1.2.2 `å¤šä¸ªå‚æ•°`ï¼Œä¾‹å¦‚emailï¼Œtype...ï¼Œå› ä¸ºå‚æ•°æ¯”è¾ƒå¤šï¼Œæœ€å¥½é€šè¿‡Interface/typeçš„æ–¹å¼SendEmailCaptchaForUserInfoModifyTypeæ¥æ˜ç¡®è¯·æ±‚å‚æ•°ç±»å‹ã€‚\n\n```javascript\nexport type SendEmailCaptchaForUserInfoModifyType = {\ntype: ModifyType;\nemail?: string;\n};\n```\n\n```javascript\nexport const getApi: SyncRequestFuncType<\nSendEmailCaptchaForUserInfoModifyType,\nvoid\n> = (params) => {\nreturn javaAxios({\n method: \"get\",\n url: \"xxx/xxx\",\n params,\n});\n};\n```\n\n### Postè¯·æ±‚å†™æ³•\n#### 1. çœ‹çœ‹Parametersä¸­æ˜¯å¦æœ‰éœ€è¦å¸¦å‚æ•°ï¼Œå…¶ä¸­`Authorization`ä¸ºæˆæƒè®¤è¯çš„tokenå¯ä»¥ä¸ç”¨è€ƒè™‘ã€‚\n1.1 è‹¥æ˜¯æ²¡æœ‰å…¶ä½™çš„å‚æ•°é™å®šï¼Œé‚£ä¹ˆSyncRequestFuncType<è¯·æ±‚å‚æ•°ç±»å‹,å“åº”è¿”å›å‚æ•°ç±»å‹>ï¼Œç¬¬ä¸€ä¸ªå‚æ•°å°±ä¸ºvoidæˆ–è€…undefinedã€‚è¿”å›ç±»å‹å¯ä»¥ä½¿ç”¨anyï¼Œç­‰è·å–åˆ°å“åº”å‚æ•°ä¹‹åï¼Œåœ¨å¯¹å…¶é€šè¿‡Interface/typeè¿›è¡Œæ˜ç¡®ã€‚\n\n```javascript\nexport const clearVideoRecycle: SyncRequestFuncType<void, void> = () => {\nreturn javaAxios({\n method: \"post\",\n url: \"xxx/xxx\",\n});\n};\n```\n\n1.2 è‹¥æ˜¯æœ‰å…¶ä½™å‚æ•°é™å®šï¼Œè¿™æ—¶éœ€è¦ç®­å¤´å‡½æ•°ä¸­éœ€è¦å¸¦ç€paramsæ¥è¿›è¡Œè¯·æ±‚ï¼Œä¸”reuturnä¸­ä¹Ÿéœ€è¦å°†paramså¸¦ç€ã€‚\n\n\t1.2.1 å•ä¸ªå‚æ•°æ—¶\n\n```javascript\nexport const cancelSubscribeVideo: SyncRequestFuncType<\n{ themeId: string },\nany\n> = (params) => {\nreturn javaAxios({\n method: \"post\",\n url: \"xxx/xxx\",\n params,\n});\n};\n```\n\n\t1.2.2 å¤šä¸ªå‚æ•°æ—¶\n\n```javascript\nexport type SendEmailCaptchaForUserInfoModifyType = {\ntype: ModifyType;\nemail?: string;\n};\n```\n\n```javascript\nexport const sendEmailCaptchaForUserInfoModify: SyncRequestFuncType<\nSendEmailCaptchaForUserInfoModifyType,\nvoid\n> = (params) => {\nreturn javaAxios({\n method: \"get\",\n url: \"xxx/xxx\",\n params,\n});\n};\n```\n\n#### 2. å½“å‡ºç°è¯·æ±‚ä½“`Request body`æ—¶ï¼Œè¿™æ—¶å°±éœ€è¦åœ¨returnçš„javaAxiosä¸­æ·»åŠ é”®å€¼å¯¹`data: params`ï¼Œæ¥å°†å‚æ•°æ·»åŠ åˆ°è¯·æ±‚ä½“ä¸­ä¼ é€’è¿‡å»ã€‚\n2.1 Request bodyä¸ºï¼š\n\n```javascript\n[\n\"string\"\n]\n```\n\n```javascript\nexport const batchDeleteVideo: SyncRequestFuncType<string[], void> = (\nparams\n) => {\nreturn javaAxios({\n method: \"post\",\n url: \"videos/themes/batchDel\",\n data: params,\n});\n};\n```\n\n2.2 Request bodyä¸ºï¼šè¿™æ—¶å€™éœ€è¦åœ¨dataä¸­è¿›ä¸€æ­¥åœ¨çº¦æŸä¸€ä¸‹ï¼Œä½¿å…¶å¯¹åº”apiçš„è¯·æ±‚ä½“çš„æ ¼å¼ã€‚\n\n```javascript\n{\n\"themes\": [\n \"string\"\n]\n}\n```\n\n```javascript\nexport const sortVideos: SyncRequestFuncType<string[], void> = (params) => {\nreturn javaAxios({\n method: \"post\",\n url: \"videos/themes/changeVideoThemesSort\",\n data: { themes: params },\n});\n};\n```\n\n","tags":["å‰ç«¯","Javascript"],"categories":["å‰ç«¯"]},{"title":"åŸºäºMindformersçš„llama3.1æ¨¡å‹å¾®è°ƒ","url":"/2025/11/06/æ¨¡å‹è®­ç»ƒè°ƒä¼˜/æ˜‡è…¾/Mindformers/llama3.1å¾®è°ƒ/","content":"## å¯åŠ¨å®¹å™¨\n```bash\ndocker run -dit --ipc=host --net=host \\\n--name=wxb_mindformers \\\n--device=/dev/davinci0 \\\n--device=/dev/davinci1 \\\n--device=/dev/davinci2 \\\n--device=/dev/davinci3 \\\n--device=/dev/davinci4 \\\n--device=/dev/davinci5 \\\n--device=/dev/davinci6 \\\n--device=/dev/davinci7 \\\n--device=/dev/davinci_manager \\\n--device=/dev/devmm_svm \\\n--device=/dev/hisi_hdc \\\n-v /etc/ascend_install.info:/etc/ascend_install.info \\\n-v /etc/hccn.conf:/etc/hccn.conf \\\n-v /etc/localtime:/etc/localtime \\\n-v /var/log/npu/:/usr/slog \\\n-v /usr/local/sbin/npu-smi:/usr/local/sbin/npu-smi \\\n-v /usr/local/Ascend/driver:/usr/local/Ascend/driver \\\n-v /reason-sharedata/training_inference/wangxiangbo/mindformers/code:/job/code \\\n-v /reason-sharedata/training_inference/wangxiangbo/mindformers/data:/job/data \\\n-v /reason-sharedata/training_inference/wangxiangbo/mindformers/output:/job/output \\\n-v /mnt/weight-1:/job/mnt \\\nswr.cn-central-221.ovaijisuan.com/mindformers/mindformers1.3_mindspore2.4:20241114 \\\n/bin/bash\n```\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Mindformers/image1.png)\n\n## ä»£ç å‡†å¤‡\n```bash\ngit clone https://gitee.com/mindspore/mindformers.git\n```\n\n## æ•°æ®é›†\n```bash\npython research/llama3/llama_preprocess.py \\\n--dataset_type qa \\\n--input_glob /job/data/alpaca/alpaca-data-conversation.json \\\n--model_file /job/mnt/huggingface/llama-3-8b-hf \\\n--seq_length 8192 \\\n--output_file /job/data/alpaca\n```\n\n## æƒé‡è½¬æ¢\n```bash\npython convert_weight.py --model llama --input_path /job/mnt/huggingface/llama-3-8b-hf --output_path /job/data/mindformers/llama3_8b_ckpt\n```\n\n## è®­ç»ƒè„šæœ¬\n```bash\nseed: 0\noutput_dir: '/job/output' # path to save checkpoint/strategy\nload_checkpoint: '/job/data/mindformers/llama3_8b_ckpt/'\nsrc_strategy_path_or_dir: ''\nauto_trans_ckpt: False  # If true, auto transform load_checkpoint to load in distributed model\nonly_save_strategy: False\nresume_training: False\nrun_mode: 'finetune'\n \n# trainer config\ntrainer:\n  type: CausalLanguageModelingTrainer\n  model_name: 'llama3_8b'\n \n# runner config\nrunner_config:\n  epochs: 2\n  batch_size: 1\n  sink_mode: True\n  sink_size: 2\n \n# optimizer\noptimizer:\n  type: FP32StateAdamWeightDecay\n  beta1: 0.9\n  beta2: 0.95\n  eps: 1.e-8\n \n# lr sechdule\nlr_schedule:\n  type: CosineWithWarmUpLR\n  learning_rate: 1.e-5\n  lr_end: 0.0\n  warmup_ratio: 0.03\n  total_steps: -1 # -1 means it will load the total steps of the dataset\n \n# dataset\ntrain_dataset: &train_dataset\n  data_loader:\n    type: MindDataset\n    dataset_dir: \"/job/data/alpaca/alpaca_llama3_8192/alpaca-fastchat8192.mindrecord\"\n    shuffle: True\n  input_columns: [\"input_ids\",\"labels\"]  # \"input_ids\", \"labels\" , labels are used in instruction finetune.\n  num_parallel_workers: 8\n  python_multiprocessing: False\n  drop_remainder: True\n  batch_size: 6\n  repeat: 1\n  numa_enable: False\n  prefetch_size: 1\ntrain_dataset_task:\n  type: CausalLanguageModelDataset\n  dataset_config: *train_dataset\n# if True, do evaluate during the training process. if false, do nothing.\n# note that the task trainer should support _evaluate_in_training function.\ndo_eval: False\n \n# eval dataset\neval_dataset: &eval_dataset\n  data_loader:\n    type: MindDataset\n    dataset_dir: \"\"\n    shuffle: False\n  input_columns: [\"input_ids\"]\n  num_parallel_workers: 8\n  python_multiprocessing: False\n  drop_remainder: False\n  repeat: 1\n  numa_enable: False\n  prefetch_size: 1\neval_dataset_task:\n  type: CausalLanguageModelDataset\n  dataset_config: *eval_dataset\n \nuse_parallel: True\n# parallel context config\nparallel:\n  parallel_mode: 1 # 0-data parallel, 1-semi-auto parallel, 2-auto parallel, 3-hybrid parallel\n  gradients_mean: False\n  enable_alltoall: False\n  full_batch: True\n  search_mode: \"sharding_propagation\"\n  enable_parallel_optimizer: True\n  strategy_ckpt_save_file: \"./ckpt_strategy.ckpt\"\n  parallel_optimizer_config:\n    gradient_accumulation_shard: False\n    parallel_optimizer_threshold: 64\n# default parallel of device num = 8 for Atlas 800T A2\nparallel_config:\n  data_parallel: 1\n  model_parallel: 4\n  pipeline_stage: 2\n  use_seq_parallel: False\n  micro_batch_num: 8\n  vocab_emb_dp: True\n  gradient_aggregation_group: 4\n# when model parallel is greater than 1, we can set micro_batch_interleave_num=2, that may accelerate the train process.\nmicro_batch_interleave_num: 1\n \n# recompute config\nrecompute_config:\n  recompute: True\n  select_recompute: False\n  parallel_optimizer_comm_recompute: True\n  mp_comm_recompute: True\n  recompute_slice_activation: True\n \n# callbacks\ncallbacks:\n  - type: MFLossMonitor\n  - type: CheckpointMointor\n    prefix: \"llama3_8b\"\n    save_checkpoint_steps: 10000\n    integrated_save: False\n    async_save: False\n  - type: ObsMonitor\n \n# mindspore context init config\ncontext:\n  mode: 0 #0--Graph Mode; 1--Pynative Mode\n  device_target: \"Ascend\"\n  enable_graph_kernel: False\n  graph_kernel_flags: \"--disable_expand_ops=Softmax,Dropout --enable_parallel_fusion=true --reduce_fuse_depth=8 --enable_auto_tensor_inplace=true\"\n  max_call_depth: 10000\n  max_device_memory: \"26GB\"\n  save_graphs: False\n  save_graphs_path: \"./graph\"\n  device_id: 0\n  runtime_num_threads: 1\n \n# model config\nmodel:\n  model_config:\n    type: LlamaConfig\n    batch_size: 1 # add for increase predict\n    seq_length: 8192\n    hidden_size: 4096\n    num_layers: 32\n    num_heads: 32\n    n_kv_heads: 8\n    vocab_size: 128256\n    intermediate_size: 14336\n    rms_norm_eps: 1.0e-5\n    bos_token_id: 128000\n    eos_token_id: 128001\n    pad_token_id: 128002\n    ignore_token_id: -100\n    compute_dtype: \"bfloat16\"\n    layernorm_compute_type: \"float32\"\n    softmax_compute_type: \"float32\"\n    rotary_dtype: \"float32\"\n    param_init_type: \"bfloat16\"\n    use_past: False\n    scaling_factor: 1.0\n    theta: 500000\n    extend_method: \"None\" # support \"None\", \"PI\", \"NTK\"\n    use_flash_attention: True # FA can accelerate training or finetune\n    offset: 0\n    fine_grain_interleave: 1\n    checkpoint_name_or_path: \"\"\n    repetition_penalty: 1\n    max_decode_length: 512\n    top_k: 3\n    top_p: 1\n    do_sample: False\n  arch:\n    type: LlamaForCausalLM\n \n# metric\nmetric:\n  type: PerplexityMetric\n \n# wrapper cell config\nrunner_wrapper:\n  type: MFTrainOneStepCell\n  scale_sense: 1.0\n  use_clip_grad: True\n \neval_callbacks:\n  - type: ObsMonitor\n \nauto_tune: False\nfilepath_prefix: './autotune'\nautotune_per_step: 10\n \nprofile: False\nprofile_start_step: 5\nprofile_stop_step: 7\ninit_start_profile: True\nprofile_communication: True\nprofile_memory: True\nlayer_scale: False\nlayer_decay: 0.65\nlr_scale_factor: 256\n \n# aicc\nremote_save_url: \"Please input obs url on AICC platform.\"\n```\n\n## è®­ç»ƒæ‹‰èµ·\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Mindformers/image2.png)\n\n<font style=\"color:transparent;\">git</font>\n\n<font style=\"color:transparent;\"> clone https://gitee.com/mindspore/mindformers.gitgit</font>\n\n<font style=\"color:transparent;\"> clone https://gitee.com/mindspore/mindformers.git</font>\n\n","tags":["æ¨¡å‹è®­ç»ƒè°ƒä¼˜","æ˜‡è…¾","910B","Mindformers"],"categories":["æ¨¡å‹è®­ç»ƒè°ƒä¼˜","æ˜‡è…¾"]},{"title":"åŸºäºModellinkçš„llama2-7bå’ŒMistral-7bæ¨¡å‹å¾®è°ƒ","url":"/2025/11/06/æ¨¡å‹è®­ç»ƒè°ƒä¼˜/æ˜‡è…¾/Modellink/llama2-7B+Mistral-7B/","content":"## åŸºäºdockerçš„mistral-7Bå¾®è°ƒ\n### å®¹å™¨æŒ‚è½½\n```bash\nsudo docker run -dit --ipc=host --net=host \\\n--name=modellink_wxb \\\n--device=/dev/davinci0 \\\n--device=/dev/davinci1 \\\n--device=/dev/davinci2 \\\n--device=/dev/davinci3 \\\n--device=/dev/davinci4 \\\n--device=/dev/davinci5 \\\n--device=/dev/davinci6 \\\n--device=/dev/davinci7 \\\n--device=/dev/davinci_manager \\\n--device=/dev/devmm_svm \\\n--device=/dev/hisi_hdc \\\n-v /etc/ascend_install.info:/etc/ascend_install.info \\\n-v /etc/hccn.conf:/etc/hccn.conf \\\n-v /etc/localtime:/etc/localtime \\\n-v /var/log/npu/:/usr/slog \\\n-v /usr/local/sbin/npu-smi:/usr/local/sbin/npu-smi \\\n-v /usr/local/Ascend/driver:/usr/local/Ascend/driver \\\n-v /reason-sharedata/training_inference/wangxiangbo/modellink/code/Modellink:/job/code \\\n-v /reason-sharedata/training_inference/wangxiangbo/modellink/data:/job/data \\\n-v /reason-sharedata/training_inference/wangxiangbo/modellink/output:/job/output \\\n-v /mnt/weight-1:/job/mnt \\\nregistry.paas/cmss/modellink-cann8.0-torch2.1-mindspeed-0.7:v1.0 \\\n/bin/bash\n```\n\n### æƒé‡è½¬æ¢\n```bash\n# ä¿®æ”¹ ascend-toolkit è·¯å¾„\nsource /usr/local/Ascend/ascend-toolkit/set_env.sh\n```\n\n```bash\npython  tools/checkpoint/convert_ckpt.py \\\n    --model-type GPT \\\n    --loader llama2_hf \\\n    --saver megatron \\\n    --load-dir /job/mnt/huggingface/mistral-7b-hf/ \\\n    --save-dir /job/data/megatron/mistral-7b-tp4-pp2 \\\n    --tokenizer-model /job/mnt/huggingface/mistral-7b-hf/tokenizer.model \\\n    --target-tensor-parallel-size 4 \\\n    --target-pipeline-parallel-size 2\n```\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Modellink/image1.png)\n\n### æ•°æ®é›†\n#### ä¸‹è½½\n```bash\nsudo wget https://hf-mirror.com/datasets/silk-road/alpaca-data-gpt4-chinese/resolve/main/Alpaca_data_gpt4_zh.jsonl\n```\n\n#### å¤„ç†\n```bash\npython tools/preprocess_data.py \\\n    --input /job/data/dataset/mistral/Alpaca_data_gpt4_zh.jsonl \\\n    --output-prefix /job/data/dataset/mistral/Alpaca_finetune/ \\\n    --tokenizer-type PretrainedFromHF \\\n    --tokenizer-name-or-path /job/mnt/huggingface/mistral-7b-hf/ \\\n    --append-eod \\\n    --tokenizer-not-use-fast \\\n    --handler-name GeneralInstructionHandler \\\n    --workers 4\n```\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Modellink/image2.png)\n\nå¤„ç†å®Œæˆ\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Modellink/image3.png)\n\n### å¾®è°ƒ\n#### å¾®è°ƒè„šæœ¬\n```bash\n#!/bin/bash\nexport CUDA_DEVICE_MAX_CONNECTIONS=1\nexport PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n\nGPUS_PER_NODE=8\nMASTER_ADDR=localhost\nMASTER_PORT=6006\nNNODES=1\nNODE_RANK=0\nWORLD_SIZE=$(($GPUS_PER_NODE * $NNODES))\n\nDISTRIBUTED_ARGS=\"\n    --nproc_per_node $GPUS_PER_NODE \\\n    --nnodes $NNODES \\\n    --node_rank $NODE_RANK \\\n    --master_addr $MASTER_ADDR \\\n    --master_port $MASTER_PORT\n\"\n\necho \"NODE_RANK ${NODE_RANK}\"\n\nDATA_PATH=\"/job/data/dataset/mistral/Alpaca_finetune/\"\nTOKENIZER_MODEL=\"/job/mnt/huggingface/mistral-7b-hf\"\nCKPT_SAVE_DIR=\"/job/output/mistral_ckpt/\"\nCKPT_LOAD_DIR=\"/job/data/megatron/mistral-7b-tp4-pp2/\"\n\n\nTP=4\nPP=2\nNUM_LAYERS=32\n\nGPT_ARGS=\"\n    --tensor-model-parallel-size ${TP} \\\n    --pipeline-model-parallel-size ${PP} \\\n    --sequence-parallel \\\n    --sliding-window 4096 \\\n    --num-layers ${NUM_LAYERS} \\\n    --hidden-size 4096 \\\n    --ffn-hidden-size 14336 \\\n    --num-attention-heads 32 \\\n    --group-query-attention \\\n    --num-query-groups 8 \\\n    --tokenizer-type PretrainedFromHF \\\n    --tokenizer-name-or-path ${TOKENIZER_MODEL} \\\n    --seq-length 32768 \\\n    --max-position-embeddings 32768 \\\n    --micro-batch-size 1 \\\n    --global-batch-size 32 \\\n    --make-vocab-size-divisible-by 1 \\\n    --lr 1.25e-6 \\\n    --train-iters 1000 \\\n    --lr-decay-style cosine \\\n    --untie-embeddings-and-output-weights \\\n    --disable-bias-linear \\\n    --attention-dropout 0.0 \\\n    --init-method-std 0.01 \\\n    --hidden-dropout 0.0 \\\n    --position-embedding-type rope \\\n    --normalization RMSNorm \\\n    --use-fused-rmsnorm \\\n    --use-fused-swiglu \\\n    --use-rotary-position-embeddings \\\n    --use-fused-rotary-pos-emb \\\n    --use-mc2 \\\n    --swiglu \\\n    --use-flash-attn \\\n    --no-masked-softmax-fusion \\\n    --attention-softmax-in-fp32 \\\n    --min-lr 1.25e-7 \\\n    --weight-decay 1e-1 \\\n    --lr-warmup-fraction 0.01 \\\n    --clip-grad 1.0 \\\n    --adam-beta1 0.9 \\\n    --initial-loss-scale 65536 \\\n    --adam-beta2 0.95 \\\n    --no-gradient-accumulation-fusion \\\n    --no-load-optim \\\n    --no-load-rng \\\n    --use-distributed-optimizer \\\n    --overlap-grad-reduce \\\n    --load ${CKPT_LOAD_DIR} \\\n    --save ${CKPT_SAVE_DIR} \\\n    --bf16 \\\n    --finetune \\\n    --is-instruction-dataset \\\n    --log-throughput \\\n    --recompute-granularity full \\\n    --recompute-method block \\\n    --recompute-num-layers 32\n\"\n\nDATA_ARGS=\"\n    --data-path $DATA_PATH  \\\n    --split 100,0,0 \\\n\"\n\nOUTPUT_ARGS=\"\n    --log-interval 1 \\\n    --save-interval 1000 \\\n    --eval-interval 1000 \\\n    --eval-iters 0 \\\n\"\n\ntorchrun $DISTRIBUTED_ARGS ../pretrain_gpt.py \\\n  $GPT_ARGS \\\n  $DATA_ARGS \\\n  $OUTPUT_ARGS \\\n  --distributed-backend nccl \\\n  | tee /job/output/logs/train_mistral_7B.log\n```\n\n#### æ‹‰èµ·è®­ç»ƒ\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Modellink/image4.png)\n\n\n\n## åŸºäºdockerçš„llama2-7Bå¾®è°ƒ\n### å®¹å™¨æŒ‚è½½\n```bash\nsudo docker run -dit --ipc=host --net=host \\\n--name=modellink_wxb \\\n--device=/dev/davinci0 \\\n--device=/dev/davinci1 \\\n--device=/dev/davinci2 \\\n--device=/dev/davinci3 \\\n--device=/dev/davinci4 \\\n--device=/dev/davinci5 \\\n--device=/dev/davinci6 \\\n--device=/dev/davinci7 \\\n--device=/dev/davinci_manager \\\n--device=/dev/devmm_svm \\\n--device=/dev/hisi_hdc \\\n-v /etc/ascend_install.info:/etc/ascend_install.info \\\n-v /etc/hccn.conf:/etc/hccn.conf \\\n-v /etc/localtime:/etc/localtime \\\n-v /var/log/npu/:/usr/slog \\\n-v /usr/local/sbin/npu-smi:/usr/local/sbin/npu-smi \\\n-v /usr/local/Ascend/driver:/usr/local/Ascend/driver \\\n-v /reason-sharedata/training_inference/wangxiangbo/modellink/code/Modellink:/job/code \\\n-v /reason-sharedata/training_inference/wangxiangbo/modellink/data:/job/data \\\n-v /reason-sharedata/training_inference/wangxiangbo/modellink/output:/job/output \\\n-v /mnt/weight-1:/job/mnt \\\nregistry.paas/cmss/modellink-cann8.0-torch2.1-mindspeed-0.7:v1.0 \\\n/bin/bash\n```\n\n### æƒé‡è½¬æ¢\n```bash\n# ä¿®æ”¹ ascend-toolkit è·¯å¾„\nsource /usr/local/Ascend/ascend-toolkit/set_env.sh\n```\n\n```bash\npython  tools/checkpoint/convert_ckpt.py \\\n       --model-type GPT \\\n       --loader llama2_hf \\\n       --saver megatron \\\n       --target-tensor-parallel-size 8 \\\n       --target-pipeline-parallel-size 1 \\\n       --load-dir /job/mnt/huggingface/Llama-2-7b-hf// \\\n       --save-dir /job/data/megatron/llama-2-7b-hf-v0.1-tp8-pp1/ \\\n       --tokenizer-model /job/mnt/huggingface/Llama-2-7b-hf/tokenizer.json\n```\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Modellink/image5.png)\n\n### æ•°æ®é›†\n```bash\npython tools/preprocess_data.py \\\n    --input /job/data/dataset/mistral/Alpaca_data_gpt4_zh.jsonl \\\n    --output-prefix /job/data/dataset/llama2/Alpaca_finetune/ \\\n    --tokenizer-type PretrainedFromHF \\\n    --tokenizer-name-or-path /job/mnt/huggingface/Llama-2-7b-hf/ \\\n    --append-eod \\\n    --tokenizer-not-use-fast \\\n    --handler-name GeneralInstructionHandler \\\n    --workers 4\n```\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Modellink/image6.png)\n\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Modellink/image7.png)\n\n### å¾®è°ƒ\n#### å¾®è°ƒè„šæœ¬\n```bash\n\n#!/bin/bash\nexport CUDA_DEVICE_MAX_CONNECTIONS=1\nexport PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n\nGPUS_PER_NODE=8\nMASTER_ADDR=localhost\nMASTER_PORT=6006\nNNODES=1\nNODE_RANK=0\nWORLD_SIZE=$(($GPUS_PER_NODE * $NNODES))\n\nDISTRIBUTED_ARGS=\"\n    --nproc_per_node $GPUS_PER_NODE \\\n    --nnodes $NNODES \\\n    --node_rank $NODE_RANK \\\n    --master_addr $MASTER_ADDR \\\n    --master_port $MASTER_PORT\n\"\n\necho \"NODE_RANK ${NODE_RANK}\"\n\nDATA_PATH=\"/job/data/dataset/llama2/Alpaca_finetune\"\nTOKENIZER_MODEL=\"/job/mnt/huggingface/Llama-2-7b-hf/\"\nCKPT_SAVE_DIR=\"/job/output/llama2_ckpt/\"\nCKPT_LOAD_DIR=\"/job/data/megatron/llama-2-7b-hf-v0.1-tp8-pp1\"\n\n\nTP=8\nPP=1\nNUM_LAYERS=32\n\nGPT_ARGS=\"\n    --tensor-model-parallel-size ${TP} \\\n    --pipeline-model-parallel-size ${PP} \\\n    --sequence-parallel \\\n    --num-layers 32 \\\n    --hidden-size 4096 \\\n    --ffn-hidden-size 11008 \\\n    --num-attention-heads 32 \\\n    --tokenizer-type Llama2Tokenizer \\\n    --tokenizer-model ${TOKENIZER_MODEL} \\\n    --seq-length 4096 \\\n    --max-position-embeddings 4096 \\\n    --micro-batch-size 1 \\\n    --global-batch-size 256 \\\n    --make-vocab-size-divisible-by 1 \\\n    --lr 1.25e-6 \\\n    --train-iters 5000 \\\n    --lr-decay-style cosine \\\n    --untie-embeddings-and-output-weights \\\n    --disable-bias-linear \\\n    --attention-dropout 0.0 \\\n    --init-method-std 0.01 \\\n    --hidden-dropout 0.0 \\\n    --position-embedding-type rope \\\n    --normalization RMSNorm \\\n    --use-fused-rmsnorm \\\n    --swiglu \\\n    --use-flash-attn \\\n    --no-masked-softmax-fusion \\\n    --attention-softmax-in-fp32 \\\n    --min-lr 1.25e-7 \\\n    --weight-decay 1e-1 \\\n    --lr-warmup-fraction 0.01 \\\n    --clip-grad 1.0 \\\n    --adam-beta1 0.9 \\\n    --initial-loss-scale 65536 \\\n    --adam-beta2 0.95 \\\n    --no-gradient-accumulation-fusion \\\n    --no-load-optim \\\n    --no-load-rng \\\n    --use-distributed-optimizer \\\n    --use-fused-swiglu \\\n    --use-fused-rotary-pos-emb \\\n    --overlap-grad-reduce \\\n    --bf16\n\"\n\nDATA_ARGS=\"\n    --data-path $DATA_PATH  \\\n    --split 100,0,0 \\\n\"\n\nOUTPUT_ARGS=\"\n    --log-interval 1 \\\n    --save-interval 1000 \\\n    --eval-interval 1000 \\\n    --eval-iters 0 \\\n\"\n\ntorchrun $DISTRIBUTED_ARGS ../pretrain_gpt.py \\\n  $GPT_ARGS \\\n  $DATA_ARGS \\\n  $OUTPUT_ARGS \\\n  --distributed-backend nccl \\\n  | tee /job/output/logs/train_llama2_7B.log\n\n```\n\n#### æ‹‰èµ·è®­ç»ƒ\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/Modellink/image8.png)\n\n\n","tags":["æ¨¡å‹è®­ç»ƒè°ƒä¼˜","æ˜‡è…¾","910B","Mindformers"],"categories":["æ¨¡å‹è®­ç»ƒè°ƒä¼˜","æ˜‡è…¾"]},{"title":"1.1-Qwenæ¨¡å‹æœ¬åœ°éƒ¨ç½²ä¸å•æœºå•å¡/å¤šå¡è®­ç»ƒ","url":"/2025/11/06/æ¨¡å‹è®­ç»ƒè°ƒä¼˜/NVIDIA/Qwen/1.1-Qwenæ¨¡å‹æœ¬åœ°éƒ¨ç½²ä¸å•æœºå•å¡_å¤šå¡è®­ç»ƒ/","content":"ä¸€ã€V100ç¯å¢ƒéƒ¨ç½²\n1. é¡¹ç›®åœ°å€ï¼š [https://github.com/QwenLM/Qwen](https://github.com/QwenLM/Qwen)\n2. ä¸‹è½½åˆ°æœ¬åœ°\n`git clone Â https://github.com/QwenLM/Qwen.git `\n3. åŸºç¡€ç¯å¢ƒæ­å»º\n`conda create -n qwen python=3.10`\n`conda activate qwen`\n4. å®‰è£…pytorch\n`conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia`\n5. å®‰è£…ä¾èµ–ç¯å¢ƒ\n`pip install -r requirements.txt `\n7. 7Bæ¨¡å‹ä¸‹è½½\n`git clone [https://www.modelscope.cn/qwen/Qwen-7B-Chat.git](https://www.modelscope.cn/qwen/Qwen-7B-Chat.git)`\nåœ¨ä½¿ç”¨sdkçš„pythonè„šæœ¬ä¸‹è½½æƒé‡æ—¶ï¼Œéœ€è¦pipå®‰è£…modelscope\n`pip install modelscope`\nä½¿ç”¨git cloneå‘ç°æƒé‡æœªä¸‹è½½æˆåŠŸï¼Œä½¿ç”¨modelscopeå®˜æ–¹sdkè„šæœ¬ä¸‹è½½ã€‚\nå°†ä»¥ä¸‹ä»£ç å†™å…¥download.pyæ–‡ä»¶ä¸­ï¼Œå¹¶æ‰§è¡Œ`python download.py`\n```python\n#æ¨¡å‹ä¸‹è½½\nfrom modelscope import snapshot_download\nmodel_dir = snapshot_download('qwen/Qwen-7B-Chat', cache_dir='/opt/tmp/Qwen', revision='v1.1.9')\n```\n8. æ•°æ®é›†ä¸‹è½½\nè¿›å…¥modelscopeä¸‹è½½æ•°æ®é›†\n`https://modelscope.cn/datasets/Robin021/DISC-Law-SFT/files`\n9. æ•°æ®æ ¼å¼å¤„ç†\næ•°æ®é›†å¤„ç†åä¼šç”Ÿæˆtrain_data_law.jsonæ–‡ä»¶\n`head -n 20 train_data_law.json`\nå¤„ç†ä¹‹åçš„æ•°æ®æ ¼å¼å¦‚ä¸‹ï¼š\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/qwen/qwen1.png)\n```python\nimport json\n# è¯»å–ä»¥.jsonlç»“å°¾çš„æ–‡ä»¶\njson_data = []\nwith open('/opt/tmp/Qwen/dataset/DISC-Law-SFT-Triplet-released.jsonl', 'r', encoding='utf-8') as file:\n    for line in file:\n        data = json.loads(line)\n        json_data.append(data)\n# å¾…å¡«å…¥çš„æ¨¡æ¿\ntemplate = []\n\n# éå†jsonæ•°æ®é›†\nfor idx, data in enumerate(json_data[:]):\n    conversation = [\n        {\n            \"from\":\"user\",\n            \"value\": data[\"input\"]\n        },\n        {\n            \"from\": \"assistant\",\n            \"value\": data[\"output\"]\n        }\n    ]\n    template.append({\n        \"id\": f\"identity_{idx}\",\n        \"conversations\": conversation\n    })\nprint(len(template))\n# è¾“å‡ºå¡«å……æ•°æ®åçš„æ¨¡æ¿\nprint(json.dumps(template[2], ensure_ascii=False, indent=2))\n# å°†templateå†™å…¥åˆ°æœ¬åœ°æ–‡ä»¶\noutput_file_path = \"/opt/tmp/Qwen/train_data_law.json\"\nwith open(output_file_path, 'w', encoding='utf-8') as f:\n    json.dump(template, f, ensure_ascii=False, indent=2)\nprint(f\"å¤„ç†å¥½çš„æ•°æ®å·²å†™å…¥åˆ°æœ¬åœ°æ–‡ä»¶: {output_file_path}\")\n```\n10. è®­ç»ƒä¾èµ–å®‰è£…\ndeepspeedå®‰è£…\n`pip install \"peft<0.8.0\" deepspeed`\n11. ä¿®æ”¹æ¨¡å‹å¾®è°ƒè„šæœ¬å‚æ•°\nä¿®æ”¹MODELå’ŒDATAçš„è·¯å¾„ï¼ŒåŠper_device_train_batch_size\n```bash\n#!/bin/bash\nexport CUDA_DEVICE_MAX_CONNECTIONS=1\n\nMODEL=\"/opt/tmp/Qwen/Qwen-7B-Chat\" # Set the path if you do not want to load from huggingface directly\n# ATTENTION: specify the path to your training data, which should be a json file consisting of a list of conversations.\n# See the section for finetuning in README for more information.\nDATA=\"/opt/tmp/Qwen/train_data_law.json\"\n\nfunction usage() {\n    echo '\nUsage: bash finetune/finetune_lora_single_gpu.sh [-m MODEL_PATH] [-d DATA_PATH]\n'\n}\n\nwhile [[ \"$1\" != \"\" ]]; do\n    case $1 in\n        -m | --model )\n            shift\n            MODEL=$1\n            ;;\n        -d | --data )\n            shift\n            DATA=$1\n            ;;\n        -h | --help )\n            usage\n            exit 0\n            ;;\n        * )\n            echo \"Unknown argument ${1}\"\n            exit 1\n            ;;\n    esac\n    shift\ndone\n\nexport CUDA_VISIBLE_DEVICES=0\n\npython finetune.py \\\n  --model_name_or_path $MODEL \\\n  --data_path $DATA \\\n  --bf16 False \\\n  --output_dir output_qwen \\\n  --num_train_epochs 5 \\\n  --per_device_train_batch_size 2 \\\n  --per_device_eval_batch_size 1 \\\n  --gradient_accumulation_steps 8 \\\n  --evaluation_strategy \"no\" \\\n  --save_strategy \"steps\" \\\n  --save_steps 100 \\\n  --save_total_limit 10 \\\n  --learning_rate 3e-4 \\\n  --weight_decay 0.1 \\\n  --adam_beta2 0.95 \\\n  --warmup_ratio 0.01 \\\n  --lr_scheduler_type \"cosine\" \\\n  --logging_steps 1 \\\n  --report_to \"none\" \\\n  --model_max_length 512 \\\n  --lazy_preprocess True \\\n  --gradient_checkpointing \\\n  --use_lora\n\n# If you use fp16 instead of bf16, you should use deepspeed\n# --fp16 True --deepspeed finetune/ds_config_zero2.json\n```\n\n12. å¼€å¯å•æœºå•å¡è®­ç»ƒ\n`bash finetune/finetune_lora_single_gpu.sh`\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/qwen/qwen2.png)\n13. å•æœºå¤šå¡è®­ç»ƒï¼ˆåœ¨åˆ†é…çš„3å·æœºå™¨ä¸Šæ‰§è¡Œï¼‰\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/qwen/qwen3.png)\ngpuæ˜¾å­˜åˆ©ç”¨æƒ…å†µ\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/qwen/qwen4.png)\n\n\n\n","tags":["V100","æ¨¡å‹è®­ç»ƒè°ƒä¼˜","Nvidia","Qwen","Deepspeed"],"categories":["æ¨¡å‹è®­ç»ƒè°ƒä¼˜","NVIDIA"]},{"title":"1.2-Qwenæ¨¡å‹é•œåƒåˆ¶ä½œ","url":"/2025/11/06/æ¨¡å‹è®­ç»ƒè°ƒä¼˜/NVIDIA/Qwen/1.2-Qwenæ¨¡å‹é•œåƒåˆ¶ä½œ/","content":"ç”±äºæ–°æœºå™¨æŒ‚è½½æ–‡ä»¶å­˜å‚¨é€Ÿåº¦éå¸¸æ…¢ï¼Œé€šè¿‡dockerfileæ–‡ä»¶æ¥ç›´æ¥ç”Ÿæˆé•œåƒéå¸¸æ…¢ï¼Œæ‰€ä»¥æœ¬é•œåƒåœ¨è‡ªå·±çš„V100äº‘ä¸»æœºä¸­è¿›è¡Œæ‰“åŒ…ã€‚\n### 1. é¦–å…ˆdocker pullæ‹‰å–ä¸€ä¸ªubuntuåŸºç¡€ç¯å¢ƒ\n[https://hub.docker.com/r/nvidia/cuda/tags?page=11&page_size=&name=&ordering=](https://hub.docker.com/r/nvidia/cuda/tags?page=11&page_size=&name=&ordering=)\n`docker pull nvidia/cuda:12.2.2-cudnn8-devel-ubuntu22.04`\n### 2. å®‰è£…nvidia-container-toolkitï¼Œä½¿dockerå¯ä»¥è°ƒç”¨å®¿ä¸»æœºgpuèµ„æº\n  #### 2.1 ä¸‹è½½nvidia-container-toolkit\n `distribution=$(. /etc/os-release;echo $ID$VERSION_ID) && \\ curl -fsSL [https://nvidia.github.io/libnvidia-container/gpgkey](https://nvidia.github.io/libnvidia-container/gpgkey) | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg && \\ curl -s -L [https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list](https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list) | sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list`\n  #### 2.2 å®‰è£…nvidia-container-toolkit\n  `sudo apt-get update && sudo apt-get install -y nvidia-container-toolkit`\n  #### 2.3 æ·»åŠ nvidia-dockeræº\n  `curl -s -L [https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list](https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list) |   sudo tee /etc/apt/sources.list.d/nvidia-docker.list`\n  #### 2.4 æ›´æ–°å¹¶é‡æ–°æ‰§è¡Œå®‰è£…\n  `sudo apt-get update && sudo apt-get install -y nvidia-container-toolkit`\nå¦‚æœæ‰§è¡Œè¿‡ç¨‹ä¸­æŠ¥W: GPG error: [https://nvidia.github.io/libnvidia-container/stable/ubuntu18.04/amd64](https://nvidia.github.io/libnvidia-container/stable/ubuntu18.04/amd64)  InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY DDCAE044F796ECB0ï¼Œåˆ™éœ€è¦ç¡®è®¤ä½ çš„ç³»ç»Ÿæ˜¯å¦ä¿¡ä»»NVIDIAçš„GPGå¯†é’¥ã€‚å¦‚æœæ²¡æœ‰ï¼Œä½ éœ€è¦å¯¼å…¥å®ƒã€‚å¯ä»¥é€šè¿‡ä»¥ä¸‹å‘½ä»¤å¯¼å…¥GPGå¯†é’¥ï¼š\n`curl -s [https://nvidia.github.io/libnvidia-container/gpgkey](https://nvidia.github.io/libnvidia-container/gpgkey) | sudo apt-key add -`\n  #### 2.5 å®Œæˆ nvidia-container-toolkit çš„å®‰è£…ä¹‹åï¼Œæˆ‘ä»¬ç»§ç»­æ‰§è¡Œ nvidia-ctk runtime configure å‘½ä»¤ï¼Œä¸º Docker æ·»åŠ  nvidia è¿™ä¸ªè¿è¡Œæ—¶ã€‚å®Œæˆåï¼Œæˆ‘ä»¬çš„åº”ç”¨å°±èƒ½åœ¨å®¹å™¨ä¸­ä½¿ç”¨æ˜¾å¡èµ„æºäº†\n  `sudo nvidia-ctk runtime configure --runtime=docker`\n\n  ![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/qwen/qwen5.png)\n  #### 2.6 é‡å¯docker\n  `sudo systemctl restart docker`\n  #### 2.7 æŸ¥çœ‹æ˜¯å¦å®‰è£…æˆåŠŸ  \n  `dpkg -l | grep nvidia-container-toolkit`\n\n  ![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/qwen/qwen6.png)\n\n### 3. æ‹‰å–åŸºç¡€é•œåƒæˆåŠŸåï¼Œåˆ›å»ºä¸€ä¸ªdockerå®¹å™¨\n`docker images`\n`sudo docker run -it --name qwen --gpus all nvidia/cuda:12.2.2-cudnn8-devel-ubuntu22.04`\n`exit`\n#### 4. é€€å‡ºå®¹å™¨åï¼Œå°†æœ¬åœ°è·‘åŒçš„qwenæ¨¡å‹ä»£ç /æƒé‡/æ•°æ®é›†/ç¯å¢ƒcpåˆ°åˆ›å»ºçš„qwené•œåƒä¸­\n`docker cp /opt/tmp/Qwen/ 02649afd9710:/qwen`\n#### 5. é‡å¯dockerï¼Œexecæ‰§è¡Œ\n`docker ps -a`\n`docker start qwen`\n`docker exec -it 02649afd9710 bash`\n#### 6. å› ä¸ºæƒ³åœ¨å®¹å™¨ä¸­æ‰§è¡Œè‡ªèº«çš„pythonç¯å¢ƒï¼Œä¸å€Ÿç”¨å®¿ä¸»æœºçš„ç¯å¢ƒï¼Œæ‰€ä»¥éœ€è¦å•ç‹¬å†å®‰è£…condaã€pytorchç­‰ç¯å¢ƒã€‚\n#### 7. å®‰è£…å®ŒåŸºç¡€ç¯å¢ƒåï¼Œéœ€è¦å®‰è£…qwenæ¨¡å‹çš„ä¾èµ–\n`pip install -r requirements.txt`\n#### 8. æ²¡æœ‰vimç¼–è¾‘å™¨è¿˜éœ€å®‰è£…vim\n`apt-get update`\n`apt-get install -y vim`\n#### 9. deepspeedå®‰è£…\n`pip install \"peft<0.8.0\" deepspeed`\n#### 10. æ­¤æ—¶åœ¨qwenå®¹å™¨ä¸­æ‰§è¡Œè®­ç»ƒè„šæœ¬ï¼Œæ‹‰èµ·è®­ç»ƒã€‚\n`bash finetune/finetune_lora_single_gpu.sh`\n#### 11. å°†æ­¤æ—¶qwenå®¹å™¨æ‰“æˆé•œåƒ\n`docker commit -a \"wangxiangbo\" -m \"qwen 7B\" 02649afd9710 qwen-7b:v1.0`\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/qwen/qwen7.png)\n#### 12. å°†æ‰“å¥½çš„é•œåƒè½¬æˆtaråŒ…ï¼Œä¾›æ–°æœºå™¨è§£å‹ä½¿ç”¨\n`docker save -o qwen-7b.tar qwen-7b:v1.0`\n#### 13. åŠ è½½taré•œåƒ, ä½¿ç”¨loadè¿›è¡Œä»taræ–‡ä»¶å¯¼å‡ºé•œåƒ\n`docker load -i qwen-7b.tar`\n#### 14. ç”±äºæ–°æœºå™¨æŒ‚è½½æ–‡ä»¶å­˜å‚¨çš„åŸå› ï¼Œé•œåƒè§£å‹é€Ÿåº¦å¤ªæ…¢ï¼Œäºæ˜¯æ‰“ç®—å°†æ‰“å¥½çš„qwené•œåƒpushåˆ°é˜¿é‡Œäº‘ä¸ªäººä»“åº“ä¸­ï¼Œåœ¨æ–°æœºå™¨ä¸­ç›´æ¥pullè¯¥é•œåƒã€‚\n#### 15. å°†é•œåƒæ¨é€åˆ°Registry\n`docker login --username=aliyun9599911612 registry.cn-shanghai.aliyuncs.com`\n`docker tag 37c7b97b67f6 registry.cn-shanghai.aliyuncs.com/aliyun_repository_wxb/repository_wxb:v1.0`\n`docker push registry.cn-shanghai.aliyuncs.com/aliyun_repository_wxb/repository_wxb:v1.0`\n#### 16. åœ¨3å·æœºå™¨ä¸­ï¼Œæ‹‰å–è¯¥é•œåƒ\n`docker pull registry.cn-shanghai.aliyuncs.com/aliyun_repository_wxb/repository_wxb:v1.0`\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/qwen/qwen8.png)\n#### 17. é€šè¿‡è¯¥é•œåƒï¼Œrunä¸€ä¸ªå®¹å™¨\n`docker run -it --name qwen --gpus all registry.cn-shanghai.aliyuncs.com/aliyun_repository_wxb/repository_wxb:v1.0 bash`\n\n","tags":["V100","æ¨¡å‹è®­ç»ƒè°ƒä¼˜","Nvidia","Qwen","Deepspeed"],"categories":["æ¨¡å‹è®­ç»ƒè°ƒä¼˜","NVIDIA"]},{"title":"1.3-åŸºäºdockerçš„Qwenå•æœºå•å¡_å¤šå¡è®­ç»ƒ","url":"/2025/11/06/æ¨¡å‹è®­ç»ƒè°ƒä¼˜/NVIDIA/Qwen/1.3-åŸºäºdockerçš„Qwenå•æœºå•å¡_å¤šå¡è®­ç»ƒ/","content":"### 1. æŸ¥çœ‹å®¹å™¨\n`docker ps`\n### 2. execè¿›å…¥å®¹å™¨\n`docker exec -it containerid bash`\n### 3. è¿›å…¥qwenç›®å½•å¹¶ä¿®æ”¹finetune_lora_single_gpu.shå‚æ•°\n```bash\n#!/bin/bash\nexport CUDA_DEVICE_MAX_CONNECTIONS=1\n\nMODEL=\"/qwen/Qwen-7B-Chat\" # Set the path if you do not want to load from huggingface directly\n# ATTENTION: specify the path to your training data, which should be a json file consisting of a list of conversations.\n# See the section for finetuning in README for more information.\nDATA=\"/qwen/train_data_law.json\"\n\nfunction usage() {\n    echo '\nUsage: bash finetune/finetune_lora_single_gpu.sh [-m MODEL_PATH] [-d DATA_PATH]\n'\n}\n\nwhile [[ \"$1\" != \"\" ]]; do\n    case $1 in\n        -m | --model )\n            shift\n            MODEL=$1\n            ;;\n        -d | --data )\n            shift\n            DATA=$1\n            ;;\n        -h | --help )\n            usage\n            exit 0\n            ;;\n        * )\n            echo \"Unknown argument ${1}\"\n            exit 1\n            ;;\n    esac\n    shift\ndone\n\nexport CUDA_VISIBLE_DEVICES=0\n\npython finetune.py \\\n  --model_name_or_path $MODEL \\\n  --data_path $DATA \\\n  --bf16 True \\\n  --output_dir output_qwen \\\n  --num_train_epochs 5 \\\n  --per_device_train_batch_size 1 \\\n  --per_device_eval_batch_size 1 \\\n  --gradient_accumulation_steps 8 \\\n  --evaluation_strategy \"no\" \\\n  --save_strategy \"steps\" \\\n  --save_steps 100 \\\n  --save_total_limit 10 \\\n  --learning_rate 3e-4 \\\n  --weight_decay 0.1 \\\n  --adam_beta2 0.95 \\\n  --warmup_ratio 0.01 \\\n  --lr_scheduler_type \"cosine\" \\\n  --logging_steps 1 \\\n  --report_to \"none\" \\\n  --model_max_length 512 \\\n  --lazy_preprocess True \\\n  --gradient_checkpointing \\\n  --use_lora\n\n# If you use fp16 instead of bf16, you should use deepspeed\n# --fp16 True --deepspeed finetune/ds_config_zero2.json\n```\n### 4. æ‰§è¡Œfinetune_lora_single_gpu.shå•æœºå•å¡\n### 5. ä¿®æ”¹finetune_lora_ds.shå‚æ•°\n```bash\n#!/bin/bash\nexport CUDA_DEVICE_MAX_CONNECTIONS=1\nDIR=`pwd`\n\n# Guide:\n# This script supports distributed training on multi-gpu workers (as well as single-worker training).\n# Please set the options below according to the comments.\n# For multi-gpu workers training, these options should be manually set for each worker.\n# After setting the options, please run the script on each worker.\n\n# Number of GPUs per GPU worker\nGPUS_PER_NODE=$(python -c 'import torch; print(torch.cuda.device_count())')\n\n# Number of GPU workers, for single-worker training, please set to 1\nNNODES=${NNODES:-1}\n\n# The rank of this worker, should be in {0, ..., WORKER_CNT-1}, for single-worker training, please set to 0\nNODE_RANK=${NODE_RANK:-0}\n\n# The ip address of the rank-0 worker, for single-worker training, please set to localhost\nMASTER_ADDR=${MASTER_ADDR:-localhost}\n\n# The port for communication\nMASTER_PORT=${MASTER_PORT:-6001}\n\nMODEL=\"/qwen/Qwen-7B-Chat\" # Set the path if you do not want to load from huggingface directly\n# ATTENTION: specify the path to your training data, which should be a json file consisting of a list of conversations.\n# See the section for finetuning in README for more information.\nDATA=\"/qwen/train_data_law.json\"\nDS_CONFIG_PATH=\"finetune/ds_config_zero2.json\"\n\nfunction usage() {\n    echo '\nUsage: bash finetune/finetune_lora_ds.sh [-m MODEL_PATH] [-d DATA_PATH] [--deepspeed DS_CONFIG_PATH]\n'\n}\n\nwhile [[ \"$1\" != \"\" ]]; do\n    case $1 in\n        -m | --model )\n            shift\n            MODEL=$1\n            ;;\n        -d | --data )\n            shift\n            DATA=$1\n            ;;\n        --deepspeed )\n            shift\n            DS_CONFIG_PATH=$1\n            ;;\n        -h | --help )\n            usage\n            exit 0\n            ;;\n        * )\n            echo \"Unknown argument ${1}\"\n            exit 1\n            ;;\n    esac\n    shift\ndone\n\nDISTRIBUTED_ARGS=\"\n    --nproc_per_node $GPUS_PER_NODE \\\n    --nnodes $NNODES \\\n    --node_rank $NODE_RANK \\\n    --master_addr $MASTER_ADDR \\\n    --master_port $MASTER_PORT\n\"\n#export CUDA_VISIBLE_DEVICES=2,3\n\ntorchrun $DISTRIBUTED_ARGS finetune.py \\\n    --model_name_or_path $MODEL \\\n    --data_path $DATA \\\n    --bf16 False \\\n    --output_dir output_qwen \\\n    --num_train_epochs 5 \\\n    --per_device_train_batch_size 2 \\\n    --per_device_eval_batch_size 1 \\\n    --gradient_accumulation_steps 8 \\\n    --evaluation_strategy \"no\" \\\n    --save_strategy \"steps\" \\\n    --save_steps 100 \\\n    --save_total_limit 10 \\\n    --learning_rate 3e-4 \\\n    --weight_decay 0.1 \\\n    --adam_beta2 0.95 \\\n    --warmup_ratio 0.01 \\\n    --lr_scheduler_type \"cosine\" \\\n    --logging_steps 1 \\\n    --report_to \"none\" \\\n    --model_max_length 512 \\\n    --lazy_preprocess True \\\n    --use_lora \\\n    --gradient_checkpointing \\\n    --deepspeed ${DS_CONFIG_PATH}\n\n```\n### 6. ä¿®æ”¹deepspeedä¸­ds_config_zero2.jsoné…ç½®æ–‡ä»¶ï¼Œå¢åŠ TFlopsæ˜¾ç¤º\nå…¶ä¸­å…·ä½“å¢åŠ çš„å‚æ•°é…ç½®ä¸ºflops_profiler\n```json\n\"flops_profiler\": {\n        \"enabled\": true,\n        \"profile_step\": 1,\n        \"module_depth\": -1,\n        \"top_modules\": 1,\n        \"detailed\": false,\n        \"output_file\": null\n    },\n```\n```json\n{\n    \"fp16\": {\n        \"enabled\": \"auto\",\n        \"loss_scale\": 0,\n        \"loss_scale_window\": 1000,\n        \"initial_scale_power\": 16,\n        \"hysteresis\": 2,\n        \"min_loss_scale\": 1\n    },\n    \"bf16\": {\n        \"enabled\": \"auto\"\n    },\n    \"optimizer\": {\n        \"type\": \"AdamW\",\n        \"params\": {\n            \"lr\": \"auto\",\n            \"betas\": \"auto\",\n            \"eps\": \"auto\",\n            \"weight_decay\": \"auto\"\n        }\n    },\n\n    \"scheduler\": {\n        \"type\": \"WarmupLR\",\n        \"params\": {\n            \"warmup_min_lr\": \"auto\",\n            \"warmup_max_lr\": \"auto\",\n            \"warmup_num_steps\": \"auto\"\n        }\n    },\n\n    \"zero_optimization\": {\n        \"stage\": 2,\n        \"offload_optimizer\": {\n            \"device\": \"none\",\n            \"pin_memory\": true\n        },\n        \"allgather_partitions\": true,\n        \"allgather_bucket_size\": 2e8,\n        \"overlap_comm\": true,\n        \"reduce_scatter\": true,\n        \"reduce_bucket_size\": 2e8,\n        \"contiguous_gradients\": true\n    },\n\n    \"flops_profiler\": {\n        \"enabled\": true,\n        \"profile_step\": 1,\n        \"module_depth\": -1,\n        \"top_modules\": 1,\n        \"detailed\": false,\n        \"output_file\": null\n    },\n\n    \"gradient_accumulation_steps\": \"auto\",\n    \"gradient_clipping\": \"auto\",\n    \"steps_per_print\": 100,\n    \"train_batch_size\": \"auto\",\n    \"train_micro_batch_size_per_gpu\": \"auto\",\n    \"wall_clock_breakdown\": false\n}\n\n```\n### 7. æ‰§è¡Œfinetune_lora_ds.shå•æœºå¤šå¡è®­ç»ƒ\nå…¶ä¸­æŠ¥äº†Error while creating shared memory segment /dev/shm/nccl-KXWrmA (size 9637888)å¯¼è‡´åœ¨dockerä¸­å•æœºå¤šå¡æ‹‰èµ·å¤±è´¥\né—®é¢˜åŸå› ï¼šdockerçš„shmå…±äº«å†…å­˜ä¸è¶³ï¼Œå¯ä»¥é€šè¿‡å‘½ä»¤\n`df -h | grep shm`æŸ¥çœ‹å½“å‰å®¹å™¨çš„shmå¤§å°ï¼Œé»˜è®¤ä¸º64Mï¼Œè¿™æ˜¯è¿œè¿œä¸å¤Ÿçš„ï¼Œæ‰€ä»¥è¦å¢åŠ è¯¥å®¹å™¨çš„shmå…±äº«å†…å­˜å¤§å°ã€‚å‚è€ƒåšæ–‡[https://blog.csdn.net/gg864461719/article/details/112466585](https://blog.csdn.net/gg864461719/article/details/112466585)\n#### è§£å†³æ–¹æ³•1ï¼šåˆ›å»ºå®Œå®¹å™¨ä¹‹åï¼Œæ‰‹åŠ¨ä¿®æ”¹shmå…±äº«å†…å­˜å¤§å°\n##### a. é¦–å…ˆè¦å…³é—­docker, å¦åˆ™ä¸‹é¢çš„æ“ä½œæ­¥éª¤ä¼šæ— æ•ˆ.\n`service docker stop`\n##### b. è¿›å…¥å®¿ä¸»æœºä¸­/docker/containers/å®¹å™¨id ä¿®æ”¹è¯¥å®¹å™¨çš„hostconfig.jsonæ–‡ä»¶ï¼ŒæŠŠå…¶ä¸­çš„ShmSizeçš„å¤§å°åé¢å¢åŠ 22ï¼ˆå°±å˜ä¸ºäº†6.3Gï¼‰å…¶é»˜è®¤çš„æ˜¯67108864_KB_ å°±çº¦ç­‰äº64Mã€‚\n##### c. é‡å¯dockeræœåŠ¡\n`systemctl start docker`\n##### d. è§£å†³å®Œä¹‹åï¼Œé‡æ–°æŸ¥çœ‹shmçš„å…±äº«å†…å­˜å¤§å°ï¼Œæ­¤æ—¶å·²ç»å˜ä¸ºäº†6.3G\n#### è§£å†³æ–¹æ³•2ï¼šåœ¨é€šè¿‡é•œåƒrunå®¹å™¨æ—¶ï¼Œå°±ç›´æ¥æŒ‡å®š--shm-size 6G\n`docker run -it --name qwen --gpus all --shm-size 6G registry.cn-shanghai.aliyuncs.com/aliyun_repository_wxb/repository_wxb:v1.0 bash`\n### é‡æ–°æ‹‰èµ·è®­ç»ƒ\n`bash finetune/finetune_lora_ds.sh`\nå…¶ä¸­tflopsåœ¨9.5~10.5ä¹‹é—´\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/qwen/qwen9.png)\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/qwen/qwen10.png)\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/qwen/qwen11.png)\n\n","tags":["V100","æ¨¡å‹è®­ç»ƒè°ƒä¼˜","Nvidia","Qwen","Deepspeed"],"categories":["æ¨¡å‹è®­ç»ƒè°ƒä¼˜","NVIDIA"]},{"title":"1.4-åŸºäºk8sæ‹‰èµ·Qwenæ¨¡å‹çš„å¤šæœºå¤šå¡å¾®è°ƒ","url":"/2025/11/06/æ¨¡å‹è®­ç»ƒè°ƒä¼˜/NVIDIA/Qwen/1.4-åŸºäºk8sæ‹‰èµ·Qwenæ¨¡å‹çš„å¤šæœºå¤šå¡å¾®è°ƒ/","content":"ä¸€ã€é•œåƒå‡†å¤‡\n### 1. æŸ¥çœ‹é•œåƒ\n`docker images`\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/qwen/qwen12.png)\n### 2. ä¿®æ”¹é•œåƒæ ‡ç­¾\n`docker tag ec99659d9677 registry.paas/library/qwen:v3.0`\n### 3. å°†é•œåƒæ¨è‡³ä»“åº“\n`docker push registry.paas/library/qwen:v3.0`\n### 4. å¦‚æœå‡ºç°ç­¾åè®¤è¯å¤±è´¥ï¼Œéœ€è¦ä¿®æ”¹dockerå®ˆæŠ¤è¿›ç¨‹é…ç½®æ–‡ä»¶\n`vim /etc/docker/daemon.json`\nå¢åŠ å¦‚ä¸‹é…ç½®ï¼š\n```json\n{\n\"insecure-registries\":[\"registry.paas\"]\n}\n```\né‡å¯docker\n`systemctl daemon-reload && systemctl restart docker`\n### 5. é‡æ–°pushè‡³registry.paas/library/xxx:tagsä»“åº“\näºŒã€ä¿®æ”¹é…ç½®æ–‡ä»¶\n### 1. qwentest.yaml\n```yaml\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: qwentest\nspec:\n  selector:\n    matchLabels:\n      app: qwentest\n  template:\n    metadata:\n      labels:\n        app: qwentest\n    spec:\n      hostNetwork: true\n      nodeSelector:\n        model: qwen-7b\n      containers:\n      - name: qwentest\n        image: registry.paas/library/qwen:v3.0\n        imagePullPolicy: IfNotPresent\n        resources:\n         limits:\n           nvidia.com/gpu: \"4\"\n         requests:\n           nvidia.com/gpu: \"4\"\n        command:                                  # training command, which can be modified\n              - \"/bin/bash\"\n              - \"-c\"\n                #- sleep 10000\n              - |\n                cd /mnt/ &&\n                cp setRank.sh /qwen/ &&\n                cd /qwen/ &&\n                chmod +x setRank.sh &&\n                bash setRank.sh &&\n                chmod +x finetune_lora_ds.sh &&\n                bash finetune_lora_ds.sh\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - name: processeddata\n          mountPath: /mnt\n        - name: dshm\n          mountPath: /dev/shm\n        - name: tmp-volume\n          mountPath: /tmp\n      volumes:\n      - name: processeddata\n        hostPath:\n          path: /mnt/users/wangxiangbo/runk8s\n      - name: dshm\n        emptyDir:\n          medium: Memory\n          sizeLimit: 1G\n      - name: tmp-volume\n        hostPath:\n          path: /tmp\n```\n### 2. hostfile\n```shell\n192.168.0.20\n192.168.0.58\n```\n### 3. setRank.sh\n```shell\n#!/bin/bash\n\nshell_name=\"finetune_lora_ds.sh\"\n\nshell_dir=\"/mnt/\"\n\nlocal_dir=\"/qwen/\"\n\n## å¤åˆ¶è„šæœ¬åˆ°/qwen/ä¸‹\ncp $shell_dir$shell_name $local_dir\n\n\n## è¯»å–hostfile\nreadarray -t ips < <(grep -vE '^[[:space:]]*$' \"$shell_dir\"hostfile)\n\n## è·å–rank0 IP\nrank0_ip=$(echo \"${ips[0]}\" | tr -d '[:space:]')\n\nnodes=${#ips[@]}\n\n## è·å–hostfileä¸­é…ç½®çš„IPå‰ç¼€\n## ä½¿ç”¨cutæå–IPåœ°å€çš„å‰ä¸‰ä¸ªæ•°å­—éƒ¨åˆ†\nip_prefix=$(echo \"${ips[0]}\" | cut -d '.' -f 1-3)\n\n## è·å–æœ¬æœºIP\nip=$(hostname -I | grep -oE \"$ip_prefix\\.[0-9]+\")\n\nls\n# åˆå§‹åŒ–rank\nnode_rank=-1\n\n# éå†æ•°ç»„\nfor i in \"${!ips[@]}\"; do\n    # ä½¿ç”¨trå‘½ä»¤å»é™¤ç©ºç™½å­—ç¬¦\n    clean_string=$(echo \"${ips[$i]}\" | tr -d '[:space:]')\n    if [[ \"$clean_string\" == \"$ip\" ]]; then\n        node_rank=$i\n        break\n    fi\ndone\n\nif [ $node_rank -ne -1 ]; then\n    ## ä¿®æ”¹è„šæœ¬ä¸­MASTER_ADDR\n    sed -i \"s/^MASTER_ADDR=.*/MASTER_ADDR=$rank0_ip/\" $local_dir$shell_name\n\n    ## ä¿®æ”¹NNODES\n    sed -i \"s/^NNODES=.*/NNODES=$nodes/\" $local_dir$shell_name\n\n    ## ä¿®æ”¹NODE_RANK\n    sed -i \"s/^NODE_RANK=.*/NODE_RANK=$node_rank/\" $local_dir$shell_name\nfi\n\n```\n\n### 4. sh\n```shell\n#!/bin/bash\n/bin/bash -i <<'EOF'\nexport NCCL_IB_DISABLE=1\nexport NCCL_SOCKET_IFNAME=eth0\nexport NCCL_P2P_DISABLE=1\nexport NCCL_DEBUG=INFO\nsource ~/.bashrc\n\n. /opt/miniconda/etc/profile.d/conda.sh\nconda activate qwen\nexport CUDA_DEVICE_MAX_CONNECTIONS=1\nexport CUDA_VISIBLE_DEVICES=0,1,2,3\nDIR=`pwd`\n\n# Number of GPUs per GPU worker\nGPUS_PER_NODE=4\n# Number of GPU workers, for single-worker training, please set to 1\nNNODES=2\n# The rank of this worker, should be in {0, ..., WORKER_CNT-1}, for single-worker training, please set to 0\nNODE_RANK=0\n# The ip address of the rank-0 worker, for single-worker training, please set to localhost\nMASTER_ADDR=192.168.0.20\n# The port for communication\nMASTER_PORT=6003\n\nMODEL=\"/qwen/Qwen-7B-Chat\" # Set the path if you do not want to load from huggingface directly\n# ATTENTION: specify the path to your training data, which should be a json file consisting of a list of conversations.\n# See the section for finetuning in README for more information.\nDATA=\"/qwen/train_data_law.json\"\nDS_CONFIG_PATH=\"/qwen/finetune/ds_config_zero2.json\"\n\nfunction usage() {\n    echo '\nUsage: bash finetune_lora_ds.sh [-m MODEL_PATH] [-d DATA_PATH] [--deepspeed DS_CONFIG_PATH]\n'\n}\n\nwhile [[ \"$1\" != \"\" ]]; do\n    case $1 in\n        -m | --model )\n            shift\n            MODEL=$1\n            ;;\n        -d | --data )\n            shift\n            DATA=$1\n            ;;\n        --deepspeed )\n            shift\n            DS_CONFIG_PATH=$1\n            ;;\n        -h | --help )\n            usage\n            exit 0\n            ;;\n        * )\n            echo \"Unknown argument ${1}\"\n            exit 1\n            ;;\n    esac\n    shift\ndone\n\nDISTRIBUTED_ARGS=\"\n    --nproc_per_node $GPUS_PER_NODE \\\n    --nnodes $NNODES \\\n    --node_rank $NODE_RANK \\\n    --master_addr $MASTER_ADDR \\\n    --master_port $MASTER_PORT\n\"\n\ntorchrun $DISTRIBUTED_ARGS finetune.py \\\n    --model_name_or_path $MODEL \\\n    --data_path $DATA \\\n    --bf16 False \\\n    --output_dir output_qwen \\\n    --num_train_epochs 5 \\\n    --per_device_train_batch_size 8 \\\n    --per_device_eval_batch_size 1 \\\n    --gradient_accumulation_steps 8 \\\n    --evaluation_strategy \"no\" \\\n    --save_strategy \"steps\" \\\n    --save_steps 100 \\\n    --save_total_limit 10 \\\n    --learning_rate 3e-4 \\\n    --weight_decay 0.1 \\\n    --adam_beta2 0.95 \\\n    --warmup_ratio 0.01 \\\n    --lr_scheduler_type \"cosine\" \\\n    --logging_steps 1 \\\n    --report_to \"none\" \\\n    --model_max_length 512 \\\n    --lazy_preprocess True \\\n    --use_lora \\\n    --gradient_checkpointing \\\n    --ddp_find_unused_parameters False \\\nEOF\n\n```\nä¸‰ã€æ‹‰èµ·è®­ç»ƒï¼ˆ3å·å’Œ4å·ä¸¤æœº8å¡ï¼‰\n### 1. åˆ‡æ¢åˆ°1å·æœºå™¨masterèŠ‚ç‚¹ä¸Šï¼Œç»™å¸¦è®­ç»ƒå¾—3å·å’Œ4å·æœºå™¨æ‰“ä¸Šæ ‡ç­¾\n`kubectl label nodes ecs-jhjs-1234-003 model=qwen-7b`\n`kubectl label nodes ecs-jhjs-1234-004 model=qwen-7b`\n### 2. å‡†å¤‡å¥½å¯åŠ¨è„šæœ¬ç­‰æ–‡ä»¶åï¼Œåœ¨masterèŠ‚ç‚¹1å·æœºå™¨ä¸Šï¼Œåˆ©ç”¨ä¿®æ”¹å¥½çš„qwentest.yamlæ–‡ä»¶æ‹‰èµ·è®­ç»ƒä»»åŠ¡\n### 3. `kubectl apply -f qwentest.yaml`\n### 4. é€šè¿‡kubectlæŸ¥çœ‹podèŠ‚ç‚¹å¯åŠ¨ä¿¡æ¯\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/qwen/qwen13.png)\n### 5. æŸ¥çœ‹ä¸¤ä¸ªèŠ‚ç‚¹podçš„logsæ—¥å¿—\n`kubectl logs qwentest-czm8n -f`\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/qwen/qwen14.png)\n`kubectl logs qwentest-qthsf -f`\n![](https://lyapunov-1312469874.cos.ap-shanghai.myqcloud.com/img/categories/model/qwen/qwen15.png)\n\n","tags":["V100","æ¨¡å‹è®­ç»ƒè°ƒä¼˜","Nvidia","Qwen","Deepspeed"],"categories":["æ¨¡å‹è®­ç»ƒè°ƒä¼˜","NVIDIA"]},{"title":"1.5-Qwenå¤šæœºå¤šå¡è°ƒä¼˜","url":"/2025/11/06/æ¨¡å‹è®­ç»ƒè°ƒä¼˜/NVIDIA/Qwen/1.5-Qwenå¤šæœºå¤šå¡è°ƒä¼˜/","content":"### 1. lora\n#### 1.1 per_device_train_batch_sizeæµ‹è¯•ï¼Œæœ€ä¼˜ä¸º16\n\n| per_device_train_batch_size | per_device_eval_batch_size | model_max_length | gradient_accumulation_steps | bf16 | tflops |\n| --- | --- | --- | --- | --- | --- |\n| 2 | 1 | 512 | 8 | true | 8.37 |\n| 4 | 1 | 512 | 8 | true | 9.07 |\n| 8 | 1 | 512 | 8 | true | 9.88 |\n| **16** | **1** | **512** | **8** | **true** | **10.32** |\n| 32 | 1 | 512 | 8 | true | OOM |\n\n\nå•ä¸ªGPUæ‰¹æ¬¡å¤§å°å¢åŠ æ—¶ï¼Œéœ€è¦çš„å†…å­˜ä¹Ÿä¼šå¢åŠ ï¼ŒGPUå†…å­˜ä¸è¶³ä»¥æ”¯æŒæ›´å¤§çš„æ‰¹æ¬¡ï¼Œå¯èƒ½ä¼šå¯¼è‡´æº¢å‡ºæˆ–æ•ˆç‡é™ä½ã€‚\n\n#### 1.2 per_device_eval_batch_sizeæµ‹è¯•ï¼Œæœ€ä¼˜ä¸º2\n\n| per_device_train_batch_size | per_device_eval_batch_size | model_max_length | gradient_accumulation_steps | bf16 | tflops |\n| --- | --- | --- | --- | --- | --- |\n| 16 | 1 | 512 | 8 | true | 10.32 |\n| **16** | **2** | **512** | **8** | **true** | **10.33** |\n| 16 | 4 | 512 | 8 | true | 10.26 |\n\n\n#### 1.3 model_max_lengthæµ‹è¯•ï¼Œæœ€ä¼˜ä¸º512\n\n| per_device_train_batch_size | per_device_eval_batch_size | model_max_length | gradient_accumulation_steps | bf16 | flops |\n| --- | --- | --- | --- | --- | --- |\n| 16 | 2 | 128 | 8 | true | 8.95 |\n| 16 | 2 | 256 | 8 | true | 9.56 |\n| **16** | **2** | **512** | **8** | **true** | **10.33** |\n| 16 | 2 | 1024 | 8 | true | OOM |\n\n\n#### 1.4 gradient_accumulation_stepsæµ‹è¯•ï¼Œæœ€ä¼˜ä¸º16\n\n| per_device_train_batch_size | per_device_eval_batch_size | model_max_length | gradient_accumulation_steps | bf16 | tflops |\n| --- | --- | --- | --- | --- | --- |\n| 16 | 2 | 512 | 1 | true | 9.07 |\n| 16 | 2 | 512 | 2 | true | 9.24 |\n| 16 | 2 | 512 | 4 | true | 9.89 |\n| 16 | 2 | 512 | 8 | true | 10.33 |\n| **16** | **2** | **512** | **16** | **true** | **11.63** |\n\n\n#### 1.5 å¼€å¯Fp16æµ‹è¯•\n\n| per_device_train_batch_size | per_device_eval_batch_size | model_max_length | gradient_accumulation_steps | fp16 | tflops |\n| --- | --- | --- | --- | --- | --- |\n| **16** | **2** | **512** | **16** | **true** | **67.13** |\n\n\n#### 1.6 å…³é—­gradient_checkpointing\n\n| per_device_train_batch_size | per_device_eval_batch_size | model_max_length | gradient_accumulation_steps | fp16 | gradient_checkpointing | tflops |\n| --- | --- | --- | --- | --- | --- | --- |\n| **16** | **2** | **512** | **16** | **true** | **true** | **67.13** |\n| 16 | 2 | 512 | 16 | true | false | OOM |\n\n\n| å‚æ•°é…ç½® | per_device_train_batch_size | per_device_eval_batch_size | model_max_length | gradient_accumulation_steps | bf16/fp16 | gradient_checkpointing | tflops |\n| --- | --- | --- | --- | --- | --- | --- | --- |\n| é»˜è®¤ | 2 | 1 | 512 | 8 | bf16 | **true** | 8.32 |\n| è°ƒä¼˜å | **<font style=\"color:#DF2A3F;\">16</font>** | **<font style=\"color:#DF2A3F;\">2</font>** | **<font style=\"color:#DF2A3F;\">512</font>** | **<font style=\"color:#DF2A3F;\">16</font>** | **<font style=\"color:#DF2A3F;\">fp16</font>** | **<font style=\"color:#DF2A3F;\">true</font>** | **<font style=\"color:#DF2A3F;\">67.13</font>** |\n\n\nåŸºäº2æœº8å¡çš„V100ï¼ŒQwen-7Bæ¨¡å‹çš„loraå¾®è°ƒè®­ç»ƒä¸­ï¼ˆé‡‡ç”¨deepspeedçš„zero2çš„å†…å­˜ä¼˜åŒ–å¹¶è¡Œæ–¹å¼ï¼‰ï¼ŒTflopsçš„å€¼æœ€é«˜ä¸º<font style=\"color:#DF2A3F;\">67.13</font>**ï¼ˆ8.32ï¼‰\n\næœ€ä½³å‚æ•°é…ç½®ï¼ˆper_device_train_batch_sizeï¼š16ï¼Œper_device_eval_batch_sizeï¼š2ï¼Œmodel_max_lengthï¼š512ï¼Œgradient_accumulation_stepsï¼š16ï¼ŒFp16ç²¾åº¦ï¼Œgradient_checkpointingï¼šTrueï¼‰\n\n### 2. qlora\n\nqloraä½¿ç”¨4æ¯”ç‰¹é‡åŒ–æ¨¡å‹ä»¥åŠpaged attentionç­‰æŠ€æœ¯å®ç°æ›´å°çš„æ˜¾å­˜å¼€é”€\n\n#### 2.1 per_device_train_batch_sizeæµ‹è¯•ï¼Œæœ€ä¼˜ä¸º32\n\n| per_device_train_batch_size | per_device_eval_batch_size | model_max_length | gradient_accumulation_steps | fp16 | tflops |\n| --- | --- | --- | --- | --- | --- |\n| 2 | 1 | 512 | 8 | true | 31.71 |\n| 4 | 1 | 512 | 8 | true | 42.91 |\n| 8 | 1 | 512 | 8 | true | 51.14 |\n| 16 | 1 | 512 | 8 | true | 55.75 |\n| **32** | **1** | **512** | **8** | **true** | **58.44** |\n| 64 | 1 | 512 | 8 | true | OOM |\n\n\n#### 2.2 per_device_eval_batch_sizeæµ‹è¯•ï¼Œæœ€ä¼˜ä¸º4\n\n| per_device_train_batch_size | per_device_eval_batch_size | model_max_length | gradient_accumulation_steps | fp16 | tflops |\n| --- | --- | --- | --- | --- | --- |\n| 32 | 1 | 512 | 8 | true | 58.44 |\n| 32 | 2 | 512 | 8 | true | 58.84 |\n| **32** | **4** | **512** | **8** | **true** | **59.05** |\n| 32 | 8 | 512 | 8 | true | 58.42 |\n\n\n#### 2.3 model_max_lengthæµ‹è¯•ï¼Œæœ€ä¼˜ä¸º512\n\n| per_device_train_batch_size | per_device_eval_batch_size | model_max_length | gradient_accumulation_steps | fp16 | tflops |\n| --- | --- | --- | --- | --- | --- |\n| 32 | 4 | 128 | 8 | true | 48.68 |\n| 32 | 4 | 256 | 8 | true | 53.02 |\n| **32** | **4** | **512** | **8** | **true** | **59.05** |\n| 32 | 4 | 1024 | 8 | true | OOM |\n\n\n#### 2.4 gradient_accumulation_stepsæµ‹è¯•ï¼Œæœ€ä¼˜ä¸º\n\n| per_device_train_batch_size | per_device_eval_batch_size | model_max_length | gradient_accumulation_steps | fp16 | tflops |\n| --- | --- | --- | --- | --- | --- |\n| 32 | 4 | 512 | 1 | true | 52.66 |\n| 32 | 4 | 512 | 2 | true | 52.18 |\n| 32 | 4 | 512 | 4 | true | 54.99 |\n| 32 | 4 | 512 | 8 | true | 59.05 |\n| 32 | 4 | 512 | 16 | true | 64.26 |\n| 32 | 4 | 512 | 32 | true | 80.37 |\n| **32** | **4** | **512** | **64** | **true** | **103.89** |\n\n\n#### 2.5 å¼€å¯BF16æµ‹è¯•\n\n| per_device_train_batch_size | per_device_eval_batch_size | model_max_length | gradient_accumulation_steps | bf16/fp16 | tflops |\n| --- | --- | --- | --- | --- | --- |\n| 32 | 4 | 512 | 64 | bf16 | 14.23 |\n| **32** | **4** | **512** | **64** | **fp16** | **103.89** |\n\n\n#### 2.6 å…³é—­gradient_checkpointing\n\n| gradient_checkpointing | per_device_train_batch_size | per_device_eval_batch_size | model_max_length | gradient_accumulation_steps | fp16 | tflops |\n| --- | --- | --- | --- | --- | --- | --- |\n| **<font style=\"color:#000000;\">True</font>** | **<font style=\"color:#000000;\">32</font>** | **<font style=\"color:#000000;\">4</font>** | **<font style=\"color:#000000;\">512</font>** | **<font style=\"color:#000000;\">64</font>** | **<font style=\"color:#000000;\">true</font>** | **<font style=\"color:#000000;\">103.89</font>** |\n| False | 32 | 4 | 512 | 64 | true | OOM |\n\n\nDeepSpeed ZeRO 3 å¯¹èŠ‚ç‚¹é—´é€šä¿¡é€Ÿç‡çš„è¦æ±‚è¿œå¤§äº ZeRO 2ï¼Œåœ¨å¤šæœºå¾®è°ƒçš„æƒ…å†µä¸‹ä¼šå¤§å¹…é™ä½è®­ç»ƒé€Ÿåº¦ã€‚å› æ­¤ï¼Œæˆ‘ä»¬ä¸å»ºè®®åœ¨å¤šæœºå¾®è°ƒçš„æƒ…å†µä¸‹ä½¿ç”¨ DeepSpeed ZeRO 3 é…ç½®ã€‚\n\n| å‚æ•°é…ç½® | per_device_train_batch_size | per_device_eval_batch_size | model_max_length | gradient_accumulation_steps | fp16 | tflops |\n| --- | --- | --- | --- | --- | --- | --- |\n| é»˜è®¤ | 2 | 1 | 512 | 8 | true | 31.71 |\n| è°ƒä¼˜å | **<font style=\"color:#DF2A3F;\">32</font>** | **<font style=\"color:#DF2A3F;\">4</font>** | **<font style=\"color:#DF2A3F;\">512</font>** | **<font style=\"color:#DF2A3F;\">64</font>** | **<font style=\"color:#DF2A3F;\">true</font>** | **<font style=\"color:#DF2A3F;\">103.89</font>** |\n\n\nåŸºäº2æœº8å¡çš„V100ï¼ŒQwen-7Bæ¨¡å‹çš„qloraå¾®è°ƒè®­ç»ƒä¸­ï¼ˆé‡‡ç”¨deepspeedçš„zero2çš„å†…å­˜ä¼˜åŒ–å¹¶è¡Œæ–¹å¼ï¼‰ï¼ŒTflopsçš„å€¼æœ€é«˜ä¸º<font style=\"color:#DF2A3F;\">103.89 </font>\n\né»˜è®¤å‚æ•°é…ç½®\n\næœ€ä½³å‚æ•°é…ç½®ï¼ˆgradient_checkpointingï¼šTrueï¼Œper_device_train_batch_sizeï¼š32ï¼Œper_device_eval_batch_sizeï¼š4ï¼Œmodel_max_lengthï¼š512ï¼Œgradient_accumulation_stepsï¼š64ï¼ŒFp16ç²¾åº¦ï¼‰\n\nqloraåœ¨æ‹‰èµ·è®­ç»ƒæ—¶ï¼Œéœ€è¦å¯¹æ¨¡å‹æƒé‡è¿›è¡ŒINT-4é‡åŒ–ï¼Œä¼šæŸå¤±æ‰æƒé‡å°æ•°éƒ¨åˆ†ç²¾åº¦ï¼Œé‡åŒ–åçš„æƒé‡ç”±äºä½¿ç”¨æ›´å°‘çš„ä½æ•°æ¥è¡¨ç¤ºï¼Œå­˜å‚¨ä¸Šæ¯”åŸå§‹æƒé‡é«˜æ•ˆï¼Œåœ¨æ‹‰èµ·æ¨¡å‹è®­ç»ƒè¿‡ç¨‹è¿‡ä¸­tflopsæœ‰æ˜æ˜¾æå‡ã€‚\n\n","tags":["V100","æ¨¡å‹è®­ç»ƒè°ƒä¼˜","Nvidia","Qwen","Deepspeed"],"categories":["æ¨¡å‹è®­ç»ƒè°ƒä¼˜","NVIDIA"]},{"title":"Git1_gitå‘½ä»¤","url":"/2025/11/04/Git/Git1_git å‘½ä»¤/","content":"**<font style=\"background-color:#FBDE28;\">git commmit -vå’Œgit push origin developä¹‹åï¼Œæˆ‘æ€ä¹ˆæ’¤é”€æœ¬æ¬¡commitæäº¤çš„ä»£ç ï¼Œå°†origin developçš„ä»“åº“è¿”å›å€¼æäº¤ä¹‹å‰çš„çŠ¶æ€ï¼Ÿ</font>**\n\nåœ¨Gitä¸­ï¼Œå¦‚æœä½ æƒ³è¦æ’¤é”€æœ€è¿‘çš„ä¸€æ¬¡æäº¤å¹¶å°†ä»“åº“çŠ¶æ€å›é€€åˆ°æäº¤ä¹‹å‰ï¼Œä½ å¯ä»¥ä½¿ç”¨`git reset`å‘½ä»¤ã€‚è¿™é‡Œæœ‰å‡ ç§æ–¹æ³•å¯ä»¥æ’¤é”€æäº¤ï¼š\n\n1. **ä½¿ç”¨**`git reset --soft`ï¼š\n    - è¿™ä¸ªå‘½ä»¤ä¼šå°†HEADæŒ‡é’ˆç§»åŠ¨åˆ°æŒ‡å®šçš„æäº¤ï¼Œä½†æ˜¯ä¸ä¼šæ”¹å˜å·¥ä½œç›®å½•å’Œç´¢å¼•çš„çŠ¶æ€ã€‚è¿™æ„å‘³ç€ä½ çš„æ›´æ”¹ä»ç„¶åœ¨æš‚å­˜åŒºï¼ˆstagedï¼‰ï¼Œä½ å¯ä»¥é‡æ–°æäº¤ã€‚\n    - å‘½ä»¤ï¼š`git reset --soft HEAD~1`ï¼ˆå°†HEADæŒ‡é’ˆå›é€€åˆ°ä¸Šä¸€ä¸ªæäº¤ï¼‰\n2. **ä½¿ç”¨**`git reset --mixed`ï¼ˆé»˜è®¤é€‰é¡¹ï¼‰ï¼š\n    - è¿™ä¸ªå‘½ä»¤ä¼šå°†HEADæŒ‡é’ˆç§»åŠ¨åˆ°æŒ‡å®šçš„æäº¤ï¼Œå¹¶ä¸”å°†ç´¢å¼•ï¼ˆstaged changesï¼‰é‡ç½®åˆ°HEADçš„çŠ¶æ€ï¼Œä½†æ˜¯ä¸ä¼šæ”¹å˜å·¥ä½œç›®å½•ã€‚\n    - å‘½ä»¤ï¼š`git reset --mixed HEAD~1`ï¼ˆå°†HEADå’Œç´¢å¼•å›é€€åˆ°ä¸Šä¸€ä¸ªæäº¤ï¼Œä½†å·¥ä½œç›®å½•ä¸å˜ï¼‰\n3. **ä½¿ç”¨**`git reset --hard`ï¼š\n    - è¿™ä¸ªå‘½ä»¤ä¼šå°†HEADæŒ‡é’ˆã€ç´¢å¼•å’Œå·¥ä½œç›®å½•éƒ½é‡ç½®åˆ°æŒ‡å®šçš„æäº¤çŠ¶æ€ã€‚è¿™æ„å‘³ç€æ‰€æœ‰æœªæäº¤çš„æ›´æ”¹éƒ½ä¼šä¸¢å¤±ã€‚\n    - å‘½ä»¤ï¼š`git reset --hard HEAD~1`ï¼ˆå°†HEADã€ç´¢å¼•å’Œå·¥ä½œç›®å½•éƒ½å›é€€åˆ°ä¸Šä¸€ä¸ªæäº¤ï¼‰\n\nå¦‚æœä½ å·²ç»å°†ä»£ç æ¨é€åˆ°äº†è¿œç¨‹ä»“åº“ï¼ˆæ¯”å¦‚`origin develop`ï¼‰ï¼Œå¹¶ä¸”æƒ³è¦æ’¤é”€è¿™æ¬¡æ¨é€ï¼Œä½ å¯ä»¥ä½¿ç”¨`git push`å‘½ä»¤é…åˆ`--force`é€‰é¡¹æ¥å¼ºåˆ¶æ¨é€æœ¬åœ°çš„æ›´æ”¹åˆ°è¿œç¨‹ä»“åº“ã€‚ä½†æ˜¯è¯·æ³¨æ„ï¼Œè¿™ä¼šè¦†ç›–è¿œç¨‹ä»“åº“çš„å†å²ï¼Œæ‰€ä»¥åªæœ‰åœ¨ä½ ç¡®å®šè¿œç¨‹ä»“åº“æ²¡æœ‰å…¶ä»–äººçš„æäº¤æˆ–è€…ä½ ä¸ä»‹æ„ä¸¢å¤±è¿™äº›æäº¤æ—¶æ‰åº”è¯¥ä½¿ç”¨ã€‚\n\nå‘½ä»¤å¦‚ä¸‹ï¼š\n\n```bash\ngit push origin develop --force\n```\n\næˆ–è€…ï¼Œå¦‚æœä½ ä½¿ç”¨çš„æ˜¯Git 2.0æˆ–æ›´é«˜ç‰ˆæœ¬ï¼Œå¯ä»¥ä½¿ç”¨æ›´å®‰å…¨çš„`--force-with-lease`é€‰é¡¹ï¼Œå®ƒä¼šåœ¨è¿œç¨‹åˆ†æ”¯æ²¡æœ‰æ–°çš„æäº¤æ—¶æ‰å…è®¸å¼ºåˆ¶æ¨é€ã€‚\n\nå‘½ä»¤å¦‚ä¸‹ï¼š\n\n```bash\ngit push origin develop --force-with-lease\n```\n\n**è­¦å‘Š**ï¼šä½¿ç”¨`--force`é€‰é¡¹ä¼šè¦†ç›–è¿œç¨‹ä»“åº“çš„å†å²ï¼Œè¿™æ˜¯ä¸€ä¸ªç ´åæ€§çš„æ“ä½œã€‚åœ¨å›¢é˜Ÿåä½œçš„ç¯å¢ƒä¸­ï¼Œè¿™å¯èƒ½ä¼šå¯¼è‡´å…¶ä»–åä½œè€…çš„å·¥ä½œä¸¢å¤±ï¼Œæ‰€ä»¥è¯·è°¨æ…ä½¿ç”¨ã€‚\n\n","tags":["å¼€å‘","git"],"categories":["å¼€å‘","git"]},{"title":"Linux1_kimié—®é¢˜","url":"/2025/11/04/Linux/Linux1_kimié—®é¢˜/","content":"1. æƒé‡è½¬æ¢ä»£ç æ¢è¡Œç¬¦\nKimi: å‡ºç°è¿™äº›é”™è¯¯é€šå¸¸æ˜¯å› ä¸ºè„šæœ¬æ–‡ä»¶åœ¨ä¸åŒçš„æ“ä½œç³»ç»Ÿç¯å¢ƒä¸‹è¢«ç¼–è¾‘æˆ–åˆ›å»ºï¼Œå¯¼è‡´æ–‡ä»¶çš„æ¢è¡Œç¬¦ä¸ä¸€è‡´ã€‚Unix/Linuxç³»ç»Ÿä½¿ç”¨LFï¼ˆLine Feedï¼Œ`\\n`ï¼‰ä½œä¸ºæ¢è¡Œç¬¦ï¼Œè€ŒWindowsç³»ç»Ÿä½¿ç”¨CR+LFï¼ˆCarriage Return + Line Feedï¼Œ`\\r\\n`ï¼‰ä½œä¸ºæ¢è¡Œç¬¦ã€‚\né”™è¯¯ä¿¡æ¯ä¸­çš„ `$'\\r': command not found` è¡¨ç¤ºè„šæœ¬å°è¯•æ‰§è¡Œä¸€ä¸ªä»¥ `\\r` å¼€å¤´çš„å‘½ä»¤ï¼Œè¿™é€šå¸¸æ˜¯å› ä¸ºè„šæœ¬æ–‡ä»¶ä¸­çš„æ¢è¡Œç¬¦æ˜¯ `\\r\\n` è€Œä¸æ˜¯ `\\n`ã€‚\næ­¤å¤–ï¼Œ`syntax error near unexpected token 'elif'` é”™è¯¯è¡¨æ˜è„šæœ¬è§£æå™¨åœ¨é‡åˆ° `elif` æ—¶é‡åˆ°äº†è¯­æ³•é”™è¯¯ï¼Œè¿™å¯èƒ½æ˜¯å› ä¸º `elif` ä¹‹å‰çš„è¡Œï¼ˆå¯èƒ½æ˜¯ç¬¬59è¡Œï¼‰ä»¥ `\\r\\n` ç»“å°¾ï¼Œå¯¼è‡´ `elif` è¡Œå®é™…ä¸Šæ˜¯ä»ä¸€ä¸ªæ–°çš„è¡Œå¼€å§‹ï¼Œè€Œä¸æ˜¯åœ¨é¢„æœŸçš„ä½ç½®ã€‚\nè¦è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½ å¯ä»¥ä½¿ç”¨ `dos2unix` å·¥å…·å°†è„šæœ¬æ–‡ä»¶ä»Windowsæ ¼å¼è½¬æ¢ä¸ºUnix/Linuxæ ¼å¼ã€‚å¦‚æœä½ æ²¡æœ‰ `dos2unix` å·¥å…·ï¼Œå¯ä»¥ä½¿ç”¨ `sed` å‘½ä»¤æ¥ç§»é™¤ `\\r` å­—ç¬¦ï¼š\n```bash\nsed -i 's/\\r$//' hf2mcore_convertor.sh\n```\nè¿™æ¡å‘½ä»¤ä¼šæŸ¥æ‰¾æ–‡ä»¶ä¸­çš„æ‰€æœ‰è¡Œï¼Œå¹¶ç§»é™¤æ¯è¡Œæœ«å°¾çš„ `\\r` å­—ç¬¦ã€‚\nå¦‚æœä½ æœ‰ `dos2unix` å·¥å…·ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ï¼š\n```bash\ndos2unix hf2mcore_convertor.sh\n```\nè¿™å°†æŠŠæ–‡ä»¶ä»Windowsæ ¼å¼è½¬æ¢ä¸ºUnix/Linuxæ ¼å¼ã€‚\nåœ¨è¿è¡Œè¿™äº›å‘½ä»¤ä¹‹åï¼Œå†æ¬¡æ‰§è¡Œè„šæœ¬åº”è¯¥å°±ä¸ä¼šå‡ºç°è¿™äº›é”™è¯¯äº†ã€‚\n2. ä¿®æ”¹æ–‡ä»¶é‡åˆ°Read-only file system\nKimi: å½“ä½ é‡åˆ° \"Read-only file system\" é”™è¯¯æ—¶ï¼Œé€šå¸¸æ„å‘³ç€ä½ çš„æ–‡ä»¶ç³»ç»Ÿå‡ºäºæŸç§åŸå› è¢«æŒ‚è½½ä¸ºåªè¯»æ¨¡å¼ã€‚è¿™å¯èƒ½æ˜¯ç”±äºæ–‡ä»¶ç³»ç»ŸæŸåã€ç£ç›˜ç¡¬ä»¶é—®é¢˜ã€æˆ–è€…æŒ‚è½½æ—¶æŒ‡å®šäº†é”™è¯¯çš„å‚æ•°ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›è§£å†³æ­¥éª¤ï¼š\n1. **æ£€æŸ¥æ–‡ä»¶ç³»ç»ŸæŒ‚è½½çŠ¶æ€**ï¼š  \nä½¿ç”¨ `mount` å‘½ä»¤æŸ¥çœ‹æ‰€æœ‰æŒ‚è½½çš„æ–‡ä»¶ç³»ç»ŸåŠå…¶çŠ¶æ€ã€‚ä½ å¯ä»¥ä½¿ç”¨å¦‚ä¸‹å‘½ä»¤ï¼š\n```bash\nmount | grep /path/to/mount/point\n```\næŸ¥çœ‹æŒ‚è½½ç‚¹æ˜¯å¦ä¸ºåªè¯»ï¼ˆroï¼‰ã€‚\n2. **é‡æ–°æŒ‚è½½æ–‡ä»¶ç³»ç»Ÿä¸ºè¯»å†™æ¨¡å¼**ï¼š  \nå¦‚æœæ–‡ä»¶ç³»ç»Ÿè¢«æŒ‚è½½ä¸ºåªè¯»ï¼Œä½ å¯ä»¥å°è¯•é‡æ–°æŒ‚è½½å®ƒä¸ºè¯»å†™æ¨¡å¼ã€‚ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ï¼š\n```bash\nsudo mount -o remount,rw /path/to/mount/point\n```\nè¯·å°† `/path/to/mount/point` æ›¿æ¢ä¸ºå®é™…çš„æŒ‚è½½ç‚¹è·¯å¾„ã€‚\n3. **æ£€æŸ¥å’Œä¿®å¤æ–‡ä»¶ç³»ç»Ÿ**ï¼š  \nå¦‚æœé‡æ–°æŒ‚è½½ä¸èµ·ä½œç”¨ï¼Œå¯èƒ½æ˜¯æ–‡ä»¶ç³»ç»ŸæŸåã€‚ä½ å¯ä»¥ä½¿ç”¨ `fsck` å‘½ä»¤æ¥æ£€æŸ¥å’Œä¿®å¤æ–‡ä»¶ç³»ç»Ÿã€‚ä¾‹å¦‚ï¼Œå¯¹äº ext4 æ–‡ä»¶ç³»ç»Ÿï¼Œå¯ä»¥ä½¿ç”¨ï¼š\n```bash\nsudo fsck -f /dev/sda1\n```\nè¯·ç¡®ä¿æ›¿æ¢ `/dev/sda1` ä¸ºä½ çš„å®é™…åˆ†åŒºã€‚\n\n","tags":["è¿ç»´","Linux"],"categories":["Linux"]},{"title":"è¿ç»´1_dockerå‘½ä»¤","url":"/2025/11/04/æœåŠ¡å™¨è¿ç»´/è¿ç»´1_dockerå‘½ä»¤/","content":"1. å¯åŠ¨ä¸€ä¸ªå®¹å™¨\n```bash\nsudo docker run -it --name qwen --gpus all nvidia/cuda:12.2.2-cudnn8-devel-ubuntu22.04\n```\nå¯åŠ¨ä¸€ä¸ªå®¹å™¨åï¼Œåˆé€šè¿‡exitå…³é—­ã€‚å‘ç°docker psæ²¡æœ‰äº†ï¼Œè¯¥å¦‚ä½•é‡æ–°å¯åŠ¨è¿™ä¸ªqwenå®¹å™¨ï¼Ÿ\n```bash\ndocker ps -a\n\ndocker start qwen\n\ndocker exec -it å®¹å™¨id bash\n```\n\n2. æ‹‰å–ä¸€ä¸ªæ–°é•œåƒåï¼Œé€šè¿‡è¿™ä¸ªé•œåƒåˆ›å»ºä¸€ä¸ªå®¹å™¨ã€‚\n```bash\ndocker run -it --name qwen --gpus all é•œåƒå:é•œåƒtags bash\n```\n\n3. å°†æ­¤æ—¶qwenå®¹å™¨æ‰“æˆé•œåƒ\n```bash\ndocker commit -a \"wangxiangbo\" -m \"qwen 7B\" 02649afd9710 qwen-7b:v1.0\n```\n\n\n\n\n","tags":["è¿ç»´","docker"],"categories":["è¿ç»´","docker"]},{"title":"Linux2_Linuxå‘½ä»¤","url":"/2025/11/04/Linux/Linux2_linuxå‘½ä»¤/","content":"1. å½“æ‰§è¡Œè®­ç»ƒä»»åŠ¡æ—¶ï¼Œæ‰‹åŠ¨å…³é—­è®­ç»ƒï¼Œæ­¤æ—¶gupèµ„æºä»ç„¶å ç”¨ï¼Œéœ€è¦æ‰‹åŠ¨killæ‰è¿›ç¨‹\næŸ¥è¯¢æ­£åœ¨è¿è¡Œçš„è¿›ç¨‹å¹¶gerp finetune_lora_single_gpu.sh\n`ps aux | grep finetune_lora_single_gpu.sh`\n`ps aux | grep finetune_lora_ds.sh`\n`kill -9 372813` æ ¹æ®ä¸Šä¸€æ­¥æŸ¥å‡ºæ¥çš„è¿›ç¨‹å·ï¼Œç”¨kill -9å¼ºåˆ¶åˆ é™¤\n`nvidia-smi `æŸ¥çœ‹æ˜¯å¦gpuæ˜¾å­˜å·²ç»æ¸…ç©º\n2. æŸ¥çœ‹æŸä¸ªæ–‡ä»¶çš„å‰20è¡Œ\n`head -n 20 train_data_law.json`\n3. æŸ¥çœ‹å½“å‰æ–‡ä»¶å¤¹çš„å¤§å°\n`du -sh .`\n4. æŸ¥çœ‹å½“å‰æ–‡ä»¶å¤¹æŒ‚è½½çš„æ˜¯å“ªä¸€ä¸ªç›˜\n`df -h .`\nä»å¤§åˆ°å°æŸ¥çœ‹å½“å‰æ–‡ä»¶å¤¹çš„ä¸‹çš„æ–‡ä»¶å¤§å°\n`du -sh * | sort -rh`\n4. æŸ¥çœ‹å½“å‰æ–‡ä»¶ä¸‹æ‰€æœ‰æ–‡ä»¶çš„å¤§å°\n`ls -lh`\n5. <font style=\"color:#000000;\">æŠŠä¸€ä¸ªåä¸ºYuan2çš„æ–‡ä»¶å¤¹çš„æ‰€æœ‰å†…å®¹ï¼ˆåŒ…æ‹¬è¯¥æ–‡ä»¶å¤¹åï¼‰ï¼Œcpåˆ°/mnt/users/wangxiangbo/nemo/modelç›®å½•ä¸‹ï¼Œä½¿æœ€åçš„ç›®å½•ä¸º /mnt/users/wangxiangbo/nemo/model/Yuan2</font>\n`cp -a Yuan2 /mnt/users/wangxiangbo/nemo/model/`\n6. é€šè¿‡pidæŸ¥çœ‹æŸä¸ªè¿›ç¨‹çš„è¯¦ç»†ä¿¡æ¯\n`<font style=\"color:rgb(56, 58, 66);background-color:rgb(250, 250, 250);\">ps -fp 167891</font>`\n7. æŸ¥çœ‹å½“å‰ç›®å½•ä¸‹æ‰€æœ‰æ–‡ä»¶çš„ç£ç›˜å ç”¨æƒ…å†µ\n`du -ah | sort -hr | head -n 20`\n8.  ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å°†`megatron-core`æ–‡ä»¶å¤¹å‹ç¼©æˆä¸€ä¸ªåä¸º`megatron-core.zip`çš„zipæ–‡ä»¶\n \t` zip -r megatron-core.zip megatron-core  `\n9.  ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å°†`megatron-core.zip`è§£å‹ç¼©  \n` unzip megatron-core.zip  `\n11. hgä¸Šé¢ä¸‹è½½æ¨¡å‹\n```bash\npip install -U huggingface_hub\nhuggingface-cli download bigscience/bloom-560m --local-dir bloom-560m\nhuggingface-cli download Qwen/Qwen2-7B-Instruct --local-dir Qwen2-7B-Instruct\nhuggingface-cli download Qwen/Qwen2.5-7B-Instruct --local-dir Qwen2.5-7B-Instruct\nhuggingface-cli download BAAI/IndustryCorpus_computer --repo-type dataset --local-dir IndustryCorpus_computer\nhuggingface-cli download BAAI/IndustryCorpus2_current_affairs_government_administration --repo-type dataset --local-dir government_administration\nhuggingface-cli download ShengbinYue/DISC-Law-SFT --repo-type dataset --local-dir DISC-Law-SFT\nhuggingface-cli download TigerResearch/sft_zh\n```\n12. å½’æ¡£å‹ç¼©æ–‡ä»¶\n```bash\n#-cï¼šåˆ›å»ºä¸€ä¸ªæ–°çš„å‹ç¼©æ–‡ä»¶ã€‚\n#-zï¼šé€šè¿‡ gzip å‹ç¼©æ–‡ä»¶ã€‚\n#-vï¼šæ˜¾ç¤ºè¯¦ç»†çš„å‹ç¼©è¿‡ç¨‹ã€‚\n#-fï¼šæŒ‡å®šå‹ç¼©åçš„æ–‡ä»¶åï¼Œè¿™é‡Œæ˜¯ colossalai.tar.gz\ntar -czvf colossalai.tar.gz colossalai/  \n\n#-xï¼šè¡¨ç¤ºè§£å‹ã€‚\n#-zï¼šè¡¨ç¤ºè§£å‹ .gz æ ¼å¼çš„æ–‡ä»¶ã€‚\n#-vï¼šæ˜¾ç¤ºè§£å‹è¿‡ç¨‹ã€‚\n#-fï¼šæŒ‡å®šè§£å‹çš„æ–‡ä»¶\ntar -xzvf file.tar.gz\n```\n\n\n\n","tags":["è¿ç»´","Linux"],"categories":["Linux"]},{"title":"Git3_gitlabä»“åº“ä»£ç æäº¤æµç¨‹","url":"/2025/11/04/Git/Git3_gitlabä»“åº“ä»£ç æäº¤æµç¨‹/","content":"1. gitlabä¸Šforkä¸»ä»“åº“ï¼Œç”Ÿæˆä¸ªäººçš„è¿œç«¯ä»“åº“origin/develop\n2. ä¿®æ”¹gitæäº¤ç”¨æˆ·é…ç½®ä¸ºä¹å¤©è´¦å·\n```bash\ngit config --global --list\ngit config --global user.name wangxiangbo_JTAGI\ngit config --global user.email wangxiangbo_JTAGI@cmss.chinamobile.com\n```\n3. æ‹‰å–ä¸ªäººçš„è¿œç«¯ä»“åº“\n```bash\ngit clone http://gitlab.cmss.com/wangxiangbo/CM_OPTIMUS.git \n```\n4. æŸ¥çœ‹åˆ†æ”¯\n```bash\ngit branch -a\n```\n5. æŸ¥çœ‹è¿œç¨‹ä»“åº“åˆ†æ”¯\n```bash\ngit branch -r\n```\n6. é€šè¿‡ä¸ªäººçš„è¿œç«¯origin/developä»“åº“ï¼Œåˆ›å»ºä¸€ä¸ªæœ¬åœ°developå¼€å‘åˆ†æ”¯\n```bash\ngit checkout -b develop origin/develop\n```\n7. <font style=\"color:rgba(0, 0, 0, 0.85);\">åˆ—å‡ºæ‰€æœ‰çš„è¿œç¨‹ä»“åº“ä»¥åŠå¯¹åº”çš„ URL</font>\n```bash\ngit remote -v\n```\n8. <font style=\"color:rgba(0, 0, 0, 0.85);\">å°†è¿œç¨‹ä»“åº“åœ°å€æ·»åŠ åˆ°æœ¬åœ°Gitä»“åº“çš„è¿œç¨‹ä»“åº“åˆ—è¡¨ä¸­ï¼Œæœ¬åœ°çš„upstream/developä»“åº“ä¼šå’Œgitlabè¿œç¨‹ä»“åº“å…³è”èµ·æ¥</font>\n```bash\ngit remote add upstream http://gitlab.cmss.com/AGI/CM_OPTIMUS.git\n```\n8. upstream/developè¿œç«¯ä»“åº“æ‹‰å–æœ€æ–°çš„ä»£ç \n```bash\ngit fetch upstream\n```\n9. å°†upstream/developè¿œç«¯ä»“åº“çš„æœ€æ–°ä»£ç åˆå¹¶åˆ°æœ¬åœ°çš„developåˆ†æ”¯ä¸­\n```bash\ngit merge upstream/develop\n```\n10. å°†æœ¬åœ°developæœ€æ–°çš„ä»£ç æ¨åˆ°ä¸ªäººçš„è¿œç«¯ä»“åº“origin/developä¸­\n```bash\ngit push origin develop\n```\n11. <font style=\"background-color:#FBDE28;\">æäº¤developåˆ°origin/developä»£ç ä¹‹å‰ï¼Œä¿è¯è‡ªå·±çš„æœ¬åœ°ä¸ªäººçš„è¿œç«¯ä»“åº“origin/developå’Œæœ¬åœ°gitlabçš„è¿œç«¯ä»“åº“upstream/developä¿æŒä¸€è‡´å†æäº¤</font>ï¼Œé˜²æ­¢åç»­origin/developåˆå¹¶æ‰“upstream/developä¸Šå‡ºç°å†²çªã€‚\n```bash\n#æœ¬åœ°ä»£ç ä¿®æ”¹åæ‹‰å–æœ€æ–°ä»£ç \n#1.æ‹‰å–æºä»£ç \ngit fetch upstream \n#2.æš‚å­˜æœ¬åœ°ä¿®æ”¹çš„ä»£ç \ngit stash\n#3.åˆå¹¶æºä»£ç åˆ°å½“å‰çš„developä»“åº“\ngit merge upstream/develop\n#4.å°†æœ¬åœ°ä¿®æ”¹çš„æ¨é€åˆ°è¿œç¨‹çš„originåˆ†æ”¯ï¼Œä½¿origin/developå’Œupstream/developä¿æŒä¸€è‡´\ngit push origin develop\n#5.å°†æš‚å­˜çš„ä»£ç å¼¹å‡ºæ¥\ngit stash pop\n```\n12. souretreeä¸Šaddéœ€è¦æäº¤çš„ä»£ç \n13. æäº¤addä¹‹åçš„ä»£ç \n```bash\ngit commit -v\n```\n```bash\n#ä¿®æ”¹ä¸‹æ–¹çš„æäº¤ä¿¡æ¯ï¼Œç¬¬ä¸€è¡Œä¸ºæäº¤æè¿°ä¿¡æ¯\ndeepseek-7Bé¢„è®­ç»ƒ\n\nCode Source From: Self Code\nDescription: deepseek-7Bé¢„è®­ç»ƒ\nJira: #CMOPTIMUS-1089\nå¸‚åœºé¡¹ç›®ç¼–å·ï¼ˆåç§°ï¼‰ï¼šCM_OPTIMUS\n```\n14. <font style=\"color:rgb(55, 53, 47);\">å°†æäº¤å®Œä¹‹åçš„ä»£ç åˆå¹¶åˆ°origin/developä¸Š</font>\n```bash\ngit push origin develop\n```\n15. <font style=\"color:rgb(55, 53, 47);\">gitlabä¸­æ‰¾çš„åˆ°è‡ªå·±ä»“åº“ä¸‹CM_OPTIMUS</font>\n16. <font style=\"color:rgb(55, 53, 47);\">æ‰¾åˆ°Merge requestsï¼Œç„¶åç‚¹å‡»å¼€å§‹ä¸€ä¸ªåˆå¹¶</font>\n17. <font style=\"color:rgb(55, 53, 47);\">ç„¶åé€‰æ‹©è‡ªå·±çš„åˆ†æ”¯ä¸ºdevelopï¼Œè¿˜æœ‰æ—è¾¹çš„åˆ†æ”¯developï¼Œç„¶åç‚¹å‡»æœ€ä¸‹æ–¹çš„mergeå³å¯ã€‚è¯¥æ“ä½œæ˜¯å°†è‡ªå·±ä¸ªäººè¿œç«¯çš„orgin/developä»“åº“æäº¤ä¿®æ”¹åçš„ä»£ç åˆå¹¶åˆ°gitlabè¿œç«¯çš„ä¸»ä»“åº“ä¸­ï¼ˆupstream/developå·²å’Œå…¶å…³è”ï¼Œå¹¶é€šè¿‡git fetchä¿æŒæœ€æ–°ï¼‰</font>\né€‰ä¸­è‡ªå·±åˆšåˆšæäº¤åˆ°origin/developä¸Šçš„ä»£ç ï¼Œåˆå¹¶åˆ°AGI/CM_OPTIMUSçš„developåˆ†æ”¯ä¸Š\nåœ¨Writeé‡Œæ·»åŠ åˆå¹¶äººä¿¡æ¯\n\n\n\n","tags":["å¼€å‘","gitlab"],"categories":["å¼€å‘","git"]},{"title":"è¿ç»´2_k8så‘½ä»¤","url":"/2025/11/04/æœåŠ¡å™¨è¿ç»´/è¿ç»´2_k8så‘½ä»¤/","content":"1. è·å–ç‰¹å®šå‘½åç©ºé—´çš„è¯¦ç»†ä¿¡æ¯\n```bash\nkubectl get ns namespace-name -o wide\n```\n2. kubectlé€šè¿‡nsè·å–æ‰€æœ‰çš„podsçš„è¯¦ç»†ä¿¡æ¯\n```bash\nkubectl get pods -n <ns_name> -o wide\n```\n3. åˆ é™¤å¯åŠ¨å¤±è´¥çš„podï¼Œå¯ä»¥ç›´æ¥åˆ é™¤å¯åŠ¨æ—¶çš„yamlï¼Œå¦åˆ™podä¼šè‡ªåŠ¨é‡å¯\n```bash\nkubectl delete -f qwentest.yaml\n```\n4. æŸ¥çœ‹æ‰€æœ‰çš„nodeçš„lableæ ‡ç­¾ä¿¡æ¯\n```bash\nkubectl get node --show-labels\n\nkubectl get node xxx --show-labels\n\nkubectl get node --show-labels | grep model\n```\n5. æ‰“æ ‡ç­¾\n```bash\nkubectl label nodes ecs-jhjs-1234-003 key=vaule\n```\n6. åˆ é™¤æŸèŠ‚ç‚¹çš„lableæ ‡ç­¾\n```bash\nkubectl label nodes cce100-64-29-79.cce-stack.com model-\n```\n6. åˆ›å»ºä¸€ä¸ªå‘½åç©ºé—´namespace\n```bash\nkubectl create namespace xxx\n```\n7. æŸ¥çœ‹æ‰€æœ‰èŠ‚ç‚¹çš„æ ‡ç­¾\n```bash\nkubectl get nodes --show-labels\nkubectl get nodes --show-labels | grep model=llama2-70b\n```\n","tags":["è¿ç»´","k8s"],"categories":["è¿ç»´","k8s"]},{"title":"Git2_gerritä»“åº“ä»£ç æäº¤æµç¨‹","url":"/2025/11/04/Git/Git2_gerritä»“åº“ä»£ç æäº¤æµç¨‹/","content":"1. ç”Ÿæˆä¸ªäººå¯†é’¥\n```bash\nssh-keygen -C wangxiangbo_JTAGI@cmss.chinamobile.com\n```\n2. ä¿®æ”¹configæ–‡ä»¶ï¼Œå¢åŠ gerritä»“åº“é…ç½®ï¼Œå¢åŠ åˆšç”Ÿæˆçš„ä¸ªäººå¯†é’¥`id_ed25519`\n```bash\nhost gerrit\nport 29418\nhostname gerrit.cmss.com\nuser wangxiangbo_JTAGI\nIdentityFile ~/.ssh/id_ed25519\n```\n3. åœ¨gerritä¸­settingè®¾ç½®ä¸­ï¼Œå¢åŠ sshçš„å…¬é’¥ï¼Œå³`id_ed25519.pub`\n4. è®¾ç½®é‚®ç®±ï¼Œé‚®ç®±å`wangxiangbo@cmss.chinamobile.com`ä¸ºä¸å¸¦JTAGIåç¼€çš„é‚®ç®±ã€‚\n5. ç”¨ssh cloneä»£ç ä»“åº“\n```bash\ngit clone \"ssh://wangxiangbo_JTAGI@gerrit.cmss.com:29418/AGI/CM_OPTIMUS\" && scp -p -P 29418 wangxiangbo_JTAGI@gerrit.cmss.com:hooks/commit-msg \"CM_OPTIMUS/.git/hooks/\"\n```\n6. æŸ¥çœ‹åˆ†æ”¯\n```bash\ngit branch -a\n```\n7. æŸ¥çœ‹è¿œç«¯åˆ†æ”¯\n```bash\ngit branch -r\n```\n8. é€šè¿‡è¿œç«¯origin/developä»“åº“ï¼Œåˆ›å»ºä¸€ä¸ªæœ¬åœ°developå¼€å‘åˆ†æ”¯\n```bash\ngit checkout -b develop origin/develop\n```\n9. ä¿®æ”¹ä»£ç åï¼Œaddä¹‹åå¹¶commitæäº¤\n```bash\ngit commit -v\n```\n10. æ¨é€è¿œç«¯origin/developä»“åº“\n```bash\ngit push origin HEAD:refs/for/develop\n```\n11. åœ¨æ¨é€è¿‡ç¨‹ä¸­ä¼šå‡ºç°ç¼ºå¤± `Change-Id `çš„é”™è¯¯\n```bash\ngitdir=$(git rev-parse --git-dir); scp -p -P 29418 wangxiangbo_JTAGI@gerrit.cmss.com:hooks/commit-msg ${gitdir}/hooks/\n```\næ‰§è¡Œå®Œæ¯•åå¦‚æœå‡ºç°subsystem request failed on channel 0ï¼Œåˆ™å°†-pä¿®æ”¹ä¸º-O\n```bash\ngitdir=$(git rev-parse --git-dir); scp -O -P 29418 wangxiangbo_JTAGI@gerrit.cmss.com:hooks/commit-msg ${gitdir}/hooks/\n```\nå°†æœ¬æ¬¡commitæäº¤çš„æœ«å°¾åŠ ä¸ŠChange-Id \n```bash\ngit commit --amend --no-edit\n```\nå†æ¬¡push\n```bash\ngit push origin HEAD:refs/for/develop\n```\n12. æäº¤å®Œæˆä¹‹åï¼Œæ‰“å¼€gerritï¼Œæ‰¾åˆ°developåˆ†æ”¯çš„gitweb\n13. é€‰æ‹©review\n14. æ‰¾åˆ°åˆšåˆšæäº¤çš„ä»£ç \n15. ç‚¹å‡»add reviewerï¼Œè¯„å®¡äººè¦æœ€å°‘è¦ä¸¤ä¸ªä»¥ä¸Š\n16. ç¬¬ä¸€æ¬¡ä¹‹åæäº¤ä»£ç æ­¥éª¤\n```bash\ngit pull origin\ngit add xxx\ngit commit -v \ngit push origin HEAD:refs/for/develop\n```\n\n","tags":["å¼€å‘","gerrit"],"categories":["å¼€å‘","git"]},{"title":"æµ‹è¯• Hexo æ ‡ç­¾åˆ†ç±»2","url":"/2025/10/31/é¡µé¢æµ‹è¯•/test copy/","content":"è¿™æ˜¯æ–‡ç« æ­£æ–‡ã€‚","tags":["æµ‹è¯•2","hexo"],"categories":["æµ‹è¯•"]}]